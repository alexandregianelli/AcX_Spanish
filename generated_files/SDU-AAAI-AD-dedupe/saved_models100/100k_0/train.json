[{"tokens": ["Furthermore", ",", "in", "a", "study", "setup", "similar", "to", "ours", ",", "developed", "a", "personalized", "SAR", "system", "for", "month", "-", "long", "interventions", "with", "children", "with", "ASD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Several", "commonly", "available", "datasets", "mentioned", "above", "are", "chosen", "as", "our", "testing", "datasets(https://github.com", "/", "mdcnn", "/", "Deep", "-", "Multiple", "-", "Description", "-", "Coding", ")", "for", "the", "comparison", "of", "different", "MDC", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["Then", ",", "the", "probability", "that", "the", "channel", "is", "idle", "is", ":", "The", "probability", "that", "the", "channel", "sees", "a", "successful", "transmission", "slot", ",", ",", "is", "given", "by", ":", "which", "accounts", "for", "that", "a", "single", "node", "(", "either", "the", "AP", "or", "a", "STA", ")", "successfully", "wins", "the", "-st", "round", "channel", "contention", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["If", "this", "polynomial", "is", ",", "then", "the", "corresponding", "MVF", "consists", "of", "the", "vectors", "and", "vectors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching vector families"}, {"tokens": ["is", "the", "distance", "between", "the", "node", "and", "BS", "at", "frame", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "base station"}, {"tokens": ["*", "cccccccccc", "RAID5", "&", "BM", "&", "CD", "&", "GRD", "&", "ID", "&", "RAID6", "&", "LSI", "&", "RAID7", "&", "SSP", "&", "R8", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "MTTDLs", "as", "a", "ratio", "and", "a", "fraction", "of", "the", "MTTF", "(", ")", "and", "the", "first", "term", "in", "asymptotic", "reliability", "expression", "with", "denoting", "the", "unreliability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group rotate declustering"}, {"tokens": ["our", "CSG", "c", "-", "measure", "and", "CNN", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["The", "OT", "and", "BS", "methods", "were", "capable", "of", "plausible", "synthesis", "with", "high", "innovation", "capacity", ",", "corroborated", "by", "a", "visual", "inspection", "revealing", "few", "or", "no", "egregious", "copies", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["As", "expected", ",", "the", "overall", "BA", "score", "drastically", "drops", "to", "a", "random", "chance", "(", "see", "Figure", ")", "with", "worse", "performance", "on", "positive", "samples", "in", "comparison", "with", "the", "negative", "ones", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "balanced accuracy"}, {"tokens": ["SCM", "solves", "the", "training", "time", "complexity", "of", "supervised", "multimodal", "hashing", "methods", "by", "avoiding", "explicit", "pairwise", "similarity", "matrix", "computing", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic correlation maximization"}, {"tokens": ["Consequently", ",", "for", "a", "given", ",", "optimum", "P1.2", "becomes-1.3emThe", "optimization", "problem", "optimum", "P1.4", "successively", "approximates", "optimum", "P1.2", "as", "an", "SDR", ",", "for", "a", "given", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "semidefine relaxation"}, {"tokens": ["Single", "Task", "Learning", "(", "STL", ")", "vs.", "Multi", "-", "Task", "Learning", "with", "different", "auxiliary", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "single task learning"}, {"tokens": ["The", "total", "number", "of", "documents", "is", "1,673,824", "in", "LSC", "(", "see", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["To", "use", "the", "pretrained", "PNN", "/", "RNN", "as", "feature", "extractors", ",", "we", "remove", "the", "final", "softmax", "layers", "from", "both", "the", "PNN", "/", "RNN", ",", "and", "freeze", "the", "parameters", "so", "that", "they", "are", "not", "further", "updated(However", ",", "we", "found", "that", "retraining", "only", "the", "batch", "normalization", "layers", "for", "the", "PNN", "slightly", "increases", "the", "model", "performance", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["We", "argue", "that", "this", "research", "is", "the", "first", "step", "towards", "a", "generalize", "BC", "solution", "for", "the", "emerging", "IoT", "area", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["It", "uses", "a", "see", "-", "through", "head", "-", "worn", "display", "with", "integral", "orientation", "tracker", ";", "a", "backpack", "holding", "a", "computer", ",", "differential", "GPS", ",", "and", "digital", "radio", "for", "wireless", "web", "access", ";", "and", "a", "hand", "-", "held", "computer", "with", "stylus", "and", "touchpad", "interface(MARS", ":", "http://graphics.cs.columbia.edu/projects/mars/mars.html", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Two", "factors", "that", "could", "impact", "strongly", "the", "performances", "of", "FER", "methods", "on", "CK+", "database", ",", "are", "not", "standard", "in", "the", "existing", "FER", "methods", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["Our", "strategy", "allows", "the", "receiver", "to", "recover", "the", "th", "bit", "of", "at", "the", "cost", "of", "two", "calls", "to", "the", "random", "oracle", "under", "the", "assumption", "that", "has", "apriori", "knowledge", "of", "its", "chosen", "input", "for", "the", "th", "extended", "OT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "oblivious transfer"}, {"tokens": ["Participant", "SAR", "Evaluation", "SAR", "survey", "results", ",", "utilizing", "a", "seven", "-", "point", "Likert", "scale", ",", "assessed", "the", "average", "adaptability", "and", "usefulness", "of", "the", "system", "throughout", "the", "study", "."], "acronym_pos": [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["To", "satisfy", "the", "channel", "bandwidth", "ratio", ",", "a", "ratio", "configurable", "MD", "correlating", "transform", "coding", "is", "introduced", "to", "adjust", "the", "description", "data", "size", "ratio", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["Nonetheless", ",", "a", "natural", "question", "is", "whether", "the", "improvements", "in", "performance", "provided", "by", "the", "GCNN", "came", "solely", "from", "increased", "dataset", "size", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["Average", "SSIM", ",", "VQM", ",", "and", "network", "footprint", "center", "tabularlccccc", "&", "1lSHIELD", "&", "1lCORVETTE", "&", "1lVaUEP", "&", "1lVaEEP", "&", "1lWithout", "FEC"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "forward error correction"}, {"tokens": ["Since", "TS", "-", "RF", "has", "reduced", "the", "number", "of", "features", "due", "to", "which", "the", "time", "complexity", "is", "also", "reduced", "significantly", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["When", "comparing", "the", "performance", "for", "different", "grid", "sizes", ",", "meta", "-", "optimization", "appears", "to", "be", "an", "increasingly", "important", "component", "in", "identifying", "reduced", "formulations", "of", "OPF", "problems", "for", "larger", "grids", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["As", "in", ",", "we", "assume", "that", "there", "is", "no", "user", "closer", "than", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["However", ",", "since", "the", "likelihood", "of", "the", "GP", "variables", "is", "not", "conjugate", "to", "the", "prior", ",", "the", "method", "has", "to", "resort", "to", "a", "time", "-", "consuming", "Metropolis", "-", "Hastings", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "derivation", "of", "the", "DE", "of", "each", "term", "of", "eq", ":", "theorem2.I.mu15", "follows", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deterministic equivalent"}, {"tokens": ["Let", "be", "the", "total", "power", "available", "at", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["The", "value", "of", ",", "for", "the", "SP", "through", "red", ",", "blue", "and", "green", "color", "solid", "lines", ",", "is", "and", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "shortest path"}, {"tokens": ["For", "example", ",", "MD", "quantizers", "often", "must", "assign", "the", "optimal", "index", "for", "multiple", "description", "generations", ",", "especially", "when", "quantizing", "more", "than", "two", "descriptions", ",", "which", "is", "an", "extremely", "complicated", "problem", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["For", "the", "PA", "task", ",", "we", "also", "match", "real", "samples", "to", "their", "spoofed", "versions", "based", "on", "the", "speaker", "identity", "and", "utterance", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["Finally", ",", "as", "for", "the", "OPF", "-", "SR", "dominance", "comparisons", "of", "Step", "10", "of", "Alg", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal pareto front"}, {"tokens": ["In", "the", "following", ",", "we", "describe", "the", "SFM", "in", "its", "original", "form", "without", "its", "extensions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "social force model"}, {"tokens": ["[", "BSP", "-", "ratio]samp", "/", "ratio.osm.bsp.epsfig", ":"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["Indeed", ",", "ICA", "fails", "because", "the", "marginal", "distribution", "of", "each", "AR(1", ")", "process", "is", "Gaussian", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["The", "main", "contributions", "of", "this", "paper", "are", "as", "followings", ":", "We", "analyzed", "widely", "used", "deep", "representations", "in", "the", "DCNN", "-", "DCF", "based", "object", "trackers", ",", "and", "devised", "a", "feature", "quality", "measurement", "function", "to", "estimate", "the", "feature", "quality", "in", "a", "numerical", "way", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["The", "player", "should", "raise", "the", "hand", "above", "the", "shoulder", "'s", "height", "to", "reach", "the", "button", "which", "requires", "higher", "ROM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "range of motion"}, {"tokens": ["3", "shows", "the", "CDF", "curves", "of", "SR", "for", "four", "TAS", "methods", "with", "three", "different", "values", "of", "SNRs", ":", "-5dB", ",", "0dB", ",", "and", "5dB.", "It", "is", "seen", "from", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["ICC", "CI", "width", "distributions", "are", "shown", "for", "all", "features", "(", "a", ")", "and", "for", "features", "acquired", "using", "a", "uniform", "spacing", "of", "1", "mm", "(", "b", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["SL", "and", "SP", "classes", "form", "infinite", "hierarchies", "of", "language", "classes", "based", "on", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["In", "fact", ",", "with", "50", "profile", "weight", "coefficients", "(", "WeSNet", "-", "HF-50", ")", ",", "WeSNet", "outperforms", "DetNet", ",", "producing", "the", "accuracy", "of", "symbol", "detection", "equivalent", "to", "SDR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "semidefine relaxation"}, {"tokens": ["Then", "we", "use", "GMM", "Classifiers", "to", "distinguish", "anomalies", "from", "normal", "activities", "in", "videos", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "final", "version", "of", "the", "pipeline", "uses", "11", "views", ",", "which", "provides", "the", "best", "OS", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "orientation score"}, {"tokens": ["LS", "Channel", "Estimator"], "acronym_pos": [1, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["HIT", "Lab", "NZ", "and", "Saatchi", "deliver", "the", "world", "'s", "first", "mobile", "phone", "based", "AR", "advertising", "application", "for", "the", "Wellington", "Zoo", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["partial", "shows", "the", "result", "of", "models", "trained", "on", "data", "processed", "with", "these", "ISP", "configurations", ",", "along", "with", "baselines", "(", "models", "trained", "on", "raw", "images", "and", "full", "RGB", "images", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Preconditioned", "RQI", "was", "better", "whether", "PI", "waspreconditioned", "or", "not", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["Simulations", "for", "systematic", "Exact", "-", "MBR", "codesThe", "simulations", "of", "systematic", "Exact", "-", "MBR", "codes", "with", "native", "approach", "and", "fast", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Finally", ",", "the", "following", "Simultaneous", "Stationarity", "Condition", "is", "a", "generic", "necessary", "condition", "for", "local", "equilibrium", "if", "the", "RUM", "choice", "probabilities", "are", "continuously", "differentiable", "in", "prices", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random utility maximization"}, {"tokens": ["Even", "if", "HEFT", "remains", "a", "good", "candidate", "for", "scheduling", "such", "linear", "algebra", "kernels", ",", "DADA", "is", "highly", "competitive", "against", "itfor", "multi", "-", "GPU", "systems", ":", "the", "experimental", "results", "demonstrate", "that", "it", "achieves", "the", "same", "range", "of", "performances", "while", "reducing", "significantly", "the", "communication", "volume", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["It", "has", "been", "shown", "that", "classical", "sigma", "-", "point", "rules", "can", "be", "cast", "as", "degenerate", "BQ", "rules", "(", "see", "for", "spline", "methods", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian quadrature"}, {"tokens": ["Further", ",", "the", "PDP", "is", "responsible", "for", "evaluating", "the", "requests", "against", "an", "Access", "Policies", "repository", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "policy decision point"}, {"tokens": ["Since", "the", "datasets", "are", "just", "different", "samples", "from", "the", "same", "manifold", ",", "only", "MGM", "GAN", "correctly", "aligns", "them", "with", "the", "identity", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["in", "is", "implemented", "and", "used", "as", "a", "reference", "(", "named", "as", "AP", "/", "STA", "-", "LI", "in", "the", "legend", ")", "to", "compare", "with", "Uni", "-", "MUMAC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Cropping", ":", "Using", "location", "information", "obtained", "from", "the", "binary", "segmented", "LOM", ",", "each", "constituent", "(", "object", ")", "in", "the", "masked", "SEM", "image", "is", "cropped", "and", "separated", "from", "the", "main", "image", "as", "shown", "in", "the", "part", "of", "\"", "cropped", "object", "\"", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["CF", "was", "calculated", "using", "all", "the", "three", "methods", "mentioned", "in", "that", "paper", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "complexity factor"}, {"tokens": ["The", "exact", "AUC", "and", "AP", "scores", "for", "each", "dataset", "are", "given", "in", "the", "Appendix", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Such", "a", "function", "solves", "SP", "in", ".For", "brevity", ",", "we", "set", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "splitting problem"}, {"tokens": ["As", "the", "meta", "-", "loss", "is", "a", "non", "-", "differentiable", "function", "of", "the", "classifier", "weights", ",", "we", "optimize", "it", "using", "the", "gradient", "-", "free", "PSO", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Geodesic", "Vascular", "Graph", "and", "GM", "problem", "of", "non", "-", "linearly", "deformed", "topologies", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph matching"}, {"tokens": ["Environmental", "conditions", "impact", "the", "quality", "of", "SAR", "interactions", "and", "the", "resulting", "assistive", "outcomes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["is", "SP", "if", "there", "is", "a", "such", "that", "it", "belong", "to", "SP", ";", "equivalently", ",", "belongs", "to", "SP", "iff", "is", "closed", "under", "subsequence", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["In", "the", "case", "of", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", ",", "CCU", "capacity", "is", "degraded", "than", "the", "proposed", "scheme", "due", "to", "using", "a", "dedicated", "time", "slot", "for", "each", "separate", "transmission", "from", "BS", "to", "CCU", ",", "excluding", "OAM", "based", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["is", "a", "time", "that", "PS", "takes", "to", "update", "the", "model", "with", "new", "results", "from", "workers", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["Accordingly", ",", "each", "SU", "submits", "its", "bid", "including", "(", "i", ")", "the", "FJ", "power", ",", "(", "ii", ")", "a", "time", "fraction", ",", "i.e.", ",", "the", "time", "for", "the", "SU", "to", "transmit", "the", "PU", "'s", "data", "to", "the", "PD", ",", "and", "(", "iii", ")", "the", "channel", "information", "related", "to", "the", "SU", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["While", "we", "get", "the", "best", "recommendation", "accuracy", "results", "for", "the", "unpersonalized", "MP", "algorithm", "in", "UC1", ",", "the", "personalized", "CF", "approach", "provides", "the", "best", "results", "for", "the", "more", "complex", "UC2", ",", "UC3", "and", "UC4", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["That", "is", ",", "if", "we", "can", "find", "and", "for", "all", "IB", "curves", "and", "all", "values", "of", ",", "then", "The", "region", "for", "all", "possible", "IB", "curves", "regardless", "of", "the", "relationship", "between", "and", "is", "depicted", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["To", "compare", "the", "impact", "of", "different", "integrating", "schemes", "on", "the", "accuracy", "of", "HMC", "and", "MD", "simulations", ",", "we", "calculated", "averages", "for", "two", "thermodynamic", "observables", ":", "the", "temperature", "and", "the", "distance", "traveled", "by", "the", "toxin", "from", "the", "center", "of", "the", "membrane", "to", "the", "preferable", "location", "at", "the", "surface", "of", "the", "membrane", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["Swedish", "Blog", "Sentences", "(", "SBS", ")", "is", "a", "corpus", "containing", "2.7", "billion", "tokens", ",", "from", "randomly", "rearranged", "sentences", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "swedish blog sentences"}, {"tokens": ["A", "major", "work", "of", "this", "paper", "is", "to", "construct", "the", "systematic", "regenerating", "codes", "at", "MBR", "points", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["In", "the", "uplink", "mode", ",", "the", "BS", "estimates", "the", "uplink", "channel", "and", "use", "a", "linear", "receivers", "to", "separate", "the", "transmitted", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Using", "UAVs", "in", "SAR", "operations", "reduces", "costs", "and", "human", "lives", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["We", "use", "ICA", "algorithm", "to", "find", "the", "best", "amount", "of", "them", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imperialist competitive algorithm"}, {"tokens": ["Continual", "GP", "classificationThe", "approach", "presented", "in", "this", "paper", "is", "also", "valid", "under", "the", "presence", "of", "non", "-", "Gaussian", "likelihood", "models", "that", "implies", "to", "introduce", "additional", "approximations", "for", "the", "computation", "of", "expectations", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "results", "of", "our", "experiments", "on", "several", "benchmark", "data", "sets", ",", "such", "as", "MS", "COCO", ",", "show", "that", "the", "variants", "of", "the", "state", "-", "of", "-", "the", "-", "art", "methods", "for", "image", "captioning", "that", "make", "use", "of", "the", "information", "extracted", "from", "knowledge", "graphs", ",", "e.g.", ",", "CNet", "-", "NIC", ",", "can", "substantiallyoutperform", "those", "that", "rely", "solely", "on", "the", "informationextracted", "from", "images", ",", "e.g.", ",", "CNet", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural image caption"}, {"tokens": ["FiguresA", "BLSTM", "Network", "for", "Printed", "Bengali", "OCR", "System", "with", "High", "AccuracyDebabrata", "PaulSociety", "for", "Natural", "Language", "Technology", "ResearchKolkata", ",", "Indiadebabratapaul90@gmail.comBidyut", "B.", "ChaudhuriTechno", "India", "UniversityKolkata", ",", "Indiabbcisical@gmail.comThis", "paper", "presents", "a", "printed", "Bengali", "and", "English", "text", "OCR", "system", "developed", "by", "us", "using", "a", "single", "hidden", "BLSTM", "-", "CTC", "architecture", "having", "128", "units", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["The", "results", "show", "how", "well", "the", "building", "components", "of", "a", "QA", "system", "perform", "in", "isolation", "and", "together", "in", "a", "pipeline", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["It", "is", "known", "that", "kurtosis-", "or", "cumulant", "-", "based", "ICA", "(", "hereafter", "refered", "to", "as", "ICA", ")", "fails", "when", "more", "then", "one", "of", "the", "independent", ",", "latent", "signals", "is", "normally", "distributed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["wherePersonalized", "SAR", "Intervention", "DesignThe", "SAR", "personalization", "framework", "was", "instantiated", "in", "a", "SAR", "systems", "designed", "for", "and", "evaluated", "in", "a", "month", "-", "long", ",", "in", "-", "home", "SAR", "intervention", "in", "the", "homes", "of", "children", "with", "ASD", ",", "and", "approved", "under", "USC", "IRB", "UP-16", "-", "00755", "."], "acronym_pos": [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["In", ",", "to", "minimize", "the", "total", "transmission", "cost", "among", "the", "BSs", "and", "from", "the", "core", "network", ",", "each", "BS", "'s", "cache", "storage", "was", "divided", "into", "two", "parts", ",", "the", "first", "part", "of", "all", "the", "BSs", "cached", "same", "files", "with", "higher", "popularity", "ranks", ",", "while", "the", "second", "part", "of", "all", "the", "BSs", "stored", "different", "files", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["[", "90.8", "]", "&", "&", "&", "&", "&", "&", "EO", "&", "&", "&", "&", "R1IR", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "eyes open"}, {"tokens": ["NP", "xusru", ",", "xusu", "'", "mother", "-", "in", "-", "law'PIr", "*", "acru-(ka)-", "'", "teardrop", "'", "MMP", "'"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Since", "CCPM", "shares", "few", "similarities", "with", "other", "neural", "networks", "and", "PNN", "*", "is", "just", "a", "combination", "of", "IPNN", "and", "OPNN", ",", "we", "only", "compare", "FNN", ",", "IPNN", "and", "OPNN", "in", "this", "section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Our", "main", "contribution", "in", "this", "paper", "is", "to", "provide", "a", "novel", "approach", "that", "extends", "the", "existing", "posterior", "-", "prior", "recursion", "of", "online", "Bayesian", "inference", ",", "to", "the", "infinite", "functional", "space", "setting", "of", "GP", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["However", "note", "that", "now", "we", "need", "to", "find", "only", "power", "variables", "instead", "of", "variables", "for", "power", "allocation", "at", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Characterizing", "the", "Empirical", "Upper", "BoundWe", "hypothesize", "that", "the", "empirical", "upper", "bound", "in", "AP", "is", "the", "score", "of", "a", "detector", "with", "ground", "truth", "bounding", "boxes", "labeled", "by", "the", "best", "object", "classifier", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "strength", "of", "(", "VO", ")", "or", "(", "CC", ")", "concept", "is", "that", "it", "models", "dynamic", "collision", "avoidance", "as", "a", "first", "order", "constraint", "in", "combined", "position", "-", "velocity", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collision cone"}, {"tokens": ["As", "both", "entities", "are", "now", "item", "types", ",", "we", "do", "no", "longer", "have", "classic", "user", "interactions", "for", "CF", "as", "we", "have", "in", "UC1", "and", "UC2", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["IS", ":", "inception", "score", "."], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["Need", "for", "Maliciously", "Secure", "OT", "in", "Lambaek", "'s", "ProtocolWe", "briefly", "describe", "an", "attack", "by", "a", "malicious", "receiver", "in", "the", "protocol", "of", ",", "if", "the", "random", "1-out", "-", "of-", "OT", "functionality", "is", "instantiated", "with", "a", "protocol", "secure", "against", "semi", "-", "honest", "adversaries", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["into", "a", "discrete", "version", ",", "we", "have", "the", "desired", "OT", "loss", ":", "where", "satisfies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["In", "this", "section", ",", "we", "present", "our", "evaluation", "study", ",", "in", "which", "we", "compare", "popularity", "-", "based", "with", "CF", "-", "based", "recommendations", "for", "all", "four", "use", "cases", "defined", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["illustrates", "the", "ROC", "curves", "for", "6-fold", "cross", "-", "validation", "of", "the", "two", "-", "tiered", "superpixel", "-", "level", "classifiers", "and", ",", "to", "assemble", "our", "frameworks", "F-1", "and", "F-2", ",", "respectively", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Finally", ",", "we", "will", "look", "at", "the", "conditions", "of", "so", "that", "for", "every", "point", "in", "the", "IB", "curve", ",", "there", "exists", "a", "unique", "s.t", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["We", "show", "the", "intersection", "of", "the", "isolines", "of", "for", "different", "with", "the", "IB", "curve.]Example", "of", "value", "convergence", "with", "the", "exponential", "IB", "Lagrangian", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Random", "target", "(", "RT", ")", "protocol", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "random target"}, {"tokens": ["ROC", "curves", "and", "AUC", "for", "each", "class", "are", "shown", "in", "Figure", "3", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "performance", "of", "DBPSK", "of", "pure", "and", "rate", "-", "selective", "RS", "is", "depicted", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["AP", "solves", "it", "sub", "-", "optimally", "in", "computations", "using", "max", "-", "sum", "algorithm", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["Many", "intelligent", "tutoring", "systems", "(", "ITS", ")", "use", "mastery", "learning", "within", "the", "Knowledge", "Tracing", "framework", ":", "making", "students", "work", "on", "a", "given", "skill", "until", "the", "system", "infers", "that", "they", "have", "mastered", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intelligent tutoring systems"}, {"tokens": ["They", "show", "how", "the", "UAV", "processing", "and", "decision", "-", "making", "technology", "is", "nimble", "enough", "to", "allow", "UAVs", "to", "operate", "in", "unpredictable", "settings", "without", "using", "any", "GPS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "global positioning system"}, {"tokens": ["Here", "RM", "means", "Random", "Forest", "while", "FM", ",", "TP", ",", "FP", "represent", "F1-Measure", ",", "True", "Positives", "rate", "and", "False", "Positives", "rate", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["Only", "with", "this", "property", "may", "the", "RB", "be", "identified", "within", "the", "bounds", "of", "available", "computational", "resources", "(", "e.g.", ",", "memory", "and", "CPU", "time", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["The", "corresponding", "ground", "-", "truth", "HR", "images", "are", "not", "spatially", "transformed", ";", "in", "this", "way", ",", "the", "models", "learn", "to", "output", "anatomically", "correct", "results", "when", "the", "input", "slices", "are", "motion", "corrupted", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["Although", "these", "correlating", "transform", "-", "based", "MDC", "methods", "provide", "an", "effective", "MD", "generation", "method", ",", "this", "kind", "of", "MDC", "method", "tends", "to", "be", "inefficient", "when", "a", "great", "deal", "of", "information", "redundancy", "is", "expected", "to", "be", "introduced", "into", "multiple", "descriptions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["We", "present", "our", "vision", "for", "such", "adaptation", "and", "report", "on", "concrete", "steps", "towards", "its", "implementation", "in", "the", "design", "and", "teaching", "of", "a", "course", "for", "graduate", "IS", "students", "at", "the", "University", "of", "Haifa", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["propose", "Ant", "Colony", "Optimization", "Algorithm", "(", "ACO", ")", "attached", "with", "2-opt", "Local", "Search", "(", "LS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "local search"}, {"tokens": ["app7", "Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs", "where", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["LScD", "is", "an", "ordered", "list", "of", "words", "from", "texts", "of", "abstracts", "in", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["As", "a", "large", "number", "of", "publications", "involving", "the", "solution", "of", "ELD", "problems", "using", "various", "PSO", "algorithms", "are", "available", "in", "the", "literature", ",", "so", "a", "new", "literature", "review", "is", "needed", "to", "obtain", "a", "broad", "idea", "about", "the", "ability", "of", "PSO", "in", "solving", "ELD", "problems", "in", "modern", "power", "systems", "prospectives", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Left", ":", "rate", "of", "convergence", "of", "FE", "solution", "for", "scalar", "PVI", "of", "Ex", ".", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "parabolic variational inequality"}, {"tokens": ["In", "our", "experiments", ",", "ARD", "boosted", "the", "robustness", "of", "both", "the", "ResNet18", "and", "MobileNetV2", "models", "(", "See", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Blocking", "Timein", "CST", "time", "."], "acronym_pos": [0, 0, 1, 0, 0], "long_form": "china standard time"}, {"tokens": ["We", "also", "tried", "FT", "on", "the", "merged", "ASNQ", "and", "TREC", "-", "QA", "dataset", "to", "show", "that", "the", "sequential", "FT", ",", "i.e.", ",", ",", "improves", "over", "simply", "using", "all", "the", "data", "combined", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["First", ",", "Section", "II", "describes", "the", "DCI", "formats", "for", "both", "LTE", "-", "eMBMS", "and", "NR", "-", "PTP", "technologies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["ACE", "is", "designed", "to", "customize", "sounds", "by", "combining", "the", "benefits", "of", "pitch", "information", "of", "the", "SPEAK", "strategy", ",", "with", "the", "higher", "rates", "of", "simulation", "offered", "by", "the", "CIS", "strategy", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "advanced combined encoder"}, {"tokens": ["The", "continuous", "and", "dashed", "black", "lines", "correspond", "to", "the", "legitimate", "forward", "and", "backward", "links", "of", "the", "legitimate", "network", ",", "respectively", ",", "while", "the", "dashed", "blue", "line", "illustrates", "the", "AN", "propagated", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Once", "again", ",", "the", "final", "expression", "of", "the", "congestion", "probability", "is", "calculated", "by", "averaging", "over", "the", "PLP", "as", "Once", "we", "have", "the", "expression", "of", "the", "congestion", "probability", ",", "we", "set", "a", "target", "value", "and", "then", ",", "the", "required", "number", "of", "PRBs", "is", "written", "as", "a", "function", "of", "through", "the", "implicit", "equation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["The", "angle", "between", "the", "noisy", "learning", "signals", "and", "that", "of", "the", "true", "gradients", "remained", "at", "roughly", "throughout", "training", ",", "comparable", "to", "the", "alignment", "achieved", "by", "FA", "with", "uSF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["This", "is", "achieved", "through", "a", "kernel", "which", "allow", "additive", "interactions", "of", "all", "orders", ",", "ranging", "from", "first", "order", "interactions", "(", "as", "in", "a", "GAM", ")", "all", "the", "way", "to", "th", "-", "order", "interactions", "(", "as", "in", "a", "SE", "-", "GP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["dB", "over", "IID", "Nakagami-", "fading", "channels", "with", "different", "values", "of", ":", "(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "maximal ratio diversity"}, {"tokens": ["Table", "reports", "the", "results", "of", "DDE", "-", "MGM", ",", "as", "well", "as", "the", "offline", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Standard", "-", "compliant", "multiple", "description", "codingResearch", "on", "the", "standard", "-", "compliant", "MDC", "framework", "has", "becomes", "increasingly", "significant", "due", "to", "the", "wide", "usage", "of", "standard", "image", "/", "video", "codecs", "such", "as", "JPEG", "and", "H.264", ",", "which", "has", "become", "essential", "parts", "of", "life", "in", "practice", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["An", "overview", "of", "the", "rest", "of", "the", "paper", "is", "as", "follows", ":", "in", "Section", "the", "literature", "of", "FER", "is", "reviewed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["shows", "the", "flow", "of", "the", "DDE", "-", "MGM", "scheme", ",", "assuming", "and", "for", "simplicity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["In", "the", "results", "tables", "below", ",", "GP", "Additive", "refers", "to", "a", "GP", "using", "the", "additive", "kernel", "with", "squared", "-", "exp", "base", "kernels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Overall", ",", "the", "participants", "commented", "very", "positively", "and", "reported", "that", "the", "activities", "covered", "a", "good", "ROM", "for", "the", "upper", "body", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "range of motion"}, {"tokens": ["Furthermore", ",", "so", "far", ",", "we", "have", "only", "evaluated", "the", "two", "algorithms", "MP", "and", "CF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "most popular"}, {"tokens": ["It", "is", "interesting", ",", "however", ",", "that", "both", "GMM", "and", "DPGMM", "found", "the", "millisecond", "pulsars", "are", "distributed", "into", "two", "clusters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "winner", "pays", "the", "source", "the", "FJ", "power", "so", "that", "the", "corresponding", "secrecy", "rate", "is", "at", "least", "the", "second", "-", "largest", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["ANN", "in", "general", "can", "be", "applied", "for", "language", "understanding", "and", "NLP", "tasks", "such", "as", "speech", "recognition", ",", "MT", "and", "text", "summarization", "using", "the", "concept", "of", "language", "modeling", "(", "LM", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Clearly", ",", "for", "both", "RS", "-", "based", "transmission", "schemes", ",", "improves", "with", "increasing", "and/or"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["This", "is", "because", "with", "OT", ",", "in", "the", "small", "regime", ",", "the", "sum", "SE", "of", "DUs", "is", "mainly", "influenced", "by", ",", "while", "in", "the", "high", "regime", ",", "it", "is", "mainly", "affected", "by", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal training"}, {"tokens": ["In", "other", "words", ",", "the", "basis", "functions", "of", "the", "RB", "method", "span", "a", "subspace", "of", "dimension", "within", "the", "high", "-", "dimensionalspace", "of", "FE", "basis", "functions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["Information", "BottleneckThe", "IB", "principlepart", ":", "tishby", ":", "ib", "describes", "an", "information", "theoretic", "approach", "which", "is", "used", "to", "compress", "a", "random", "variable", "with", "respect", "to", "a", "second", "random", "variable", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Using", "ARD", ",", "robustness", "is", "preserved", "on", "architectures", "and", "datasets", "that", "do", "not", "transfer", "robustness", "under", "vanilla", "knowledge", "distillation", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Using", "the", "energy", "measurement", ",", "we", "identify", "the", "number", "of", "Wi", "-", "Fi", "APs", "in", "the", "following", "scenarios", ":", "Scenario", "0", ":", "Measure", "the", "energy", "at", "the", "LTE", "-", "U", "BS", "during", "theLTE", "-", "U", "OFF", "period", "when", "no", "Wi", "-", "Fi", "APs", "are", "deployed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["This", "scheme", "uses", "real", "-", "time", "monitoring", "of", "the", "decoder", "buffer", "occupancy", "and", "the", "channel", "state", ",", "to", "calculate", "the", "optimal", "parameters", "for", "FEC", "redundancy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Therefore", ",", "we", "can", "not", "ensure", "the", "exploration", "of", "the", "IB", "curve", "for", "s.t", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Why", "did", "not", "the", "QA", "system", "answer", "something", "else", "?"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["High", "-", "resolution", "SEM", "imaging", "is", "very", "expensive", "compared", "with", "LOM", "imaging", "in", "terms", "of", "time", "and", "operating", "costs", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Observing", "the", "energy", "values", "(", "at", "LTE", "-", "U", "BS", "OFF", "time", ")", "is", "a", "much", "simpler", "operation", "than", "decoding", "the", "entire", "Wi", "-", "Fi", "packets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Earlier", ",", "proposed", "a", "similar", "method", "that", "after", "clustering", "the", "dataset", "by", "using", "-means", ",", "instances", "that", "are", "close", "to", "the", "centroid", "of", "the", "cluster", ",", "which", "they", "belong", "to", ",", "were", "pruned", ",", "and", "LDOF", "was", "used", "merely", "on", "instances", "that", "were", "away", "from", "the", "centroid", ",", "i.e.", ",", "outside", "of", "a", "predefined", "radius", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "local distance - based outlier factor"}, {"tokens": ["They", "show", "performance", "gains", "compared", "to", "BNN", "on", "ImageNet", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "binary neural networks"}, {"tokens": ["However", ",", "on", "PSC", "Bridges", "the", "I", "/", "O", "time", "was", "on", "average", "about", "two", "and", "a", "half", "times", "larger", "and", "the", "I", "/", "O", "time", "distribution", "was", "also", "more", "variable", "across", "different", "ranks"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["More", "importantly", ",", "even", "for", "strong", "source", "to", "destination", "channel", "conditions", ",", "as", "increases", "the", "improvement", "on", "with", "RS", "-", "based", "transmission", "becomes", "larger", "than", "that", "with", "the", "non", "-", "relay", "assisted", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Our", "result", "implies", "that", "choice", "forests", "are", "capable", "of", "explaining", "some", "of", "the", "pathological", "cases", "that", "do", "not", "exhibit", "regularity", "and", "are", "outside", "the", "RUM", ",", "including", "the", "decoy", "effect", "and", "the", "comparison", "-", "based", "choice", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random utility modelwe"}, {"tokens": ["We", "also", "design", "FG", "for", "integrating", "multi", "-", "direction", "features", "by", "using", "the", "character", "placement", "clues", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "filter gate"}, {"tokens": ["The", "second", "mechanism", "(", "MINT", "-", "FEC", ")", "follows", "the", "same", "procedure", ",", "but", "differs", "by", "using", "additional", "parameters", ",", "such", "as", "the", "temporal", "video", "intensity", "and", "the", "ability", "to", "cope", "with", "videos", "of", "arbitrary", "size", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["ACO", "is", "selected", "as", "another", "benchmarking", "algorithm", ",", "since", "its", "underlying", "search", "principle", "is", "similar", "to", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Spectrum", "kernel", "as", "part", "of", "SK", "has", "been", "applied", "to", "many", "different", "applications", ",", "including", "text", ",", "DNA", ",", "and", "protein", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "string kernel"}, {"tokens": ["We", "propose", "a", "novel", "and", "more", "practical", "online", "modeling", "and", "classification", "scheme", ",", "DDE", "-", "MGM", ",", "which", "does", "not", "make", "any", "assumptions", "on", "the", "time", "series", "while", "maintaining", "high", "efficiency", "and", "state", "-", "of", "-", "the", "-", "art", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["4", "shows", "the", "average", "achievable", "rate", "with", "respect", "to", "the", "received", "signal", "power", "threshold", "considering", "different", "intensities", "of", "SBSs", "when", "the", "SBS", "cooperation", "strategy", "with", "the", "received", "signal", "power", "constraint", "is", "adopted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["The", "two", "-", "pass", "IB", "based", "speaker", "diarization", "(", "TPIB", ")", "system", "is", "a", "recently", "proposed", "unsupervised", "approach", "that", "does", "not", "use", "any", "separate", "training", "data", "to", "learn", "speaker", "discriminative", "characteristics", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["When", "did", "the", "QA", "system", "succeed", "?"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["In", "this", "case", ",", "the", "path", "loss", "exponent", "of", "the", "link", "between", "UE", "and", "is", "assumed", "to", "follow", "a", "Gamma", "distribution", ",", "i.e.", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Each", "traveler", "makes", "her", "route", "choice", "decision", "solely", "based", "on", "the", "perception", "of", "the", "past", "traffic", "conditions", ",", "unlike", "the", "classical", "Wardrop", "UE", "or", "atomic", "Nash", "Equilibrium", "where", "each", "traveler", "is", "fully", "aware", "of", "others", "'", "choices", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equilibrium"}, {"tokens": ["Within", "the", "DTN", ",", "maps", "a", "RGB", "image", "to", "the", "activations", "of", "the", "last", "convolutional", "layer", "of", "size", "(", "post", "a", "max", "pooling", "and", "before", "the", "ReLU", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "domain transfer network"}, {"tokens": ["To", "reduce", "the", "likelihood", "of", "agents", "blocking", "each", "other", ",", "FAR", "annotates", "at", "each", "node", "with", "the", "direction", "that", "agents", "at", "that", "node", "should", "follow", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "flow annotation replanning"}, {"tokens": ["With", "upscatter", "partitioning", ",", "the", "downscatter", "groups", "are", "replicated", "and", "solved", "using", "GS", "while", "the", "upscatter", "groups", "are", "solved", "with", "a", "Krylov", "solver", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gauss seidel"}, {"tokens": ["Next", "we", "define", "these", "classes", ",", "focusing", "on", "the", "SL", "and", "SP", "classes", "since", "languages", "belonging", "to", "them", "form", "the", "learning", "targets", "in", "the", "experiments", "described", "in", "sec", ":", "exp", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["For", "an", "experimental", "comparison", ",", "we", "implemented", "our", "two", "incremental", "approaches", "IA", "and", "IAW", ",", "as", "well", "as", "the", "static", "approximation", "RK", ",", "the", "static", "exact", "BA", ",", "the", "dynamic", "exact", "algorithms", "GMB", "and", "KDB", "for", "unweighted", "graphs", "and", "the", "dynamic", "exact", "algorithm", "NPR", "for", "weighted", "graphs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "incremental approximation"}, {"tokens": ["How", "does", "the", "power", "allocation", "strategy", "between", "AN", "and", "confidential", "messages", "affect", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["To", "deal", "with", "general", "kernels", "we", "will", "resort", "instead", "to", "a", "the", "well", "known", "variational", "sparse", "GP", "approximation", "with", "inducing", "points", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Corollaries", "and", "allow", "us", "to", "reduce", "the", "range", "search", "for", "when", "we", "want", "to", "explore", "the", "IB", "curve", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Alternatively", ",", "draw", "the", "IB", "curve", "with", "multiple", "values", "of", "on", "the", "range", "defined", "by", "Corollary", "and", "select", "the", "representations", "that", "best", "fit", "their", "interests", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Parameter", "server", "(", "PS", ")", "architecture", "uses", "a", "number", "of", "parameter", "servers", "that", "serve", "to", "coordinate/"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["The", "BDI", "agent", "connects", "to", "BS", "and", "starts", "again", "the", "discovery", "phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Furthermore", ",", "the", "possibility", "of", "using", "an", "RIS", "as", "an", "AP", "(", "transmitter", ")", "by", "utilizing", "an", "unmodulated", "carrier", "for", "intelligent", "reflection", "is", "studied", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Performance", "Comparison", "of", "various", "OT", "extensions", "for", "producing", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Consulting", "higher", "expertise", "nodes", "leads", "to", "a", "higher", "TP", "rate", "and", "a", "lower", "FP", "rate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["For", "each", "sample", "we", "compared", "the", "optimal", "value", "of", "the", "objective", "of", "the", "warm", "-", "start", "and", "reduced", "OPF", "formulations", "to", "the", "solution", "of", "the", "full", "problem", "and", "found", "that", "they", "were", "indeed", "equal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["We", "use", "the", "following", "exponential", "functional", "forms", ":", "for", "GP", "-", "UCB", "with", "current", "variance", "of", "decreasing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "this", "paper", ",", "FCA", "is", "applied", "to", "this", "aim", "with", "a", "specific", "application", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "formal concept analysis"}, {"tokens": ["[", ",", ",", "]", "T=30", ",", "Linear", "regression", "models", "for", "the", "CNS", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["Swedish", "Blog", "Sentences", "(", "SBS", ")", "is", "a", "corpus", "containing", "2.7", "billion", "tokens", ",", "from", "randomly", "rearranged", "sentences", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "swedish blog sentences"}, {"tokens": ["For", "a", "submodular", "function", ",", "the", "LB", "divergence", "associated", "with", "is", "derived", "as", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["The", "advantage", "of", "increasing", "the", "intensity", "of", "SBSs", "is", "weakened", "by", "the", "SBS", "cooperation", "with", "the", "received", "signal", "power", "constraint", ",", "which", "indicates", "a", "challenge", "on", "the", "deployment", "and", "SBS", "cooperation", "design", "for", "fractal", "small", "-", "cell", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["25]Hoffmann1976", "attributes", "the", "long", "vowel", "to", "Vrddhi", ")", "MP", "mahig", "'", "fish", "'", "NP", "mahiPIIr", "*", "tuscia-(ka-", ")", "likely", "PIr", "*", "tucia", "-", "ka-", "MP", "tuhig", "'", "barren'PIr", "*", "kaciapa", "-", "ka-", "MP", "kasavag", "'", "tortoise", "'", "NP", "kasav", ",", "kasaf", ";", "cf", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["From", "this", "figure", ",", "the", "FL", "procedure", "contains", "three", "steps", "at", "each", "iteration", ":", "Local", "computation", "at", "each", "user", "(", "using", "several", "local", "iterations", ")", ",", "local", "FL", "parameter", "transmission", "for", "each", "user", ",", "and", "result", "aggregation", "and", "broadcast", "at", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["PA", "-", "RTClem", ":"], "acronym_pos": [1, 0, 0, 0], "long_form": "peano 's arithmetics"}, {"tokens": ["Another", "important", "aspect", "that", "is", "worth", "highlighting", ",", "is", "that", "with", "5", "and", "10", "of", "packet", "loss", "rates", ",", "the", "video", "quality", "of", "sequences", "without", "FEC", "are", ",", "on", "average", ",", "virtually", "the", "same", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["A", "sub", "-", "pixel", "cardiac", "MR", "image", "segmentation", "approach", "that", ",", "in", "contrast", "to", "previous", "CNN", "approaches", ",", "is", "robust", "against", "slice", "misalignment", "and", "coverage", "problems", ";", "(", "II", ")"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["Therefore", ",", "we", "select", "the", "representation", "which", "yields", "the", "value", "of", "the", "IB", "curve", "that", "best", "fits", "our", "requirements", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Exploiting", "value", "convergenceWhen", "the", "aim", "is", "not", "to", "draw", "or", "explore", "the", "IB", "curve", ",", "but", "to", "obtain", "a", "specific", "level", "of", "performance", ",", "the", "power", "or", "exponential", "IB", "Lagrangians", "aforementioned", "might", "not", "be", "the", "best", "choice", "due", "to", "the", "problems", "with", "value", "convergence", "or", "non", "-", "strong", "convexity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Further", ",", "both", "methods", "work", "better", "with", "linear", "ML", "models", "(", "SVM", ",", "LDA", ",", "LR", ")", "as", "opposed", "as", "non", "-", "linear", "ones", "(", "DT", ",", "RF", ",", "KNN", ")", ",", "especially", "with", "the", "artificial", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["The", "pre", "-", "post", "assessments", "supported", "this", "finding", "while", "providing", "quantitative", "data", "about", "the", "learning", "gains", "of", "each", "participant", "as", "a", "result", "of", "SAR", "personalization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Consequently", ",", "we", "can", "conclude", "that", "the", "SAR", "system", "was", "able", "to", "adapt", "and", "personalize", "to", "each", "child", "over", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["However", ",", "it", "is", "clear", "that", "in", "VAT", ",", "functions", "would", "be", "penalized", "for", "changing", "rapidly", "around", "the", "manifold", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["The", "average", "computational", "time", "of", "different", "algorithms", "(", "i.e.", ",", "DBNMS", ",", "DBN", ",", "MLP", ",", "ELM", ",", "SVM", ",", "RR", ",", "Lasso", ",", "AdaBoost", ",", "SGD", ",", "EN", ",", "LAR", ")", "over", "10", "trials", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Appendix", "A.", "Complete", "derivation", "of", "continual", "lower", "boundsSingle", "-", "output", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["However", ",", "the", "most", "dominant", "periodic", "component", "can", "not", "be", "simply", "determined", "in", "terms", "of", "the", "value", "of", "the", "energy", "of", "the", "component", "captured", "by", "the", "subspace", ",", "as", "done", "in", "MP", "or", "SP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "subspace pursuit"}, {"tokens": ["Our", "approach", "establishes", "the", "state", "of", "the", "art", "on", "two", "well", "-", "known", "benchmarks", ",", "WikiQA", "and", "TREC", "-", "QA", ",", "achieving", "MAP", "scores", "of", "92", "and", "94.3", ",", "respectively", ",", "which", "largely", "outperform", "the", "previous", "highest", "scores", "of", "83.4", "and", "87.5", ",", "obtained", "in", "very", "recent", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "visual", "features", "from", "PIN", "are", "concatenated", "with", "5D", "spatial", "representation", "(", "for", "regression", ")", "and", "8", "*", "8", "one", "-", "hot", "embedded", "vector", "for", "source", "and", "target", "phrase", "categories", ";", "for", "generating", "representation", "vector", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["Comparison", "of", "the", "average", "computational", "time", "of", "ECS", "-", "DBN", "and", "DBN", "with", "5-fold", "cross", "validation", "on", "the", "gun", "drilling", "imbalanced", "dataset", "over", "10", "trials", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["That", "is", ",", "the", "dimension", "of", "BQ", "matrix", ",", "called", ",", "is", "4800", "by", "215623", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["The", "users", "current", "location", "which", "is", "tracked", "through", "the", "GPS", "tracker", "and", "other", "important", "user", "information", "is", "stored", "in", "a", "database", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["The", "results", "where", "the", "training", "of", "ANN", "is", "used", "incrementally", "in", "TPIB", "-", "ITL", "using", "only", "development", "data", "is", "given", "in", "TPIB", "-", "ITL(Dev", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["t]Three", "elaborated", "types", "of", "OpenSARShipWhat", "to", "TransferIn", "this", "section", ",", "we", "will", "discuss", "how", "the", "different", "networks", "and", "source", "tasks", "affect", "the", "transferability", "of", "features", "in", "SAR", "target", "recognition", "and", "then", "apply", "the", "conclusion", "to", "our", "subsequent", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["In", "this", "scenario", ",", "UE", "7", "is", "not", "selected", "for", "serving", "and", "the", "candidate", "sets", "of", "RRHs", "for", "the", "selected", "UEs", "are", "given", "by", ",", ",", ",", ",", "and", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["alignThe", "regression", "problem", "concerns", "the", "prediction", "of", "a", "continuous", "quantityrasmussen05", ",", "here", "a", "function", ",", "given", "a", "data", "set", ",", "where", "are", "assumed", "as", "noisy", "measurements", "of", "at", "typically", "regularly", "-", "spaced", "time", "instants", "(", "though", "GP", "regression", "framework", "allows", "for", "irregular", "sampling", "or", "missing", "data", ")", ",", "i.e.", ",", "where", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Dominating", "frequencies", "(", "DF", ")", "of", "the", "entropy", "of", "MRs", "are", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dominating frequencies"}, {"tokens": ["Assortative", "SBM"], "acronym_pos": [0, 1], "long_form": "sequential monte carlo"}, {"tokens": ["A", "larger", "enables", "DE", "of", "better", "exploitation", "ability", "while", "a", "smaller", "enables", "DE", "of", "better", "exploration", "ability", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["This", "is", "because", "HARP", "computes", "the", "initial", "embedding", "of", "each", "node", "in", "a", "hierarchical", "manner", "that", "requires", "several", "iterations", "of", "computation", ",", "while", "GPA", "reduces", "the", "input", "graph", "to", "the", "abstract", "graph", "of", "size", "whose", "embeddings", "are", "then", "propagated", "among", "the", "nodes", "in", "the", "input", "graph", "with", "a", "linear", "cost", ",", "where", "is", "the", "number", "of", "nodes", "in", "the", "input", "graph", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["The", "transfer", "learning", "models", "show", "slight", "improvement", "in", "CER", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "character error rate"}, {"tokens": ["Research", "can", "be", "focused", "to", "apply", "improved", "PSO", "algorithms", "to", "limit", "the", "fault", "currents", "in", "smart", "grids", "by", "the", "size", "of", "thyristor", "-", "controlled", "impedance", "[", "(", "c", ")", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Note", "that", "each", "level", "owns", "their", "own", "OT", "module", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Moreover", ",", "in", "Figure", ",", "the", "FCFS", ",", "LE", "and", "HP", "also", "have", "smaller", "dead", "nodes", "compared", "with", "the", "NOP", "scenario", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high prr"}, {"tokens": ["Correlating", "transform", "-", "based", "MDC", "methodsThe", "transform", "-", "based", "MDC", "framework", "employs", "a", "pairwise", "correlating", "transform", "to", "correlate", "pairs", "of", "transform", "coefficients", ",", "in", "which", "the", "best", "strategy", "for", "image", "compression", "redundancy", "allocation", "is", "given", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["gray!25", "-2*Provider", "&", "BM", "&", "VM", "&", "BM", "&", "VM", "&", "BM", "&", "VM", "&", "BM", "&", "VM", "&", "BM", "&", "VM", "&", "BM", "&", "VM", "Amazon", "aws", ":", "iaas", "&", "*", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "Microsoft"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bare metal"}, {"tokens": ["The", "random", "access", "terminates", "when", "the", "AP", "receives", "a", "predefined", "number", "of", "successful", "RTSs", ",", "and", "then", "the", "data", "transmission", "follows", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Sample", "postures", "and", "the", "plot", "of", "the", "corresponding", "HOG", "features", "are", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "histogram of oriented gradient"}, {"tokens": ["The", "resulting", "representation", "of", "the", "source", "textcan", "then", "be", "used", "to", "facilitate", "a", "variety", "of", "artificial", "intelligence", "tasks", ",", "such", "as", "building", "QA", "systems", "or", "supporting", "semantic", "inferences", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["With", "this", "loss", ",", "the", "MGM", "GAN", "preserves", "the", "relationships", "between", "points", "before", "and", "after", "mapping", ",", "keeping", "the", "two", "representations", "(", "one", "in", "each", "domain", ")", "of", "similar", "points", "similar", "and", "different", "points", "different", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["For", "the", "simpler", "levels", "i.e.", "level", "1", "and", "2", ",", "SC", "and", "SC", "+", "Masking", "perform", "better", "than", "Baseline", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "score contextualisation"}, {"tokens": ["(", "AHECM", ")", "solution", "adopts", "a", "dynamic", "FEC", "block", "length", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "results", "suggest", "that", "ECS", "-", "DBN", "is", "more", "suitable", "for", "diagnostics", "than", "the", "other", "competing", "algorithms", ",", "therefore", ",", "potentially", "leads", "to", "better", "prognostics", "in", "the", "MDP", "framework", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "RA", "algorithm", "allows", "worker", "nodes", "to", "average", "gradients", "and", "send", "them", "to", "all", "nodes", "without", "the", "need", "for", "a", "PS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "parameter server"}, {"tokens": ["This", "allows", "the", "ANN", "to", "learn", "the", "contributions", "of", "each", "feature", "for", "the", "output", "prediction", "amidst", "distorted", "inputs", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["propose", "a", "closed", "-", "form", "approximation", "for", "the", "LTE", "rate", "function", ",", "where", "is", "the", "system", "efficiency", "that", "accounts", "for", "various", "system", "-", "level", "overheads", "including", "cyclic", "prefix", ",", "pilot", "assisted", "channel", "estimation", ",", "and", "non", "-", "fully", "utilized", "frequency", "bandwidth", "(", "to", "prevent", "signal", "leakage", "to", "adjacent", "frequencies", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["For", "this", "reason", ",", "we", "believe", "that", "training", "with", "a", "larger", "sample", "size", "will", "improve", "the", "CCR", "and", "allow", "for", "deeper", "networks", "that", "have", "been", "successfully", "used", "in", "the", "semantic", "segmentation", "of", "other", "image", "sets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["As", "shown", "in", "Figures", "3(a", ")", "and", "3(b", ")", "rebuild", "time", "with", "VSM", "is", "lower", "than", "PCM", ",", "and", "except", "for", "the", "highest", "arrival", "rates", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "permanent customer model"}, {"tokens": ["By", "forcing", ",", "the", "DC", "-", "SBM", "by", "again", "showed", "a", "high", "agreement", "with", "the", "ground", "truth", ",", "while", "the", "original", "SBM", "did", "not", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["For", "samples", "and", "tasks", ",", "the", "time", "complexity", "of", "MT", "-", "GPR", "is", "cubic", "with", "respect", "to", "the", "number", "of", "samples", "and", "tasks", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process regression"}, {"tokens": ["Moreover", ",", "we", "choose", "an", "RBF", "kernel", "for", "the", "GP", "prior", "of", "both", "latent", "functions", "and", "their", "hyperparameters", "are", "initialized", "to", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Compared", "with", "the", "baseline", "zoom", "-", "out", "structure", ",", "ZIP", "achieves", "a", "larger", "improvement", "of", "AR", "on", "small", "objects", "(", "8.3", ")", "than", "medium", "-", "sized", "objects", "(", "4.96)and", "large", "objects", "(", "4.59", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average recall"}, {"tokens": ["Observe", "that", "GPA", "consistently", "outperforms", "HARP", "in", "all", "settings", ",", "and", "HARP", "is", "slightly", "better", "than", "Random", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["For", "the", "same", "system", ",", "the", "authors", "of", "focused", "their", "attention", "on", "optimizing", "the", "transmit", "beamformer", "and", "RIS", "phases", ",", "and", "proposed", "two", "algorithms", "to", "jointly", "optimize", "the", "beamformer", "at", "the", "AP", "and", "the", "phase", "shifts", "at", "the", "RIS", "by", "considering", "the", "maximum", "achievable", "spectral", "efficiency", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["[", "ROC", "Curve", "for", "the", "MI", "Class][ROC", "Curve", "for", "the", "PAC", "Class]ROC", "curves", "obtained", "[", "!"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Accordingly", ",", "in", "this", "paper", "we", "will", "focus", "on", "a", "particular", "class", "of", "deep", "neural", "networks", "called", "autoencoders", "which", "are", "used", "extensively", "for", "DR", "but", "are", "less", "well", "studied", "for", "DE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "dimension estimation"}, {"tokens": ["In", "MacroUsers", ",", "the", "priority", "in", "serving", "users", "is", "given", "to", "MBSs", "and", "DBSs", "as", "macrocell", "BS", "'s", "transmit", "power", "is", "usually", "higher", "than", "that", "of", "MBS", "and", "DBS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["and", "UE", "(", "Sec", ".", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "unreal engine"}, {"tokens": ["As", "seen", "in", "fig", ":", "top-10-dsa", ",", "Structured", "Query", "Language", "(", "'", "SQL", "'", ")", "has", "consistently", "been", "the", "DSA", "skill", "in", "the", "highest", "demand", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["There", "are", "however", "FEC", "schemes", "which", "provide", "good", "performance", "and", "can", "be", "used", "in", "real", "-", "time", "video", "transmission", ",", "RS", "codes", ",", "which", "will", "be", "detailed", "below", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Image", "processing", "methods", "can", "be", "used", "in", "autonomous", "single", "and", "multi", "-", "UAV", "systems", "to", "locate", "potential", "targets", "in", "support", "of", "SAR", "operations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "search and rescue"}, {"tokens": ["Hence", ",", "The", "infeasibility", "condition", "occurs", "when", "the", "cell", "capacity", "constraint", "of", "the", "macrocell", "BS", "is", "violated", "since", "the", "system", "gives", "priority", "to", "small", "cells", "(", "i.e.", ",", "DBS", "and", "MBS", ")", "to", "serve", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "schema", "of", "the", "inference", "process", ",", "where", "the", "input", "received", "by", "the", "LTE", "-", "U", "BS", "is", "signals", "from", "Wi", "-", "Fis", "and", "the", "output", "is", "the", "predicted", "number", "of", "Wi", "-", "Fis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Typically", "we", "have", "a", "large", "number", "of", "observations", "about", "user", "browsing", "behaviours", "and", "we", "can", "use", "the", "knowledge", "learned", "from", "publisher", "CF", "recommendation", "to", "help", "infer", "display", "advertising", "CTR", "estimation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["It", "is", "therefore", "worth", "studying", "channel", "learning", "and", "EB", "design", "schemes", "with", "faster", "convergence", "speed", "under", "limited", "feedback", "to", "improve", "WET", "performance", ",", "taking", "into", "account", "the", "tradeoff", "involved", "due", "to", "the", "increase", "in", "the", "amount", "of", "feedback", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy beam"}, {"tokens": ["a", ")", "shows", "AP", "of", "each", "class", "before", "progressive", "instance", "-", "switching", "in", "descending", "order", ";", "(", "b", ")", "gives", "gain", "ratios", "of", "each", "class", "brought", "by", "progressive", "instance", "-", "switching", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Providing", "a", "consistent", "and", "easy", "to", "reference", "identifier", "such", "as", "FEC", "or", "EIN", "for", "each", "sponsor", "enables", "us", "to", "better", "study", "sponsors", "in", "Google", "and", "Twitter", "'s", "archive", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federal election candidate"}, {"tokens": ["The", "MDC", "then", "sends", "the", "encrypted", "measurements", "to", "the", "Dispatcher", "via", "TCP", "sockets", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "metering data collector"}, {"tokens": ["Our", "ContributionWe", "present", "an", "actively", "secure", "OT", "extension", "for", "short", "secrets", "building", "upon", "the", "semi", "-", "honest", "secure", "protocol", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["In", "the", "case", "of", "the", "graph", "isomorphism", "problem", ",", "GI", ",", "the", "number", ",", "in", "the", "notation", "of", "sec", ":", "limitations", ",", "is", "the", "number", "of", "(", "pairwise", ")", "non", "-", "isomorphic", "graphs", "on", "at", "most", "vertices", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph isomorphism"}, {"tokens": ["We", "build", "on", "recent", "SRL", "models", "to", "address", "textual", "relational", "problems", ",", "showing", "that", "they", "are", "more", "expressive", ",", "and", "can", "alleviate", "issues", "from", "simpler", "compositions", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "statistical relational learning"}, {"tokens": ["RB", ":"], "acronym_pos": [1, 0], "long_form": "reduced basis"}, {"tokens": ["The", "UE", "starts", "its", "trajectory", "at", "approximately", "2", "km", "away", "from", "the", "MgNB", "experiencing", "dB", "SINR", "for", "all", "its", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Problem", "Description", "and", "Proposed", "FrameworkWe", "propose", "a", "systematic", "BN", "-", "SV", "-", "MR", "based", "risk", "and", "sensitivity", "analysis", "framework", "to", "facilitate", "the", "understanding", "and", "stability", "control", "for", "end", "-", "to", "-", "end", "biopharmaceutical", "production", "processes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "model risk"}, {"tokens": ["As", "sample", "preparation", "and", "imaging", "for", "TEM", "are", "more", "challenging", "than", "SEM", ",", "differentiating", "between", "the", "programmed", "and", "unprogrammed", "bits", "is", "difficult", "but", "not", "impossible", "for", "antifuse", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["itemizeSingle", "-", "turn", "QA"], "acronym_pos": [0, 0, 0, 1], "long_form": "question answering"}, {"tokens": ["An", "alternative", "mechanism", "is", "the", "Adaptive", "Packet", "and", "Block", "length", "FEC", "(", "APB", "-", "FEC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Furthermore", ",", "pure", "RS", "is", "inefficient", "when", "is", "small", "and", "rate", "-", "selective", "RS", "leads", "to", "significant", "gains", "over", "the", "pure", "one", "as", "decreases", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Hence", ",", "functions", "drawn", "from", "a", "GP", "prior", "have", "to", "be", "passed", "through", "a", "nonlinear", "squashing", "function", "and", "the", "results", "have", "to", "be", "normalised", "subsequently", "to", "model", "a", "density", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["After", "all", ",", "the", "baseline", "model", ",", "a", "comparatively", "simple", "TDNN", ",", "is", "able", "to", "achieve", "well", "under", "100", "CER", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "character error rate"}, {"tokens": ["Full", "skeleton", "with", "universal", "POS", ":", "Technical", "witchcraft", "for", "everyoneA", "witchcraft", "to", "get", "out", "of", "the", "magicThe", "sheer", "magic", "of", "practiceExercise", "sorcery", "witchcraftWe", "again", "find", "respectable", "results", "for", "this", "approach", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Accordingly", ",", "the", "strategy", "of", "each", "source", "is", "to", "find", "its", "FJ", "power", "to", "maximize", "the", "difference", "between", "its", "secrecy", "rate", "and", "the", "price", "that", "it", "pays", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["Particularly", ",", "the", "method", "based", "on", "the", "nested", "structured", "LB", "divergence", "obtains", "the", "maximum", "gain", ",", "while", "ULARA", "performs", "even", "better", "than", "the", "method", "based", "on", "the", "linear", "structured", "LB", "divergence", "and", "the", "simple", "averaging", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["tab", ":", "docqatableGiven", "the", "practical", "importance", "of", "AQG", "and", "its", "potential", "to", "influence", "research", "in", "QA", ",", "it", "is", "not", "surprising", "that", "there", "has", "been", "prolific", "work", "in", "this", "field", "in", "the", "past", "one", "year", "itselfqgvae", ",", "qgvqa", ",", "qggoaloriented", ",", "learningtoask", ",", "modelqgforqa", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Geometric", "Programming", "Method", "for", "PS", "Ratios", "and", "Relays", "'", "Transmit", "Power", "OptimizationGP", "is", "a", "class", "of", "nonlinear", "and", "nonconvex", "optimization", "problems", "that", "can", "be", "efficiently", "solved", "after", "converting", "them", "to", "nonlinear", "but", "convex", "problems", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["(", "CCq)Read2011CCq", "is", "a", "version", "of", "CC", "which", "is", "able", "to", "down", "-", "sample", "the", "number", "of", "training", "instances", "across", "the", "binary", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classifier chain"}, {"tokens": ["Concluding", ",", "the", "main", "takeaway", "of", "our", "formalisation", "is", "that", "we", "could", "extend", "the", "syntax", "of", "to", "additional", "cases", "that", "allow", "valid", "uses", "of", "explicit", "intersection", "types", ",", "while", "keeping", "the", "type", "checking", "straightforward", "as", "in", "FJ", "and", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "featherweight java"}, {"tokens": ["Adamic", "Adar", "(", "AA", ")"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "adamic adar"}, {"tokens": ["ViewFEC", "Performance", "Evaluation", "and", "ResultsThe", "main", "objective", "of", "the", "ViewFEC", "mechanism", "is", "to", "reduce", "the", "network", "overhead", "introduced", "by", "FEC", "-", "based", "schemes", "while", "maintaining", "videos", "with", "an", "acceptable", "level", "of", "quality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "particular", "set", "of", "16", ",", "17", ",", "30", ",", "50", "and", "50", "significant", "calls", "filtered", "with", "WFS", "(", "GS", ")", ",", "CFS", ",", "IG", ",", "CHI", ",", "and", "SU", "are", "grouped", "together", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "genetic search"}, {"tokens": ["ResultsThe", "performance", "of", "the", "network", "is", "reported", "by", "estimating", "the", "CCR", ",", "computed", "using", "equation", ",", "of", "the", "Vysis", "samples", "from", "the", "ADIR", "dataset", ",", "using", "leave", "-", "one", "-", "out", "-", "cross", "-", "validation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["We", "will", "evaluate", "and", "also", "test", "blind", "relevance", "feedback", "in", "IR", "for", "QA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "question answering"}, {"tokens": ["Currently", ",", "the", "state", "-", "of", "-", "the", "-", "art", "specification", "for", "eMBMS", "is", "LTE", "-", "Advanced", "Pro", "Rel-14", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["This", "approach", "referred", "as", "HR", "-", "LR", "and", "HR", "-", "SVM", "shows", "improved", "classification", "performance", "but", "the", "training", "procedure", "for", "large", "-", "scale", "problem", "requires", "a", "distributed", "implementation", "and", "map", "-", "reduce", "supported", "infrastructure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Based", "on", "this", "motivation", ",", "we", "implement", "the", "native", "and", "fast", "approaches", "of", "Exact", "-", "MBR", "codes", ",", "and", "the", "simulation", "results", "are", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Note", "that", "in", "general", "not", "all", "nodes", "can", "communicate", "with", "the", "AP", "and", ",", "where", "is", "the", "number", "of", "elements", "in", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["This", "result", "can", "be", "attributed", "to", "the", "negligible", "cost", "of", "the", "ISP", "in", "comparison", "to", "CNNs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["With", "the", "transformation", "and", "miniaturization", "of", "physical", "devices", "and", "displays", ",", "the", "concept", "of", "mobile", "AR", "evolved", "towards", "the", "notion", "of", "\"", "mobile", "device", "\"", ",", "aka", "AR", "on", "a", "mobile", "device", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["&", "Less", "than", "1", "kg", "/", "LAP", "/", "less", "than", "1", "hour", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "low altitude platform"}, {"tokens": ["Logistic", "RegressionOne", "of", "the", "earliest", "methods", "of", "classification", "is", "logistic", "regression", "(", "LR", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "logistic regression"}, {"tokens": ["OLS", "is", "similar", "to", "OMP", "except", "for", "the", "atom", "selection", "process", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["This", "happens", "because", "of", "the", "increasing", "value", "of", "causes", "a", "reduction", "of", "transmit", "power", "for", "relaying", "(", ")", "at", "CCU", "due", "to", "degradation", "of", "channel", "conditions", "between", "BS", "and", "CCU", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "base station"}, {"tokens": ["As", "mentioned", "in", "the", "introduction", ",", "we", "propose", "three", "new", "RNN", "variants", "to", "take", "into", "account", "low", "level", "(", "POS", ")", "information", "in", "a", "higher", "level", "(", "SST", ")", "annotation", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["TAM"], "acronym_pos": [1], "long_form": "transparent attention model"}, {"tokens": ["They", "are", "generally", "not", "strongly", "FR", "-", "determined", "Kucherabook11", ",", "but", "they", "are", "strongly", "MD", "-", "determined", "under", "any", "of", "the", "conditions", "provided", "by", "Theorem", "thm", ":", "reachability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["Adding", "more", "stages", "to", "the", "ISP", "pipeline", "provides", "both", "marginal", "increases", "in", "accuracy", "and", "marginal", "computational", "costs", "(", "ISP", "cost", "independent", "of", "the", "CNN", "model", "cost", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["We", "maintain", "the", "residuals", "of", "either", "the", "messages", "for", "RBP", "or", "the", "vertices", "for", "RS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "residual splash"}, {"tokens": ["When", "the", "number", "of", "GPUs", "increases", ",", "the", "efficient", "of", "PS", "will", "have", "a", "great", "decline", "because", "of", "the", "big", "communication", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["Another", "finding", "is", "that", "personalized", "methods", "such", "as", "CF", "should", "be", "favored", "when", "the", "use", "cases", "get", "more", "complex", ",", "for", "example", "if", "we", "have", "a", "larger", "set", "of", "candidate", "entities", "as", "it", "is", "the", "case", "in", "UC2", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Structure", "of", "this", "paperIn", "Section", "SECsbm", "we", "will", "review", "the", "standard", "SBM", "ofNowicki-01", "-", "defining", "thebasic", "notation", "and", "models", "which", "will", "be", "used", "throughout", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["As", "shown", "in", "Figure", "(", "b", ")", "and", "(", "c", ")", ",", "detection", "performance", "(", "i.e.", ",", "AP", ")", "of", "each", "class", "is", "quite", "different", ",", "while", "AP", "of", "each", "class", "does", "not", "always", "show", "positive", "correlation", "with", "distribution", "of", "instances", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["GPS", "technology", "has", "been", "used", "in", "many", "health", "applications", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["The", "OT", "divergence", "is", "hence", "referred", "to", "as", "Sinkhorn", "divergence", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["(", "1", ")", "OpenSQuAD", ":", "question", "-", "answer", "pairs", "are", "from", "SQuAD", "1.1", ",", "but", "a", "QA", "model", "will", "find", "answers", "from", "the", "entire", "Wikipedia", "rather", "than", "the", "given", "context", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["For", "example", ",", "skills", "such", "as", "'", "Design", "Thinking", "'", ",", "'", "Front", "-", "end", "Development", "'", ",", "and", "'", "Atlassian", "JIRA", "'", "-", "which", "are", "technical", ",", "but", "not", "DSA", "specific", "-", "were", "just", "outside", "of", "the", "top", "150", "skills", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["The", "best", "achieved", "MSE", "for", "training", "data", "by", "using", "ICA", "algorithm", "is", "0.097", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "imperialist competitive algorithm"}, {"tokens": ["Unlike", "the", "state", "-", "of", "-", "the", "-", "art", "image", "captioning", "systems", ",", "CNet", "-", "NIC", "is", "specifically", "designed", "to", "take", "advantage", "of", "background", "knowledge", "to", "augment", "the", "information", "extracted", "from", "the", "image", "(", "image", "features", ",", "objects", ")", "to", "improve", "machine", "-", "produced", "captions", "or", "image", "descriptions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural image caption"}, {"tokens": ["However", "computation", "of", "the", "stroke", "map", "was", "done", "once", "with", "the", "algorithms", "by", ",", "i.e.", "only", "DMD", ",", "only", "EMD", ",", "and", "combined", ",", "and", "once", "with", "iterative", "improvement", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deficient mapping dissolution"}, {"tokens": ["The", "SAR", "system", "maintained", "reasonable", "levels", "of", "participant", "engagement", "during", "individual", "sessions", "and", "over", "the", "month", "-", "long", "intervention", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Autonomous", ":", "In", "autonomous", "mode", ",", "the", "device", "can", "only", "use", "and", "communicate", "with", "other", "devices", "under", "the", "unlicensed", "spectrum", ",", "without", "accessing", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["&", "&", "&", "None", "&", "0.79", "&", "0.92", "&", "0.76", "AWGN", "&", "0.79", "&", "0.92", "&", "0.77", "APN", "&", "0.82", "&", "0.91", "&", "0.79", "ET", "-", "Small", "&", "0.78", "&", "0.91", "&", "0.76", "ET", "-", "Large", "&", "0.79", "&", "0.94", "&", "0.78"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elastic transformations"}, {"tokens": ["FIGsampson000K0SCFfigureZachary", "'s", "Karate", "clubNow", ",", "we", "apply", "the", "SCF", "to", "a", "network", "of", "interactions", "at", "a", "karate", "clubZacharyKarate", ",", "again", "demonstratingthe", "ability", "of", "the", "SCF", "to", "detect", "community", "structure", "where", "the", "SBM", "focusses", "on", "other", "types", "of", "structure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "ROC", "scores", "on", "the", "dataset", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["While", "most", "of", "the", "tested", "web", "servers", "accept", "any", "permutation", "of", "CR", "and", "LF", ",", "Apache", "just", "ignores", "the", "CRLF", "sequence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "line feeds"}, {"tokens": ["At", "the", "AP", "level", ",", "with", "longer", "time", "bins", ",", "the", "accuracy", "for", "both", "Flutes", "and", "Cellos", "decreases", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["OT", "'", "(", "in", "red", ")", "stands", "for", "the", "optimal", "transport", "divergence", ",", "which", "aligns", "information", "between", "levels", "(", "for", "details", "see", "Sec", ".", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Then", "intermediate", "values", "are", "linearly", "interpolated", "and", "the", "threshold", "level", "for", "equal", "FAR", "and", "FRR", "is", "chosen", "as", "the", "final", "threshold", ",", "and", "the", "error", "rate", "(", "EER", ")", "is", "evaluated", "at", "that", "threshold", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "false acceptance rate"}, {"tokens": ["We", "demonstrated", "the", "capability", "of", "this", "meta", "-", "optimization", "for", "two", "synthetic", "grids", "using", "DC", "-", "OPF", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Furthermore", ",", "we", "explore", "the", "roles", "of", "HN", ",", "VN", ",", "CN", "and", "FG", "in", "AON", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "filter gate"}, {"tokens": ["Moreover", ",", "it", "lets", "us", "see", "how", "if", "for", "maximizing", "the", "IB", "Lagrangian", "could", "obtain", "any", "point", "with", ",", "then", "the", "same", "happens", "for", "the", "IB", "convex", "Lagrangian", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["It", "can", "be", "suppressed", "without", "loss", "in", "the", "original", "signal", ",", "by", "a", "high", "-", "pass", "digital", "filter", "or", "by", "the", "use", "of", "a", "standard", "Wavelet", "Transform", "(", "WT", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "wavelet transform"}, {"tokens": ["T=30", ",", "CNS", "dataset", ":", "correlation", "between", "the", "four", "dimensions", "of", "social", "and", "spatial", "behaviour", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["ImageNet", "images", "(", "Original", "RGB", ")", "are", "processed", "using", "the", "capture", "model", "to", "generate", "raw", "images", "(", "Simulated", "Raw", ")", ",", "which", "are", "then", "processed", "using", "our", "software", "ISP", "model", "to", "generate", "RGB", "images", "(", "Simulated", "RGB", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["The", "classifier", "is", "trained", "using", "a", "meta", "-", "loss", "objective", ",", "defined", "by", "the", "total", "computational", "cost", "of", "solving", "the", "reduced", "OPF", "problems", "constructed", "during", "the", "iterative", "procedure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Furthermore", ",", "most", "families", "reported", "the", "SAR", "system", "to", "be", "useful", "and", "adaptable", ",", "and", "correspondingly", ",", "all", "users", "were", "engaged", "for", "a", "majority", "of", "the", "in", "-", "home", "intervention", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["G", "-", "mean", "of", "training", "set", "is", "chosen", "as", "the", "objective", "to", "be", "maximized", "for", "ECS", "-", "DBN", "on", "training", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "FCA", "resources", "are", "replaced", "by", "NGCC", "located", "at", "the", "Hub", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward capacity auctions"}, {"tokens": ["Due", "to", "the", "incomplete", "CSI", ",", "it", "is", "intractable", "to", "derive", "the", "exact", "closed", "-", "form", "expression", "of", "the", "data", "rate", "for", "each", "UE", ",", "and", "thus", "stringent", "QoS", "requirements", "for", "each", "UE", "are", "difficult", "to", "be", "guaranteed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "the", "SBM", ",", "the", "elements", "of", "are", "independent", "of", "each", "other", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "first", "method", "is", "designed", "for", "finding", "visually", "similar", "images", "without", "the", "need", "of", "labels", "and", "is", "based", "on", "modeling", "image", "representations", "with", "a", "Gaussian", "Mixture", "Model", "(", "GMM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["LI", ":", "liver", ",", "ST", ":", "stomach", ",", "DU", ":", "duodenum", ",", "LK", ":", "left", "kidney", ",", "and", "RK", ":", "right", "kidney", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "right kidney"}, {"tokens": ["This", "constrained", "events", "to", "lie", "within", "a", "reasonable", "duration", "but", "did", "not", "learn", "a", "distribution", "on", "the", "duration", ",", "and", "allowed", "us", "to", "probe", "the", "extent", "of", "the", "benefit", "provided", "by", "the", "GMM", "duration", "prior", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Object", "detection", "performance", "measured", "by", "average", "precision", "per", "class", "(", "AP", ")", "at", "IoU", "levels", ",", "and", "and", "resulting", "mean", "average", "precision", "(", "mAP", ")", "for", "each", "deep", "learning", "classifierSimilarly", "to", "the", "classification", "task", ",", "model", "2", "performs", "best", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["LBP", ",", "with", "full", "parallelism", ",", "demonstrates", "only", "partial", "convergence", ",", "while", "RS", "is", "able", "to", "extend", "convergence", ",", "given", "time", ",", "by", "reducing", "parallelism", "(", ",", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["In", "practice", ",", "theWiFi", "rate", "function", "and", "LTE", "rate", "function", "are", "dependent", "on", "their", "MCSs", "and", "bandwidth", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["As", "shown", "by", ",", "we", "need", "an", "overarching", "framework", "to", "help", "us", "\"", "reconstruct", "the", "whole", "debate", ",", "understand", "its", "main", "issues", ",", "and", "hence", "offer", "a", "starting", "point", "for", "better", "ways", "of", "designing", "RS", "and", "regulating", "their", "use", "\"", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["A", "heuristic", "that", "guides", "the", "development", "of", "neural", "baseline", "systems", "for", "the", "extractive", "QA", "task", "is", "described", "in", ",", "which", "serves", "as", "guideline", "for", "the", "development", "of", "two", "neural", "baseline", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["OT", "invocations", ")", "."], "acronym_pos": [1, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Table", "summarizes", "the", "average", "GPR", "achieved", "over", "all", "KBP", "-", "generated", "plans", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gamma passing rate"}, {"tokens": ["Gradient", "signal", "alignmentWhen", "investigating", "FA", "in", "shallow", "feedforward", "networks", ",", "observed", "that", "as", "training", "progressed", ",", "the", "signal", "calculated", "in", "FA", "and", "the", "gradient", "used", "by", "BP", "are", "roughly", "orthogonal", "at", "initialization", "but", "that", "the", "angle", "between", "them", "converges", "to", "approximately", "by", "the", "end", "of", "training", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["In", "addition", ",", "there", "is", "no", "impact", "of", "on", "SC", "of", "CNMOMA", "-", "SWIPT", "-", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["Union", "pairs", "of", "HJ", ",", "RT", "and", "AE", "datasets", "into", "the", "MJ", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ruthes"}, {"tokens": ["Question", "answering", "(", "QA", ")", "systems", "can", "directly", "benefit", "from", "this", "novel", "approaches", ",", "because", "it", "only", "requires", "mapping", "between", "questions", "and", "their", "answers", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["[", "]", "Experiment", "results", "for", "state", "-", "of", "-", "the", "-", "art", "QA", "models", "demonstrating", "degrading", "performance", "under", "spoken", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["For", "brevity", ",", "we", "put", "the", "descriptions", "of", "dividing", "two", "sets", "in", "the", "detection", "task", ",", "related", "work", "(", "partial", ")", ",", "background", "knowledge", "on", "OT", "theory", "and", "additional", "experiments", "in", "the", "appendix", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Since", "the", "phase", "-", "shifting", "error", "and", "gain", "error", "are", "unknown", "to", "the", "BS", ",", "they", "ca", "n't", "be", "compensated", "in", "the", "baseband", "domain", "and", "the", "practical", "digital", "beamforming", "matrix", "has", "no", "relation", "with", "the", "phase", "-", "shifting", "error", "and", "gain", "error", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["DI", "is", "an", "implementation", "of", "Inverse", "of", "Control", "(", "IoC", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dependency injection"}, {"tokens": ["MetricsWe", "use", "COCO", "API", "to", "measure", "AP", "over", "IOU", "thresholds", "of", "0.5", "and", "0.75", "as", "well", "as", "the", "average", "AP", "over", "IOUs", "in", "the", "range", "0.5:.05:0.95", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["In", "the", "absence", "of", "real", "LR", "images", "with", "annotated", "landmarks", ",", "this", "is", "done", "to", "create", "a", "substitute", "for", "low", "resolution", "dataset", "with", "annotations", "on", "which", "localization", "performance", "can", "be", "evaluated", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Even", "though", "our", "proposed", "method", "has", "only", "seen", "healthy", "subjects", "with", "normally", "sized", "ventricles", "during", "training", "it", "managed", "to", "properly", "reconstruct", "the", "CST", "and", "the", "OR", "which", "are", "heavily", "distorted", "by", "the", "enlarged", "ventricles", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optic radiation"}, {"tokens": ["The", "improvement", "on", "log", "expected", "test", "likelihood", "per", "test", "point", "compared", "to", "GMM", ",", "when", "using", "same", "as", "base", "measure", "for", "the", "VB", "inference", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["PS", "Architecture", "."], "acronym_pos": [1, 0, 0], "long_form": "parameter server"}, {"tokens": ["Moreover", ",", "likelihoods", "depend", "on", "all", "the", "infinitely", "many", "GP", "function", "values", "in", "the", "domain", "rather", "than", "on", "the", "finite", "number", "of", "function", "values", "at", "observed", "data", "points", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Our", "two", "algorithms", "IA", "(", "for", "incremental", "approximation", ")", "and", "IAW", "(", "for", "IA", "weighted)work", "for", "unweighted", "and", "weighted", "networks", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "incremental approximation"}, {"tokens": ["LTE", "Wi", "-", "Fi", "Co", "-", "existence", "Deployment", "Setup", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Performance", "of", "the", "system", "is", "higher", "when", "the", "PLDA", "based", "classifier", "is", "used", "versus", "that", "for", "the", "GMM", "-", "UBM", "based", "classifier", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Dominating", "frequency", "of", "droplet", "'s", "MR", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0], "long_form": "morphological richness"}, {"tokens": ["In", "the", "IHDP", "case", ",", "we", "see", "reductions", "in", "the", "error", "in", "estimating", "the", "ACE", "up", "to", "0.58", "for", "in", "-", "sample", "predictions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average causal effect"}, {"tokens": ["Training", "Datasets", "for", "the", "QA", "systemFor", "our", "QA", "system", "we", "used", "the", "DBpedia", "repository", "and", "the", "Subtitles", "corpus", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["powergraphBy", "providing", "a", "measure", "of", "information", "loss", ",", "previous", "subsection", "focuses", "on", "the", "objective", "function", "of", "the", "GCP", ",", "that", "is", "on", "the", "quality", "measure", "to", "be", "optimised", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph compression problem"}, {"tokens": ["It", "forces", "the", "DG", "community", "to", "be", "closer", "to", "the", "negative", "class", "whereas", "the", "FG", "community", "is", "placed", "further", "away", "from", "the", "negative", "class", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "favoured granted"}, {"tokens": ["There", "are", "no", "HEP", "journals", "included", ",", "so", "administrators", "can", "see", "that", "their", "institution", "is", "above", "world", "average", ",", "and", "going", "upwards", ",", "no", "matter", "whether", "you", "look", "at", "the", "AA", "or", "the", "PSS", "category", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "astronomy and astrophysics"}, {"tokens": ["In", "this", "history", "of", "mobile", "AR", "we", "considered", "both", "definitions", "and", "the", "evolution", "of", "the", "term", "over", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["In", "BA", "model", ",", "appearance", "of", "new", "connections", "totally", "depends", "on", "the", "addition", "of", "new", "nodes", "to", "the", "system", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "barabasi albert"}, {"tokens": ["Since", "the", "high", "frequency", "components", "are", "missing", "in", "the", "observation", "space", ",", "usually", "training", "examples", "are", "used", "to", "predict", "the", "most", "likely", "HR", "output", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "high - resolution"}, {"tokens": ["First", ",", "each", "user", "can", "directly", "transmit", "result", "data", "to", "the", "BS", "after", "local", "computation", "in", "FDMA", ",", "while", "the", "wireless", "transmission", "should", "be", "performed", "after", "the", "local", "computation", "for", "all", "users", "in", "TDMA", ",", "which", "needs", "a", "longer", "time", "compared", "to", "FDMA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "can", "see", "that", "the", "SHAMO", "performs", "better", "than", "STL", "but", "worse", "than", "ITL", "which", "shows", "that", "learning", "these", "tasks", "separately", "is", "beneficial", "than", "combining", "them", "to", "learn", "a", "fewer", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "single task learning"}, {"tokens": ["The", "second", "definition", "only", "replies", "on", "the", ",", "i.e.", ",", "predicting", "the", "MVF", "from", "conditional", "features", "without", "any", "prior", "knowledge", "of", "the", "voicing", "status", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["binomial", "shows", "the", "average", "running", "time", "versus", "the", "number", "of", "buckets", "for", "BMS", "and", "RB", "-", "sort", "with", "binomial", "and", "uniform", "distributions", ",", "on", "our", "Tesla", "K40c", "(", "ECC", "off", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["Kuo", ",", "proposed", "a", "hybrid", "optimization", "algorithm", "using", "simulated", "annealing", "and", "PSO", "called", "SA", "-", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0], "long_form": "power system operations"}, {"tokens": ["The", "reduction", "is", "also", "significant", "for", "ensemble", "learners", ":", "up", "to", "three", "order", "of", "magnitude", "for", "Ba", "-", "DT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "decision tree"}, {"tokens": ["As", "such", ",", "a", "comparison", "of", "our", "method", "'s", "performance", "with", "the", "performance", "of", "CF", "for", "users", "for", "whom", "there", "is", "some", "existing", "editing", "history", ",", "allows", "us", "to", "gauge", "how", "far", "we", "are", "from", "a", "potentially", "unattainable", "high", "level", "of", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["When", "the", "robot", "needs", "to", "adapt", ",", "a", "BO", "algorithm", "searches", "for", "the", "best", "policy", "in", "the", "low", "-", "dimensional", "map", "and", "uses", "the", "reward", "stored", "in", "the", "map", "as", "the", "mean", "function", "of", "a", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["And", "the", "ZF", "precoder", "at", "the", "BS", "is", "given", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["When", "these", "are", "output", "from", "CTC", ",", "these", "trigger", "the", "generation", "of", "the", "appropriate", "compound", "character", "in", "a", "UNICODE", "compliant", "Bengali", "font", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["For", "\"", "with", "CF", "\"", "users", ",", "two", "of", "the", "remaining", "six", "were", "View", "-", "pop", ",", "two", "Edit", "-", "pop", ",", "and", "two", "CF", "-", "based", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Creating", "Noisy", "QuestionsWe", "took", "questions", "each", "from", "popular", "QA", "datasets", ",", "viz", ".", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Experimental", "SetupTo", "conduct", "an", "automatic", "comparative", "evaluation", ",", "we", "integrate", "Graphene", "into", "Stanovsky2016EMNLP", "'s", "Open", "IE", "benchmark", "framework", ",", "which", "was", "created", "from", "a", "QA", "-", "SRL", "dataset", "where", "every", "verbal", "predicate", "was", "considered", "as", "constituting", "an", "own", "extraction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["NP", "barra", "'", "lamb'PIr"], "acronym_pos": [1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["&", "7", "kg", "/", "LAP", "/", "30", "min", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "low altitude platform"}, {"tokens": ["We", "design", "a", "3D", "Faster", "R", "-", "CNN", "for", "nodule", "detection", ",", "and", "propose", "GBM", "with", "deep", "3D", "DPN", "features", ",", "raw", "nodule", "CT", "pixels", "and", "nodule", "size", "for", "nodule", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["ChallengesIn", "this", "section", "we", "present", "question", "answering", "challenges", "from", "four", "different", "aspects", "namely", ",", "(", "i", ")", "Speech", "-", "based", "interface", "challenge", ",", "(", "ii", ")", "query", "understanding", ",", "interpreting", ",", "disambiguating", "and", "parsing", "challenges", ",", "(", "iii", ")", "data", "-", "oriented", "challenges", "(", "iv", ")", "interoperability", "of", "QA", "components", "challenge", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Here", ",", "one", "of", "machine", "learning", "methods", ",", "Bayesian", "learning", "in", "is", "adopted", "to", "improve", "the", "measurement", "precision", "of", "DOA", "angles", ",", "which", "subsequently", "serves", "for", "designing", "the", "precoding", "vector", "and", "AN", "projection", "matrix", "at", "DM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["The", "resulted", "PNN", "should", "at", "least", "be", "as", "good", "as", "FNN", "or", "FM", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["This", "problem", "is", "formulated", "as", "a", "sum", "-", "rate", "maximization", "problem", "with", "proportional", "rate", "constraints", "by", "adjusting", "the", "users", "'", "transmit", "power", "and", "the", "BS", "'s", "decoding", "order", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "confusion", "matrix", "of", "DDE", "-", "MGM", "is", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Thus", "to", "compute", "the", "VAT", "loss", "for", "an", "episode", "we", "first", "generate", "the", "prototypes", "using", "the", "labelled", "points", ",", "with", "this", "we", "have", "a", "classifier", "and", "we", "can", "compute", "the", "VAT", "loss", "for", "an", "episode", ",", "where", "and", "is", "a", "hyperparameter", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["By", "utilising", "both", "and", "together", "in", "inferring", ",", "found", "that", "the", "two", "types", "of", "information", "can", "complement", "each", "other", ",", "and", "therefore", "their", "attribute", "SBM", "is", "useful", "for", "link", "prediction", "(", "Section", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["The", "error", "bars", "are", "set", "to", "(", "95", "of", "the", "measurements", "for", "the", "normal", "distribution)All", "-", "reduce", "PAP", "optimization", "for", "training", "of", "a", "deep", "neural", "networkIn", "this", "section", "we", "present", "a", "practical", "application", "of", "the", "proposed", "method", "for", "a", "deep", "learning", "iterative", "procedure", ",", "implemented", "using", "tiny", "-", "dnn", "open", "-", "source", "library", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["Most", "schemes", "developed", "in", "this", "paper", ",", "such", "as", "schemes", "RT", "to", "IO", "in", "Table", ",", "can", "achieve", "the", "optimal", "gain", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random target"}, {"tokens": ["The", "PS", "latency", "at", "Figure", "reduced", "by", "adding", "machines", "but", "latency", "after", "some", "point", "(", "the", "fifth", "machine", "in", "our", "experiment", ")", ",", "increased", "due", "to", "all", "-", "to", "-", "one", "communication", "and", "data", "overloading", "which", "leads", "to", "bottleneck", "on", "CPU", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["For", "the", "GP", "density", "model", "a", "Gaussian", "density", "is", "assumed", "as", "base", "measure", ",", "and", "hyperparameters", ",", "and", "are", "now", "optimised", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "code", "provided", "for", "DEC", "could", "only", "be", "parallelized", "over", "the", "GPU", ",", "while", "methods", "AEC", "and", "SC", "could", "only", "be", "executed", "over", "the", "CPUs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral clustering"}, {"tokens": ["Since", "the", "BS", "has", "high", "computation", "capacity", ",", "the", "latency", "of", "implementing", "Algorithm", "3", "at", "the", "BS", "will", "not", "affect", "the", "latency", "of", "the", "FL", "process", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Compared", "to", "canonical", "CF", ",", "these", "tasks", "also", "include", "a", "large", "amount", "of", "context", "which", "can", "be", "used", "to", "better", "predict", "user", "and", "item", "interaction", "events", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "goal", "is", "a", "vector", "of", "rewards", "that", "the", "parent", "expects", "the", "architecture", "will", "receive", "if", "the", "child", "can", "produce", "a", "projection", "which", "will", "cause", "the", "parent", "SP", "to", "produce", "a", "hidden", "state", "corresponding", "to", "the", "index", "of", "the", "goal", "value", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial pooler"}, {"tokens": ["Severe", "Sepsis", ",", "SK", "=", "Septic", "Shock", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0], "long_form": "septic shock"}, {"tokens": ["Hence", ",", "BC", "-", "BC", "correlation", "is", "used", "to", "find", "user", "'s", "route", "."], "acronym_pos": [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["eq", ":", "density", ",", "where", "is", "drawn", "from", "the", "GP", "prior", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["4", "illustrates", "the", "curves", "of", "average", "BER", "versus", "SNR", "for", "the", "three", "TAS", "methods", "described", "in", "Section", "-", "III", "with", ",", "where", "the", "random", "method", "is", "used", "for", "performance", "reference", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["Modelling", "The", "formulation", "of", "the", "SBM", "and", "the", "inference", "algorithm", "in", "Section", "relies", "on", "being", "specified", "beforehand", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Finally", ",", "we", "find", "that", "P2P", "and", "PS", "systems", "have", "load", "imbalance", "among", "peers", "because", "tensor", "size", "in", "each", "DNN", "layer", "is", "different", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["First", ",", "MD", "multi", "-", "scale", "-", "dilated", "encoder", "network", "generates", "multiple", "description", "tensors", ",", "which", "are", "discretized", "by", "scalar", "quantizers", ",", "while", "these", "quantized", "tensors", "are", "decompressed", "by", "MD", "cascaded", "-", "ResBlock", "decoder", "networks", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": [",", "SP", "OT", "are", "more", "interesting", "as", "they", "can", "explain", "BO", "(", "lines", "1", "-", "3", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "set point"}, {"tokens": ["This", "involves", "showing", "that", "the", "assignment", "computed", "by", "restricted", "to", "any", "such", "type", "is", "the", "same", "as", "the", "output", "of", "PS", "applied", "to", "the", "preference", "profile", "restricted", "to", "preferences", "over", "such", "a", "type", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["illustrates", "of", "chromosome", "encoding", "and", "evolution", "process", "in", "ECS", "-", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["The", "method", "achieved", "a", "CCR", "of", "99", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["We", "also", "compare", "against", "importance", "sampling", "as", "presented", "in", ",", "which", "we", "refer", "to", "as", "IS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "importance sampling"}, {"tokens": ["Machine", "LearningMachine", "learning", "techniques", "can", "be", "applied", "on", "images", "captured", "by", "UAVs", "to", "help", "in", "SAR", "operations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "search and rescue"}, {"tokens": ["Joint", "angle", "inaccuracies", "on", "the", "wrist", "of", "the", "slave", "-", "tool", "will", "cause", "inconsistency", "between", "the", "AR", "rendering", "and", "the", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Calculating", "CER", "error", "between", "words", "tymme", "and", "time", "using", "dynamic", "programming", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["This", "result", "on", "DBP", "automata", "has", "first", "been", "proved", "in", ",", "and", "then", "a", "more", "general", "version", "allowing", "lookahead", "was", "proved", "using", "a", "game", "-", "based", "approach", "in", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["The", "overall", "results", "in", "Table", "and", "illustrate", "that", "(", "i", ")", "FM", "outperforms", "LR", ",", "demonstrating", "the", "effectiveness", "of", "feature", "interactions", ";", "(", "ii", ")", "Neural", "networks", "outperform", "LR", "and", "FM", ",", "which", "validates", "the", "importance", "of", "high", "-", "order", "latent", "patterns", ";", "(", "iii", ")", "PNNs", "perform", "the", "best", "on", "both", "Criteo", "and", "iPinYou", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["We", "observed", "that", ":", "For", "a", "fixed", "number", "of", "processors", ",", "when", "number", "of", "applications", "increase", ",", "the", "difference", "between", "LB", "and", "makespan", "time", "decreases", "i.e.", "efficiency", "in", "time", "increases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lower bound"}, {"tokens": ["Including", "spectral", "information", "at", "the", "grouping", "stage", "might", "help", "to", "improve", "FR", "-", "such", "information", "could", "be", "provided", "by", "the", "classification", "back", "-", "end", ",", "in", "a", "similar", "approach", "to", "the", "baseline", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "frame recall"}, {"tokens": ["t", "]", "Performance", "for", "network", "size", "and", "In", "the", "first", "set", "of", "experiments", ",", "the", "network", "size", "is", "20", "(", "1", "BS", ",", "9", "CHs", ",", "and", "10", "RNs", ")", "and", "it", "is", "incremented", "by", "10", "up", "to", "60", "for", "subsequent", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Potential", "limitations", "of", "the", "GP", "density", "model", "are", "given", "by", "high", "dimensional", "problems", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["With", "the", "knowledge", "of", "its", "chosen", "input", "and", "the", "padded", "message", "that", "the", "receiver", "receives", "in", "the", "OT", "extension", "protocol", ",", "the", "malicious", "receiver", "recovers", "the", "value", "of", "the", "pad", "by", "finding", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Hence", ",", "adaptive", "and", "optimized", "PS", "ratios", "is", "mandatory", "for", "such", "scenarios", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["If", "necessary", ",", "for", "areas", "that", "are", "difficult", "to", "align", ",", "the", "user", "can", "actively", "add", "new", "landmarks", "based", "on", "the", "image", "context", "and", "visualization", "of", "the", "uncertainty", "measure", "provided", "by", "the", "GP", "to", "further", "improve", "the", "registration", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Black", "-", "DROPS", "with", "priors", "proposes", "a", "new", "GP", "learning", "scheme", "that", "combines", "model", "identification", "and", "non", "-", "parametric", "model", "learning", "(", "called", "GP", "-", "MI", ")", "and", "then", "performs", "policy", "search", "with", "Black", "-", "DROPS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "general", "expectation", "integral", "takes", "the", "formand", "considering", "we", "denote", "as", "the", "expected", "variational", "distribution", "over", "the", "output", "vector", ",", "that", "can", "be", "analytically", "calculated", "as", "followsAppendix", "B.", "Continual", "GP", "priorsSingle", "-", "output", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["In", "case", "of", "the", "OP", "of", "at", "CEU", ",", "EHS", "-", "CNOMA", "with", "MRC", "provides", "less", "OP", "than", "HS", "-", "CNOMA", "with", "SC", "due", "to", "MRC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "selection combining"}, {"tokens": ["Experiments", "show", "promising", "results", "for", "TS", "-", "RF", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["A", "cooperative", "jamming", "scheme", "was", "proposed", "in", "to", "enhance", "the", "PLS", ",", "and", "the", "authors", "analysed", "the", "impact", "of", "PA", "parameter", "between", "confidential", "information", "and", "AN", "by", "minimizing", "the", "secrecy", "outage", "probability", "subject", "to", "a", "minimum", "SR", "constraint", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["/", "A", "=", "no", "data", "availableTable", "is", "an", "excerpt", "from", "a", "table", "in", "our", "exhaustive", "survey", "of", "open", "QA", "systems(The", "full", "data", "collection"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["So", ",", "the", "capacity", "enhancement", "of", "CCU", "in", "case", "of", "proposed", "scheme", "can", "be", "achieved", "by", "utilizing", "an", "additional", "OAM", "channel", "to", "transmit", "from", "BS", "to", "CCU", "simultaneously", "in", "the", "first", "time", "slot", "which", "is", "shown", "in", "Fig.4", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["RSs", "researchers", "and", "developers", "have", "worked", "on", "incorporating", "the", "notions", "of", "diversity", ",", "popularity", "and", "serendipity", "in", "the", "evaluation", "of", "RS", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "recommender systems"}, {"tokens": ["We", "use", "the", "HOG", "descriptor", "for", "recognition", "of", "the", "postures", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "histogram of oriented gradient"}, {"tokens": ["The", "fraction", "of", "variance", "explained", "by", "each", "principal", "component", "for", "the", "CNS", "and", "MDC", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["During", "the", "second", "link", ",", "we", "employ", "the", "RS", "transmission", "scheme", ",", "in", "order", "to", "mitigate", "the", "saturation", "of", "the", "system", "at", "high", "SNR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["Most", "recently", ",", "image", "representation", "-", "based", "compression", "with", "CNNs", "has", "been", "extended", "for", "multiple", "description", "image", "generation", "to", "form", "a", "standard", "-", "compliant", "convolutional", "neural", "network", "-", "based", "MDC", "framework", ",", "which", "is", "trainable", "in", "an", "end", "-", "to", "-", "end", "fashion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["The", "variance", "across", "participants", "accounted", "for", "91", "of", "the", "total", "variance", ",", "indicating", "the", "importance", "of", "personalization", "in", "SAR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "socially assistive robots"}, {"tokens": ["(", ".south", "east", ")", "-", "(", ".south", "west", ")", ";", "[", "Classification", "of", "Path", "loss", "Models", "for", "UAVs", "[", "Altitude", "of", "UAV", "[", "LAP", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "low altitude platform"}, {"tokens": ["It", "is", "important", "to", "note", "that", "standard", "TS", "can", "not", "guarantee", "that", "grid", "reliability", "constraints", "are", "upheld", "during", "the", "learning", "process", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["The", "structure", "of", "this", "dataset", "is", "the", "same", "as", "the", "structure", "of", "the", "RT", "dataset", ":", "each", "source", "word", "has", "the", "same", "number", "of", "related", "and", "unrelated", "target", "words", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ruthes"}, {"tokens": ["After", "correcting", "the", "global", "shift", "of", "the", "LED", "array", ",", "all", "LR", "images", "are", "used", "to", "reconstruct", "the", "HR", "images", "of", "the", "sample", "using", "the", "conventional", "FPM", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Our", "experimental", "results", "show", "that", "TS", "based", "algorithms", "always", "perform", "better", "than", "UCB", "based", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["One", "of", "the", "main", "goals", "of", "this", "technology", "is", "to", "provide", "ubiquitous", "connectivity", "as", "well", "as", "to", "allow", "efficient", "vehicle", "-", "to", "-", "vehicle", "communications", ",", "which", "is", "necessary", "to", "implement", "an", "Intelligent", "Transportation", "Systems", "(", "ITS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "intelligent transportation system"}, {"tokens": ["In", "this", "case", ",", "the", "likelihood", "part", "of", "the", "resulting", "'", "-function", "'", "that", "needs", "to", "be", "maximised", "in", "the", "M", "-", "step", "becomes", "(", "as", "in", "the", "variational", "approach", "before", ")", "the", "likelihoodof", "a", "Gaussian", "model", "in", "the", "GP", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["we", "have", "that", "the", "theoretically", "maximum", "AR", "and", "EL", "are", "both", "3000", "due", "to", "our", "episode", "termination", "criterion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "accumulated reward"}, {"tokens": ["Next", ",", "we", "apply", "this", "adaptive", "skills", "similarity", "technique", "to", "a", "dataset", "of", "over", "6.7", "million", "Australian", "job", "ads", "in", "order", "to", "identify", "occupations", "with", "the", "highest", "proportions", "of", "DSA", "skills", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["we", "investigate", "the", "impact", "of", "the", "decoding", "error", "probability", "requirement", "of", "the", "vehicles", "on", "the", "TTP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "total transmit power"}, {"tokens": ["In", "plot", ":", "gyrate", "the", "average", "radii", "of", "gyration", "obtained", "from", "HMC", "(", "left", ")", "and", "MD", "(", "right", ")", "simulations", "using", "different", "integrators", "and", "different", "values", "of", "simulation", "step", "sizes", "and", "trajectory", "lengths", "are", "presented", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["Many", "efforts", "have", "been", "devoted", "in", "order", "to", "reduce", "the", "time", "complexity", "of", "MT", "-", "GPR", "for", "large", "output", "spaces", "(", "i.e.", ",", "large", ")", "low", "-", "rank", "approximation", "and", "properties", "of", "Kronecker", "product", "alvarez2009sparse", ",", "stegle2011efficient", ",", "rakitsch2013all", ",", "kia2018normative", ",", "kia2018scalable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process regression"}, {"tokens": ["Interpolate", "the", "coefficients", "from", "step", "using", "a", "GP", "to", "obtain", "a", "function", "of", "the", "inputs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["MAD", "extension", "and", "feature", "boosting", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["A", "scenario", "refers", "to", "each", "pair", "of", "learning", "algorithm", "and", "performance", "indicator", "of", "a", "software", ",", "e.g.", ",", "using", "LR", "to", "predict", "the", "throughput", "of", "ASOS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear regression"}, {"tokens": ["Additionally", ",", "we", "give", "affine", "invariant", "extensions", "of", "the", "MP", "and", "FW", "algorithm", "variants", ",", "as", "well", "as", "convergence", "rates", "in", "terms", "of", "affine", "invariant", "quantities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["Its", "main", "merit", "is", "in", "taking", "into", "account", "true", "negatives", "(", "accuracy", "or", "do", "not", ")", ",", "which", "makes", "MCC", "especially", "useful", "when", "negative", "examples", "are", "the", "minority", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["Hence", ",", "we", "choose", "OPIUM", "-", "B", "algorithm", "as", "OCC", "for", "machine", "health", "monitoring", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "one class classifier"}, {"tokens": ["a", ")", "ROC", "curves", "for", "mel", ",", "sk", ",", "and", "nev", "classes", "for", "ISIC-2017", "test", "dataset", "and", "b", ")", "ROC", "curves", "for", "mel", "and", "nev", "classes", "for", "PH2", "dataset", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "underlying", "output", "latent", "function", "is", "generated", "from", "a", "GP", "prior", "with", "a", "Matern", "kernel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["For", "this", "purpose", ",", "we", "used", "a", "fixed", "single", "value", "for", "the", "number", "of", "factors", "(", "pLSA", ")", "and", "the", "number", "of", "Gaussians", "(", "GMM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Transforming", "each", "sentence", "of", "the", "dataset", ",", "our", "DisSim", "approach", "reaches", "the", "highest", "splitting", "rate", "among", "the", "TS", "systems", "under", "consideration", ",", "together", "with", "Hybrid", ",", "DSS", "and", "SENTS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["The", "DOE", "is", "designed", "as", "a", "distorted", "phase", "gratings", ",", "also", "referred", "to", "as", "a", "multifocal", "gratings", "(", "MFG", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "diffractive optical element"}, {"tokens": ["Receptive", "Field", "in", "DCNNs", "Receptive", "field", "is", "an", "important", "concept", "in", "the", "DCNN", ",", "which", "determines", "the", "sensing", "space", "of", "a", "convolutional", "neuron", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["-.5emResource", "Allocation", "for", "FL", "Completion", "Time", "Minimization-.5emIn", "this", "section", ",", "we", "consider", "the", "special", "case", "of", "delay", "sensitive", "scenarios", ",", "where", "the", "completion", "time", "of", "the", "FL", "algorithm", "is", "more", "important", "than", "the", "energy", "consumption", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["The", "provisional", "labels", "and", "pixel", "positions", "are", "associated", "with", "the", "thread", "ID", "within", "a", "threads", "block", "as", "is", "shown", "in", "the", "steps", "of", "Algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "input data"}, {"tokens": ["User", "'s", "data", "rate", "is", "maximized", "by", "selecting", "the", "shortest", "path", "whose", "nodes", "are", "the", "least", "BC", "-", "BC", "correlated", "with", "its", "neighbors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["Another", "work", "that", "lends", "itself", "for", "comparison", "is", ",", "when", "considered", "for", "similar", "BS", "and", "UE", "power", "as", "well", "as", "node", "density", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Sublinear", "MP", "ratesthm", ":"], "acronym_pos": [0, 1, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["Conversely", ",", "for", "time", "-", "series", "data", ",", "RF", "is", "2.2", "better", "for", "Mixed", "-", "InGame", "data", "yet", "LR", "is", "5", "better", "for", "Pro", "-", "InGame", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["We", "would", "obviously", "discard", "this", "system", "and", "not", "use", "the", "questions", "generated", "by", "it", "to", "train", "a", "QA", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["In", "this", "case", ",", "solving", "the", "RLAP", "is", "equivalent", "to", "solving", "a", "LAP", "with", "size", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "linear assignment problem"}, {"tokens": ["KHARMA", "is", "a", "lightweight", "and", "open", "architecture", "for", "referencing", "and", "delivering", "content", "explicitly", "aiming", "for", "mobile", "AR", "applications", "running", "on", "a", "global", "scale", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["The", "PS", "training", "is", "proceeding", "at", "the", "speed", "of", "the", "slowest", "machine", "in", "any", "iteration", "with", "a", "synchronous", "model", "while", "an", "asynchronous", "model", "overcome", "strugglers", "node", "who", "degrade", "the", "training", "speed", "but", "asynchronous", "model", "may", "affect", "the", "general", "model", "accuracy", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["cnn_arc", "denotes", ":", "BN", "for", "batch", "normalization", ",", "BB", "-", "a", "basic", "block", ",", "MP", "-", "max", "pooling", "with", "kernel", "size", "and", "stride", ",", "for", "convolutions", "-", "a", "number", "of", "input", "and", "output", "channels", ",", "a", "kernel", "size", ",", "a", "stride", "and", "a", "padding", "respectively", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "max pooling"}, {"tokens": ["In", "the", "case", "of", "MRI", "reconstruction", ",", "the", "goal", "of", "the", "generator", "is", "to", "learn", "the", "mapping", "between", "the", "data", "distribution", "of", "the", "ZF", "image", "(", ")", "and", "FS", "image", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "fully sampled"}, {"tokens": ["PSO", "for", "Optimal", "Bandwidth"], "acronym_pos": [1, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["This", "work", "is", "related", "to", "which", "proposesthat", "LTE", "small", "cells", "use", "the", "licensed", "-", "exempt", "TV", "whitespace", "band", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["It", "was", "verified", "analytically", "and", "via", "simulations", "that", "the", "gain", "of", "the", "PS", "protocol", "is", "superior", "to", "that", "of", "the", "TS", "protocol", "in", "terms", "of", "outage", "probability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Differential", "fault", "includes", "two", "types", ":", "classic", "DFA", "and", "sign", "change", "FA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "fault attack"}, {"tokens": ["Because", "the", "MDC", "may", "be", "limited", "in", "functionality", ",", "the", "usage", "of", "the", "Dispatcher", "enables", "further", "flexibility", "in", "the", "setup", "of", "the", "rest", "of", "the", "system", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "metering data collector"}, {"tokens": ["IEEEtranAppendixConfusion", "Matrix", "of", "our", "proposed", "method", "for", "5", "Class", "Classification", "on", "SC", "-", "taskImplementation", "Details", "of", "Proposed", "ArchitectureImplementation", "Details", "of", "Proposed", "Architecture", "(", "Continued", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subset compared"}, {"tokens": ["caurat-", "MP", "cehel", "NP", "cihil", "'", "forty", "'", ",", "Judeo", "-", "Tati", "cul", ",", "cf", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["In", "the", "field", "of", "SAR", "image", "interpretation", ",", "various", "kind", "of", "tasks", ",", "such", "as", "image", "classification", ",", "reconstruction", ",", "target", "detection", "and", "recognition", ",", "are", "solved", "individually", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["illustrates", "a", "block", "diagram", "of", "a", "SAR", "system", "utilizing", "UAVs", "in", "conjunction", "with", "machine", "learning", "technology", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["The", "intuitive", "meaning", "of", "variational", "IB", "is", "clear", ":", "the", "larger", "the", "-divergence", "between", "and", ",", "the", "stronger", "the", "dependence", "between", "and", ",", "indicating", "that", "encodes", "more", "information", "from", ",", "in", "which", "case", "some", "of", "them", "might", "be", "not", "task", "-", "related", "and", "therefore", "harmful", "to", "the", "adaptation", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["c", "c", "c", "c", "c", "c", "c", "&", "3cDice", "&", "3cHausdorff", "&", "ET", "&", "WT", "&", "TC", "&", "ET", "&", "WT", "&", "TC", "Development", "set", "&", "0.671", "&", "0.869", "&", "0.685", "&", "7.145", "&", "6.410", "&", "9.584", "Validation", "set", "&", "0.714", "&", "0.877", "&", "0.637", "&", "5.434", "&", "8.343", "&", "11.173Results", "for", "BraTS", "2017", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["On", "the", "task", "of", "orientation", "estimation", ",", "evaluated", "as", "AOS", "on", "the", "test", "server", ",", "our", "method", "outperforms", "all", "other", "methods", "on", "the", "benchmark", "across", "all", "difficulties", ",", "and", "produces", "the", "highest", "OS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "orientation score"}, {"tokens": ["Due", "to", "the", "increasing", "values", "of", ",", "the", "channel", "condition", "between", "BS", "to", "CCU", "is", "degrading", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Firstly", ",", "our", "methods", "(", "both", "and", ")", "always", "outperform", "the", "others", "significantly", ",", "in", "terms", "of", "both", "ACC", "and", "NMI", ",", "on", "all", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "accuracy"}, {"tokens": ["The", "objective", "of", "TR", "is", "to", "find", "the", "time", "-", "domain", "signal", "to", "be", "added", "to", "the", "original", "time", "-", "domain", "signal", "to", "reduce", "the", "PAPR", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tone reservation"}, {"tokens": ["This", "enables", "the", "generator", "to", "generate", "realistic", "heatmaps", "for", "un", "-", "annotated", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["Motivated", "by", "this", "observation", ",", "we", "employ", "GM", "and", "LoG", "features", "to", "represent", "the", "local", "spatial", "contrast", "information", "in", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient magnitude"}, {"tokens": ["Therefore", ",", "the", "proposed", "ECS", "-", "DBN", "can", "provide", "better", "performances", "on", "minority", "class", "as", "well", "as", "those", "on", "majority", "class", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["eq", ":", "augmented", "likelihood", "we", "obtain", "the", "joint", "posterior", "over", "the", "GP", ",", "the", "rate", "scaling", ",", "the", "marked", "Poisson", "process", ",", "and", "the", "Polya", "-", "Gamma", "variables", "at", "the", "observations", "asIn", "the", "following", ",", "this", "new", "representation", "will", "be", "used", "to", "derive", "two", "inference", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["By", "considering", "the", "approximations", "of", "sum_snr_expand", ",", "eqcons1", ",", "and", "eqcons2", "and", "given", "a", "fixed", "value", "of", ",", "we", "can", "formulate", "the", "GP", "approximated", "subproblem", "at", "the", "iteration", "of", "the", "SCA", "for", "the", "max", "sum", "utility", "as", "follows", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["In", "this", "paper", ",", "we", "demonstrate", "the", "way", "our", "PNN", "models", "learn", "local", "dependencies", "and", "high", "-", "order", "feature", "interactions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Many", "intelligent", "tutoring", "systems", "(", "ITS", ")", "use", "mastery", "learning", "within", "the", "Knowledge", "Tracing", "framework", ":", "making", "students", "work", "on", "a", "given", "skill", "until", "the", "system", "infers", "that", "they", "have", "mastered", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intelligent tutoring systems"}, {"tokens": ["The", "work", "presented", "in", "proposed", "a", "continuous", "time", "and", "discrete", "time", "EH", "scheme", "based", "on", "TS", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "time switching"}, {"tokens": ["We", "illustrate", "this", "using", "the", "Bernoulli", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "construction", "of", "the", "RB", "from", "large", "sets", "of", "snapshots", "is", "computationally", "intense", ",", "as", "much", "data", "needs", "to", "be", "processed", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["We", "also", "found", "that", "RA", "achieves", "better", "performance", "due", "to", "the", "efficient", "use", "of", "network", "bandwidth", "and", "overlapping", "computation", "and", "communication", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["Comparing", "CMA", "-", "ES", "-", "SB", "with", "CMA", "-", "ES", "using", "ideal", "separation", "by", "brute", "force", "symmetry", "breaking", "(", "CMA", "-", "ES", "-", "SB", "-", "BF", ")", "on", "the", "syn5", ",", "sinc", "and", "inc", "-", "sinc", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "brute force search"}, {"tokens": ["Other", "applications", "include", ",", "who", "found", "out", "that", "their", "ICL", "criterion", "did", "not", "manage", "to", "select", "a", "reasonably", "small", "under", "their", "SBM", "with", "conditional", "Poisson", "processes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["In", "addition", ",", "we", "show", "that", "the", "integration", "of", "POS", "information", "in", "RNN", "models", "is", "useful", "to", "build", "multilingual", "coarse", "-", "grain", "semantic", "(", "Super", "Senses", ")", "taggers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["We", "therefore", "present", "a", "small", "comparison", "for", "image", "-", "to", "-", "image", "translation", "of", "T1-", "and", "T2-weighted", "MR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["In", "the", "adopted", "design", ",", "sensor", "nodes", "occupy", "lower", "layer", "and", "they", "primarily", "collect", "data", "of", "interest", "and", "relay", "information", "to", "upper", "layer", "devices", "(", "RN", "or", "CH", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "cluster head"}, {"tokens": ["On", "average", ",", "we", "see", "relative", "improvements", "of", "the", "accuracy", ",", "ranging", "from", "to", ",", "when", "applying", "our", "proposed", "method", "of", "fine", "-", "tuning", "for", "DST", "domain", "transfer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["A", "Receiver", "Operating", "Characteristic", "(", "ROC", ")", "curve", "is", "used", "to", "evaluate", "all", "the", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["@X", "rrrrr@", "&", "N", "&", "&", "&", "&", "CNS", "&", "850", "&", "16", "s", "&", "24", "months", "&", "10", "m", "&", "0.84", "MDC", "&", "185", "&", "60", "s", "&", "19", "months", "&", "100", "-", "200", "m", "&", "0.73", "Characteristics", "of", "the", "mobility", "datasets", "considered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["The", "number", "of", "samples", "collected", "per", "second", "by", "the", "LTE", "-", "U", "BS", "is", "about", "192", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["VSM", "-", "Vacationing", "Server", "Model", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "vacationing server model"}, {"tokens": ["Here", "again", ",", "the", "MINT", "-", "FEC", "performs", "better", "than", "the", "others", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["modelwhere", "is", "the", "Poisson", "process", "density", "over", "sets", "of", "point", "with", "and", "is", "a", "GP", "density", "with", "mean", "and", "covariance", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "this", "paper", ",", "we", "propose", "a", "different", "RV", "representation", "using", "the", "configuration", "of", "the", "LiDAR", ",", "and", "demonstrate", "that", "it", "leads", "to", "better", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "range view"}, {"tokens": ["DBN", "is", "trained", "by", "greedy", "unsupervised", "layer", "-", "wise", "pre", "-", "training", "and", "discriminative", "supervised", "fine", "-", "tuning", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "regret", "minimization", "phase", "of", "adapts", "Multiple", "-", "Play", "Thompson", "Sampling", "(", "MP", "-", "TS", ")", "for", "our", "setting", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["The", "results", "indicate", "that", "the", "universal", "conclusions", "about", "transfer", "learning", "in", "natural", "images", "can", "not", "be", "completely", "applied", "to", "SAR", "targets", ",", "and", "the", "analysis", "of", "what", "and", "where", "to", "transfer", "in", "SAR", "target", "recognition", "is", "helpful", "to", "decide", "how", "to", "transfer", "more", "effectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Under", "assumptions", "-", ",", "with", "in", "equations", "prob1-prob3", "chosen", "such", "that", ",", "with", "probability", ",", "the", "Con", "-", "TS", "-", "RTP", "algorithm", "with", "Constraint", "Set", "B", "will", "uphold", "the", "probabilistic", "distribution", "system", "constraints", "as", "formulated", "in", "NOTclairvoyant_constraint", "for", "each", "day", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Also", ",", "as", "the", "output", "power", "increases", ",", "the", "DC", "value", "of", "gradually", "declines", "from", "OCC", "voltage", "to", "MPP", "voltage", ",", "and", "the", "amount", "of", "100", "Hz", "ripple", "seen", "in", "and", "tends", "to", "increase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "open circuit condition"}, {"tokens": ["In", "addition", ",", "we", "show", "that", "RS", "with", "perfect", "CSIT", "for", "both", "FD", "and", "HD", "increase", "with", "without", "bound", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["Therefore", ",", "the", "problem", "is", "usually", "solved", "by", "maximizing", "the", "IB", "Lagrangian", "with", "adaptations", "of", "the", "Blahut", "-", "Arimoto", "algorithm", ",", "deterministic", "annealing", "approaches", "or", "a", "bottom", "-", "up", "greedy", "agglomerative", "clustering", "or", "its", "improved", "sequential", "counterpart", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["If", "we", "take", "the", "rates", "of", "the", "devices", "at", "the", "point", "where", "the", "CC", "phase", "ends", ",", "we", "find", "that", "AC", "charging", "rates", "of", "the", "new", "batteries", "of", "Galaxy", "S2", ",", "S3", ",", "and", "S4", "are", "0.38", ",", "0.44", ",", "and", "0.59", "C", "respectively", "which", "are", "very", "close", "to", "the", "measured", "rates", "presented", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["For", "a", "given", "sampling", "time", "window", "w", ",", "our", "discrete", "-", "time", "series", "may", "result", "in", "different", "sequences", "depending", "on", "whether", "we", "choose", "an", "AP", "or", "a", "building", "as", "the", "level", "of", "spatial", "resolution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["This", "is", "independent", "of", "the", "extended", "sufficient", "condition", "(", "E", "-", "SC", ")", "that", "we", "now", "introduce", ";", "as", "we", "will", "see", ",", "this", "condition", "does", "n't", "help", "us", "for", "joint", "uniform", "noise", "robustness", "and", "cost", "sensitivity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "symmetry condition"}, {"tokens": ["Although", "several", "studies", "have", "attempted", "to", "explore", "how", "to", "transfer", "knowledge", "from", "optical", "to", "SAR", "images", ",", "even", "the", "rationality", "of", "this", "transfer", "is", "still", "under", "debate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["In", "Section", "III", ",", "we", "design", "the", "information", "beamforming", "matrix", "and", "AN", "beamformingmatrix", "to", "maximize", "the", "worst", "-", "case", "system", "sum", "secrecy", "rate", "with", "the", "VMD", "-", "SSRM", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["For", "training", "with", "distractors", ",", "and", "are", "0", ",", "and", "the", "VAT", "is", "12", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["Our", "method", "uses", "the", "sum", "of", "two", "metrics", "as", "a", "reward", ":", "MDR", "CCR", "and", "Rule", "Utility", "yang2018multiple", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["Both", "NOMA", "and", "EH", "are", "in", "operation", "in", "the", "last", "K", "phases", "where", "MTCGs", "transmit", "data", "to", "the", "BS", "and", "simultaneously", "MTCDs", "harvest", "energy", "from", "all", "MTCGs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Adopting", "QA", ",", "our", "algorithm", "iteratively", "performs", "two", "parts", ",", "as", "shown", "in", "Alg", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "quantum annealing"}, {"tokens": ["A", "beacon", "sent", "by", "the", "AP", "will", "announce", "the", "maximum", "number", "of", "STAs", "that", "are", "allowed", "to", "transmit", "in", "parallel", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Regarding", "RS", "image", "classification", ",", "OTB", "already", "implement", "a", "number", "of", "algorithms", "in", "its", "classification", "application", ",", "e.g.", "SVM", ",", "Random", "Forests", ",", "boost", "classifier", ",", "decision", "tree", "classifier", ",", "gradient", "boosted", "tree", "classifier", ",", "normal", "Bayes", "classifier", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["b", ")", ":", "Commercial", "AR", "museum", "guide", "by", "METAIO", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["indicated", "that", "the", "large", "scale", "of", "unlabeled", "SAR", "scene", "data", "can", "be", "reconstructed", "with", "training", "a", "stacked", "convolution", "auto", "-", "encoders", "of", "which", "the", "stacked", "convolutional", "layers", "are", "capable", "to", "transfer", "to", "SAR", "target", "recognition", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Basically", ",", "DE", "moves", "the", "candidate", "solutions", "around", "the", "search", "space", "by", "using", "simple", "mathematical", "formulae", "to", "combine", "the", "positions", "of", "existing", "solutions", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["We", "propose", "to", "link", "the", "evolution", "of", "the", "fee", "to", "the", "increase", "of", "the", "world", "GDP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gross domestic product"}, {"tokens": ["mostellar:64", "pioneered", "the", "statistical", "approach", "to", "AA", "by", "using", "functional", "and", "non", "-", "contextual", "words", "to", "identify", "authors", "of", "disputed", "\"", "Federalist", "Papers", ",", "\"", "written", "by", "three", "American", "congressmen", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["A", "comparison", "between", "HAP", "and", "LAP", "is", "presented", "in", "Table", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "high altitude platform"}, {"tokens": ["litreview", "summarizes", "some", "of", "the", "most", "important", "review", "papers", "to", "date", "where", "AI", ",", "SA", "and", "ANN", "stand", "for", "Artificial", "Intelligence", ",", "Signal", "Analysis", "and", "Artificial", "Neural", "Networks", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Similar", "to", "Algorithm", "3", "in", "Section", "III", ",", "Algorithm", "4", "is", "done", "at", "the", "BS", "side", "before", "executing", "the", "FL", "scheme", "in", "Algorithm", "1", ",", "which", "will", "not", "affect", "the", "latency", "of", "the", "FL", "process", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Hence", ",", "in", "the", "proposed", "strategy", ",", "a", "node", "with", "low", "BC", "is", "chosen", "for", "rewiring", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["We", "derive", "the", "deterministic", "SINRs", "of", "NoRS", "and", "RS", "in", "multipair", "FD", "systems", "with", "imperfect", "CSIT", "and", "use", "them", "to", "investigate", "the", "performance", "benefits", "of", "RS", "over", "NoRS", "in", "the", "presence", "of", "SI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["After", "that", "an", "example", "of", "using", "the", "toolkit", "for", "prediction", "of", "chaotic", "time", "series", "is", "given", ",", "in", "which", "the", "parameters", "of", "fuzzy", "system", "are", "determined", "using", "PSO", "algorithm", "to", "have", "minimum", "mean", "square", "error", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Almost", "20", "years", "ago", ",", "already", "proposed", "the", "LeNet", ",", "a", "novel", "DCNN", "architecture", "for", "object", "recognition", ",", "but", "only", "in", "2012", "an", "implementation", "by", ",", "the", "AlexNet", ",", "was", "first", "able", "to", "beat", "more", "traditional", "geometrical", "approaches", "on", "the", "most", "popular", "object", "recognition", "contest", "-", "the", "ILSVRC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["During", "training", ",", "we", "choose", "Adam", "optimization", "to", "minimize", "the", "objective", "loss", "of", "our", "MDC", "framework", "with", "the", "initial", "learning", "rate", "of", "4e-3", "for", "our", "autoencoder", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["China", "Standard", "Time", "(", "CST", ")", "is", "UTC+08:00", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "china standard time"}, {"tokens": ["Thus", ",", "the", "protocol", "is", "reconfigured", "according", "to", "the", "statuses", "of", "the", "UEs", ":", "If", "mobility", "is", "low", ",", "then", "frequency", "-", "domain", "scheduling", "is", "applied", "in", "order", "to", "assign", "the", "optimum", "RBs", "to", "each", "UE", "according", "to", "their", "CSI", ";", "otherwise", ",", "RBs", "are", "assigned", "over", "a", "broader", "part", "of", "the", "bandwidth", "to", "utilize", "frequency", "diversity", "in", "case", "of", "high", "mobility", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Additionally", ",", "since", "we", "have", "reached", "the", "final", "stage", ",", "the", "set", "of", "surviving", "routes", "is", "not", "identified", "and", "the", "process", "exits", "by", "exporting", "the", "hitherto", "observed", "OPF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "optimal pareto front"}, {"tokens": ["How", "we", "define", "Equation", "(", ")", "depends", "on", "our", "prior", "knowledge", "about", "the", "MVF", "and", "its", "relationship", "with", "the", "voicing", "status", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["Figure", "presents", "the", "regret", "performance", "(", "both", "the", "cumulative", "regret", "and", "number", "of", "suboptimal", "price", "signals", "selected", ")", "of", "Con", "-", "TS", "-", "RTP", "at", "node", "10", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["In", "recent", "years", ",", "other", "ANN", "designs", "have", "become", "commonly", "used", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "AP", "employs", "an", "array", "of", "antennas", ",", "while", "each", "STA", "has", "only", "one", "antenna", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["It", "is", "observed", "that", "using", "300", "ranked", "syntax", "features", "of", "these", "Android", "mobile", "datasets", ",", "the", "benign", "distribution", "and", "LR", "attack", "algorithms", "could", "fool", "the", "classification", "algorithms", "using", "the", "Drebin", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["For", "LR", ",", "we", "varied", "the", "ridge", "in", "the", "log", "-", "likelihood", "and", "for", "RF", "we", "varied", "the", "number", "of", "trees", "(", "iterations", "in", "WEKA", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["signals", "at", "each", "antenna", "of", "the", "AP", "are", "multiplied", "by", "a", "complex", "weight", "and", "then", "summed", "up", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["MIS", "-", "SLAM", "is", "suitable", "for", "clinical", "AR", "or", "VR", "applications", "when", "camera", "is", "moving", "relatively", "fast", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["introduced", "an", "OT", "-", "based", "PSI", "protocol", "relying", "on", "black", "-", "box", "usage", "of", "random", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Note", "that", "DTP", ",", "FA", ",", "and", "BP", "often", "fail", "or", "are", "unstable", "with", "this", "initialization", ",", "especially", "when", "training", "deep", "sigmoidal", "networks", "on", "Fashion", "MNIST", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["Recently", ",", "several", "datasets", "which", "are", "very", "appropriate", "for", "the", "context", "of", "QA", "dialogue", "systems", "have", "been", "released", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Later", ",", "many", "PSO", "variants", "have", "been", "developed", "to", "improved", "results", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Finally", ",", "AC", "-", "OPF", "cases", "for", "3", "grids", "were", "also", "investigated", "using", "k", "samples", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Using", "88", "features", "including", "pitch", ",", "Mel", "-", "PLP", ",", "and", "TRAP", "-", "DCT", "input", "into", "a", "bottleneck", "DNN", ",", "they", "are", "able", "to", "improve", "the", "CER", "to", "40.2", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["In", "the", "first", ",", "we", "only", "trained", "and", "tested", "on", "the", "10-fold", "splits", "for", "MIM", "-", "GOLD", ",", "but", "in", "the", "second", "we", "added", "the", "whole", "IFD", "corpus", "to", "the", "training", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "icelandic frequency dictionary"}, {"tokens": ["[", "CC", "-", "CV", "DLC][DLC", "Fast", "Charging", "]", "Battery", "temperature", "with", "different", "charging", "techniques", "via", "AC", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant charging"}, {"tokens": ["During", "the", "CC", "period", ",", "the", "charging", "current", "is", "constant", "until", "the", "battery", "voltage", "reaches", "a", "specified", "maximum", "(", "4.2/4.35V", ")", ",", "after", "which", "the", "charging", "current", "is", "trickled", "until", "the", "battery", "is", "fully", "charged", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["The", "AA", "group", "was", "strongest", "(", "58", "of", "the", "total", "Nordic", "output", ")", ",", "except", "for", "Norway", ",", "where", "the", "PPF", "was", "on", "top", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "astronomy and astrophysics"}, {"tokens": ["The", "most", "famous", "model", "of", "networks", "with", "group", "structure", "is", "the", "stochastic", "block", "model", "(", "SBM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["In", "this", "first", "version", "of", "the", "GCP", ",", "one", "considers", "any", "possible", "vertex", "subset", "as", "a", "potential", "candidate", "for", "compression", ",", "thus", "leading", "to", "an", "unconstrained", "compression", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph compression problem"}, {"tokens": ["For", "UE", ",", "we", "generate", "an", "environment", "named", "Square", "with", "random", "invisible", "background", "objects", "and", "a", "target", "named", "Stefani", "walking", "along", "a", "fixed", "path", "for", "training", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "unreal engine"}, {"tokens": ["The", "top", "row", "shows", "the", "results", "for", "the", "normal", "IB", "Lagrangian", ",", "and", "the", "bottom", "row", "for", "the", "exponential", "IB", "Lagrangian", "with", ",", "both", "in", "the", "California", "housing", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["This", "represents", "a", "slight", "improvement", "of", "around", "1,5", ",", "on", "average", ",", "in", "terms", "of", "SSIM", "value", "for", "the", "adaptive", "neuralFEC", "mechanism", "in", "comparison", "to", "the", "non", "-", "adaptive", "video", "-", "aware", "FEC", "mechanism", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Here", ",", "the", "distributed", "ledger", "of", "blockchain", "is", "used", "for", "maintaining", "the", "network", "information", "while", "the", "highly", "secure", "ECC", "is", "employed", "for", "mutual", "authentication", "between", "vehicles", "and", "RSUs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["The", "pink", "line", "corresponds", "to", "the", "limit", "between", "the", "past", "and", "the", "new", "input", "domain", "explored", "by", "the", "continual", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["compares", "the", "online", "performance", "where", "it", "is", "obvious", "that", "DDE", "-", "MGM", "still", "preserves", "relatively", "good", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["For", "example", ",", "a", "possible", "interesting", "research", "would", "be", "investigating", "if", "some", "particularization", "of", "the", "concave", "IB", "Lagrangian", "suffers", "from", "an", "issue", "like", "value", "convergence", "that", "can", "be", "exploited", "for", "approximately", "obtaining", "any", "predictability", "level", "for", "many", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Structural", "Factorization", "Machine", "(", "SFM", ")", "is", "the", "proposed", "model", "that", "learns", "the", "common", "latent", "spaces", "shared", "in", "multi", "-", "way", "data", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "structural factorization machine"}, {"tokens": ["From", "simulation", "results", ",", "we", "find", "the", "following", "facts", ":", "in", "the", "medium", "and", "high", "signal", "-", "to", "-", "noise", "-", "ratio", "(", "SNR", ")", "regions", ",", "compared", "with", "three", "typical", "PA", "parameters", "such", ",", "and", ",", "the", "optimal", "PA", "shows", "a", "substantial", "SR", "performance", "gain", "with", "maximum", "gain", "percent", "up", "to", "more", "than", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["For", "example", ",", "for", "sentiment", ",", "we", "generate", "continuations", "for", "each", "of", "the", "3", "sentiment", "values", "and", "compare", "to", "BS", "and", "TS", "with", "3", "continuations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "beam search"}, {"tokens": ["indicate", "that", "due", "to", "high", "power", "attenuation", "in", "NLOS", "links", ",", "typical", "UE", "rarely", "associates", "to", "NLOS", "BSs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "recent", "development", "in", "RT", "allows", "more", "distributions", "to", "be", "used", "in", "VAEs", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reparameterization trick"}, {"tokens": ["These", "findings", "highlight", "the", "tremendous", "potential", "of", "in", "-", "home", "personalized", "SAR", "interventions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "learned", "MSC", "features", "are", "specifically", "designed", "for", "visual", "tracking", ",", "and", "they", "can", "be", "easily", "incorporated", "into", "any", "CF", "-", "based", "tracking", "methods", "without", "using", "the", "time", "-", "consuming", "online", "fine", "-", "tuning", "steps", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correlation filter"}, {"tokens": ["Here", ",", "the", "angular", "component", "is", "considered", "to", "be", "the", "input", "to", "the", "GP", "and", "the", "radial", "as", "the", "corresponding", "observations", "described", "by", "the", "latent", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["PAP", "therapy", "is", "applied", "through", "the", "use", "of", "a", "specialised", "medical", "device", "which", "delivers", "a", "highly", "controlled", "wave", "of", "pressurised", "air", "to", "the", "upper", "airway", ",", "acting", "as", "a", "pneumatic", "splint", "and", "preventing", "the", "blockage", "of", "the", "pharynx", "that", "characterises", "OSA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "obstructive sleep apnoea"}, {"tokens": ["for", "-stage", "classification", "&", "&", "&", "&", "&", "IIR", "-", "MMD", "-", "DT", "&", "RS", "-", "task", "&", "15.6", "&", "58.2", "&", "95.6", "&", "83.8", "&", "80.3", "IIR", "-", "MMD", "-", "DT", "&", "SC", "-", "task", "&", "26.4", "&", "61.9", "&", "94.8", "&", "84.3", "&", "84.3", "Proposed", "Method", "&", "RS", "-", "task", "&", "43.8", "&", "66.5", "&", "97.9", "&", "88.8", "&", "85.5", "Proposed", "Method", "&", "SC", "-", "task", "&", "43.3", "&", "67.9", "&", "97.0", "&", "90.1", "&", "90.0"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random split"}, {"tokens": ["For", ",", "we", "also", "designed", "a", "new", "experiment", "where", "and", "was", "scaled", "up", "to", "1000", "(", "left", "panel", "of", "Figure", "fig", ":", "MB", "-", "large", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["Discriminative", "models", "were", "then", "proposed", "to", "overcome", "these", "limits.metallinou-bohus-williams:2013:ACL2013", "proposed", "to", "use", "linear", "classifier", "where", "the", "dialogue", "history", "in", "the", "input", "features", "andhenderson2013deep", "proposed", "to", "map", "directly", "the", "ASR", "hypotheses", "onto", "a", "dialogue", "state", "by", "means", "of", "recurrent", "neural", "networks", "which", "integrated", "both", "NLU", "and", "DST", "into", "a", "single", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["ConclusionIn", "this", "work", ",", "we", "put", "forward", "the", "attention", "drift", "concept", "to", "explain", "the", "poor", "performance", "of", "existing", "AN", "based", "methods", "of", "scene", "text", "recognition", "on", "complicated", "and/or", "low", "-", "quality", "images", ",", "and", "propose", "a", "novel", "method", "FAN", "to", "solve", "this", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["The", "PSC", "instance", "is", "reduced", "to", "a", "bipartite", "graph", ",", "in", "which", "each", "node", "corresponds", "to", "a", "subset", "one", "to", "one", ",", "each", "node", "corresponds", "to", "an", "element", "one", "to", "one", ",", "there", "is", "an", "edge", "if", "and", "only", "if", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial set cover"}, {"tokens": ["4", ")", "For", "variable", "velocities", ",", "but", "simple", "scenarios", ",", "GMM", "is", "the", "algorithm", "to", "choose", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["If", "the", "direction", "angle", "estimation", "error", "toward", "each", "eavesdropper", "is", "bounded", ",", "we", "can", "prove", "that", "the", "channel", "estimation", "error", "between", "the", "BS", "and", "each", "eavesdropper", "is", "norm", "-", "bounded", "(", "the", "detailed", "procedure", "is", "illustrated", "in", "Appendix", "B", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["As", "stated", "previously", ",", "the", "proposed", "satisfies", "the", "two", "conditions", "of", "Exact", "-", "MBR", "encoding", "matrix", ",", "which", "enables", "the", "node", "-", "repairing", "algorithm", "and", "data", "reconstruction", "algorithm", "addressed", "in", "Sec", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["The", "key", "technical", "property", "of", "our", "method", "is", "the", "recursive", "reconstruction", "of", "conditional", "GP", "priors", "conditioned", "on", "the", "variational", "parameters", "learned", "so", "far", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Denote", "the", "set", "of", "SCCs", "in", "as", ",", "where", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "strongly connected components"}, {"tokens": ["SCCs", "have", "rigidly", "mounted", "camera", "configurations", "with", "static", "extrinsic", "parameters", ",", "while", "DCCs", "incorporate", "a", "camera", "mounted", "to", "an", "actuated", "mechanism", ",", "such", "as", "a", "gimbal", ",", "allowing", "the", "cameras", "to", "reconfigure", "their", "orientation", "independent", "of", "each", "other", "and", "irrespective", "of", "robot", "motion", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "static camera clusters"}, {"tokens": ["The", "simultaneous", "transmissions", "are", "assumed", "to", "be", "decodable", "by", "the", "AP", ",", "and", "a", "single", "data", "rate", "is", "also", "assumed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["With", "the", "optimized", "and", "other", "properly", "configured", "parameters", "(", "e.g.", ",", "the", "number", "of", "aggregated", "frames", "and", "the", "queue", "length", "of", "the", "AP", ")", ",", "Uni", "-", "MUMAC", "is", "then", "extensively", "evaluated", "through", "simulations", "in", "the", "downlink", "-", "dominant", "and", "the", "down", "/", "up", "-", "link", "balanced", "traffic", "scenarios", "in", "IEEE", "802.11ac", "based", "WLANs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Here", ",", "since", "GFG", "and", "DBP", "are", "no", "longer", "equivalent", ",", "aiming", "for", "a", "GFG", "automaton", "becomes", "a", "problem", "that", "is", "different", "from", "determinization", "via", "DBP", "automata", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["The", "DE", "method", "extended", "by", "the", "global", "optimum", "invariant", "symmetry", "breaking", "is", "denoted", "by", "DE", "-", "INV", "-", "SB", ",", "DE", "extended", "by", "the", "proposed", "global", "optimum", "variant", "symmetry", "breaking", ",", "described", "by", "Algorithm", ",", "is", "denoted", "by", "DE", "-", "SB", "and", "DE", "with", "global", "optimum", "variant", "ideal", "symmetry", "breaking", "using", "brute", "force", "search", "is", "denoted", "by", "DE", "-", "SB", "-", "BF", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["The", "Receiver", "Operating", "Characteristic", "(", "ROC", ")", "curves", "(", "Appendix", ")", "illustrate", "all", "trade", "-", "offs", "points", "between", "TP", "and", "FP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["To", "reduce", "the", "computational", "complexity", ",", "each", "UE", "is", "restricted", "to", "be", "served", "by", "its", "nearby", "RRHs", "since", "only", "nearby", "RRHs", "contribute", "significantly", "to", "the", "UE", "'s", "signals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "authors", "themselves", "have", "widely", "used", "FJ", "to", "formalise", "extensions", "of", "Java", "with", "additional", "features", ",", "aiming", "at", "dynamic", "flexibility", ",", "at", "assuring", "safety", "of", "communications", "and", "at", "enhancing", "code", "reuse", "under", "several", "aspects", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "featherweight java"}, {"tokens": ["The", "OEC", ":", "Facts", "about", "the", "language", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0], "long_form": "oxford english corpus"}, {"tokens": ["Figure", "E", "depicts", "the", "CM", "for", "the", "TFL1", "gene", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "canalizing map"}, {"tokens": ["TS", "moves", "from", "a", "solution", "to", "its", "best", "admissible", "neighbor", ",", "even", "if", "this", "causes", "the", "objective", "function", "to", "deteriorate", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["illustrates", "an", "example", "LTE", "-", "U", "/", "Wi", "-", "Fi", "coexistence", "scenario", ",", "where", "two", "Wi", "-", "Fi", "APs", "and", "one", "LTE", "-", "U", "BS", "are", "operating", "on", "the", "same", "channel", ",", "with", "multiple", "clients", "associated", "with", "each", "AP", "and", "BS", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Note", "that", "one", "target", "can", "have", "several", "TP", "detections", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "true positives"}, {"tokens": ["Stochastic", "block", "models", "(", "SBM", ")", "are", "an", "alternative", "line", "of", "network", "clustering", "research", "that", "partitions", "nodes", "into", "communities", "in", "order", "to", "generatively", "infer", "link", "probabilities", "Holland1983", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["VAT", "-", "V", "significantly", "increase", "with", "age", "in", "both", "men", "and", "women", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["[", "]", "Results", "from", "continual", "GP", "regression", "applied", "to", "toy", "streaming", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Future", "work", "includes", "exploring", "non", "-", "isotropic", "variograms", "and", "other", "advanced", "schemes", "for", "GP", "kernel", "estimation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["As", "VGI", ",", "SC", "faces", "challenges", "regarding", "availability", "of", "workers", "in", "areas", "where", "they", "are", "needed", ",", "plus", "specific", "challenges", "like", "optimal", "task", "assignment", "according", "to", "workers", "'", "current", "positions", "and", "available", "budget", ",", "and", "how", "to", "preserve", "their", "privacy", "kandappu_obfuscation_2018,tong_flexible_2017", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "special case"}, {"tokens": ["M.", "Hoque", ",", "X.", "Hong", ",", "and", "B.", "Dixon", ",", "\"", "Innovative", "taxi", "hailing", "system", "using", "dsrc", "infrastructure", ",", "\"", "in", "ITS"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "intelligent transportation system"}, {"tokens": ["DC", "architecture", "between", "LTE", "MN", "and", "LTE", "SN", "is", "displayed", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "abundant", "SAR", "scene", "images", "from", "similar", "sensors", "to", "SAR", "targets", "are", "suitable", "for", "pre", "-", "training", "a", "deep", "network", "to", "transfer", "to", "other", "SAR", "related", "tasks", "with", "limited", "data", ",", "but", "the", "image", "reconstruction", "task", "with", "unlabeled", "data", "is", "distant", "to", "SAR", "target", "recognition", "task", "which", "affect", "the", "transferability", "of", "features", "in", "mid", "and", "high", "layers", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["The", "PDP", "illustrates", "how", "the", "RF", "model", "predictions", "are", "affected", "by", "each", "feature", "assuming", "the", "rest", "of", "the", "features", "in", "the", "RF", "model", "are", "controlled", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial dependence plots"}, {"tokens": ["In", "contrast", ",", "QA", "systems", "usually", "work", "on", "broader", "domains", "(", "e.g.", "factoid", "QA", "can", "be", "done", "over", "different", "domains", "at", "once", ")", ",", "although", "there", "are", "also", "some", "QA", "systems", "focused", "only", "on", "a", "specific", "domainSarrouti2017,DoNTNN17", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Subsequently", ",", "we", "propose", "two", "TAS", "methods", ":", "leakage", "-", "based", "and", "Max", "-", "SR", ",", "and", "generalize", "the", "conventional", "EDAS", "scheme", "to", "secure", "SM", "system", "in", "Section", "III", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["The", "number", "of", "mixtures", "in", "the", "GMM", "is", "20", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["where", "and", "CER", "=", "where", "is", "the", "length", "of", "the", "label", "and", "is", "the", "length", "of", "the", "prediction", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["The", "weights", ",", ",", "are", "taken", "as", "inputs", "and", "multiplied", "with", "parameters", "to", "get", "the", "final", "estimate", "for", "DI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "document index"}, {"tokens": ["Likewise", ",", "on", "the", "PA", "task", ",", "the", "playback", "device", "properties", "may", "impact", "high", "-", "frequency", "content", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["The", "DE", "method", "extended", "by", "the", "global", "optimum", "invariant", "symmetry", "breaking", "is", "denoted", "by", "DE", "-", "INV", "-", "SB", ",", "DE", "extended", "by", "the", "proposed", "global", "optimum", "variant", "symmetry", "breaking", ",", "described", "by", "Algorithm", ",", "is", "denoted", "by", "DE", "-", "SB", "and", "DE", "with", "global", "optimum", "variant", "ideal", "symmetry", "breaking", "using", "brute", "force", "search", "is", "denoted", "by", "DE", "-", "SB", "-", "BF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "brute force search"}, {"tokens": ["Open", "Access", "Case", "subsection_Open2The", "overall", "interference", "in", "the", "uplink", "of", "the", "typical", "femtocell", "UE", "has", "five", "parts", ":", "from", "macrocell", "UEs", "not", "inside", "any", "femtocell", "(", ")", ",", "from", "open", "access", "UEs", "outside", "the", "typical", "femtocell", "(", ")", ",", "from", "femtocell", "UEs", "outside", "the", "typical", "femtocell", "(", ")", ",", "from", "local", "femtocell", "UEs", "inside", "the", "typical", "femtocell", "(", ")", ",", "and", "from", "open", "access", "UEs", "inside", "the", "typical", "femtocell", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Note", "that", "given", "in", "PLnlos", "in", "the", "case", "of", "a", "macrocell", "BS", "or", "MBS", "and", "given", "in", "avgPLd", "in", "the", "case", "of", "a", "DBS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["As", "anticipated", ",", "the", "performance", "of", "both", "RF", "and", "ANN", "models", "improved", "when", "supplying", "the", "model", "with", "more", "training", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Experimental", "results", "from", "our", "models", "as", "well", "as", "other", "state", "-", "of", "-", "the", "-", "art", "models", "are", "shown", "in", "Table", ",", "where", "the", "first", "group", "are", "open", "-", "domain", "QA", "models", "without", "using", "the", "BERT", "model", ",", "the", "second", "group", "are", "BERT", "-", "based", "models", ",", "and", "the", "last", "group", "are", "our", "multi", "-", "passage", "BERT", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Therefore", ",", "in", "this", "paper", ",", "we", "focus", "on", "the", "PS", "protocol", "for", "two", "-", "way", "multiple", "-", "relay", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Without", "loss", "of", "generality", ",", "we", "focus", "on", "the", "NOMA", "with", "two", "users", ":", "one", "from", "near", "and", "one", "from", "far", "user", "sets", "where", "the", "near", "user", "directly", "communicates", "with", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["We", "integrate", "AON", ",", "FG", "and", "an", "attention", "-", "based", "decoder", "into", "the", "character", "recognition", "framework", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "filter gate"}, {"tokens": ["Given", "that", "all", "requests", "assigned", "to", "a", "cluster", "(", "as", "a", "result", "of", "using", "EM", ")", "can", "be", "represented", "by", "a", "component", "of", "the", "GMM", ",", "we", "approximate", "the", "distribution", "of", "teh", "distances", "with", "a", "normal", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Because", "TS", "samples", "parameters", "from", "the", "prior", "distribution", ",", "the", "algorithm", "has", "a", "chance", "to", "explore", "(", "i.e.", ",", "draw", "new", "parameters", ")", "and", "can", "exploit", "(", "i.e.", ",", "draw", "parameters", "that", "are", "likely", "to", "be", "the", "true", "parameter", ")", "throughout", "the", "run", "of", "the", "algorithm", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["In", "the", "SBM", ",", "each", "node", "belongs", "to", "one", "of", "the", "groups", ",", "where", "in", "the", "example", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Collaborative", "filtering", "(", "CF", ")", ":"], "acronym_pos": [0, 0, 0, 1, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Others", "systems", "like", "has", "built", "on", "RA", ",", "or", "has", "built", "on", "a", "P2P", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["In", "CUTS", ",", "each", "STA", "selects", "one", "of", "the", "available", "subcarriers", "to", "transmit", "a", "predefined", "signal", ",", "which", "is", "used", "by", "the", "AP", "to", "identify", "the", "winning", "STAs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["From", "Theorem", "1", ",", "we", "can", "also", "see", "that", "the", "FL", "performance", "depends", "on", "parameters", ",", ",", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["LTE", "-", "U", "Forum", ",", "\"", "LTE", "-", "U", "CSAT", "Procedure", "TS", "V1.0"], "acronym_pos": [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "this", "example", ",", "the", "additive", "GP", "is", "able", "to", "recover", "the", "relevant", "structure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["conclusionIn", "this", "paper", ",", "we", "have", "made", "an", "extensive", "investigation", "of", "TAS", "methods", "in", "secure", "SM", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["proposed", "a", "novel", "adaptive", "variable", "population", "PSO", "approach", "to", "DED", "problem", "of", "power", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["OUTIS", "OUTIS", "replaces", "a", "single", "trusted", "data", "curator", "by", "two", "untrusted", "non", "-", "collaborative", "servers", "i.e.", "the", "CSP", "and", "the", "AS", "the", "third", "party", "association", "in", "the", "CDP", "model", "is", "diminished", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["QA", ":"], "acronym_pos": [1, 0], "long_form": "question answering"}, {"tokens": ["Combining", "the", "features", "generated", "both", "the", "residual", "network", "and", "convolutional", "autoencoder", ",", "we", "obtain", "the", "mean", "AP", "of", "61.1", ",", "outperforming", "hand", "-", "crafted", "features", "by", "10", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["We", "first", "provide", "a", "new", "application", "dedicated", "to", "RS", "images", "sampling", "suited", "for", "DL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["Ageing", "coupled", "with", "RLS", "and", "SBM", "can", "reach", "the", "optimum", "by", "local", "moves", ",", "which", "respectively", "yields", "upper", "bounds", "of", "and", "for", "arbitrarily", "small", "constant", "on", "their", "runtimes", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard bit mutations"}, {"tokens": ["TS", "does", "very", "well", "in", "terms", "of", "diversity", ",", "and", "this", "diversity", "enables", "it", "to", "produce", "higher", "max", "scores", "than", "BS", ",", "but", "it", "has", "lower", "averages", "when", "using", "small", "numbers", "of", "continuations", "(", "3", "or", "5", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "beam search"}, {"tokens": ["A", "control", "plane", "can", "be", "established", "from", "any", "node", "(", "MgNB", "and/or", "SgNB", ")", "to", "the", "UE", ";", "however", ",", "the", "data", "plane", "interface", "is", "configured", "to", "either", "MgNB", "or", "SgNB", "but", "not", "both", ",", "in", "accordance", "with", "the", "so", "-", "called", "split", "bearer", "architecture", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["On", "the", "one", "hand", ",", "RNN", "models", "became", "the", "state", "of", "the", "art", "models", "in", "DST", ",", "on", "the", "other", "hand", ",", "most", "state", "-", "of", "-", "the", "-", "art", "DST", "models", "are", "only", "turn", "-", "based", "and", "require", "dataset", "-", "specific", "preprocessing", "(", "e.g.", "DSTC2-specific", ")", "in", "order", "to", "achieve", "such", "results", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["Max", "and", "min", "scores", "represent", "the", "highest", "and", "the", "lowest", "FR", "scores", ",", "respectively", ",", "recorded", "by", "a", "single", "person", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fooling rate"}, {"tokens": ["BAM", "configuration", "involves", "3", "phases", ":", "i", ")", "the", "definition", "of", "classes", "of", "services", "(", "TCs", "-", "Traffic", "Classes", ")", "with", "common", "requirements", "(", "QoS", ",", "SLA", "or", "other", "user/", "application", "parameter", ")", ";", "ii", ")", "the", "definition", "of", "the", "amount", "of", "bandwidth", "per", "class", "(", "BC", "-", "Bandwidth", "Constraint", ")", ";", "and", "iii", ")", "BAM", "model", "configuration", "with", "an", "inherent", "behavior", "for", "resource", "sharing", "among", "TCs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bandwidth constraint"}, {"tokens": ["Data", "packets", "collected", "by", "the", "BS", ",", "is", "from", "10", "to", "300", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["These", "results", "for", "the", "LSTMs", "and", "the", "s", "-", "RNNs", "and", "RPNI", "are", "given", "in", "Table", "for", "the", "SL", "targets", "and", "in", "Table", "for", "the", "SP", "targets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Here", ",", "the", "proposed", "adaptive", "STA", "is", "employed", "as", "the", "sliding", "mode", "control", "instead", "of", "the", "first", "order", "sliding", "mode", "control", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["Using", "instantaneous", "CSI", "and", "Eq", ":", "g_end_PureRS", ",", "rate", "-", "selective", "RS", "chooses", "between", "direct", "(", "non", "-", "relay", "assisted", ")", "and", "relay", "-", "assisted", "transmission", "based", "on", "the", "following", "criterionAs", "shown", "in", ",", "the", "MGF", "of", "can", "be", "obtained", "using", "the", "of", "pure", "RS", "aswhere", "is", "a", "RV", "with", "CDF", "given", "by", "which", "can", "be", "obtained", "using", "inverse", "sampling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["The", "black", "line", "is", "the", "posterior", "mean", "of", "a", "GP", "with", "only", "one", "term", "in", "its", "kernel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["It", "is", "assumed", "that", "each", "UE", "is", "potentially", "served", "by", "its", "nearest", "RRHs", ",", "i.e.", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["table*[t]F1", "scores", "in", "the", "task", "of", "node", "classification.tbl:exp-node-classificationtabularcccccc", "2*Algorithm", "&", "2*Initialization", "&", "2cMicro", "-", "F1", "score", "&", "2cMacro", "-", "F1", "score", "3", "-", "6", "&", "&", "Blog", "&", "Wiki", "&", "Blog", "&", "Wiki", "3*node2vec", "&", "GPA", "&", "0.3174", "&", "0.6310", "&", "0.2395", "&", "0.5830", "2", "-", "6", "&", "HARP", "&", "0.3028", "&", "0.6192", "&", "0.2281", "&", "0.5631", "2", "-", "6", "&", "Random", "&", "0.2916", "&", "0.6033", "&", "0.2195", "&", "0.5587", "3*DeepWalk", "&", "GPA", "&", "0.3399", "&", "0.6295", "&", "0.2563", "&", "0.5616", "2", "-", "6", "&", "HARP", "&", "0.3191", "&", "0.6029", "&", "0.2387", "&", "0.5481", "2", "-", "6", "&", "Random", "&", "0.3106", "&", "0.5967", "&", "0.2315", "&", "0.5380", "3*LINE", "&", "GPA", "&", "0.3070", "&", "0.4987", "&", "0.2082", "&", "0.4282", "2", "-", "6", "&", "HARP", "&", "0.2823", "&", "0.4798", "&", "0.2029", "&", "0.4165", "2", "-", "6", "&", "Random", "&", "0.2799", "&", "0.4687", "&", "0.1982", "&", "0.4091", "tabulartable*Evaluations", "on", "Node", "ClassificationIn", "node", "classification", ",", "we", "evaluate", "the", "performance", "of", "GPA", ",", "HARP", "and", "Random", "on", "the", "datasets", ",", "i.e.", ",", "Blog", "and", "Wiki", ",", "whose", "nodes", "are", "associated", "with", "labels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["Along", "-", "fiber", "GFA", "visualization", "and", "cosine", "similarity", "between", "pairs", "of", "fibers", "from", "three", "prominent", "bundles", ":", "a", ")", "CST", "(", "R", ")", ",", "b", ")", "CC", ",", "c", ")", "IFOF", "(", "R", ")", ",", "using", "framework", "of", "varifolds", "(", "Var", ")", "and", "functional", "varifolds", "(", "fVar", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "corticospinal tract"}, {"tokens": ["Figure", "presents", "the", "distribution", "of", "voltage", ",", "and", "the", "relationship", "between", "battery", "voltage", "and", "battery", "level", "for", "the", "CC", "-", "CV", "and", "DLC", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "constant current"}, {"tokens": ["a)-(c", ")", "plot", "the", "total", "energy", "consumption", "of", "the", "drones", ",", "MBSs", ",", "and", "macrocell", "BS", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "base station"}, {"tokens": ["This", "suggests", "that", "participants", "might", "be", "more", "inclined", "to", "persist", "with", "the", "TDW", "environment", "further", "than", "with", "the", "SDD", ",", "however", "this", "may", "be", "a", "result", "of", "the", "novelty", "factor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["A", "third", "-", "order", "sliding", "mode", "observer", "is", "employed", "to", "exactly", "obtain", "the", "magnitude", "of", "perturbation", ",", "which", "is", "the", "minimum", "level", "of", "the", "two", "gains", "in", "STA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["Qualcomm", "Inc.", "acquires", "the", "mobile", "AR", "IP", "from", "Imagination", "Computer", "Services", "GmbH.", ",", "Vienna", ",", "and", "takes", "over", "the", "funding", "of", "the", "Christian", "Doppler", "Laboratory", "for", "Handheld", "AR", "at", "Graz", "University", "of", "Technology", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Many", "intelligent", "tutoring", "systems", "(", "ITS", ")", "use", "mastery", "learning", "within", "the", "Knowledge", "Tracing", "framework", ":", "making", "students", "work", "on", "a", "given", "skill", "until", "the", "system", "infers", "that", "they", "have", "mastered", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intelligent tutoring systems"}, {"tokens": ["MethodOverviewThe", "Orfeo", "ToolBox", "(", "OTB", ")", "is", "a", "library", "for", "RS", "image", "processing", ",", "built", "on", "top", "of", "an", "application", "development", "framework", "widely", "used", "in", "medical", "image", "processing", ",", "the", "Insight", "Toolkit", "(", "ITK", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["The", "Pareto", "-", "fair", "classifier", "exhibits", "the", "lowest", "discrepancy", "on", "Acc", "and", "BS", "while", "still", "being", "Pareto", "-", "optimal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "brier score"}, {"tokens": ["Therefore", ",", "while", "training", ",", "the", "downsampled", "annotations", "are", "considered", "to", "be", "groundtruth", "for", "the", "generated", "LR", "images", ",", "and", "the", "networks", "are", "trained", "to", "predict", "heatmaps", "as", "close", "to", "the", "groundtruth", "as", "possible", "in", "order", "to", "fool", "the", "discriminator", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["At", "point", "size", "30", ",", "the", "words", "were", "no", "longer", "readable", "on", "the", "SDD", "and", "therefore", "virtual", "navigation", "was", "necessary", ",", "causing", "a", "performance", "decline", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["In", "our", "case", ",", "however", ",", "the", "types", "of", "SAR", "targets", "to", "be", "recognized", "are", "never", "seen", "before", "and", "the", "classification", "layer", "should", "be", "retrained", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Connection", "of", "OT", "divergence", "is", "omitted", "for", "brevity", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["We", "evaluate", "the", "visual", "quality", "that", "is", "obtained", "per", "person", "and", "not", "just", "per", "image", ",", "by", "testing", "DTN", "on", "the", "Facescrub", "dataset", "facescrub", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "domain transfer network"}, {"tokens": ["we", "describe", "the", "quantum", "memory", "environment", "the", "PS", "agent", "is", "interacting", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "projective simulation"}, {"tokens": ["Therefore", ",", "on", "the", "energy", "utilizations", "of", "RNs", ",", "CHs", ",", "and", "BS", "are", "considered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "base station"}, {"tokens": ["aligngatheras", "a", "result", "of", "the", "Markov", "assumption", "in", "the", "IB", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["We", "found", "that", "setting", "was", "effective", "at", "producing", "an", "alignment", "comparable", "to", "that", "of", "FA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "feedback alignment"}, {"tokens": ["In", "the", "case", "of", "arithmetic", "this", "rule", "captures", "the", "induction", "rule", "of", "Peano", "'s", "Arithmetics", "PA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "peano 's arithmetics"}, {"tokens": ["In", "uplink", "RSMA", ",", "each", "user", "first", "transmits", "a", "superposition", "code", "of", "two", "messages", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["In", "this", "paper", ",", "SBS", "cooperation", "in", "the", "downlink", "of", "5", "G", "fractal", "small", "-", "cell", "networks", "is", "investigated", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["Optimal", "transport", "(", "OT", ")", "has", "been", "applied", "in", "two", "important", "tasks", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["[", "CC", "-", "phase", "rates", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0], "long_form": "constant current"}, {"tokens": ["Due", "to", "the", "nature", "of", "the", "estimation", "of", "the", "IB", "Lagrangian", ",", "the", "theoretical", "and", "practical", "value", "of", "that", "yield", "a", "specific", "may", "vary", "slightly", "(", "see", "Figure", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Performance", "comparison", "in", "terms", "of", "RMSE", "and", "CER", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "clustering error rate"}, {"tokens": ["Plain", "bars", "show", "results", "for", "the", "CNS", "dataset", ",", "dashed", "bars", "for", "the", "MDC", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["We", "denote", "by", "the", "average", "total", "number", "of", "users", "located", "in", "the", "macrocell", "BS", "during", "time", "slot", "and", "by", ",", ",", "and", "the", "maximum", "number", "of", "users", "that", "can", "be", "served", "by", "macrocell", "BS", ",", "MBS", ",", "and", "DBS", ",", "respectively", ",", "such", "that", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["After", "that", ",", "AA", "theory", "was", "developed", "and", "has", "been", "applied", "to", "OPF", "problems", "in", "power", "systems", ",", "which", "can", "take", "the", "correlation", "among", "variables", "into", "account", "and", "yield", "much", "tighter", "lower", "and", "upper", "bounds", "compared", "to", "IA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["where", "is", "the", "SINR", "of", "the", "th", "user", "and", "is", "the", "corresponding", "DE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deterministic equivalent"}, {"tokens": ["The", "most", "significant", "(", "based", "on", "region", "-", "score", ")", "subset", "identified", "by", "the", "gender", "grouping", "was", "between", "the", "FA", "DTI", "measurement", "in", "the", "left", "cingulum", "gyrus", "as", "well", "as", "the", "scores", "on", "the", "Rey", "Auditory", "Verbal", "Learning", "Test", "(", "RAVLT", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fractional anisotropy"}, {"tokens": ["The", "second", "author", "is", "partially", "supported", "by", "FWF", "(", "Austrian", "Science", "Fund", ")", "project", "I-608-N18This", "paper", "is", "concerned", "with", "the", "automated", "complexity", "analysis", "of", "term", "rewrite", "systems", "(", "TRSs", "for", "short)and", "the", "ramification", "of", "these", "in", "implicit", "computational", "complexity", "theory", "(", "ICC", "for", "short", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "implicit computational complexity"}, {"tokens": ["In", "this", "study", ",", "a", "GMM", "-", "UBM", "classifier", "with", "512", "mixture", "components", "is", "used", "to", "train", "the", "proposed", "features", "to", "generate", "a", "model", "for", "each", "speaker", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Sparse", "Gaussian", "process", "approximationapp", ":", "sparse", "GPTo", "solve", "the", "inference", "problem", "for", "the", "function", ",", "we", "define", "a", "sparse", "GP", ",", "using", "the", "same", "prior", ",", "but", "by", "an", "effective", "likelihood", "which", "depends", "on", "a", "finite", "set", "of", "function", "values", "only", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["These", "counts", "are", "accumulated", "for", "each", "batch", "through", "the", "entire", "data", "set", ",", "and", "after", "each", "complete", "pass", "through", "the", "data", ",", "the", "FAR", "and", "FRR", "are", "calculated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "false acceptance rate"}, {"tokens": ["When", "the", "G", "-", "CTS", "is", "received", "by", "the", "targeted", "STAs", ",", "they", "are", "synchronized", "to", "send", "data", "frames", "to", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["Although", "samples", "consisted", "of", "a", "wide", "range", "of", "current", "levels", "and", "spatial", "locations", ",", "relatively", "stable", "prediction", "performance", "was", "achieved", "by", "both", "machine", "learning", "models", ",", "especially", "the", "ANN", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Parameter", "selection", "of", "PSO", "Parameter", "selection", "of", "PSO", "is", "of", "extreme", "importance", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["The", "node", "with", "the", "maximum", "BC", "can", "be", "easily", "congested", "hence", ",", "it", "is", "necessary", "to", "consider", "only", "the", "traffic", "load", "of", "this", "node", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["CNNs", "are", "computationally", "expensive", ",", "so", "it", "is", "helpful", "to", "start", "with", "efficient", "hardware", "and", "an", "efficient", "network", "architecture", "before", "attempting", "to", "optimize", "the", "ISP", "for", "system", "efficiency", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["At", "run", "-", "time", ",", "we", "test", "the", "resulting", "cost", "-", "sensitive", "DBN", "with", "test", "dataset", "to", "report", "the", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Gaussian", "processes", "with", "priors", "for", "dynamical", "modelsAssuming", "is", "a", "set", "of", "observations", ",", "and", "being", "the", "simulator", "function", "(", "i.e.", ",", "the", "initial", "guess", "of", "the", "dynamics", ")", ",", "we", "can", "query", "the", "GP", "at", "a", "new", "input", "point", "similar", "to", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "this", "figure", ",", "the", "input", "image", "is", "an", "SEM", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["In", "this", "paper", ",", "given", "any", "beamforming", "vector", "and", "AN", "projection", "at", "DM", "transmitter", ",", "we", "propose", "an", "OPA", "strategy", "to", "maximize", "the", "SR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["The", "SCF", "finds", "the", "two", "communities", ",", "and", "the", "SBM", "finds", "the", "roles", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["As", "soon", "as", "the", "Ant", "-", "CTS", "is", "sent", ",", "the", "AP", "sets", "the", "G", "-", "CTS", "timer", "to", "account", "for", "up", "to", "slots", "(", "as", "shown", "in", "Equation", "(", ")", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Note", "that", "the", "prior", "work", "in", "only", "studied", "the", "number", "of", "iterations", "needed", "for", "FL", "convergence", "under", "the", "special", "case", "in", "which", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["ht", "]", "Sum", "secrecy", "rate", "versus", "the", "number", "of", "transmit", "antennas", "at", "the", "BS", "for", ",", ",", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Kashiviswanathan", "et", "al", "has", "stated", "that", "there", "exits", "an", "exponential", "separation", "between", "the", "sampling", "complexity", "and", "accuracy", "in", "the", "LDP", "and", "CDP", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["Basically", ",", "one", "needs", "to", "create", "a", "main", "file", "to", "call", "PSO", "procedure", "as", "follows:#include"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "input", "to", "the", "first", "convolution", "layer", "is", "the", "HR", "image", "concatenated", "with", "the", "noise", "vector", "which", "has", "been", "projected", "using", "a", "fully", "connected", "layer", "and", "reshaped", "to", "match", "the", "input", "size", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["Two", "methods", "were", "compared", "here", ",", "one", "is", "called", "the", "proposed", "method(two", "-", "level", "structure", "approach", ")", "with", "a", "training", "parameters", ",", "the", "other", "one", "is", "called", "the", "general", "method(the", "reference", "model", ")", "with", "a", "training", "parameters", "DiscussionThe", "benefit", "of", "our", "approach", "becomes", "quite", "obvious", "when", "comparing", "the", "results", "of", "the", "two", "-", "level", "structure", "approach", "with", "the", "referenced", "general", "GMM", "-", "GMR", "model", ",", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["FER_FF_rate2third", "-", "snr", "compares", "the", "performance", "of", "length", "2048", "SC", "-", "decoded", "and", "SCL", "-", "decoded", "BIPCM", "SCMA", "systems", ",", "length", "2048", "SC", "-", "decoded", "and", "SCL", "-", "decoded", "MLPC(The", "length", "of", "the", "constituent", "polar", "code", "with", "MLPC", "for", "each", "level", "is", "1024", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "successive cancellation"}, {"tokens": ["Epoch", "time", "of", "RA", "."], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "ring allreduce"}, {"tokens": ["After", "interpolating", "the", "GPS", "coordinates", ",", "the", "format", "of", "the", "measurement", "and", "an", "example", "of", "the", "road", "test", "trace", "are", "given", "as", "follows", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["The", "improved", "based", "on", "neighborhood", "matching", "is", "defined", "aswhere", "denotes", "the", "set", "of", "neighbors", "within", "radius", "around", ",", "and", "walks", "all", "possible", "states", "learned", "by", "the", "MGM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "markov geographic model"}, {"tokens": ["If", "the", "FRR", "is", "less", "or", "equal", "to", "the", "FAR", ",", "then", "on", "the", "next", "iteration", ",", "the", "lower", "threshold", "will", "be", "set", "to", "midpoint", "between", "the", "lower", "and", "upper", "thresholds", ",", "and", "the", "upper", "threshold", "will", "not", "change", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "false acceptance rate"}, {"tokens": ["As", "evident", "from", "the", "theoretical", "and", "experimental", "results", "presented", "in", "this", "work", ",", "our", "maliciously", "secure", "OT", "extension", "protocol", "is", "a", "better", "choice", "compared", "to", "the", "existing", "maliciously", "secure", "extension", "protocols", "when", "-out", "-", "of-", "OTs", "are", "required", "as", "output", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "runtimes", "of", "the", "RB", "model", "for", "different", "sizes", "are", "depicted", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["The", "kind", "of", "structure", "which", "can", "be", "captured", "by", "a", "GP", "model", "is", "mainly", "determined", "by", "its", "kernel", ":", "the", "covariance", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["GS", "is", "fundamentally", "serial", "in", "energy", "because", "of", "how", "the", "group", "-", "to", "-", "group", "coupling", "is", "treated", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gauss seidel"}, {"tokens": ["It", "allowed", "authors", "to", "preview", "their", "results", "on", "a", "desktop", "workstation", ",", "as", "well", "as", "with", "a", "wearable", "AR", "or", "VR", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["In", "conducting", "this", "analysis", ",", "we", "also", "find", "strong", "evidence", "of", "skills", "shortages", "in", "Australia", "for", "highly", "technical", "DSA", "skills", "and", "occupations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["In", "SAR", "operations", ",", "UAVs", "can", "provide", "timely", "disaster", "warnings", "and", "assist", "in", "speeding", "up", "rescue", "and", "recovery", "operations", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["proposed", "a", "generation", "approach", "on", "SAR", "data", ",", "and", "answered", "the", "question", "about", "how", "to", "transfer", "the", "knowledge", "from", "the", "simulated", "SAR", "data", "to", "the", "real", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Consistent", "with", "recent", "findings", ",", "we", "show", "that", "relatively", "simple", "neural", "sequence", "models", "are", "competitive", "with", ",", "and", "in", "some", "cases", "outperform", ",", "traditional", "grammar", "-", "based", "SP", "methods", "on", "benchmark", "SP", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], "long_form": "semantic parsing"}, {"tokens": ["MCC", "computation", "is", "done", "at", "the", "end", "of", "each", "iteration", ",", "to", "find", "the", "parent", "community", "of", "the", "deleted", "node", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal connected component"}, {"tokens": ["If", "the", "difference", "in", "the", "rank", "of", "the", "two", "methods", "lies", "within", "CD", ",", "then", "they", "are", "not", "significantly", "different", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "critical difference"}, {"tokens": ["For", "example", ",", "rather", "than", "sharing", "a", "SDD", ",", "can", "the", "frustration", "caused", "by", "sharing", "control", "be", "alleviated", "by", "providing", "each", "participant", "with", "a", "SDD", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "standard desktop display"}, {"tokens": ["In", "the", "table", ",", "Prob", "denotes", "the", "Chakrabarti", "method", "(", "with", "several", "thousands", "parameters", ")", "and", "RB", "the", "rank", "-", "based", "method", "with", "408", "parameters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rank - based"}, {"tokens": ["LI", ":", "liver", ",", "ST", ":", "stomach", ",", "DU", ":", "duodenum", ",", "LK", ":", "left", "kidney", ",", "and", "RK", ":", "right", "kidney", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "right kidney"}, {"tokens": ["The", "information", "bottleneck", "(", "IB", ")", "investigates", "the", "problem", "of", "extracting", "the", "relevant", "information", "from", "for", "the", "task", "of", "predicting", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Evaluation", "of", "ISP", "Stagessec", ":", "stagesIn", "this", "section", ",", "we", "discuss", "the", "results", "of", "CNN", "training", "experiments", "using", "images", "generated", "by", "different", "ISP", "configurations", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "image signal processor"}, {"tokens": ["htb]4", ",", "clip]Figures", "/", "c1_true.png", ",", "clip]Figures", "/", "c1_est.png", ",", "clip]Figures", "/", "c1_est_pca.png", ",", "clip]Figures", "/", "c1_est_ica.png", ",", "clip]Figures", "/", "c2_true.png", ",", "clip]Figures", "/", "c2_est.png", ",", "DMD", ",", "clip]Figures", "/", "c2_est_pca.png", ",", "PCA", ",", "clip]Figures", "/", "c2_est_ica.png", ",", "ICA", ",", "clip]Figures", "/"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["In", "this", "paper", ",", "we", "tackle", "the", "cloud", "detection", "problem", "by", "presenting", "a", "framework", "based", "on", "deep", "pyramid", "network", "architecture", "(", "DPN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "deep pyramid network"}, {"tokens": ["We", "observe", "that", "appending", "SA", "-", "layer", "can", "significantly", "improve", "the", "standard", "IB", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["For", "this", "exploitation", ",", "we", "can", "employ", "the", "shifted", "version", "of", "the", "exponential", "IB", "Lagrangian", "(", "which", "is", "also", "a", "particular", "case", "of", "the", "convex", "IB", "Lagrangian):the", "shifted", "exponential", "IB", "Lagrangians", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "reason", "is", "that", "LE", "scheduling", "fails", "when", "the", "low", "energy", "nodes", "have", "poor", "link", "quality", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low energy"}, {"tokens": ["This", "means", "that", "it", "is", "not", "necessary", "to", "consider", "the", "far", "away", "RRHs", "for", "each", "UE", "since", "they", "contribute", "less", "to", "their", "performance", "and", "the", "candidate", "size", "should", "not", "be", "larger", "than", "4", "to", "obtain", "a", "tradeoff", "between", "performance", "and", "implementation", "complexity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["By", "this", "definition", ",", "BS", "can", "be", "directly", "applied", "to", "our", "ranking", "problem", "by", "considering", "the", "related", "items", "as", "seeds", "and", "class", "as", "domain", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian sets"}, {"tokens": ["RB", ":"], "acronym_pos": [1, 0], "long_form": "reduced basis"}, {"tokens": ["While", ",", "recently", ",", "datasets", "underlying", "QA", "systems", "have", "been", "promoted", "from", "unstructured", "datasets", "to", "structured", "datasets", "with", "semantically", "highly", "enriched", "metadata", ",", "question", "answering", "systems", "are", "still", "facing", "serious", "challenges", "and", "are", "therefore", "not", "meeting", "users", "'", "expectations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Regardless", "of", "their", "conceptual", "differences", ",", "UTAUT", ",", "TPB", ",", "and", "TAM", "have", "gained", "considerable", "evidence", "that", "supports", "them", "as", "relevant", "ones", "to", "understand", "the", "complexities", "of", "the", "technology", "-", "mediated", "relationships", "between", "buyers", "and", "sellers", "through", "E", "-", "commerce", "platforms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "technology acceptance model"}, {"tokens": ["[", "Domain", "of", "convex", "IB", "Lagrange", "multiplier", "with", "known", "IB", "curve", "shape", "]"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["However", ",", "RV", "strategy", "shows", "very", "poor", "performance", "at", "a", "lower", "value", "of", "with", "the", "vaccination", "of", "about", "5000", "nodes", "in", "both", "networks", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["The", "Expert", "has", "60", "cluster", "centers", "and", "was", "allowed", "to", "learn", "3000", "sequences", "of", "length", "3", ",", "where", "the", "lookbehind", "(", "how", "far", "in", "the", "past", "the", "TP", "looks", "to", "calculate", "in", "which", "sequence", "it", "is", "currently", "in", ")", "is", "and", "the", "lookahead", "(", "how", "many", "future", "steps", "the", "TP", "predicts", ")", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["For", "ease", "of", "exposure", ",", "we", "will", "first", "conduct", "ouranalysis", "using", "Shannon", "capacity", "as", "in", "Section", ";", "then", "in", "Section", ",", "we", "will", "consider", "aclosed", "-", "form", "approximation", "for", "the", "actual", "LTE", "rate", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["For", "accuracy", ",", "however", ",", "DDE", "-", "MGM", "is", "superior", "to", "the", "state", "-", "of", "-", "the", "-", "art", "in", "both", "off-", "and", "on", "-", "line", "categories", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["This", "discriminator", "receives", "three", "inputs", "corresponding", "to", "the", "generated", "LR", "image", "with", "groundtruth", "heatmap", ",", "generated", "LR", "image", "with", "predicted", "heatmap", "and", "a", "real", "LR", "image", "with", "predicted", "heatmap", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["c3_est.png", ",", "DMD", ",", "clip]Figures", "/", "c3_est_pca.png", ",", "PCA", ",", "clip]Figures", "/", "c3_est_ica.png", ",", "ICA", ",", "clip]Figures", "/", "c4_true.png", ",", "clip]Figures", "/", "c4_est.png", ",", "DMD", ",", "clip]Figures", "/", "c4_est_pca.png", ",", "PCA", ",", "clip]Figures", "/"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["Another", "important", "feature", "should", "be", "provided", "by", "FL", "frameworks", "is", "the", "support", "fordynamic", "participation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["(", "ECC", "on", ")", ",", "14.15", "Gkeys"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["ExperimentsThe", "Domain", "Transfer", "Network", "(", "DTN", ")", "is", "evaluated", "in", "two", "application", "domains", ":", "digits", "and", "face", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "domain transfer network"}, {"tokens": ["Upon", "comparison", "with", "simply", "fitting", "an", "SBM", "to", "the", "network", ",", "they", "found", "that", "two", "employees", "in", "the", "same", "group", "inferred", "by", "the", "SBM", "might", "actually", "have", "vastly", "different", "roles", "in", "the", "company", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["For", "arousal", ",", "we", "consistently", "observe", "better", "performance", "(", "lower", "RMSE", "and", "higher", "PR", "and", "CCC", ")", "with", "one", "shared", "layer", "between", "the", "domain", "and", "task", "classifiers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["Because", "the", "energy", "equation", "will", "be", "used", ",", "the", "FEM", "is", "only", "efficient", "for", "the", "small", "deformation", "of", "the", "elastic", "object", ",", "such", "as", "application", "to", "the", "plastic", "material", ",", "which", "has", "a", "small", "deformation", "range", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["They", "combine", "a", "notebook", "with", "a", "differential", "GPS", "receiver", "and", "a", "head", "-", "worn", "electronic", "compass", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["GPR", "measures", "the", "similarity", "between", "two", "dose", "distributions", "on", "a", "voxel", "-", "by", "-", "voxel", "basis", ",", "computing", "for", "each", "voxel", ",", "a", "pass", "-", "fail", "test", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gamma passing rate"}, {"tokens": ["BC", "learning", "was", "also", "shown", "to", "boost", "the", "performance", "of", "other", "ESC", "models", "as", "well", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "between class"}, {"tokens": ["In", "general", ",", "we", "believe", "that", "focusing", "on", "polyglot", "and", "mixed", "language", "decoding", "is", "not", "only", "of", "interest", "to", "applications", "(", "e.g", ",", "mixed", "language", "API", "QA", ")", "but", "also", "allows", "for", "new", "forms", "of", "SP", "evaluation", "that", "are", "more", "revealing", "than", "only", "translation", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic parsing"}, {"tokens": ["Kurtosis", "-", "based", "ICA", "also", "fails", ",", "as", "the", "two", "AR", "processes", "have", "Gaussian", "marginals", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["As", "shown", "in", "Figure", ",", "the", "proposed", "DADA", "consists", "of", "a", "feature", "extractor", ",", "a", "class", "predictor", "and", "two", "discriminators", "with", "-dimensional", "output", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dual adversarial domain adaptation"}, {"tokens": ["We", "also", "showed", "that", "the", "CSG", "closely", "matches", "the", "accuracy", "achievable", "by", "standard", "CNN", "architectures", ",", "an", "important", "feature", "when", "assessing", "an", "image", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["CC", "-", "CV", "and", "Charging", "Current", "as", "the", "Battery", "Ages"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["In", "a", "previous", "comparison", "between", "GMM", "and", "FMM", ",", "GMM", "was", "about", "50", "faster", "in", "all", "cases", "than", "FMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["The", "population", "size", "for", "all", "DE", "-", "based", "methods", "is", ",", "and", "for", "all", "CMA", "-", "ES", "-", "based", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Moreover", ",", "and", "are", "two", "different", "OAM", "modes", "as", "well", "to", "transmit", "additional", "symbols", "to", "and", "respectively", "from", "the", "BS", "to", "enhance", "the", "capacities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "total", ",", "21", "LOM", "and", "SEM", "images", "with", "an", "average", "size", "of", "7000x8000px", "were", "available", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["In", "June", ",", "Magic", "Leap", "announces", "that", "they", "will", "release", "its", "AR", "platform", "SDK", "to", "the", "public", "soon", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["*", "ui", "-", "naca-", "MP", "winah", "NP", "gunah", "'", "sin'PIr"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["CNet", "-", "NIC", "Ablation", "Study", "ResultsWe", "report", "results", "of", "an", "ablation", "study", "of", "CNet", "-", "NIC", ",", "where", "we", "examine", "the", "relative", "contributions", "of", "the", "different", "components", "of", "the", "CNet", "-", "NIC", "architecture", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "neural image caption"}, {"tokens": ["proposed", "species", "based", "quantum", "PSO", "(", "SQPSO", ")", "algorithm", "for", "solving", "different", "types", "of", "ELD", "problems", "of", "power", "systems", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["figure[!t", "]", "semantic-eps-converted-to.pdfAverage", "ACC", ":", "class", "labels", "vs.", "attributes", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "accuracy"}, {"tokens": ["Visualization", "of", "latent", "embeddings", "as", "classified", "by", "GMM", "for", "patch", "size", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["demonstrate", "an", "end", "-", "to", "-", "end", "neural", "network", "model", "for", "generative", "QA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "question answering"}, {"tokens": ["Suppose", "the", "optimal", "distribution", "is", ",", "since", "the", "points", "in", "is", "farthest", "to", "each", "other", ",", "it", "should", "correspond", "to", "the", "highest", "probability", "in", "looking", "for", "a", "distinct", "RV", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "resilience vector"}, {"tokens": ["The", "ANN", "model", "showed", "an", "80", "improvement", "over", "the", "LMEM", "based", "on", "both", "the", "component", "-", "wise", "and", "field", "-", "magnitude", "RMSE", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "nodes", "with", "maximum", "packet", "forwarding", "capacity", "and", "maximum", "BC", "are", "denoted", "by", "and", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["NN", "-", "RSSD", "algorithm", "finds", "the", "solution", "by", "sequentially", "solving", "two", "optimization", "problems", "of", "the", "SCP", "central", "plant", "problem", "and", "the", "RSSD", "output", "feedback", "controller", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["The", "results", "again", "show", "that", "SFM", "consistently", "outperforms", "other", "methods", "with", "various", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "structural factorization machine"}, {"tokens": ["An", "RBF", "-", "PSO", "based", "approach", "for", "early", "detection", "of", "DDoS", "attacks", "in", "SDN", "'", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "previous", "observations", "about", "sensitivity", "preserving", "reductions", "imply", "that", "we", "get", "thesame", "lower", "bounds", "for", "st", "-", "reach", ",", "BP", "-", "Match", "and", "SC", "with", "sensitivity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "strongly connected"}, {"tokens": ["We", "use", "the", "notation", "to", "denote", "the", "LTS", "induced", "from", "the", "actors", ",", "using", "the", "coarse", "-", "grained", "semantic", "description", "of", "AML", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "actor modeling language"}, {"tokens": ["The", "PSO", "does", "not", "have", "parent", "selection", ",", "recombination", "and", "mutation", "steps", ";", "thus", ",", "this", "enables", "PSO", "to", "behave", "in", "a", "particular", "way", "in", "comparison", "with", "other", "evolutionary", "algorithms", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["To", "verify", "the", "effect", "of", "PSIS", ",", "we", "further", "analysis", "the", "gain", "AP", "for", "each", "class", "brought", "by", "PSIS", "using", "Faster", "R", "-", "CNN", "(", "ResNet-101", ")", "on", "MS", "COCO", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Lastly", ",", "we", "find", "a", "concrete", "vulnerability", "for", "the", "malicious", "corrupt", "case", "in", "Lambaek", "'s", "PSI", "protocol", "when", "semi", "-", "honest", "KK13", "OT", "extension", "is", "used", "in", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Interestingly", ",", "both", "MP", "and", "CF", "provide", "a", "perfect", "score", "for", "P@1", "of", "1.000", ",", "which", "indicates", "that", "both", "algorithms", "rank", "a", "highly", "-", "connected", "dataset", "on", "the", "first", "position", "that", "is", "relevant", "for", "all", "2,338", "evaluated", "services", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "GSP", "model", ":", "the", "classical", "GSP", "auction", "mechanism", "with", "in", "the", "quality", "score", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized second price"}, {"tokens": ["However", ",", "most", "existing", "DCNN", "based", "SSR", "methods", "treat", "all", "pixels", "in", "HSIs", "equally", "and", "learn", "a", "universal", "mapping", "function", "with", "a", "fixed", "-", "sized", "receptive", "field", ",", "as", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Since", "the", "TP", "runs", "only", "if", "the", "winning", "cluster", "of", "the", "SP", "changes", ",", "this", "results", "in", "a", "situation", "where", "the", "data", "for", "the", "TP", "changes", "very", "infrequently", ",", "which", "means", "that", "the", "TP", "learns", "very", "slowly", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["This", "first", "population", "confirms", "the", "MGM", "GAN", "'s", "ability", "to", "make", "changes", "to", "the", "geometry", "of", "the", "manifold", "in", "order", "to", "convincingly", "generate", "points", "in", "the", "opposite", "domain", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["The", "GMM", "is", "applied", "to", "train", "the", "cluster", "model", "both", "for", "the", "path", "primitives", "and", "motion", "primitives", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "table", "compares", "the", "results", "for", "LR", "and", "RF", "with", "a", "single", "time", "-", "series", "feature", ",", "all", "features", "and", "features", "selected", "by", "the", "CFS", "feature", "selector", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["From", "the", "perspective", "of", "natural", "language", "processing", ",", "SL", "is", "the", "formal", "language", "-", "theoretic", "basis", "of", "n", "-", "gram", "models", "and", "SP", "models", "aspects", "of", "phonology", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["So", "when", "transmit", "power", "of", "the", "BS", "increases", ",", "the", "power", "allocated", "to", "confidential", "signal", "is", "much", "more", "than", "that", "of", "AN", ",", "providing", "the", "eavesdroppers", "more", "chance", "to", "decipher", "confidential", "signals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["For", "high", "enough", ",", "the", "LDPC", "design", "can", "outperform", "the", "DI", "approach", ",", "but", "still", "gives", "a", "utility", "lower", "than", "our", "GT", "strategy", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "direct inspection"}, {"tokens": ["When", "=", "0", ",", "it", "refers", "to", "all", "DUs", "in", "H", "-", "CRAN", ",", "=", "refers", "to", "set", "of", "DUs", "in", "the", "CC", ",", "=", "refers", "to", "the", "set", "of", "DUs", "in", "EC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Structural", "equivalence", ",", "and", "so", "the", "GCP", ",", "is", "also", "related", "to", "community", "detection", "Fortunato10", ",", "also", "known", "as", "graph", "clustering", ",", "that", "is", "a", "classical", "problem", "for", "graph", "analysis", "which", "consists", "in", "finding", "groups", "of", "vertices", "that", "are", "strongly", "connected", "with", "each", "others", "while", "being", "loosely", "connected", "to", "other", "groups", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph compression problem"}, {"tokens": ["The", "results", "of", "this", "exercise", "for", "unemployment", ",", "inflation", "and", "GDP", "are", "summarised", "in", "Tab", ".", "-", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gross domestic product"}, {"tokens": ["A", "detection", "algorithm", "is", "utilized", "by", "estimating", "of", "the", "received", "power", "at", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access part"}, {"tokens": ["While", "many", "of", "the", "previous", "work", "studied", "SRL", "on", "large", "scale", "English", "datasets", "in", "news", "domain", ",", "our", "research", "aims", "to", "explore", "SRL", "in", "Indonesian", "conversational", "language", ",", "which", "is", "still", "under", "-", "resourced", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["Since", "its", "introduction", ",", "PSO", "has", "attracted", "many", "researchers", "and", "over", "the", "years", "many", "PSO", "variants", "have", "been", "proposed", "to", "improve", "the", "performance", "of", "the", "original", "algorithm", "albeit", "the", "research", "has", "been", "mostly", "restricted", "to", "the", "'", "continuous", "domain", "'", ",", "i.e.", ",", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["In", "Toral2007", ",", "the", "authors", "considered", "a", "MR", "model", ",", "and", "concluded", "that", "the", "behavior", "of", "their", "system", "resembles", "the", "movement", "of", "a", "Brownian", "particle", "in", "a", "potential", "field", "that", "is", "unknown", "a", "priori", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "majority rule"}, {"tokens": ["The", "MDC", "then", "collects", "measurements", "every", "second", "from", "the", "Smart", "Meter", ",", "via", "a", "secure", "HTTPS", "channel", ",", "and", "encrypts", "them", "using", "the", "AES", "-", "CTR", "encryption", "mode", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "metering data collector"}, {"tokens": ["Another", "enhancement", "in", "PredictiveAnts", "is", "the", "use", "of", "FEC", "blocks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Meanwhile", ",", "we", "analyze", "and", "compare", "the", "complexity", "for", "the", "three", "TAS", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["[", "LAP", "]", "Low", "Altitude", "Platform", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "low altitude platform"}, {"tokens": ["its", "performance", "heavily", "relies", "on", "the", "quality", "of", "CSI", "for", "RS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "rate - selective"}, {"tokens": ["These", "are", "the", "desired", "centres", "of", "LV", ",", "RV", ",", "RA", "and", "LA", "cavities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "right atrium"}, {"tokens": ["Table", "reports", "the", "average", "computational", "time", "of", "ECS", "-", "DBN", "with", "5-fold", "cross", "validation", "over", "10", "trials", "on", "the", "overall", "58", "benchmark", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["We", "provide", "the", "coarse", "-", "grained", "semantics", "of", "AML", "in", "which", "the", "execution", "of", "methods", "are", "non", "-", "preemptive", ",", "i.e.", ",", "when", "an", "actor", "takes", "a", "message", ",", "it", "executes", "the", "entire", "body", "of", "the", "method", "before", "starting", "execution", "of", "another", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["This", "could", "be", "because", "the", "continuations", "from", "BS", "are", "shorter", ",", "simpler", ",", "and", "more", "fluent", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "beam search"}, {"tokens": ["For", "this", "reason", ",", "we", "generalize", "the", "effort", "from", "and", "look", "for", "families", "of", "Lagrangians", "which", "are", "able", "to", "explore", "the", "IB", "curve", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Theoretic", "approach", "on", "new", "agents", "features", "for", "Android", "applicationsSeveral", "common", "features", "for", "Multi", "Agent", "Systems", "and", "an", "Android", "application", "are", ":", "Concurrency", ":", "the", "Android", "components", "are", "activated", "by", "intents", "(", "decentralized", "events", "trigger", "an", "agent", "behavior", "or", "the", "Yellow", "Pages", "service", "provided", "by", "the", "DF", "special", "JADE", "agent", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "direction facilities"}, {"tokens": ["The", "authors", "defined", "a", "PAP", "to", "be", "imbalanced", "for", "a", "given", "collective", "operation", "with", "a", "specific", "message", "length", "when", "its", "imbalance", "factor", "(", "a", "ratio", "between", "the", "highest", "difference", "between", "the", "arrival", "times", "of", "the", "processes", "and", "time", "of", "the", "simple", "(", "point", "-", "to", "-", "point", ")", "message", "delivery", "between", "each", "other", ")", "is", "larger", "than", "1", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["When", "UE", "is", "used", "as", "the", "constraint", "for", "Formulation", ",", "it", "can", "not", "guarantee", "the", "optimal", "path", "flow", "estimator", "to", "be", "unique", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equilibrium"}, {"tokens": ["GS", "function", "scores", "an", "appearance", "of", "a", "word", "as", "the", "sum", "of", "the", "scores", "of", "all", "its", "following", "appearances", "as", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric sequence"}, {"tokens": ["Additionally", "we", "introduced", "a", "new", "way", "of", "on", "-", "line", "PAP", "detection", ",", "including", "PAT", "estimations", "and", "their", "distribution", "among", "cooperating", "processes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival time"}, {"tokens": ["DE", "optimizes", "an", "optimization", "problem", "by", "iteratively", "searching", "for", "a", "solution", "given", "an", "evaluation", "metric", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["ARD", "works", "on", "datasets", "where", "knowledge", "distillation", "failsIn", "Section", ",", "we", "saw", "that", "a", "student", "network", "inherited", "little", "robustness", "from", "an", "adversarially", "trained", "teacher", "network", "on", "CIFAR-100", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["To", "configure", "MC", "and", "facilitate", "the", "selection", "of", "the", "most", "suitable", "SN", ",", "the", "MN", "instructs", "the", "UE", "to", "make", "channel", "measurements", "and", "report", "back", "the", "detected", "cells", "through", "the", "RRC", "connection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["hpcresourcesThe", "computational", "experiments", "were", "executed", "on", "standard", "compute", "nodes", "of", "three", "XSEDExsede", "supercomputers", ",", "SDSC", "Comet", ",", "PSC", "Bridges", ",", "and", "LSU", "SuperMIC"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["It", "consists", "of", "100", "Wikipedia", "sentences", "per", "syntactic", "phenomenon", "tackled", "by", "our", "TS", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "tree structures"}, {"tokens": ["With", "lr=0.25", ",", "the", "CER", "after", "cleaning", "went", "up", "from", "137.1", "to", "170.0", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["Level", "-", "wise", "error", "analysis", "of", "LR", "+", "-norm", "model", "for", "CLEF", ",", "IPC", "and", "DMOZ", "-", "SMALL", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["As", "velocities", "are", "constant", ",", "UFMM", "provides", "the", "same", "solution", "as", "other", "methods", ",", "GMM", "slightly", "improves", "FMM", "and", "FMMFib", "in", "2D."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["Interval", "type", "2", "fuzzy", "setsThe", "IT2FS", "class", "defines", "interval", "type", "2", "fuzzy", "sets", "by", "specifying", "the", "domain", ",", "UMF", ",", "parameters", "of", "UMF", "function", ",", "LMF", ",", "and", "parameters", "of", "LMF", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], "long_form": "lower membership function"}, {"tokens": ["GS", "is", "group", "sweep", "and", "Non", "-", "Pru"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "group sweep"}, {"tokens": ["By", "advancing", "technologies", ",", "wrapper", "-", "based", "FS", "also", "can", "be", "adopted", "in", "every", "system", ",", "even", "real", "-", "time", "decision", "making", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feature selection"}, {"tokens": ["Robustness", "of", "each", "feature", "was", "measured", "by", "the", "intraclass", "correlation", "coefficient", "(", "1,1", ")", "(", "ICC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["For", "instance", ",", "for", "the", "CF", "task", "on", "MovieLens"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["In", "eq", ":", "eff", ",", "represents", "the", "variance", "of", "the", "ASE", "noise", "and", "the", "variance", "of", "the", "NLI", "that", "includes", "both", "intra-", "and", "inter", "-", "channel", "distortions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "amplified spontaneous emission"}, {"tokens": ["A", "GP", "system", "for", "classification", "based", "on", "multidimensional", "clustering", "was", "recently", "demonstrated", "on", "biomedical", "classification", "problems", "as", "a", "competitive", "alternative", "to", "traditional", "machine", "learning", "approaches", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["For", "identifying", "proportion", "to", ",", "the", "performance", "of", "IMV", "and", "DV", "strategy", "does", "not", "change", "while", "RV", "strategy", "is", "strongly", "affected", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["Subsequently", ",", "the", "feasible", "compensators", "are", "given", "asAlso", ",", "the", "feasible", "RSSD", "static", "output", "feedback", "controller", "gain", "is", "given", "asBesides", ",", "the", "SCP", "central", "plant", "is", "=", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["it", "is", "assumed", "there", "is", "a", "random", "variable", "which", "subsumes", "possible", "permutations", ",", "and", "the", "LB", "divergence", "computes", "the", "divergence", "between", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["Local", "ExemplarsThe", "local", "exemplars", "discovered", "by", "AP", "and", "EAP", "often", "represent", "the", "typical", "characteristics", "of", "a", "subset", "of", "the", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["Our", "numerical", "results", "verify", "that", "the", "expected", "error", "of", "trained", "network", "has", "a", "linear", "relationship", "with", "respect", "to", "the", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "cover complexity"}, {"tokens": ["After", "that", ",", "nodes", "in", "the", "inner", "cores", "are", "ranked", "according", "to", "BC", "of", "the", "nodes", "in", "the", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["Modelling", ":", "How", "should", "the", "SBM", "be", "structured", "or", "extended", "to", "realistically", "describe", "real", "-", "world", "networks", ",", "with", "or", "without", "additional", "information", "on", "the", "nodes", "or", "the", "edges", "?"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "attacker", "had", "the", "ability", "to", "(", "1", ")", "launch", "the", "attack", "using", "the", "Edison", "SoC", "remotely", "from", "the", "CC", "and", "to", "(", "2", ")", "maneuver", "the", "drone", "using", "its", "joystick", "and", "watch", "the", "streamed", "video", "in", "an", "Android", "application", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "covert channels"}, {"tokens": ["=", "feature", "available", "from", "VM", "or", "BM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0], "long_form": "bare metal"}, {"tokens": ["Data", "ParallelismIn", "the", "data", "parallelism", "scheme", ",", "as", "shown", "in", "Figure", ",", "each", "worker", "machine", "creates", "a", "complete", "computation", "graph", "and", "typically", "communicates", "gradients", "with", "a", "model", "parameter", "holder", "such", "as", "PS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "parameter server"}, {"tokens": ["passiveAs", "discussed", "in", "s", ":", "resultingRequirements", ",", "the", "process", "is", "split", "into", "the", "Spatial", "Pooler", ",", "the", "Temporal", "Pooler(The", "terminology", "adopted", "from", "Hawkins2015", ")", ",", "and", "Output", "Projection", ",", "which", "can", "be", "expressed", "by", "the", "following", "three", "equations", ":", "alignx(t", ")", "&", "=", "f_1(o(t", ")", "_", "SP", ")", ",", "eq:1P(S)(t", ")", "&", "=", "f_2(x(t", ")", ",", "x(t-1", ")", ",", ",", "x(t", "-", "T_h", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial pooler"}, {"tokens": ["We", "will", "demonstrate", "later", "that", "the", "signal", "reconstruction", "performance", "of", "OLS", "is", "close", "to", "optimal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["Given", "a", "good", "shift", ",", ",", "SII", "usually", "converges", "more", "quickly", "than", "PI", ",", "especially", "for", "loosely", "coupled", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["In", "this", "part", ",", "we", "mainly", "focus", "on", "the", "four", "pre", "-", "trained", "models", "from", "AlexNetConv", "and", "HNet", "to", "see", "how", "to", "make", "them", "more", "effective", "in", "transferring", "to", "SAR", "targets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Here", "again", ",", "to", "overcome", "these", "challenges", "an", "adaptive", "FEC", "-", "based", "scheme", "can", "be", "tailored", "to", "shield", "the", "video", "transmission", "with", "QoE", "assurance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["A", "missing", "point", "in", "all", "types", "of", "QA", "systems", "is", "that", "in", "case", "of", "either", "success", "or", "failure", ",", "they", "are", "silent", "to", "the", "question", "of", "why", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["We", "demonstrated", "the", "strengths", "and", "weaknesses", "of", "existing", "computational", "AA", "paradigms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["Apart", "from", "using", "RF", "for", "quantile", "regression", "forest", ",", "we", "shall", "use", "RF", "for", "feature", "importance", "and", "partial", "dependence", "plots", "(", "PDP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "partial dependence plots"}, {"tokens": ["ContributionsIn", "this", "paper", ",", "we", "introduce", "a", "framework", "of", "a", "hybrid", "RF", "/", "RE", "-", "based", "EH", "scheme", "using", "the", "PS", "protocol", "for", "two", "-", "way", "multiple", "-", "relay", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Thus", ",", "the", "preventive", "efficiency", "of", "RV", "strategy", "is", "about", "18", "in", "the", "DDT", "network", "and", "16", "in", "the", "GDT", "network", "at", "the", "vaccination", "rate", "(", "see", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["If", "necessary", ",", "the", "user", "can", "actively", "add", "new", "landmarks", "based", "on", "the", "image", "context", "and", "visualization", "of", "the", "uncertainty", "measure", "provided", "by", "the", "GP", "to", "further", "improve", "the", "result", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": [":", "u1:tzf", ":", "def2", ",", "for", "can", "be", "written", "as-0.5emwhere", "is", "the", "distance", "from", "the", "nearest", "to", "the", "BS", "and", "is", "the", "distance", "from", "to", "the", "nearest", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Compared", "with", "the", "76.8", "mAP", "(", "SSD", "in", "Table", ")", "baseline", "on", "PASCAL", ",", "the", "single", "stage", "trained", "detector", "with", "our", "design", "achieves", "better", "performance", "at", "78.1", ",", "we", "believe", "the", "enhancement", "derive", "from", "better", "feature", "representation", "by", "deconvolution", "and", "the", "automatic", "feature", "selection", "via", "MAD", "unit", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "map attention decision"}, {"tokens": ["Accuracy", "-", "the", "accuracy", "metric", "is", "a", "weighted", "average", "of", "the", "true", "positive", "rates", "across", "all", "four", "classes;AUC", "-", "average", "area", "under", "the", "curve", ";", "as", "the", "ROC", "curve", "depicts", "the", "relation", "between", "the", "false", "positive", "rate", "and", "the", "true", "positive", "rate", "when", "the", "pairwise", "discrimination", "threshold", "is", "varied", ";", "in", "our", "case", "we", "report", "the", "average", "AUC", "between", "the", "target", "class", "and", "the", "sum", "of", "the", "negative", "classes", ";", "Figures", "9", "-", "11", "below", "show", "the", "best", "results", "for", "each", "data", "set", "in", "graphical", "form", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["IntSST", "and", "ClassicLit", "and", "LMRCSST", "and", "LMRCSST", "and", "SST", "2TE", "and", "ATTE", "and", "ATIS", "IntTE", "and", "NYR", "10YTS", "and", "ATYTS", "and", "ATIS", "IntYTS", "and", "TE", "and", "PSC", "and", "RS"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "paper sentence classification"}, {"tokens": ["We", "conduct", "a", "series", "of", "experiments", "on", "two", "representative", "state", "of", "the", "art", "deep", "nets", "for", "RS", "images", ",", "the", "Maggiori", "et", "al", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["An", "antenna", "information", "field", "is", "added", "to", "Ant", "-", "CTS", ",", "which", "is", "broadcast", "by", "the", "AP", "to", "announce", "the", "number", "of", "available", "antennas", "(", "after", "one", "antenna", "is", "occupied", "in", "the", "first", "contention", "round", ")", "and", "the", "start", "of", "the", "-nd", "contention", "round", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "poor", "results", "for", "UC4", "indicate", "that", "we", "need", "more", "sophisticated", "algorithms", "than", "MP", "and", "CF", "in", "this", "setting", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["However", ",", "our", "preliminary", "experiments", "for", "DC", "-", "OPF", "showed", "that", "although", "there", "is", "a", "further", "reduction", "of", "the", "meta", "-", "loss", ",", "it", "still", "required", "a", "subsequent", "meta", "-", "optimization", "of", "the", "NN", "to", "have", "competitive", "performance", "to", "the", "above", "results", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["In", "all", "plots", ",", "the", "cases", "keep", "their", "respective", "locations", ",", "and", "are", "sorted", "by", "the", "probability", "of", "'", "3", "'", "as", "inferred", "by", "the", "MNIST", "classifier", "on", "the", "results", "of", "our", "DTN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "domain transfer network"}, {"tokens": ["Several", "independent", "yet", "correlated", "bit", "streams", "generated", "by", "the", "MDC", "technique", "facilitate", "to", "the", "independent", "decoding", "of", "each", "packet", ",", "while", "joint", "decoding", "of", "two", "or", "more", "bit", "-", "streams", "is", "also", "supported", "by", "the", "MDC", "technique", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["To", "show", "the", "applicability", "of", "our", "approach", "to", "more", "conventional", "SP", "tasks", ",", "we", "apply", "our", "methods", "to", "the", "GeoQuery", "domain", "and", "the", "Sportscaster", "corpus", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic parsing"}, {"tokens": ["Although", "this", "is", "impressive", "and", "helpful", "under", "the", "case", "of", "lacking", "enough", "SAR", "targets", "but", "with", "adequate", "unlabeled", "SAR", "images", ",", "how", "generic", "or", "specific", "are", "the", "features", "from", "different", "source", "tasks", "transferred", "to", "SAR", "targets", "is", "still", "unknown", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Upon", "receiving", "the", "detection", "message", ",", "each", "RS", "callsPrediction", "(", ")", "to", "calculate", "its", "potentialenergy", "and", "inform", "the", "energy", "capacity", "to", "the", "initiator", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["ConclusionsWe", "presented", "the", "work", "on", "a", "QA", "system", "trained", "with", "a", "sequence", "-", "to", "-", "sequence", "neural", "model", "with", "the", "DBpedia", "knowledge", "and", "movie", "dialogues", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["In", "other", "words", ",", "we", "assume", "that", "the", "warping", "functions", "can", "be", "written", "as", ":", "where", "is", "the", "DST", "coefficients", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "discrete sine transform"}, {"tokens": ["Similarly", ",", "for", "protein", "interactions", "dataset", ",", "interested", "readers", "can", "compare", "our", "results", "to", "which", "provides", "a", "detailed", "comparison", "between", "AP", "and", "MCL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["KNN", "-", "MSE", "results", "for", "each", "SRL", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "state representation learning"}, {"tokens": ["(", "GI", ":", "gradient", "initialization", ",", "SSS", ":", "staggered", "sample", "selection", ",", "SOM", ":", "standard", "SOM", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient initialization"}, {"tokens": ["Yet", ",", "the", "main", "difference", "is", "that", "MP", "methods", "optimize", "over", "the", "linear", "span", "of", "the", "atoms", ",", "while", "FW", "methods", "optimize", "over", "their", "convex", "hull", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["We", "demonstrate", "that", "our", "proposed", "IoT", "-", "BC", "architecture", "is", "sufficiently", "secure", "with", "regard", "to", "fundamental", "security", "goals", "i.e.", ",", "confidentiality", ",", "integrity", ",", "and", "availability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["Therefore", ",", "E", "-", "SC", "can", "not", "be", "sufficient", "condition", "for", "SLN", "robustness", "if", "there", "is", "differential", "costing", "of"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "symmetry condition"}, {"tokens": ["It", "seems", "that", "Cox", "point", "process", "driven", "by", "PLP", "is", "a", "relevant", "model", "for", "roads", "in", "urban", "environment", "that", "is", "gaining", "popularity", "recently", "and", "merits", "investigations", "when", "looking", "for", "performance", "analysis", "and", "dimensioning", "problems", "of", "wireless", "cellular", "communications", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["The", "impact", "of", "normalized", "transmission", "distance", "between", "BS", "to", "CCU", "and", "number", "of", "OAM", "modes", "for", "NOMA", "-", "OAM", "-", "MDMA", "over", "user", "capacities", "and", "SC", "improvements", "of", "the", "proposed", "(", "NOMA", "-", "OAM", "-", "MDMA", ")", "scheme", "are", "analyzed", "and", "compared", "with", "conventional", "NOMA", ",", "and", "OMA", "-", "OAM", "-", "MDMA", "are", "also", "analyzed", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["In", "Figure", "9", ",", "the", "EE", "w.r.t", "is", "plotted", "for", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["Additionally", ",", "there", "has", "been", "work", "combining", "both", "RV", "and", "BEV", "representations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "range view"}, {"tokens": ["Performance", "of", "TRADES", "WideResNet", "distilled", "onto", "MobileNetV2", "using", "ARD", "with", "different", "values", "of", "on", "CIFAR-10", ",", "where", "robust", "accuracy", "is", "with", "respect", "to", "a", "-step", "PGD", "attack", "as", "in", "[", "15].Appendix", "F", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["The", "private", "messages", "of", "the", "RS", "transmission", "in", "the", "second", "link", "achieve", "almost", "the", "same", "sum", "rate", "as", "the", "conventional", "BC", "with", "full", "power", ",", "when", "holds", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["The", "number", "of", "subject", "categories", "that", "a", "paper", "is", "assigned", "to", "vary", "from", "1", "to", "6", "in", "the", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Unfortunately", ",", "the", "conventional", "algorithms", "such", "as", "neural", "network", ",", "DBN", "generally", "assume", "all", "misclassification", "costs", "are", "equal", "which", "is", "not", "suitable", "for", "such", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["At", "the", "core", "of", "both", "algorithms", "is", "a", "subroutine", "to", "solve", "the", "Linear", "Assignment", "Problem", "(", "LAP", "-", "see", "Equation"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "linear assignment problem"}, {"tokens": ["Therefore", ",", "the", "aforementioned", "memory", "technologies", "are", "protected", "against", "the", "conventional", "charge", "probing", "techniques", "like", "SKPM", ",", "SCM", ",", "PVC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "scanning capacitance microscopy"}, {"tokens": ["Our", "work", "differs", "from", "previous", "works", "in", "that", "we", "do", "not", "attempt", "to", "emulate", "ISP", "functions", "with", "neural", "algorithms", ",", "but", "rather", "explore", "the", "need", "for", "ISP", "functions", "in", "the", "first", "place", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["It", "is", "due", "to", "the", "fact", "that", "the", "AP", "manages", "all", "traffic", "to", "and", "from", "STAs", "in", "a", "WLAN", ",", "while", "it", "has", "the", "same", "probability", "to", "access", "the", "channel", "as", "the", "STAs", "due", "to", "the", "random", "backoff", "mechanism", "of", "CSMA", "/", "CA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Mixture", ":", "The", "data", "points", "are", "sampled", "from", "a", "Gaussian", "mixture", "model", "(", "GMM", ";", "see", "appendix", "for", "details", ")", "consisting", "of", "three", "clusters", "of", "nominal", "points", "positioned", "at", "the", "vertices", "of", "a", "triangle", "in", "8-d", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["This", "behavior", "of", "MP", "outperforming", "CF", "can", "only", "be", "observed", "in", "this", "use", "case", ",", "which", "shows", "that", "personalized", "approaches", "are", "not", "always", "necessary", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "most popular"}, {"tokens": ["in", "DE", "-", "based", "symmetry", "breaking", "approaches", ",", "symmetry", "breaking", "is", "always", "applied", "on", "each", "solution", "candidate", "right", "after", "it", "has", "been", "updated", "for", "the", "next", "iteration", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["The", "lower", "part", "shows", "the", "uP", "that", "runs", "the", "code", "for", "implementing", "the", "ELM", "-", "B", "based", "OCC", "and", "ADEPOS", "controller", "for", "DNS", ",", "while", "the", "upper", "part", "depicts", "the", "DC", "-", "DC", "converter", "for", "DVS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "one class classifier"}, {"tokens": ["According", "to", "the", "previous", "researches", ",", "it", "'s", "important", "to", "select", "the", "appropriate", "network", "and", "source", "task", "to", "transfer", "in", "SAR", "target", "recognition", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["In", "the", "RV", ",", "the", "sensor", "data", "is", "dense", ",", "but", "the", "perceived", "size", "of", "objects", "varies", "with", "range", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "range view"}, {"tokens": ["In", "practice", "the", "segmentation", "of", "VAT", "and", "SAT", "is", "usually", "performed", "with", "the", "help", "of", "automatic", "or", "semi", "-", "automatic", "methods", "which", "often", "require", "manual", "inspection", "and", "corrections", "by", "human", "experts", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["[", "]", "Representation", "of", "the", "continual", "learning", "process", "of", "the", "GP", "at", "time", "-", "steps", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "decomposed", "conditional", "variance", "for", "the", "-th", "arm", "can", "be", "computed", "as", ":", "We", "call", "this", "planning", "strategy", "as", "GP", "-", "UCB", "with", "future", "variance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "strength", "of", "(", "VO", ")", "or", "(", "CC", ")", "concept", "is", "that", "it", "models", "dynamic", "collision", "avoidance", "as", "a", "first", "order", "constraint", "in", "combined", "position", "-", "velocity", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collision cone"}, {"tokens": ["The", "perturbation", "ICC", "is", "the", "average", "of", "ICC", "1", "and", "2", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["Identification", "of", "such", "words", "is", "done", "by", "sampling", "of", "abstracts", "from", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["The", "Department", "of", "Energy", "will", "provide", "public", "access", "to", "these", "results", "of", "federally", "sponsored", "research", "in", "accordance", "with", "the", "DOE", "Public", "Access", "Plan", "(", "http://energy.gov/downloads/doe-public-access-plan", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "department of energy"}, {"tokens": ["Let", "us", "assume", "that", "is", "relay", "'s", "PS", "ratio", "during", "the", "time", "slot", ",", "where", ",", "such", "that", "corresponds", "to", "the", "part", "of", "RF", "signal", "that", "will", "be", "converted", "to", "a", "current", ",", "while", "the", "remaining", "part", "of", "the", "signal", "is", "used", "for", "information", "processing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["While", "this", "general", "approach", "has", "been", "used", "recently", "for", "the", "coverage", "analysis", "of", "cellular", "networks", "in", ",", ",", "we", "will", "demonstrate", "in", "this", "letter", "that", "a", "similar", "approach", "can", "also", "be", "leveraged", "to", "derive", "remarkably", "simple", "expressions", "for", "the", "CD", "and", "NND", "distributions", "of", "an", "-D", "MCP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "contact distance"}, {"tokens": ["NP", "-", "hardness", "of", "the", "membership", "problem", "follows", "fromStockmeyerMeyer:1973", ",", "where", "it", "is", "shown", "that", "membership", "is", "already", "NP", "-", "hard", "when", "restricted", "to", "intersection", "-", "free", "systems", "with", "only", "non", "-", "negative", "constants", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "non - emptiness problem"}, {"tokens": ["In", "Section", "sec", ":", "cand", ",", "we", "show", "that", "one", "can", "extend", "the", "connection", "between", "GDP", "and", "Lipschitz", "testing", "to", "design", "an", "algorithm", "which", "converts", "the", "candidate", "algorithm", "in", "to", "a", "-generalized", "differentially", "private", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["rulepropcentertabularlccccccRules", "&", "&", "&", "&", "&", "&", "NS1", "&", "14", "&", "67", "&", "1", "&", "29", "&", "12", "&", "11", "NS2", "&", "40", "&", "21", "&", "42", "&", "36", "&", "68", "&", "32", "GS", "&", "13", "&", "4", "&", "1", "&", "9", "&", "12", "&", "48", "Non", "-", "Pru", "&", "33", "&", "8", "&", "56", "&", "26", "&", "8", "&", "9", "tabularcentertableTesting", "the", "Effectiveness", "of", "Sweep", "Rules", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group sweep"}, {"tokens": ["This", "is", "how", "we", "define", "the", "SP", "languages", "in", "the", "experiments", "in", "this", "paper", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["All", "tests", "probing", "various", "integrating", "schemes", "have", "been", "repeated", "with", "three", "different", "simulation", "techniques", ",", "MD", ",", "HMC", "and", "GHMC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["We", "first", "infer", "the", "illegally", "-", "parked", "cars", "by", "checking", "whether", "GPS", "coordinates", "of", "the", "detected", "cars", "are", "in", "the", "parking", "database", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Since", "serving", "MBS", "is", "the", "closest", "LOS", "/", "NLOS", "MBS", "to", "the", "typical", "UE", ",", "serving", "hole", "is", "the", "nearest", "LOS", "/", "NLOS", "hole", "to", "the", "typical", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["Gaussian", "processes", "with", "priorsAssuming", "is", "a", "set", "of", "observations", "and", "being", "the", "reward", "in", "the", "map", ",", "we", "can", "query", "the", "GP", "at", "a", "new", "input", "point", "as", "follows", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["EBV&Encrypted", "Bit", "Vector", "FJ", "&", "Friendly", "Jamming", "HMAC&Hash", "Message", "Authentication", "Code", "KKT", "&", "Karush", "-", "Kuhn", "-", "Tucker", "LSA", "&", "Licensed", "Shared", "Access", "MANET", "&", "Mobile", "Ad"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["Although", "these", "correlating", "transform", "-", "based", "MDC", "methods", "provide", "an", "effective", "MD", "generation", "method", ",", "this", "kind", "of", "MDC", "method", "tends", "to", "be", "inefficient", "when", "a", "great", "deal", "of", "information", "redundancy", "is", "expected", "to", "be", "introduced", "into", "multiple", "descriptions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["A", "single", "outlier", "is", "that", "SCM", "without", "the", "DSCN", "achieves", "slightly", "better", "performance", "compared", "to", "the", "baseline", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial compositional model"}, {"tokens": ["The", "reason", "why", "the", "VOI", "map", "has", "the", "greatest", "improvement", "on", "the", "ET", "is", "that", "the", "percentiles", "of", "ET", "heatmap", "have", "the", "highest", "priorities", "while", "we", "create", "the", "VOI", "map", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["Typically", ",", "the", "output", "of", "the", "DST", "unit", "is", "represented", "as", "a", "probability", "distribution", "over", "multiple", "possible", "dialogue", "states", ",", "which", "provides", "a", "representation", "of", "the", "uncertainty", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["Given", "a", "potential", "location", "for", "a", "sensor", "and", "positions", "of", "energy", "transmitters", ",", "it", "computes", "(", "line", "2", "-", "7", ")", "the", "charge", "received", "at", "from", "each", "of", "the", "ET", ",", "located", "at", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "energy transmitters"}, {"tokens": ["Among", "these", "comparative", "MDC", "methods", "in", "TABLE", ",", "\"", "MDCNN", "\"", "requires", "the", "least", "coding", "time", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["As", "previously", "mentioned", ",", "this", "finding", "is", "expected", "as", "AP", "often", "acts", "as", "a", "news", "wire", "service", "for", "other", "news", "producers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "associated press"}, {"tokens": ["ACE", "is", "defined", "as", "follows", ":", "where", "is", "the", "target", "PI", "coverage", ",", "known", "as", "the", "PI", "nominal", "coverage", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average coverage error"}, {"tokens": ["the", "learning", "algorithms", ",", "we", "found", "that", "the", "retrained", "and", "incremental", "modeling", "have", "similar", "effect", "on", "LR", "and", "DT", ",", "but", "they", "lead", "to", "considerably", "diverse", "result", "while", "working", "on", "SVM", "and", "MLP", ":", "overall", ",", "the", "retrained", "modeling", "is", "clearly", "better", "in", "accuracy", "on", "SVM", "while", "the", "incremental", "one", "yields", "much", "better", "results", "on", "MLP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear regression"}, {"tokens": ["Multi", "-", "parameter", "GP", "priorThe"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["Then", ",", "AR", "Technologies", "along", "with", "its", "workflow", "is", "depicted", ",", "which", "includes", "the", "complete", "AR", "Process", "consisting", "of", "the", "stages", "of", "Image", "Acquisition", ",", "Feature", "Extraction", ",", "Feature", "Matching", ",", "Geometric", "Verification", ",", "and", "Associated", "Information", "Retrieval", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Each", "of", "these", "checks", "can", "be", "done", "in", "NP", ",", "as", "they", "reduce", "to", "non", "-", "emptiness", "of", "the", "intersection", "of", "the", "Parikh", "images", "of", "two", "context", "-", "free", "languages", ":", "itemize", "the", "language", "of", "a", "context", "-", "free", "grammar", "over", "obtained", "from", "by", "replacing", "addition", "with", "concatenation", "(", "as", "in", "the", "proof", "of", "Lemma", "lem", ":", "setsofeq", ":", "PTIME", ")", ",", "and", "the", "language", "over", "containing", "words", "with", "the", "same", "number", "of", "'s", "and"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "non - emptiness problem"}, {"tokens": ["Additionally", "we", "introduced", "a", "new", "way", "of", "on", "-", "line", "PAP", "detection", ",", "including", "PAT", "estimations", "and", "their", "distribution", "among", "cooperating", "processes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["Besides", ",", "the", "EC", "caching", "capacity", "is", "also", "less", "than", "that", "of", "the", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "central cloud"}, {"tokens": ["Regarding", "Module", "1", ",", "it", "takes", "the", "encoded", "MQ", "as", "input", "and", "uses", "the", "matrix", "of", "the", "encoded", "BQ", "to", "output", "the", "BQ", "of", "query", "question", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["The", "AIR", "gains", "from", "shaping", "translate", "into", "sensitivity", "improvements", "in", "nonlinear", "optical", "channel", ",", "which", "is", "linear", "gain", "plus", "the", "nonlinear", "gain", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "achievable information rates"}, {"tokens": ["How", "Fast", "is", "DDE", "-", "MGM", "Model", "?"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Feedback", "alignment", "(", "FA", ")", ",", "a", "modification", "to", "BP", "in", "which", "this", "symmetry", "is", "broken", "by", "replacing", "the", "forward", "weights", "with", "randomized", "connections", "for", "the", "backward", "pass", ",", "avoids", "the", "weight", "transport", "problem", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["Given", "an", "instance", "of", "with", "agents", "'", "partial", "preferences", ",", "involves", "applying", "the", "PS", "mechanism", "to", "a", "modified", "profile", "over", "using", "an", "arbitrary", "deterministic", "topological", "sorting", "in", "multiple", "rounds", "as", "follows", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["Recent", "studies", "employ", "distributional", "semantics", "of", "words", "to", "address", "limitations", "of", "VSM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "vector space model"}, {"tokens": ["The", "average", "achievable", "rate", "with", "respect", "to", "the", "number", "of", "cooperative", "SBSs", "considering", "different", "intensities", "of", "SBSs", "when", "the", "SBS", "cooperation", "strategy", "with", "distance", "constraint", "is", "adopted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["Our", "algorithm", "showed", "better", "performance", "in", "AFP", "and", "DBP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "discrete base problem"}, {"tokens": ["For", "this", "reason", ",", "we", "believe", "our", "datasets", "provide", "new", "challenges", "for", "neural", "-", "based", "SP", ",", "and", "serve", "as", "a", "cautionary", "tale", "about", "the", "scalability", "and", "applicability", "of", "commonly", "used", "neural", "models", "to", "lower", "-", "resource", "SP", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "semantic parsing"}, {"tokens": ["The", "LB", "divergence", "is", "shown", "as", "(", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["At", "run", "-", "time", ",", "we", "test", "the", "resulting", "ECS", "-", "DBN", "with", "test", "dataset", "to", "report", "the", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["Then", "player", "wins", "with", "the", "MD", "strategy", "from", "Lemma", "lem", ":", "optmin", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["At", "inference", "time", ",", "the", "WT", "prediction", "from", "the", "previous", "step", "is", "used", "in", "place", "of", "the", "ground", "truth", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "whole tumor"}, {"tokens": ["Time", "varying", "inertial", "weight", "of", "PSO", "Earlier", ",", "inertia", "weight", "of", "the", "PSO", "was", "considered", "a", "fixed", "value", "between", "[", "0.4", ",", "0.9]."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["It", "was", "assumed", "that", "the", "BS", "has", "the", "imperfect", "knowledge", "of", "the", "direction", "angle", "toward", "each", "eavesdropper", "and", "the", "direction", "angle", "estimation", "errors", "follow", "the", "Von", "Mises", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Figure", "a", ")", ",", "comparing", "the", "FEM", "result", "to", "the", "RB", "for", "various", "number", "of", "basis", "elements", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["proposed", "a", "new", "hybrid", "PSO", "-", "RLD", "algorithm", "by", "combining", "PSO", "with", "recombination", "and", "dynamic", "linkage", "discovery", "(", "RLD", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Their", "use", "in", "SAR", "operations", "attracted", "considerable", "attention", "and", "became", "a", "topic", "of", "interest", "in", "the", "recent", "past", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["RS", "Approach"], "acronym_pos": [1, 0], "long_form": "rate saturation"}, {"tokens": ["Solid", "red", "and", "dashed", "black", "lines", "represent", "upper", "bound", "AP", ",", "and", "the", "best", "model", "AP", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "motivation", "for", "this", "extrinsic", "evaluation", "comes", "from", "the", "fact", "that", "one", "of", "the", "intended", "purposes", "of", "the", "modified", "metrics", "is", "to", "use", "them", "for", "training", "QA", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["We", "can", "describe", "a", "GMM", "by", "generative", "process", "below:*We", "can", "modify", "the", "GMM", "for", "the", "setting", "of", "multi", "-", "label", "classification", "by", "providing", "an", "unbiased", "estimator", "of", "the", "probability", "of", "each", "binary", "sample:*where", "are", "samples", "drawn", "from", "a", "multivariate", "normal", "over", "a", "subset", "of", "the", "variables", "in", "and", ",", "are", "the", "parameters", "of", "a", "multivariate", "normal", "conditioned", "on", "the", "value", "of", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["This", "is", "because", "of", "feeding", "a", "constant", "current", "to", "the", "battery", "pack", "during", "the", "CC", "period", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "charging current"}, {"tokens": ["Since", "the", "TP", "runs", "only", "if", "the", "winning", "cluster", "of", "the", "SP", "changes", ",", "this", "results", "in", "a", "situation", "where", "the", "data", "for", "the", "TP", "changes", "very", "infrequently", ",", "which", "means", "that", "the", "TP", "learns", "very", "slowly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial pooler"}, {"tokens": ["The", "first", "is", "to", "fit", "an", "SBM", "to", "multiple", "values", "of", ",", "with", "a", "measure", "computed", "to", "quantify", "the", "goodness", "of", "fit", ",", "followed", "by", "selecting", "the", "optimal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["To", "achieve", "this", "goal", ",", "we", "introduce", "a", "novel", "factorization", "of", "past", "variational", "distributions", ",", "where", "the", "predictive", "GP", "equation", "propagates", "the", "posterior", "uncertainty", "forward", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["covariance", "function", "e.ker_expcua", "is", "probably", "the", "most", "widely", "-", "used", "kernel", "within", "the", "kernel", "machines", "field", ",", "because", "the", "GP", "with", "a", "exponentiated", "-", "quadratic", "covariance", "function", "is", "very", "smooth", "rasmussen05", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "BQ", "approach", "posits", "that", "the", "integrand", "can", "be", "modelled", "by", "a", "stochastic", "process", "defined", "on", "the", "domain", "of", "integration", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian quadrature"}, {"tokens": ["The", "left", "part", "is", "for", "the", "CF", "task", ":", ",", ",", "and", "work", "together", "to", "infer", "our", "CF", "task", "target", ",", "i.e.", ",", "whether", "the", "user", "would", "visit", "a", "specific", "publisher", "or", "not", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["However", ",", "conventional", "DBN", "does", "not", "work", "well", "for", "imbalanced", "data", "classification", "because", "it", "assumes", "equal", "costs", "for", "each", "class", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Both", "the", "theoretical", "derivation", "and", "numerical", "simulation", "show", "that", "when", "the", "number", "of", "antennas", "at", "the", "BS", "is", "far", "more", "than", "the", "number", "of", "users", ",", "the", "upper", "bound", "can", "be", "very", "tight", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Gbps", "IB", "&", "SLURM", "&", "Lustre", "PSC", "Bridges", "&", "RSM", "&", "752", "&", "2"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["In", "the", "algorithm", ",", "PSO", "exploits", "and", "DE", "explores", "the", "search", "space", "to", "obtain", "the", "global", "optimum", "solution", "efficiently", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["When", "did", "the", "QA", "system", "fail", "?"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "IFD", "corpus", "was", "collected", "in", "the", "early", "1990s", "and", "contains", "texts", "from", "published", "books", ",", "primarily", "fiction", "(", "60", ")", "but", "also", "biographies", "(", "20", ")", "and", "scholarly", "work", "(", "20", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "icelandic frequency dictionary"}, {"tokens": ["It", "is", "clear", "that", "the", "comparison", "shows", "that", "accuracy", "for", "PCA", "is", "92.50", "and", "74.17", ",", "while", "for", "N", "-", "PCA", "is", "93.75", "and", "76.67", "on", "ORL", "and", "IFD", "for", "80/20", "Ratio", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "indian face database"}, {"tokens": ["Then", "there", "is", "an", "MD", "strategy", "that", "is", "optimal", "maximizing", "in", "every", "state", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["The", "meta", "-", "loss", "objective", "therefore", "includes", "the", "solution", "time", "of", "a", "sequence", "of", "reduced", "OPF", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["*", "The", "cosine", "distance", "is", "then", "defined", "as", "*", "CD", "'s", "prediction", "for", "a", "degree", "of", "LSC", "of", "between", "time", "periods", "and", "is", "obtained", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cosine distance"}, {"tokens": ["We", "also", "see", "that", "generating", "helpful", "suggestions", "is", "a", "difficult", "task", ":", "in", "many", "cases", "workers", "thought", "neither", "system", "was", "helpful", ",", "especially", "when", "given", "the", "outputs", "from", "BS", "/", "TS", "or", "TS", "/", "predicted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0], "long_form": "temperature - based sampling"}, {"tokens": ["AUCs", "of", "ROC", "VGGNet-19", "classification", "ROC", "curves", "of", "Cardiomegaly", "trained", "with", "Chest", "X", "-", "ray", "dataset", "augmented", "in", "different", "ways", "."], "acronym_pos": [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["this", "section", ",", "we", "investigate", "the", "performance", "of", "DBN", "in", "different", "settings", "that", "include", "ECS", "-", "DBN", ",", "DBN", ",", "ADASYN", "-", "DBN", ",", "SMOTE", "-", "DBN", ",", "SMOTE", "-", "borderline1-DBN", ",", "SMOTE", "-", "borderline2-DBN", "and", "SMOTE", "-", "SVM", "-", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["TP", "-", "FP", "-", "FN", "center", "figureFigure", "fig", ":"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["The", "following", "reduction", "from", "ANN", "to", "APM", "is", "presented", "in", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "approximate nearest neighbor"}, {"tokens": ["Ablation", "studyWe", "present", "an", "ablation", "study", "of", "our", "proposed", "GCNN", "model", "on", "the", "set", "covering", "problem", "by", "comparing", "three", "variants", "of", "the", "convolution", "operation", "in", "(", "):", "mean", "rather", "than", "sum", "convolutions", "(", "mean", ")", ",", "sum", "convolutions", "without", "our", "prenorm", "layer", "(", "sum", ")", "and", "finally", "sum", "convolutions", "with", "prenorm", "layers", ",", "which", "is", "the", "model", "we", "use", "throughout", "our", "experiments", "(", "gcnn", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["Sensors", "outside", "the", "backbone", "network", "move", "randomly", "and", "check", "if", "there", "is", "a", "path", "to", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["Furthermore", ",", "in", "accordance", "with", "prior", "work", "on", "TS", ",", "we", "report", "average", "BLEU", "and", "SARI", "scores", "for", "the", "rephrasings", "of", "each", "system.(For", "the", "computation", "of", "the", "BLEU", "and", "SARI", "scores", "we", "used", "the", "implementation", "of", "nisioi2017exploring", "which", "is", "available", "under", "https://github.com/senisioi/NeuralTextSimplification", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["[", "GPS", "unit", "and", "Arduino", "Micro", "-", "controllers][Rangefinder", "mounted", "at", "Side", "Door]Prototype", "DeploymentParking", "Spotter", "is", "an", "ongoing", "joint", "work", "by", "Ford", "and", "Georgia", "Tech", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["This", "is", "an", "expected", "result", "since", "the", "AR", "rendering", "should", "not", "assist", "when", "small", ",", "precise", "motions", "are", "made", "which", "is", "when", "the", "errors", "in", "our", "user", "study", "occur", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Illustration", "of", "RBM", "(", "left", ")", "and", "DBN", "(", "right", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": [":", "corv", ":", "qoeSSIM", "figureOverall", ",", "the", "proposed", "mechanism", "exceeds", "by", "48", "the", "without", "FEC", "scheme", "when", "it", "comes", "to", "video", "quality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["ConclusionOur", "proposed", "CRNN", "models", "for", "CDA", "recognition", "impose", "fewer", "restrictions", "on", "the", "structure", "of", "DAs", "and", "capture", "textual", "features", "from", "a", "wider", "context", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concurrent dialogue acts"}, {"tokens": ["According", "to", "the", "RS", "method", ",", "the", "message", ",", "intended", "for", "destination", "UE", ",", "is", "split", "into", "two", "parts", ",", "namely", ",", "the", "common", "and", "private", "parts", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["The", "initialization", "and", "optimization", "strategy", "in", "GMM", "is", "illustrated", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "GP", "approach", "is", "better", "suited", "for", "parallelization", ",", "speedups", "and", "energy", "saving", "via", "approximated", "computing", "Angerer2015", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["For", "future", "work", ",", "we", "plan", "to", "evaluate", "the", "classification", "of", "the", "rhetorical", "relations", ",", "examine", "to", "what", "extent", "other", "NLP", "tasks", "such", "as", "QA", "systems", "may", "benefit", "from", "the", "results", "produced", "by", "our", "framework", "and", "investigate", "the", "creation", "of", "big", "knowledge", "graphs", "used", "for", "QA", "by", "performing", "a", "large", "-", "scale", "Wikipedia", "extraction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Thus", ",", "energy", "cooperation", "within", "the", "E", "-", "LAN", "can", "be", "jointly", "achieved", "through", "energy", "allocation", "and", "routing", "procedures", ",", "leveraging", "the", "mobile", "device(s", ")", "location", "information", "provided", "by", "the", "LS", "API", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "location service"}, {"tokens": ["Given", "a", "data", "structure", "for", "approximate", "polytope", "membership", "in", "-dimensional", "space", "with", "query", "time", ",", "storage", ",", "and", "preprocessing", "time", "it", "is", "possible", "to", "preprocess", "into", "a", "-well", "-", "separated", "ANN", "data", "structure", "withCombining", "the", "previous", "reduction", "with", "Theorem", "we", "have", ":", "Given", "a", "set", "of", "points", "in", ",", "an", "approximation", "parameter", ",", "and", "a", "constant", ",", "there", "is", "a", "data", "structure", "that", "can", "answer", "-well", "-", "separated", "Euclidean", "-approximate", "nearest", "neighbor", "queries", "withNext", ",", "we", "prove", "Theorem", "using", "a", "reduction", "to", "well", "-", "separated", "approximate", "nearest", "neighbor", "searching", "that", "is", "based", "on", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "approximate nearest neighbor"}, {"tokens": ["E.", "Chai", ",", "K.", "Sundaresan", ",", "M.", "A.", "Khojastepour", ",", "and", "S.", "Rangarajan", ",", "\"", "LTE", "in", "unlicensed", "spectrum", ":", "Are", "we", "there", "yet", "?", "\"", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Toxin", "data", "at", "fsThe", "data", "collected", "from", "the", "HMC", "and", "MD", "simulations", "of", "the", "unconstrained", "toxin", "system", "at", "the", "step", "size", ",", "identified", "as", "the", "stability", "limit", "for", "the", "velocity", "Verlet", "integrator", ",", "are", "presented", "in", "tab", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["Since", "our", "main", "goal", "in", "this", "paper", "is", "to", "extend", "and", "adapt", "this", "discussion", "to", "the", "context", "of", "IS", ",", "we", "start", "by", "briefly", "outlining", "some", "relevant", "proposals", "(", "mostly", "in", "the", "context", "of", "CS", ")", ",", "the", "ideas", "of", "which", "are", "close", "in", "spirit", "to", "the", "vision", "we", "present", "below", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["In", "this", "results", "GMM", "is", "at", "most", "40", "better", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["Registration", "uncertainty", "in", "transformation", "parameters", "can", "be", "naturally", "obtained", "from", "the", "GP", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["User", "Capacities", "and", "Sum", "CapacityThe", "impact", "of", ",", "and", "on", "the", "capacity", "of", "CCU", ",", "CEU", ",", "and", "SC", "of", "the", "proposed", "system", "is", "shown", "in", "this", "part", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["In", "the", "case", "of", "Dice", "-", "WT", ",", "our", "method", "is", "very", "close", "to", "the", "results", "obtained", "by", "the", "top", "performing", "methods", "while", ",", "again", ",", "our", "method", "achieves", "rather", "low", "Dice", "-", "ET", "and", "Dice", "-", "TC", "metrics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["&", "8cNumber", "of", "bits", "in", "each", "key", "4", "-", "11", "&", "&", "Method", "&", "1", "&", "2", "&", "3", "&", "4", "&", "5", "&", "6", "&", "7", "&", "8", "6*turn90K40c", "(", "ECC", "on)turn", "&", "3*turn0key", "-", "onlyturn", "&", "WMS", "&", "14.08", "(", "1.12", "x", ")", "&", "13.88", "(", "1.12", "x", ")", "&", "12.17", "(", "0.99", "x", ")", "&", "10.12", "("], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["The", "pruning", "process", "of", "the", "DBP", "automaton", "yields", "here", "the", "minimal", "DFA", "of", "size", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["Acronyms", ":", "AUC", "-", "Area", "Under", "ROC", "Curve", ";", "AP", "-", "Average", "Precision", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Activity", "space", "rank", "turnover", ",", "&", "&", "&", "MDC", "dataset", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["As", "the", "size", "of", "the", "network", "increases", ",", "packets", "are", "more", "likely", "to", "be", "routed", "to", "the", "nodes", "with", "higher", "BC", "and", "packets", "are", "more", "likely", "to", "be", "accumulated", "at", "these", "nodes", ",", "resulting", "in", "traffic", "congestion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["Therefore", ",", "a", "natural", "question", "arises", ":", "what", "is", "the", "optimal", "cut", "for", "rare", "words", "in", "LSC", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["In", "Figure", ",", "because", "the", "coordinator", "is", "and", ",", "the", "subject", "NP", "number", "is", "plural", "even", "though", "both", "conjuncts", "(", "the", "star", "and", "the", "moon", ")", "are", "singular", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "noun phrase"}, {"tokens": ["Therefore", ",", "this", "experiment", "intends", "to", "showcase", "how", "the", "convex", "IB", "Lagrangian", "can", "explore", "the", "IB", "curve", "for", "different", "neural", "network", "architectures", "and", "harder", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Proposition", "1", ":", "Problem", "can", "be", "formulated", "into", "a", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "geometric programming"}, {"tokens": ["Coref", ",", "WMD", "and", "FS", "denotes", "coreference", "system", ",", "word", "mover", "'s", "distance", "and", "frame", "semantics", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "frame semantic"}, {"tokens": ["shows", "the", "comparison", "result", "between", "MP", "and", "LASSO", "based", "hypothesis", "testing", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "message passing"}, {"tokens": ["FDMAIn", "FDMA", ",", "each", "user", "will", "be", "allocated", "a", "fraction", "of", "the", "BS", "bandwidth", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "base station"}, {"tokens": ["the", "BW", "-", "BBHT", "-", "QSA", "step", "is", "repeated", "for", "an", "additional", "iteration", "in", "order", "to", "ensure", "the", "detection", "of", "the", "entire", "OPF", ",", "as", "seen", "in", "Steps", "12", "and", "14", "of", "Alg", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal pareto front"}, {"tokens": ["lemmaOne", "challenge", "in", "proving", "Theorem", "thm", ":", "reachability", "is", "that", "an", "optimal", "minimizing", "player", "MD", "strategy", "according", "to", "Lemma", "lem", ":", "optmin", "is", "not", "necessarily", "winning", "for", "player", ",", "even", "for", "almost", "-", "sure", "reachability", "and", "even", "if", "player", "has", "a", "winning", "strategy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["-", "Propose", "a", "set", "of", "adaptive", "FEC", "-", "based", "content-", "and", "video", "-", "aware", "mechanisms", ",", "which", "aim", "to", "support", "video", "distribution", "to", "wireless", "users", "over", "error", "-", "prone", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Multiple", "convolutional", "layers", "(", "feature", "maps", ")", "of", "decreasing", "size", "are", "appended", "to", "the", "DCNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["SAR", "target", "recognition", ",", "transfer", "learning", ",", "deep", "convolutional", "neural", "networks", ",", "domain", "adaptation", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Three", "RAID1", "configurations", "are", "considered", "BM", ",", "CD", ",", "and", "GRD", ",", "where", "GRD", "is", "shown", "to", "provide", "the", "best", "performance", "for", "small", "and", "large", "I", "/", "O", "environments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group rotate declustering"}, {"tokens": ["When", "the", "maximum", "applied", "current", "was", "within", "30", "-", "35", ",", "the", "improvement", "of", "the", "RF", "and", "ANN", "models", "over", "the", "LMEM", "were", "20", "and", "35", "respectively", "in", "terms", "of", "field", "-", "magnitude", "RMSE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "BS", "records", "the", "number", "of", "data", "packets", "from", "the", "node", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["DBN", "is", "stacked", "with", "several", "RBMs", "and", "its", "architecture", "allows", "to", "abstract", "higher", "level", "features", "through", "layer", "conformation", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "RA", "process", "presented", "a", "mean", "time", "of", "2.5", "seconds", ",", "what", "is", "considered", "acceptable", "for", "our", "application", ",", "since", "it", "is", "commonly", "performed", "just", "one", "time", "for", "each", "new", "producer", "or", "consumer", ",", "to", "validate", "the", "system", "or", "the", "new", "member", ",", "respectively", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote attestation"}, {"tokens": ["b", ")", ",", "where", "the", "MPPT", "controller", "continuously", "varies", "the", "PV", "bus", "voltage", "reference", "from", "OCC", ",", "and", "the", "control", "loop", "tracks", "this", "reference", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "open circuit condition"}, {"tokens": ["For", "decision", "making", "by", "the", "resource", "controller", ",", "the", "received", "EB", "level", "reports", "are", "compared", "with", "the", "following", "thresholds", ":", "and", ",", "respectively", "termed", "the", "lower", "and", "the", "upper", "energy", "threshold", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy buffer"}, {"tokens": ["For", "some", "etyma", ",", "Persian", "lacks", "l", ",", "while", "a", "non", "-", "Persian", "reflex", "displays", "it", ",", "e.g.", ",", "NP", "supurz", "'", "spleen", "'", "versus", "Kd", "sipil", "'"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["To", "shed", "light", "on", "the", "above", "matters", ",", "first", "we", "systematically", "and", "carefully", "approximate", "the", "empirical", "upper", "bound", "in", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "average precision"}, {"tokens": ["OT", "Extension", "Phase", "II", ":", "On", "receiving", "from", ",", "computes", "for", "and", "sends", "to", "functionality", "on", "behalf", "of", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["While", "Heer", "and", "Stone", "'s", "model", "shows", "low", "FR", "of", "39.6", ",", "our", "TPN", "has", "the", "FR", "of", "56.2", "while", "maintaining", "a", "high", "level", "of", "diversity", "and", "multimodality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fooling rate"}, {"tokens": ["From", "a", "top", "-", "down", "perspective", ",", "the", "output", "of", "PNN", "is", "a", "real", "number", "as", "the", "predicted", "CTR", ":", "where", "and", "are", "the", "parameters", "of", "the", "output", "layer", ",", "is", "the", "output", "of", "the", "second", "hidden", "layer", ",", "and", "is", "the", "sigmoid", "activation", "function", ":", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["As", "a", "general", "rule", "the", "dice", "scores", "for", "more", "obese", "patients", "with", "larger", "volumes", "of", "VAT", "and", "SAT", "are", "higher", "than", "those", "for", "thin", "patients", ",", "a", "pattern", "that", "is", "also", "visible", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["NBC_Normalization", "and", "then", "uses", "the", "centroid", "classifier", "in", "NBC", "for", "unbalanced", "classes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "naive bayes classifier"}, {"tokens": ["The", "non", "-", "adaptive", "Video", "-", "aware", "FEC", "mechanism", "was", "able", "to", "deliver", "videos", "with", "a", "network", "overhead", "between", "53", "and", "78", ",", "as", "shown", "in", "Figure", "fig", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "idea", "is", "to", "isolate", "qualitate", "attributes", "from", "(", "past", ")", "local", "interactions", "among", "components", "of", "complex", "system", "and", "to", "apply", "FCA", "tools", "in", "order", "to", "predict", "properties", "system", "'s", "behavior", "in", "a", "near", "future", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "formal concept analysis"}, {"tokens": ["In", "contrast", ",", "a", "reference", "approach", ",", "based", "on", "logistic", "regression", ",", "yielded", "AUC", "of", "0.75", "(", "0.74", "-", "0.77", ")", "and", "AP", "of", "0.62", "(", "0.60", "-", "0.64", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["[", "t]0.49", "AUC", "[", "t]0.49", "AP", "Boxplots", "for", "AUC", "and", "AP", "scores", "on", "23", "real", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["CF", "takes", "into", "account", "three", "factors-", "language", "(", "LF", ")", ",", "switching", "(", "SF", ")", "and", "mix", "(", "MF", ")", "factors", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "complexity factor"}, {"tokens": ["Note", "that", "DTP", ",", "FA", ",", "and", "BP", "often", "fail", "or", "are", "unstable", "with", "this", "initialization", ",", "especially", "when", "training", "deep", "sigmoidal", "networks", "on", "Fashion", "MNIST", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "difference target propagation"}, {"tokens": ["The", "first", "kind", "of", "users", "are", "modeled", "by", "Cox", "point", "process", "driven", "by", "PLP", "whereas", "the", "second", "kind", "is", "described", "by", "a", "spatial", "PPP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["This", "is", "at", "the", "expense", "of", "the", "strictest", "AP", "metrics", "worsening", "with", "20", "steps", ",", "where", "this", "bias", "is", "not", "necessary", "anymore", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["We", "also", "discussed", "performance", "overhead", "of", "some", "transactions", "and", "found", "no", "extra", "overhead", "by", "our", "application", "interface", "developed", "on", "top", "of", "Fabric", "for", "IoT.", "Furthermore", ",", "a", "comparison", "has", "been", "done", "with", "QUORAM", "-", "BC", "which", "shows", "that", "our", "architecture", "is", "more", "efficient", ",", "specifically", "for", "IoT", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["WM", "Age", "Estimator", ";", "[", "block3", ",", "below", "left", "of", "=", "f", ",", "node", "distance", "=", "1.5", "cm", "]", "(", "om", ")", "BF", "Age", "Estimator", ";", "[", "block3", ",", "below", "right", "of", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "black females"}, {"tokens": ["Scaling", "to", "deep", "networks", "We", "now", "describe", "in", "more", "detail", "the", "relevant", "considerations", "when", "extending", "FA", "to", "deeper", "networks", "and", "the", "modifications", "we", "made", "to", "improve", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["In", "this", "case", ",", "the", "MINT", "-", "FEC", "mechanism", "managed", "to", "reduce", "the", "overhead", "by", "up", "to", "11.74", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["All", "figures", "are", "plotted", "for", "the", "parameters", ",", "and", "due", "to", "Rician", "fading", "channel", "[", "25,27].", "CCU", "(", ")", "capacity", "behavior", "with", "respect", "to", "(", "w.r.t", ")", "transmit", "SNR", "is", "demonstrated", "in", "Figure", "3", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "[", "22].", "Parameters", ",", ",", ",", ",", ",", ",", "and", "are", "set", "during", "the", "simulation", "purpose", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["Convergence", "curves", "for", "regression", "by", "DE", "(", "left", ")", "and", "CMA", "-", "ES", "(", "right", ")", "using", "the", "sinc3d", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["After", "discussing", "CDP", "and", "it", "'s", "implementation", "PROCHLO", "in", "the", "next", "two", "paragraphs", ","], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["By", "combining", "PFD", "with", "MD", ",", "UD", "further", "improves", "the", "prediction", "performance", "of", "the", "student", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "model distillation"}, {"tokens": ["Very", "few", "of", "the", "10", "point", "words", "were", "found", "in", "the", "SDD", "environment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Each", "data", "region", "of", "one", "or", "multiple", "RT", "instances", "can", "be", "associated", "with", "different", "data", "storage", "implementations", ",", "defined", "by", "the", "application", "designer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "region template"}, {"tokens": ["However", ",", "the", "drawback", "is", "that", "LI", "-", "MAC", "has", "a", "big", "throughput", "gap", "between", "the", "AP", "and", "STAs", ",", "which", "does", "not", "satisfy", "the", "traffic", "requirements", "of", "the", "considered", "scenario", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["It", "shows", "FCFS", ",", "LE", "and", "HP", "have", "much", "more", "dead", "nodes", "than", "the", "EHFS", "algorithm", "starting", "from", "N", "=", "50", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low energy"}, {"tokens": ["shows", "the", "PDF", "of", "CD", "."], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "contact distance"}, {"tokens": ["blackOther", "alternatives", "to", "MAD", "."], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "map attention decision"}, {"tokens": ["The", "results", "also", "show", "that", "XOR", "-", "based", "coding", "outperforms", "the", "RLC", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random linear coding"}, {"tokens": ["Only", "word", "pairs", "from", "the", "HJ", "dataset", "have", "continuous", "scores", ",", "while", "the", "other", "pairs", "which", "come", "from", "the", "RT", "and", "the", "AE", "datasets", "have", "binary", "relatedness", "scores", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ruthes"}, {"tokens": ["TerraSAR", "-", "X", "images", "and", "SAR", "targets", "of", "MSTAR", ",", "for", "classification", "or", "reconstruction", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["The", "on", "-", "board", "loads", "could", "include", "optical", "wavelength", "range", "camera", ",", "TIR", "camera", ",", "color", "and", "stereo", "vision", "cameras", ",", "different", "types", "of", "sensors", "such", "as", "gas", "detection", ",", "GPS", ",", "etc", ".", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["The", "energy", "of", "the", "local", "histograms", "are", "then", "normalized", "over", "a", "large", "spatial", "regions", "called", "blocks", "to", "get", "the", "intended", "HOG", "feature", "descriptor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "histogram of gradients"}, {"tokens": ["We", "discuss", "our", "choice", "of", ",", "and", "denoting", "the", "number", "of", "extended", "output", "OTs", ",", "the", "number", "of", "inputs", "of", "in", "each", "extended", "OT", "and", "the", "bit", "length", "of", "'s", "input", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["As", "the", "number", "of", "noise", "samples", "increases", ",", "the", "NCE", "derivative", "provably", "converges", "to", "the", "gradient", "of", "cross", "-", "entropy", ";", "thus", ",", "by", "virtue", "of", "NCE", "'s", "asymptotic", "convergence", "guarantees", ",", "we", "are", "in", "effect", "minimizing", "the", "-divergence", "from", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "noise contrastive estimation"}, {"tokens": ["The", "data", "communication", "policy", "along", "with", "the", "signal", "-", "to", "-", "interference", "-", "plus", "-", "noise", "ratio", "(", "SINR", ")", "model", "of", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "are", "discussed", "explicitly", "in", "section", "2.1", "and", "2.2", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Scenario", "2", ":", "Measure", "the", "energy", "at", "the", "LTE", "-", "U", "BS", "during", "theLTE", "-", "U", "OFF", "period", "when", "two", "Wi", "-", "Fi", "APs", "(", "i.e.", ",", "Cell", "A", "Cell", "C", ")", "and", "LTE", "-", "U", "(", "i.e.", ",", "Cell", "B", ")", "are", "deployed", "with", "fullbuffer", "downlink", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["CF", ":", "collaborative", "filtering", "."], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "BAM", "reconfiguration", "approach", "adopted", "is", "based", "on", "switching", "among", "available", "BAM", "implementations", "(", "MAM", ",", "RDM", "and", "ATCS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "russian dolls model"}, {"tokens": ["Figure", "7", "illustrates", "that", "due", "to", "increasing", "values", "of", ",", "the", "SC", "is", "decreasing", "for", "all", "schemes", "except", "CNMOMA", "-", "SWIPT", "-", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["The", "continuum", "simulation", "model", ",", "for", "instance", ",", "the", "most", "accurate", "model", ",", "FEM", ",", "is", "not", "ideal", "for", "simulation", "requiring", "real", "time", "interaction", "and", "the", "object", "undergoing", "large", "deformation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["Whereas", "human", "behavior", "is", "best", "modeled", "as", "a", "'", "percolation", "'", "process", ",", "the", "neural", "models", "appear", "to", "be", "using", "a", "linear", "combination", "of", "NP", "constituent", "number", "to", "drive", "CoordNP", "/", "verb", "number", "agreement", ",", "with", "the", "second", "noun", "weighted", "more", "heavily", "than", "the", "first", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "noun phrase"}, {"tokens": ["Row", "3", "of", "Table", "shows", "how", "the", "unlabeled", "SAR", "images", "performs", "in", "transferring", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["The", "BA", "is", "an", "asynchronous", "probabilistic", "protocol", "with", "bit", "complexity", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary agreement"}, {"tokens": ["]", "center", "./loss_distribution_MINT.eps", "center", "MINT", "-", "FEC", "'s", "experiment", "PLR", "distribution", "fig", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Eventually", ",", "we", "obtain", "the", "best", "misclassification", "costs", "and", "apply", "it", "on", "the", "output", "layer", "of", "DBN", "to", "form", "ECS", "-", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["We", "need", "to", "analyze", "quite", "big", "data", "-", "set", ",", "more", "than", "one", "probe", "for", "each", "ISP", "present", "on", "the", "Island", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "internet service providers"}, {"tokens": ["Daniel", "Wagner", "and", "Dieter", "Schmalstieg", "present", "an", "indoor", "AR", "guidance", "system", "running", "autonomously", "on", "a", "PDA", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Figure", ",", "illustrates", "the", "use", "of", "multi", "-", "UAV", "systems", "in", "support", "of", "SAR", "operations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "search and rescue"}, {"tokens": ["Mobile", "AR", "restaurant", "guide", "by", "Bell", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["For", "instance", ",", "the", "activity", "distribution", "in", "ET", "is", "smooth", ",", "therefore", ",", "penalties", "like", "EL", "are", "particularly", "suitable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "emission tomography"}, {"tokens": ["For", "this", "use", "case", ",", "we", "also", "have", "a", "large", "set", "of", "95,249", "interactions", "between", "datasets", "and", "services", "available", ",", "leading", "to", "the", "overall", "best", "results", "for", "CF", "across", "all", "four", "use", "cases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["LayAR", "AR", "browser", "."], "acronym_pos": [0, 1, 0, 0], "long_form": "augmented reality"}, {"tokens": ["We", "have", "recently", "showed", "that", "DPGMM", "is", "better", "than", "GMM", "in", "both", "clustering", "and", "classifying", "pulsars", "in", "the", "parameter", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "authors", "summarized", "the", "computational", "time", "required", "in", "executing", "the", "cryptographic", "hash", "function", "(", ")", "and", "ECC", "-", "based", "multiplicative", "operation", "(", ")", "in", "their", "work", "as", "0.596", "msec", "and", "1.473", "msec", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["On", "changing", "from", "1", "to", "6", "(", "vaccinating", "21600", "nodes", ")", ",", "there", "is", "a", "1", "K", "infections", "reduction", "in", "the", "average", "outbreak", "size", "for", "RV", "strategy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random vaccination"}, {"tokens": ["Introduction", "sec", ":", "introductionThe", "advent", "of", "large", "scale", "datasets", "for", "document", "Question", "Answering", "(", "QA)datasquad", ",", "datamarco", ",", "trivia", ",", "duorcsaha", "knowledge", "base", "driven", "QAdatasimpleqa", ",", "saha2018complex", "and", "Visual", "QAVQA", ",", "dataclevr", "has", "enabled", "the", "development", "of", "end", "-", "to", "-", "end", "supervised", "models", "for", "QA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "question answering"}, {"tokens": ["In", "contrast", ",", "both", "RF", "and", "GBM", "performed", "well", "for", "classification", "on", "these", "data", "sets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["For", "instance", ",", "an", "H.264-compliant", "MD", "video", "coding", "is", "achieved", "by", "interlacing", "primary", "and", "redundant", "slices", ",", "whose", "rate", "distortion", "is", "optimized", "in", "an", "end", "-", "to", "-", "end", "manner", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["shows", "the", "locations", "of", "the", "BS", ",", "destination", "users", "and", "eavesdroppers", "in", "the", "Cartesian", "coordinate", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Analytical", "results", "of", "the", "optimal", "storage", "allocation", "(", "how", "to", "partition", "the", "storage", "capacity", "between", "the", "control", "BS", "and", "traffic", "BS", ")", "and", "cache", "placement", "(", "decision", "on", "which", "file", "to", "cache", ")", "were", "obtained", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Ablation", "AnalysisOn", "DukeMTMC", "-", "VideoReID", ",", "both", "WF", "and", "WPR", "improve", "the", "baseline", "(", "and", "respectively", "for", "rank", "1", "accuracy", "and", "mAP", ")", "that", "simply", "performs", "the", "average", "pooling", "of", "the", "frame", "-", "level", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "weighted fusion"}, {"tokens": ["The", "sum", "rate", "for", "DL", "and", "UL", "of", "the", "proposed", "CFPI", "method", "versus", "under", "various", "maximal", "transmission", "power", "constraints", "of", "the", "BS", "is", "presented", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Finally", ",", "RA", "systems", "also", "excel", "by", "virtue", "of", "overlapping", "computation", "time", "and", "communication", "time", ",", "which", "PS", "and", "P2P", "architectures", "fail", "to", "achieve", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["In", "January", ",", "Microsoft", "announces", "the", "Hololens", ",", "a", "headset", "to", "fuse", "AR", "and", "VR", "to", "be", "made", "available", "later", "in", "2015", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Notice", "that", "on", "the", "first", "iteration", ",", "there", "is", "no", "past", "variational", "distribution", "to", "reconstruct", "the", "conditional", "GP", "from", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "RDM", "model", "allows", "temporary", "sharing", "of", "unused", "higher", "priority", "classes", "bandwidth", "by", "lower", "priority", "traffic", "classes", "(", "High", "-", "to", "-", "Low", "-", "HTL", "strategy", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "russian dolls model"}, {"tokens": ["From", "simulation", "results", "and", "analysis", ",", "the", "four", "TAS", "schemes", "have", "an", "decreasing", "order", ":", "Max", "-", "SR", ",", "leakage", "-", "based", ",", "generalized", "EDAS", ",", "and", "random", "(", "conventional", ")", ",", "in", "terms", "of", "SR", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["After", "step", "2", "of", "the", "above", "FPM", "algorithm", ",", "the", "SA", "module", "is", "added", "to", "search", "the", "deviation", "of", "the", "illumination", "wave", "vector", ",", ",", "and", "the", "corresponding", "pupil", "function", "with", "the", "cost", "function", "is", "defined", "aswhere", "is", "the", "calculated", "complex", "field", "of", "the", "LR", "image", "according", "to", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["07-orasan", "-", "stafford", "try", "to", "test", "the", "effect", "of", "AR", "on", "the", "summarization", "process", "using", "the", "TF*IDF", "for", "scoring", "and", "three", "different", "AR", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "anaphora resolution"}, {"tokens": ["One", "percent", "charging", "time", "is", "almost", "constant", "with", "respect", "to", "SOC", "within", "the", "CC", "phase", "(", "75", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["Prior", "to", "characterizing", "the", "EQPO", "algorithm", "and", "the", "CDP", "method", "we", "will", "analyze", "the", "the", "orders", "of", "the", "number", "of", "the", "surviving", "routes", "and", "of", "the", "number", "of", "the", "Pareto", "-", "optimal", "routes", "identified", "across", "the", "first", "trellis", "stages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classical dynamic programming"}, {"tokens": ["We", "also", "add", "professor", ",", "which", "does", "not", "have", "a", "clear", "definition", "as", "per", "CPS", "but", "has", "been", "known", "to", "have", "different", "gender", "splits", "at", "senior", "and", "junior", "levels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "current population survey"}, {"tokens": ["PreliminariescNrGASearch", "history", "is", "accumulatively", "stored", "at", "each", "generation", "in", "cNrGA", ":", "The", "BSP", "tree", "expands", "and", "the", "whole", "search", "space", "is", "partitioned", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["RA", "scales", "independently", "of", "the", "number", "of", "nodes", "as", "we", "find", "in", "our", "experiments", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["For", "testing", "samples", "with", "the", "maximum", "current", "over", "10", ",", "the", "ANN", "model", "performed", "better", "than", "the", "LMEM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["To", "enable", "a", "broader", "range", "of", "behaviors", ",", "implemented", "a", "hierarchical", "RL", "model", "to", "personalize", "feedback", "within", "a", "memory", "-", "based", "SAR", "interaction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["This", "implies", "that", "for", "the", "DI", "case", ",", "the", "optimization", "in", "eq", ":", "optimization_problem_intro", "can", "be", "expressed", "solely", "in", "terms", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "direct inspection"}, {"tokens": ["Similarly", ",", "in", "the", "work", "in", ",", "RN", "and", "MB", "are", "added", "to", "the", "synthetic", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "motion blurring"}, {"tokens": ["According", "to", "Figure", "7", ",", "SC", "is", "decreasing", "for", "increasing", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["Type", "of", "graph", "and", "extensions", "of", "the", "SBM"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1], "long_form": "sequential monte carlo"}, {"tokens": ["Furthermore", ",", "Fast", "-", "ARD", "from", "a", "TRADES", "WideResNet", "onto", "MobileNetV2", "produces", "a", "more", "robust", "student", "than", "our", "most", "robust", "MobileNetV2", "produced", "during", "vanilla", "knowledge", "distillation", "and", "in", "the", "same", "amount", "of", "training", "time", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["In", "scenarios", "with", "dynamic", "RA", ",", "it", "is", "easy", "to", "make", "an", "upper", "-", "triangular", "matrix", "during", "the", "RA", "phase", "by", "relabelling", "the", "REs", "and", "users", ",", "provided", "that", "there", "exists", "orthogonal", "users(On", "the", "occasion", "that", "there", "are", "not", "orthogonal", "active", "users", "in", "the", "system", ",", "we", "can", "relabel", "the", "layers", "rather", "than", "the", "users", "and", "some", "minor", "modifications", "to", "the", "SD", "algorithm", "will", "be", "needed", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resource allocation"}, {"tokens": ["It", "also", "demands", "high", "processing", "power", "and", "storage", "space", ",", "since", "there", "is", "the", "need", "to", "encode", "multiple", "times", "the", "same", "video", "with", "different", "bit", "rates", "and", "FEC", "redundancy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "particular", ",", "we", "present", "closed", "-", "form", "expressions", "for", "the", "statistics", "of", "the", "instantaneous", "output", "signal", "-", "to", "-", "noise", "ratio", "of", "four", "significant", "relaying", "schemes", "with", "DF", ";", "two", "based", "on", "repetitive", "transmission", "and", "the", "other", "two", "based", "on", "relay", "selection", "(", "RS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Constraint", "(", ")", "ensures", "that", "the", "number", "of", "UPs", "that", "are", "accommodated", "by", "a", "DU", "at", "CC", "can", "not", "exceed", "this", "CC", "-", "DU", "\u2019s", "UP", "capacity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["In", "particular", ",", "we", "remark", "that", "the", "AIRs", "that", "the", "authors", "computed", "in", "for", "HDD", "corresponds", "to", "the", "AIRs", "of", "a", "CM", "scheme", "where", "the", "detector", "takes", "a", "hard", "decision", "on", "the", "channel", "output", ",", "i.e.", ",", "it", "performs", "hard", "detection", ",", "but", "the", "decoder", "exploits", "the", "transition", "probabilities", "of", "the", "resulting", "discrete", "-", "input", "discrete", "-", "output", "channel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "coded modulation"}, {"tokens": ["The", "GMM", "distribution", "agrees", "very", "well", "with", "the", "empirical", "distribution", "found", "through", "Monte", "-", "Carlo", "simulation", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["As", "it", "is", "known", "that", "there", "are", "a", "huge", "numbers", "of", "peers", "in", "BC", ",", "only", "few", "of", "them", "are", "supposed", "to", "implement", "ordering", "service", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["In", "this", "work", ",", "the", "contour", "estimation", "is", "performed", "using", "the", "GP", "-", "PF", "method", "with", "the", "Matern", "5/2covariance", "function", "as", "a", "more", "flexible", "and", "general", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "this", "article", ",", "a", "pre", "-", "defined", "list", "of", "outstanding", "environment", "signatures", "is", "used", "to", "offset", "the", "GPS", "drift", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Experimental", "results", "analysisIn", "experiments", ",", "we", "compare", "the", "proposed", "method", "with", "eight", "methods", ",", "which", "include", "five", "kinds", "of", "state", "-", "of", "-", "the", "-", "art", "methods", "(", "DVN", ",", "HM", ",", "VCL", ",", "TVN", "and", "FGN", "in", "section", ")", ",", "three", "kinds", "of", "base", "-", "line", "methods(FGN", ",", "TFGNSCS-1", "and", "TFGNSCS-2", "in", "section", ")", "and", "a", "alternative", "transfer", "method", "(", "TFGNSCS", "-", "alt", "in", "section", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "hybrid model"}, {"tokens": ["The", "result", "was", "that", "these", "participants", "all", "felt", "obliged", "to", "use", "the", "TDW", "in", "exactly", "the", "same", "way", "they", "had", "used", "the", "SDD", ",", "i.e.", "they", "sat", "well", "back", "from", "the", "screen", "to", "obtain", "the", "same", "field", "of", "view", "and", "used", "a", "mouse", "to", "zoom", "and", "pan", "rather", "than", "walk", "closer", "to", "the", "screen", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["In", "each", "RDM", ",", "rows", "and", "columns", "are", "sorted", "based", "on", "image", "categories", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "representational dissimilarity matrix"}, {"tokens": ["In", "this", "regard", ",", "Gravel", "is", "fundamentally", "different", "from", "open", "-", "cell", "MCC", ",", "which", "has", "larger", "cells", "that", "are", "driven", "by", "overturning", "circulations", "in", "the", "boundary", "layer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mesoscale cellular convection"}, {"tokens": ["On", "the", "other", "hand", ",", "in", "the", "network", "evaluation", ",", "a", "negative", "percentage", "means", "that", "the", "MINT", "-", "FEC", "generated", "less", "overhead", ",", "which", "is", "also", "advantageous", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["If", "a", "RS", "is", "busy", "and", "its", "energy", "goes", "downsignificantly", ",", "the", "new", "communication", "will", "not", "rely", "on", "it", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["indicated", "that", "features", "learned", "from", "a", "large", "amount", "of", "unlabeled", "SAR", "scene", "images", "via", "stacked", "convolutional", "auto", "-", "encoders", "are", "transferable", "to", "SAR", "target", "recognition", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["NQ", "is", "a", "large", "scale", "dataset", "intended", "for", "the", "MR", "task", ",", "where", "each", "question", "is", "associated", "with", "a", "Wikipedia", "page", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "machine reading"}, {"tokens": ["In", "addition", ",", "another", "unsupervised", "rank", "aggregation", "method", "based", "on", "ULARA", "is", "tested", "for", "the", "purpose", "of", "comparison", "with", "the", "LB", "divergence", "-", "based", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["researchers", "have", "begun", "to", "utilize", "DCNN", "for", "low", "-", "level", "tasks", "such", "as", "edge", "detection", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["htb", "]", "SEM", "image", "of", "a", "steel", "microstructure", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["EfficiencyThe", "actively", "secure", "protocol", "incurs", "a", "communication", "of", "bits", "in", "Seed", "OT", "Phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["To", "minimize", "the", "impact", "of", "the", "small", "cell", "frequency", "bandwidth", "imbalance", "between", "Case", "1", "and", "the", "other", "three", "cases", ",", "we", "assume", "that", "LTE", "licensed", "bandwidth", "is", "1.4MHz", "which", "is", "the", "lowest", "allowed", "LTE", "bandwidth", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "long term evolution"}, {"tokens": ["We", "approximate", "by", "a", "sparse", "likelihood", "GP", "with", "respect", "to", "the", "GP", "priorwhich", "depends", "only", "on", "a", "finite", "dimensional", "vectorof", "function", "values", "at", "a", "set", "of", "inducing", "points", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["MethodsAccording", "to", "the", "three", "questions", "of", "what", ",", "where", "and", "how", "to", "transfer", "in", "SAR", "target", "recognition", "that", "this", "paper", "prepare", "to", "explore", ",", "we", "will", "firstly", "elaborate", "the", "method", "of", "analyzing", "the", "transferability", "of", "features", "and", "then", "propose", "our", "approaches", "to", "make", "full", "use", "of", "the", "transferred", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["-", "7(r)8", "-", "10(r)11", "-", "1314", "-", "15Metric", "/", "Model", "&", "COR", "&", "QRFA", "&", "GS", "&", "COR", "&", "QRFA", "&", "GS", "&", "COR", "&", "QRFA", "&", "GS", "&", "COR", "&", "QRFA", "&", "GS", "&", "COR", "&", "QRFA", "Average", "/", "case", "&", "0.58", "&", "0.89", "&", "&", "0.74", "&", "1", "&", "&", "0.66", "&", "0.96", "&", "&", "0.7", "&", "0.99", "&", "&", "0.67", "&", "0.96", "Max", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gold standard"}, {"tokens": ["Technology", "Overview*[t", "]", "LTE", "eMBMS", "physical", "layer", "transmitter", "block", "diagram"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Work", "has", "been", "done", "on", "relevance", "feedback", "specific", "to", "IR", "for", "QA", ",", "where", "it", "is", "has", "usually", "be", "found", "to", "be", "unhelpful", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Proof", "of", "Lemma", "Based", "on", "the", "considered", "cell", "association", "rule", ",", "the", "typical", "UE", "is", "associated", "with", "a", "BS", "in", "tier", "if", "the", "following", "is", "satisfiedwhere", "(", "a", ")", "follows", "by", "the", "serving", "link", "directivity", "gain", "assumption", "and", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Due", "to", "utilizing", "the", "separate", "time", "slot", "for", "each", "transmission", "except", "OAM", "based", "transmission", ",", "the", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "provides", "significantly", "lower", "EE", "than", "the", "proposed", "scheme", "w.r.t", "which", "is", "illustrated", "in", "Figure", "9", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["If", "approached", "naively", ",", "the", "combination", "of", "the", "sparse", "GP", "approximation", "and", "the", "numerical", "integration", "using", "importance", "sampling", "is", "expected", "to", "yield", "bad", "approximations", "in", "such", "cases.(Potentially", "in", "such", "cases", "other", "sparsity", "methods", "might", "be", "more", "favourable", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Additional", "layers", "for", "the", "frame", "-", "level", "frame", "-", "level", "many", "-", "shapes", "architectures", ",", "similar", "as", "in", "-", "where", "MP", "stands", "for", "max", "pooling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "max pooling"}, {"tokens": ["CK+", ":", "Several", "experiences", "are", "performed", "to", "assess", "the", "performances", "of", "the", "proposed", "MFP", "-", "CNN", "-", "based", "approach", "for", "FER", "as", "shown", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["Pattern", "search", "methodsdescribed", "using", "a", "GPS", "formalism", "mainly", "differ", "on", "the", "heuristics", "used", "for", "the", "selection", "of", "exploratory", "moves", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["The", "future", "works", "cover", "the", "following", "topics", ":", "evaluation", "of", "the", "method", "for", "a", "wider", "range", "of", "interconnecting", "network", "speeds", "and", "larger", "number", "of", "nodes", "using", "a", "simulation", "tool", "e.g.", ",", "expansion", "of", "the", "method", "for", "other", "collective", "communication", "algorithms", ",", "e.g.", "all", "-", "gather", ",", "a", "framework", "for", "automatic", "PAP", "detection", "and", "proper", "algorithm", "selection", ",", "e.g.", "providing", "a", "regular", "ring", "for", "balanced", "PAPs", "and", "PRR", "for", "imbalanced", "ones", ",", "introduction", "of", "the", "presented", "PAT", "estimation", "method", "for", "other", "purposes", "e.g.", "asynchronous", "SDG", "training", "or", "deadlock", "and", "race", "detection", "in", "distributed", "programs", ",", "deployment", "of", "the", "solution", "in", "a", "production", "environment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pre - reduced ring"}, {"tokens": ["This", "paper", "provides", "an", "exhaustive", "insight", "of", "challenges", "known", "so", "far", "for", "building", "QA", "systems", ",", "with", "a", "special", "focus", "on", "employing", "structured", "data", "(", "i.e.", "knowledge", "graphs", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Finally", ",", "constraint", "capacity0", "ensures", "that", "the", "macrocell", "BS", "'s", "capacity", "is", "not", "violated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["This", "result", "is", "expected", "as", "AP", "primarily", "serves", "as", "a", "news", "wire", "service", "for", "other", "publishers", "and", "is", "well", "-", "established", "as", "a", "non", "-", "profit", "news", "agency", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "associated press"}, {"tokens": ["The", "maximum", "number", "of", "disk", "failures", "that", "can", "be", "tolerated", "by", "ID", "is", ",", "while", "for", "BM", ",", "GRD", ",", "and", "CD", "organizations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["Our", "next", "steps", "comprise", "of", "studying", "terrain", "rendering", "with", "TS", "implementations", "and", "adapt", "them", "to", "usage", "with", "PCG", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tessellation shader"}, {"tokens": ["In", "Table", ",", "observe", "that", "LRA", "is", "able", "to", "effectively", "train", "networks", "composed", "of", "stochastic", "binary", "units", ",", "competitive", "with", "DTP", "and", "outperforming", "the", "other", "estimators", "used", "in", "back", "-", "propagation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "difference target propagation"}, {"tokens": ["There", "are", "a", "number", "of", "possible", "improvements", "that", "could", "be", "made", "to", "the", "basic", "SIR", "particle", "filter", "to", "reduce", "the", "number", "of", "particles", "required", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential importance resampling"}, {"tokens": ["In", "this", "work", ",", "we", "investigate", "the", "efficacy", "of", "the", "ISP", "in", "CNN", "classification", "tasks", ",", "and", "outline", "the", "system", "-", "level", "trade", "-", "offs", "between", "prediction", "accuracy", "and", "computational", "cost", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["For", "example", ",", "researchers", "have", "proposed", "Bypass", "attack", ",", "SPS", "attack", ",", "App", "-", "SAT", "attack", ",", "and", "FALL", "attack", "that", "can", "easily", "circumvent", "the", "effect", "of", "the", "SAT", "-", "resistant", "locking", "schemes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "signal probability skey"}, {"tokens": ["Standard", "ML", "algorithms", "like", "the", "compared", "methods", "have", "typically", "at", "best", "a", "linear", "complexity", "in", ",", "while", "using", "the", "relational", "structure", "representation", "for", "SFM", "have", "a", "linear", "complexity", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "structural factorization machine"}, {"tokens": ["As", "the", "original", "PNN", ",", "only", "one", "position", "remains", "active", "per", "field", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Her", "recent", "experience", "includes", "dynamic", "spectrum", "management", "and", "shared", "spectrum", "technologies", ",", "algorithm", "design", ",", "modeling", "and", "simulations", "for", "WCDMA", ",", "HSPA", "and", "LTE", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "long term evolution"}, {"tokens": ["This", "way", ",", "one", "has", "the", "benefit", "of", "not", "needing", "to", "build", "the", "image", "from", "scratch", "via", "OT", "and", "a", "more", "meaningful", "distance", "metric", "through", "the", "patch", "representation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["h]Simulation", "Parameters", "SettingThe", "distance", "between", "the", "BS", "and", "each", "destination", "user", "is", "set", "to", "80", "m", ",", "while", "the", "distance", "between", "the", "BS", "and", "each", "eavesdropper", "is", "set", "to", "50", "m", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "this", "work", ",", "both", "source", "and", "target", "tasks", "adopt", "logistic", "regression", "as", "a", "behaviour", "prediction", "model", ",", "which", "uses", "the", "linear", "model", "to", "minimise", "the", "logistic", "loss", "from", "each", "observation", "sample", ":", "In", "our", "context", "of", "regarding", "the", "CF", "task", "as", "source", "task", "and", "CTR", "task", "as", "target", "task", ",", "the", "learning", "objectives", "are", "listed", "below", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "private", "messages", "of", "the", "RS", "transmission", "in", "the", "second", "link", "achieve", "almost", "the", "same", "sum", "rate", "as", "the", "conventional", "BC", "with", "full", "power", ",", "when", "holds", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "broadcast channel"}, {"tokens": ["Hence", ",", "the", "probability", "of", "selecting", "the", "shortest", "path", "depends", "on", "the", "value", "of", "sum", "of", "BC", "(", ")", "of", "the", "nodes", "appearing", "in", "the", "route", "of", "user", "and", "may", "be", "defined", "as", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["They", "typically", "expect", "the", "topics", "to", "be", "directly", "relevant", "to", "their", "IS", "practice", ",", "and", "usually", "exhibit", "difficulty", "in", "coping", "with", "the", "dense", "and", "abstract", "material", "taught", "in", "the", "course", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["The", "Symbol", "CNN", "uses", "123", "symbols", ",", "and", "we", "use", "probabilistic", "CER", "correction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "character error rate"}, {"tokens": ["In", "this", "paper", ",", "we", "design", "algorithms", "(", ")", "to", "test", "whether", "a", "given", "algorithm", "satisfies", "GDP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "generalized differential privacy"}, {"tokens": ["The", "more", "interesting", "takeaway", "is", "that", "both", "MB", "-", "enumerating", "algorithms", "run", "considerably", "faster", "than", "their", "MIB", "-", "enumerating", "counterparts", "(", "e.g.", "right", "panel", "of", "Figure", "fig", ":", "orig", ")", ",", "mostly", "because", "the", "number", "of", "MIBs", "is", "often", "one", "to", "two", "orders", "of", "magnitude", "larger", "than", "the", "number", "of", "MBs", "in", "these", "instances", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["Since", "this", "is", "a", "polynomial", "time", "reduction", "from", "Hamiltonian", "Cycle", "to", "the", "DBP", "property", "of", "an", "NCA", ",", "we", "showedthat", "checking", "whether", "an", "NCA", "is", "DBP", "is", "NP", "-", "hard", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["Case", "4", "(", "DBF+WLAN", ")", ":", "Each", "small", "cell", "(", "DBF)operates", "in", "both", "licensed", "and", "unlicensed", "bands", "with", "LTE", "airinterface", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "cluster", "localization", ",", "we", "consider", "a", "receiver", "BS", "with", "an", "-element", "antenna", "array", "located", "at", "an", "reference", "point-", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["On", "the", "other", "hand", ",", "if", "the", "fee", "is", "set", "to", "the", "largest", "cost", "per", "address", "currently", "used", "by", "the", "RIRs", "(", "e.g.", ",", "to", "the", "cost", "per", "address", "used", "in", "/48", "PI", "allocations", ")", ",", "this", "would", "render", "the", "cost", "of", "a", "larger", "block", "impractically", "high", "(", "the", "cost", "of", "a", "/32", "would", "be", "tens", "of", "millions", "of", "US", "if", "the", "cost", "per", "address", "of", "a", "/48", "is", "used).It", "is", "challenging", "for", "the", "InBlock", "to", "have", "different", "cost", "per", "address", "depending", "on", "the", "size", "of", "the", "allocation", ",", "because", "this", "may", "incentivize", "applications", "for", "larger", "blocks", "even", "when", "not", "needed", ",", "resulting", "in", "address", "waste", "(", "note", "that", "we", "do", "not", "have", "a", "complementary", "mechanism", "such", "as", "a", "need", "assessment", "procedure", ",", "to", "modulate", "user", "requests", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["The", "WDR", "is", "defined", "at", "each", "node", "in", "D2D", "communication", "as", "the", "minimum", "Data", "Rate", "in", "the", "path", "that", "the", "UE", "selected", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "user equipment"}, {"tokens": ["Proposition", "states", "that", "the", "IB", "curve", "in", "the", "information", "plane", "follows", "the", "equation", "if", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["We", "analyze", "the", "co", "-", "evolution", "of", "the", "interaction", "between", "users", "and", "a", "RS", "in", "its", "time", "domain", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["The", "Optimised", "Cross", "-", "Layer", "FEC", "(", "OCLFEC", ")", "computes", "priority", "values", "based", "on", "the", "mean", "squared", "error", "of", "each", "frame", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["An", "IT2FS", "with", "trapezoidal", "UMF", ",", "and", "triangular", "LMF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "lower membership function"}, {"tokens": ["itemizeSingle", "-", "turn", "QA"], "acronym_pos": [0, 0, 0, 1], "long_form": "question answering"}, {"tokens": ["PROCHLO", "implementation", "of", "ESA", "This", "is", "a", "very", "good", "example", "of", "CDP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "centralized differential privacy"}, {"tokens": ["MLconv", "and", "LR", "network", "initialized", "with", "CNN", "marked", "with", "\"", "i", "\"", "at", "last", "Experimental", "results[t", "!", "]"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low rank"}, {"tokens": ["The", "location", "of", "the", "user", "is", "based", "in", "terms", "of", "GPS", "coordinates", ";", "latitude", "and", "longitude", "referenced", "to", "WGS84", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Our", "results", "suggest", "that", "models", "use", "a", "linear", "combination", "of", "NP", "constituent", "number", "to", "drive", "CoordNP", "/", "verb", "number", "agreement", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "noun phrase"}, {"tokens": ["When", "the", "Highway", "values", "are", "analysed", ",", "one", "can", "notice", "that", "over", "61", "of", "the", "packets", "belong", "to", "B", "-", "Frames", ",", "which", "are", "not", "considered", "in", "either", "the", "non", "-", "adaptive", "Video", "-", "aware", "FEC", "or", "in", "ViewFEC", ",", "because", "they", "lead", "to", "minor", "impairments", "if", "lost", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "similar", "task", "is", "quite", "challenging", "with", "canonical", "PSO", "due", "to", "euclidean", "distance", "based", "learning", "at", "its", "core", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Moreover", ",", "the", "LS", "and", "LMMSE", "estimators", "in", "Section", "serve", "as", "the", "benchmarks", "to", "assess", "the", "estimation", "performance", "of", "the", "DL", "estimator", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["We", "argue", "that", "because", "the", "InBlock", "charges", "a", "similar", "fee", "than", "the", "RIR", "for", "a", "PI", "/48", "allocation", ",", "it", "is", "unlikely", "that", "there", "will", "be", "an", "increased", "demand", "of", "PI", "allocations", "due", "to", "the", "InBlock", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["Feature", "selection", "(", "FS", ")", ",", "the", "latter", "one", ",", "which", "is", "the", "process", "of", "choosing", "proper", "sets", "of", "relevant", "features", "rather", "than", "converting", "to", "a", "new", "dimension", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feature selection"}, {"tokens": ["They", "pointed", "out", "that", "their", "scheme", "provides", "security", "against", "FA", "attacks", "by", "using", "the", "Montgomery", "method", "for", "coherent", "check", "and", "high", "probability", "detecting", "injected", "errors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fault attack"}, {"tokens": ["It", "is", "shown", "that", ",", "as", "increases", "and", "as", "the", "fading", "conditions", "of", "the", "relay", "to", "destination", "channels", "become", "more", "favorable", "than", "those", "of", "the", "direct", "source", "to", "destination", "channel", ",", "RS", "-", "based", "transmission", "results", "in", "larger", "improvement", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["However", ",", "using", "UAVs", "in", "SAR", "operations", "reduces", "the", "costs", ",", "resources", "and", "human", "risks", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["We", "can", "see", "this", "more", "clearly", "if", "we", "consider", "the", "shifted", "exponential", "IB", "Lagrangian", ",", "since", "then", "the", "application", "of", "Proposition", "results", "on", ",", "where", "is", "the", "derivative", "of", "evaluated", "at", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Table", "tbl", ":", "exp", "-", "link", "-", "prediction", "shows", "the", "accuracy", "of", "node2vec", ",", "DeepWalk", ",", "and", "LINE", "with", "the", "initialization", "techniques", ",", "i.e.", ",", "GPA", ",", "HARP", ",", "and", "Random", ",", "for", "link", "prediction", "by", "Cosine", "similarity", "and", "Euclidean", "similarity", "on", "the", "datasets", "Enron", ",", "GRQC", ",", "Blog", ",", "and", "Wiki", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["(", "GI", ":", "gradient", "initialization", ",", "SSS", ":", "staggered", "sample", "selection", ",", "SOM", ":", "standard", "SOM", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient initialization"}, {"tokens": ["It", "seemed", "to", "be", "difficult", "to", "learn", "a", "trainable", "function", "to", "merge", "the", "u", "/", "v", "and", "the", "other", "acoustic", "features", "for", "MVF", "prediction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["0core", "connectedness", "(", "CC", ")", "property", "that", "allows", "us", "to", "efficiently", "predict", "the", "highly", "central", "vertices", "in", "time", "-", "varying", "networks", "(", "section", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "core connected"}, {"tokens": ["For", "the", "squeal", "category", "this", "detector", "shows", "slightly", "higher", "AP", "values", "than", "models", "1", "and", "3", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["All", "other", "aspects", "of", "GP", "inference", "remain", "the", "same", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["LF", "-", "RCNNLate", "fusion", "encoder", "with", "concatenated", "history", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "late fusion"}, {"tokens": ["The", "idea", "of", "building", "continual", "GP", "priors", ",", "instead", "of", "concatenating", "inducing", "-", "points", "in", "a", "sparse", "approximation", "context", "had", "not", "been", "considered", "before", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["MINT", "-", "FEC", "Adopted", "Notation"], "acronym_pos": [0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["As", "discussed", "previously", "is", "much", "smaller", "than", "for", "the", "ANN", "problem", ",", "the", "precision", "will", "be", "almost", "0", "due", "to", "the", "high", "value", "of", "regardless", "of", "whether", "the", "true", "nearest", "neighbor", "points", "are", "retrieved", "or", "not", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "approximate nearest neighbor"}, {"tokens": ["Additionally", ",", "by", "playing", "a", "central", "role", ",", "the", "AP", "can", "ask", "for", "buffer", "and", "other", "information", "from", "STAs", ",", "enabling", "it", "to", "make", "the", "best", "scheduling", "decision", "in", "the", "dense", "scenario", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Beside", "the", "parameters", "that", "were", "changed", "for", "DC", "-", "OPF", ",", "re", "-", "scaled", "nodal", "load", "reactive", "power", ",", "maximum", "reactive", "power", "output", "of", "generators", ",", "and", "line", "resistance", "values", "were", "produced", "by", "scaling", "factors", "sampled", "from", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["EMD", "itself", "performs", "not", "very", "well", ",", "but", "complements", "DMD", "and", "improves", "overall", "recognition", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deficient mapping dissolution"}, {"tokens": ["We", "evaluated", "the", "performance", "of", "CNN", "and", "DBN", "with", "combination", "of", "dropout", "and", "different", "filters", "on", "a", "standard", "benchmark", "dataset", ":", "CMATERdb", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["propose", "techniques", "for", "terrain", "rendering", "using", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0], "long_form": "tessellation shader"}, {"tokens": ["There", "has", "also", "been", "work", "operating", "on", "the", "dense", "RV", "representation", "directly", ",", "but", "these", "methods", "have", "not", "matched", "the", "performance", "of", "the", "BEV", "approaches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "range view"}, {"tokens": ["The", "definition", "of", "GDP", "below", "is", "a", "slight", "modification", "to", "the", "definition", "proposed", "inBBGLT11", "and", "in", "most", "natural", "settings", "is", "stronger", "thanBBGLT11", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["In", "Table", ",", "the", "effect", "of", "data", "augmentation", "and", "fine", "tuning", "using", "SEM", "images", "in", "the", "MVFCNN", "approach", "have", "been", "depicted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["The", "best", "performing", "algorithms", "are", "aggregated", "using", "a", "probability", "vote", "in", "order", "to", "create", "a", "model", "which", "has", "the", "largest", "area", "under", "ROC", "curve", "of", "all", "the", "developed", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["We", "first", "identify", "the", "tool", "states", "using", "evolutionary", "cost", "-", "sensitive", "deep", "belief", "network", "(", "ECS", "-", "DBN", ")", "which", "is", "suitable", "for", "imbalanced", "data", "classification", ",", "then", "based", "on", "different", "tool", "states", "choose", "appropriate", "DBN", "models", "for", "more", "accurate", "and", "robust", "tool", "wear", "estimation", "based", "on", "the", "tool", "states", ",", "finally", "we", "make", "reliable", "decisions", "based", "on", "the", "accurate", "estimates", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["All", "documents", "in", "LSC", "have", "non", "-", "empty", "abstract", ",", "title", ",", "categories", ",", "research", "areas", "and", "times", "cited", "in", "WoS", "databases", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Validation", "of", "intermediate", "results", "and", "random", "ephemeral", "are", "used", "to", "prevent", "classic", "DFA", "attacks", "while", "Montgomery", "ladder", "and", "verify", "the", "final", "results", "used", "to", "prevent", "sign", "change", "FA", "attacks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "fault attack"}, {"tokens": ["The", "cryptographic", "algorithms", "used", "in", "BC", "ensure", "superior", "security", "and", "privacy", "for", "device", "data", "and", "IoT", "is", "increasingly", "adopting", "BC", "technology", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "blockchain"}, {"tokens": ["DWA", "GP", "-", "UCB"], "acronym_pos": [0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "each", "scenario", ",", "Cell", "B", "measures", "the", "energy", "values", "during", "the", "LTE", "-", "U", "OFF", "period", ",", "while", "other", "cells", "are", "transmitting", "full", "buffer", "downlink", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Section", "4", "describes", "our", "experimental", "setup", "and", "the", "results", "of", "our", "experiments", "assessing", "the", "performance", "of", "CNet", "-", "NIC", "on", "the", "MS", "COCO", "image", "captioning", "benchmark", "dataset", "along", "with", "comparisons", "with", "the", "competing", "state", "-", "of", "-", "the", "-", "art", "methods", "using", "the", "standard", "performance", "measures", "(", "BLEU@", "(", ")", ",", "METEOR", ",", "ROUGE", "-", "L", ",", "and", "CIDEr", "-", "D", ")", "as", "well", "as", "a", "qualitative", "analysis", "of", "a", "representative", "sample", "of", "the", "captions", "produced", "by", "CNet", "-", "NIC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "neural image caption"}, {"tokens": ["Comparison", "of", "ring", "and", "PRR", "algorithms", "for", "1Gbps", "Ethernet", "and", "48", "processes", "/", "nodes", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pre - reduced ring"}, {"tokens": ["SemanticsThe", "formal", "semantics", "of", "AML", "models", "is", "given", "in", "terms", "of", "LTSs", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["In", "general", ",", "the", "PLR", "input", "set", "is", "lower", "in", "MINF", "-", "FEC", "than", "in", "uavFEC", "because", "videos", "with", "higher", "resolution", "tend", "to", "consume", "more", "network", "resources", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "experiments", "show", "very", "promising", "results", ":", "our", "learnt", "auction", "mechanism", "can", "outperform", "several", "baselines", "including", "the", "widely", "used", "classic", "GSP", "auction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "generalized second price"}, {"tokens": ["(", "f", ")", "CP3-Online", ",", "(", "g", ")", "GMM", "-", "Stauffer", ",", "(", "h", ")", "KDE", "-", "ElGammal", ",", "(", "i", ")", "RMOG", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["IPNN2-fig.pdf", "Architecture", "of", "the", "PNN", "context", "encoder", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["On", "an", "ROC", "curve", "the", "X", "-", "axis", "represents", "and", "the", "Y", "-", "axis", "represents", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Based", "on", "the", "analysis", ",", "a", "transitive", "transfer", "method", "via", "multi", "-", "source", "data", "with", "domain", "adaptation", "is", "proposed", "in", "this", "paper", "to", "decrease", "the", "discrepancy", "between", "the", "source", "data", "and", "SAR", "targets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Further", ",", "inertia", "weight", "and", "acceleration", "factors", "of", "PSO", "are", "tuned", "using", "the", "fuzzy", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["This", "point", "was", "further", "confirmed", "using", "mutual", "information", "and", "representational", "dissimilarity", "matrix", "(", "RDM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "representational dissimilarity matrix"}, {"tokens": ["Authors", "introduced", "an", "Adaptive", "inertia", "weight", "-", "based", "PSO", "called", "APSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Output", "of", "GP", "\"", "is", "the", "NRMSE", "between", "the", "output", "of", "the", "trained", "GP", "model", "and", "the", "temporal", "profile", "of", "the", "new", "venue", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["For", "moderate", "stretches", ",", "even", "an", "RB", "size", "of", "suffices", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["Access", "to", "the", "data", "elements", "in", "data", "regions", "is", "performed", "through", "a", "lightweight", "class", "that", "encapsulates", "the", "data", "layout", ",", "provided", "by", "the", "RT", "library", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "region template"}, {"tokens": ["For", "example", ",", "a", "fractal", "noise", "can", "be", "generated", "on", "the", "FS", ",", "it", "then", "can", "be", "applied", "as", "a", "displacement", "map", ",", "creating", "a", "rough", "aspect", "on", "the", "mesh", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fragment shader"}, {"tokens": ["STL", "has", "monitoring", "routines", "both", "for", "its", "Boolean", "and", "quantitative", "semantics", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "signal temporal logic"}, {"tokens": ["In", "the", "following", ",", "we", "show", "how", "the", "proposed", "SFM", "method", "can", "make", "use", "of", "relational", "structure", "of", "each", "mode", ",", "such", "that", "the", "learning", "and", "prediction", "can", "be", "scaled", "to", "predictor", "variables", "generated", "from", "relational", "data", "involving", "relations", "of", "high", "cardinality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "structural factorization machine"}, {"tokens": ["In", "Section", "SECscf", "we", "will", "define", "our", "modification", "to", "the", "SBM", "which", "we", "call", "Stochastic", "Community", "Finding", "(", "SCF", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["OT", "Extension", "Phase"], "acronym_pos": [1, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["However", ",", "directly", "applying", "such", "approaches", "in", "the", "FL", "setting", "results", "in", "poor", "model", "performance", "because", "each", "party", "trains", "its", "own", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["This", "is", "expected", "as", "the", "ANN", "has", "learned", "speaker", "discrimination", "from", "only", "a", "few", "recordings", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["From", "left", "to", "right", "it", "is", "shown", "(", "i", ")", "the", "information", "plane", ",", "where", "the", "region", "of", "possible", "solutions", "of", "the", "IB", "problem", "is", "shadowed", "in", "light", "orange", "and", "the", "information", "-", "theoretic", "limits", "are", "the", "dashed", "orange", "line", ";", "(", "ii", ")", "as", "a", "function", "of", ";", "and", "(", "iii", ")", "the", "compression", "as", "a", "function", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Privacy", "of", "FL", "FrameworkOur", "proposed", "FL", "framework", "can", "ensure", "the", "privacy", "of", "the", "output", "model", "and", "the", "aggregation", "computation", "."], "acronym_pos": [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["we", "deployed", "a", "PS", "agent", "as", "described", "in", "Sec", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "projective simulation"}, {"tokens": ["For", "operator", "gains", ",", "is", "the", "welfare", "-", "minimizing", "SSS", ",", "i.e.", "it", "satisfies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "stochastically stable states"}, {"tokens": ["These", "results", "confirm", "our", "earlier", "observations", "from", "synthetic", "and", "CD", "patient", "datasets", "about", ":", "1", ")", "the", "superior", "performance", "of", ";", "2", ")", "effectiveness", "of", "SSL", "in", "predicting", "missing", "annotation", "information", ";", "3", ")", "inferior", "performance", "of", "LMStaple", "due", "to", "predicting", "sensitivity", "and", "specificity", "parameters", "from", "annotations", "without", "considering", "their", "overall", "consistency", ",", "and", "using", "EM", ";", "and", "4", ")", "contribution", "of", "our", "SC", "score", "and", "graph", "cuts", "in", "obtaining", "better", "consensus", "annotations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "self consistency"}, {"tokens": ["SAR", "has", "also", "shown", "success", "in", "helping", "users", "learn", "abstract", "concepts", ";", "for", "example", ",", "implemented", "a", "SAR", "system", "that", "used", "deictic", "gestures", "to", "help", "preschoolers", "learn", "number", "concepts", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "Final", "accuracy", "of", "IFAB", "is", "60.98", "and", "68.22", "for", "SPAM", "and", "CC", "-", "PEV", "data", "set", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subtractive pixel adjacency matrix"}, {"tokens": ["In", "the", "case", "of", "the", "Poisson", "SBM", "eqn.graph_ypq_poisson", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["define", "the", "elapsed", "time", "as", ",", "and", "the", "average", "elapsed", "time", "for", "the", "whole", "PAP", ":", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["SRL", "with", "100", "training", "data", "and", "SRL", "with", "random", "query", "serve", "as", "baseline", "strategies", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["Since", "in", "ET", "the", "activity", "distribution", "is", "piecewise", "-", "smooth", "and", "the", "use", "of", "TV", "penalty", "can", "result", "in", "undesirable", "artifacts", ",", "this", "can", "potentially", "bias", "the", "following", "clinical", "interpretation", "of", "reconstructed", "images", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "emission tomography"}, {"tokens": ["In", "synthetic", "and", "empirical", "networks", "with", "a", "heavy", "-", "tailed", "degree", "distributionthe", "SBM", "may", "have", "a", "tendency", "to", "cluster", "nodes", "according", "to", "theirdegree", ",", "or", "other", "structural", "roles", ",", "and", "not", "according", "to", "community", "structure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Socially", "assistive", "robotics", "(", "SAR", ")", "combines", "robotics", "and", "computational", "methods", "to", "broaden", "access", "to", "personalized", ",", "socially", "situated", ",", "and", "physically", "co", "-", "present", "interventions", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Although", "some", "GM", "algorithms", "do", "not", "require", "any", "spatial", "initialisation", "of", "the", "graphs", ",", "we", "present", "a", "two", "-", "steps", "approach", "(", "Fig", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph matching"}, {"tokens": ["A", "complete", "Group", "-", "ID", "table", "is", "created", "and", "disseminated", "by", "the", "AP", ",", "and", "will", "be", "recomputed", "as", "STAs", "associate", "or", "de", "-", "associate", "to", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["MDCN", "takes", "a", "significant", "lead", "in", "all", "the", "three", "difficulty", "levels", "of", "cyclist", ",", "where", "MDCN", "-", "I1", "even", "has", "nearly", "20", "higher", "AP", "than", "that", "of", "the", "second", "record", "from", "WR", "-", "Inception", "-", "I2", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["We", "conjecture", "that", "this", "particular", "phenomenon", "is", "a", "result", "of", "the", "specific", "tasks", "and", "ET", "placement", "for", "the", "environment", "setting", "shown", "in", "Table", "2", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy transmitters"}, {"tokens": ["The", "base", "station", "as", "an", "auctioneer", "allocates", "its", "subcarriers", "and", "FJ", "power", "to", "the", "mobile", "users", "as", "bidders", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["This", "tailored", "amount", "of", "redundancy", "is", "used", "to", "optimally", "adjust", "the", "FEC", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Instead", "of", "communicating", "with", "a", "legitimate", "AP", ",", "connecting", "to", "a", "rogue", "AP", "can", "result", "in", "the", "interception", "of", "data", "from", "clients", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["In", "general", ",", "any", "density", "which", "can", "be", "evaluated", "on", "the", "data", "space", "and", "which", "allowsfor", "efficient", "sampling", ",", "is", "a", "valid", "choice", "as", "base", "measure", "in", "our", "inference", "approach", "for", "the", "GP", "density", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "define", "Signal", "-", "to", "-", "Noise", "ratio", "(", "SNR", ")", "for", "data", "communication", "between", "the", "node", "and", "BS", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "base station"}, {"tokens": ["As", "the", "foundry", "can", "learn", "about", "the", "location", "of", "key", "-", "gates", "and", "key", "-", "delivery", "unit", ";", "applying", "FA", "methods", "like", "optical", "and", "electrical", "probing", "for", "extracting", "the", "key", "value", "of", "the", "key", "-", "gate", "is", "more", "convenient", "for", "the", "attacker", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["Copenhagen", "Networks", "Study", "MDC", ":"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "mobile data challenge"}, {"tokens": ["These", "points", "in", "have", "to", "be", "chosen", "carefully", "so", "that", "causality", "is", "not", "violated", "since", "GMM", "does", "not", "sort", "the", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["dB", "over", "IID", "Nakagami-", "fading", "channels", "with", "different", "values", "of", ":", "(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "maximal ratio diversity"}, {"tokens": ["This", "is", "particularly", "consequential", "for", "fast", "developing", "skills", "and", "occupations", ",", "such", "as", "those", "relating", "to", "Data", "Science", "and", "Analytics", "(", "DSA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["More", "precisely", ",", "a", "PSO", "-", "BP", "neural", "network", "is", "used", "to", "predict", "the", "traffic", "load", "for", "every", "light", "-", "path", "within", "a", "particular", "time", "interval", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["a", ")", "illustrates", "the", "attention", "drift", "phenomenon", "in", "the", "AN", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "attention network"}, {"tokens": ["Categories", "are", "sorted", "based", "on", "the", "average", "model", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "average precision"}, {"tokens": ["We", "want", "to", "check", "whether", "it", "is", "DBP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "determinisable by pruning"}, {"tokens": ["We", "then", "demonstrate", "that", "it", "is", "possible", "to", "derive", "GP", "models", "over", "many", "types", "of", "sequential", "observations", ",", "either", "discrete", "or", "continuous", "and", "amenable", "to", "stochastic", "optimization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Moreover", ",", "with", "Equations", "(", ")", "and", "(", ")", ",", "GP", "-", "UCB", "can", "handle", "various", "noise", "levels", "for", "collected", "measurements", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Moreover", ",", "recent", "long", "-", "term", "SAR", "studies", "have", "demonstrated", "success", "in", "maintaining", "persistent", "co", "-", "present", "support", "for", "educators", ",", "students", ",", "and", "caregivers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Particularly", ",", "we", "see", "that", "to", "achieve", "a", "target", "FER", "of", "around", ",", "the", "SC", "-", "decoded", "BIPCM", "system", "performs", "better", "than", "the", "SC", "-", "decoded", "MLPC", "system", "by", "about", "0.2", "dB", "in", "the", "fast", "fading", "case", ",", "and", "about", "0.1", "dB", "in", "the", "block", "fading", "scenario", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "successive cancellation"}, {"tokens": ["Moreover", ",", "the", "EXH", "-", "FDMA", "scheme", "achieves", "almost", "the", "same", "performance", "as", "the", "proposed", "FL", "scheme", ",", "which", "shows", "that", "the", "proposed", "approach", "achieves", "the", "optimum", "solution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "PS", "scheme", "splits", "the", "received", "signal", "into", "two", "streams", ",", "where", "one", "stream", "with", "power", "ratio", "is", "used", "for", "EH", "and", "the", "other", "with", "power", "ratio", "is", "used", "for", "ID", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Similar", "to", "the", "other", "strategy", ",", "the", "outbreak", "sizes", "do", "not", "reduce", "to", "1", "K", "infections", "in", "RV", "strategy", "even", "vaccinating", "11", "K", "nodes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["We", "convert", "the", "native", "text", "to", "CPS", "phonetic", "text", "using", "deterministic", "converters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "common phone set"}, {"tokens": ["We", "invite", "researchers", "to", "periodically", "update", "the", "upper", "bound", "in", "detection", "scores", "including", "AP", "and", "other", "recently", "proposed", "ones", "such", "as", "LIP", "and", "probability", "-", "based", "detection", "quality", ",", "as", "new", "object", "recognition", "models", "surface", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "SDD", "was", "a", "familiar", "environment", "for", "all", "participants", "and", "very", "little", "introduction", "to", "the", "environment", "was", "required", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Conversely", ",", "the", "front", "-", "end", "fails", "regarding", "FR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "frame recall"}, {"tokens": ["Since", "in", "the", "Canonical", "PSO", ",", "the", "current", "position", "of", "the", "particle", "contributes", "to", "the", "new", "position", ",", "as", "illustrated", "by", "(", ")", ",", "in", "the", "proposed", "learning", "approach", "this", "property", "is", "retained", "by", "introducing", "another", "learning", "set", ",", "''", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["We", "will", "discuss", "the", "noteworthy", "trends", "in", "OEC", "using", "separate", "figures", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["An", "important", "role", "in", "the", "achievement", "of", "the", "AP", "property", "is", "played", "by", "the", "splitting", "of", "the", "pressure", "following", "the", "studies", "of", "Klein", "as", "used", "in", "the", "schemes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "asymptotic preserving"}, {"tokens": ["Paper", "Sentence", "Classification", "(", "PSC", ")"], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "paper sentence classification"}, {"tokens": ["_", "TP", ")"], "acronym_pos": [0, 1, 0], "long_form": "temporal pooler"}, {"tokens": ["If", "none", "of", "the", "helpers", "cache", "the", "requested", "file", ",", "the", "user", "will", "fetch", "the", "file", "from", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["To", "start", "off", ",", "one", "challenge", "is", "how", "to", "provide", "a", "reliable", "way", "to", "calculate", "a", "proper", "FEC", "block", "size", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["For", "the", "multiple", "output", "case", ",", "the", "derivation", "of", "the", "continual", "GP", "expression", "is", "analogous", "but", "considering", "the", "two", "-", "layers", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["denotes", "the", "number", "of", "DST", "coefficients", "in", "Equation", "(", "11", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "discrete sine transform"}, {"tokens": ["The", "fine", "-", "tuned", "ANN", "weights", "(", "and", ")", "are", "stored", "as", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["We", "next", "determine", "the", "model-", "and", "user", "-", "specific", "relative", "charging", "rates", "during", "the", "CC", "phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "charging current"}, {"tokens": ["htb", "]", "Average", "SSIM", "QoE", "for", "all", "scenarios", "Network", "footprint", "analysisMINT", "-", "FEC", "can", "provide", "enhanced", "video", "quality", ",", "especially", "over", "higher", "distances", ",", "however", ",", "it", "is", "equally", "important", "to", "do", "so", "with", "lower", "network", "overhead", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["b", "]", "There", "exist", "sub", "-", "bands", "contained", "within", "a", "10", "MHz", "ITS", "channel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "intelligent transportation system"}, {"tokens": ["In", "addition", ",", "the", "total", "number", "of", "packets", "received", "by", "the", "sink", "throughout", "the", "simulation", "time", "has", "improved", "by", "approximately", "55", "in", "compared", "to", "conventional", "clustering", "protocols", ",", "and", "20", "compared", "to", "the", "optimization", "based", "(", "PSO", ")", "clustering", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["More", "specifically", ",", "the", "downlink", "beam", "-", "vectors", ",", "RRH", "selection", "and", "UE", "-", "RRH", "associations", "were", "jointly", "optimized", "to", "minimize", "the", "total", "NPC", "for", "dense", "C", "-", "RAN", "with", "incomplete", "CSI", "subject", "to", "fronthaul", "capacity", "constraints", ",", "UEs", "'", "QoS", "targets", "and", "per", "-", "RRH", "power", "constraints", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", ",", "we", "investigated", "the", "FL", "loss", "function", "minimization", "problem", "with", "taking", "into", "account", "packet", "errors", "over", "wireless", "links", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["-", "OEC", "has", "a", "special", "forgetful", "prototype", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["J.", "Nichols", ",", "S.", "Trickey", ",", "M.", "Seaver", ",", "S.", "Motley", ",", "Using", "ROC", "curves", "to", "assess", "the", "efficacy", "of", "several", "detectors", "of", "damage", "-", "induced", "nonlinearities", "in", "a", "bolted", "composite", "structure", ",", "Mech", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["We", "denote", "a", "-out", "-", "of-", "OT", "on", "bit", "strings", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Therefore", ",", "we", "adopted", "NCE", "to", "evaluate", "diversity", "in", "our", "global", "search", "application", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["Another", "ANN", "model", "that", "was", "built", "for", "indoor", "air", "temperature", "forecasting", "outperformed", "competing", "regression", "methods", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["In", "line", "5", ",", "it", "incrementally", "sums", "up", "charged", "received", "at", "from", "each", "ET", "location", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "energy transmitters"}, {"tokens": ["The", "BBU", "pool", "is", "assumed", "to", "have", "all", "UEs", "'", "data", "and", "distributes", "each", "UE", "'s", "data", "to", "a", "carefully", "selected", "set", "of", "RRHs", "through", "the", "fronthaul", "links", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["CE", ":", "context", "encoder", ",", "SI", ":", "semantic", "inpainting", ","], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "semantic inpainting"}, {"tokens": ["Germanylangec@cs.uni-bonn.deQuestion", "Answering", "(", "QA", ")", "systems", "are", "becoming", "the", "inspiring", "model", "for", "the", "future", "of", "search", "engines", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Finally", "as", "a", "last", "remark", ",", "it", "is", "important", "to", "mention", "that", "by", "using", "the", "present", "contribution", "'s", "methodology", ",", "the", "obtainment", "of", "quantile", "regressions", "with", "non", "-", "linear", "and", "complex", "data", "mining", "techniques", "(", "i.e.", "ANN", "and", "SVR", ")", "is", "simplified", "and", "made", "possible", "without", "changing", "the", "traditional", "algorithms", "used", "for", "their", "model", "'s", "training", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Thus", ",", "DMD", "can", "and", "should", "be", "used", "by", "practitioners", "to", "re", "-", "analyze", "multivariate", "time", "series", "data", "for", "which", "the", "use", "of", "ICA", "has", "not", "revealed", "any", "insights", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["This", "forces", "the", "ANN", "to", "use", "more", "attributes", "during", "the", "training", "phase", "instead", "of", "relying", "on", "a", "single", "small", "subset", "of", "attributes", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "discriminator", "learns", "to", "distinguish", "generated", "LR", "images", "vs.", "real", "LR", "images", "in", "an", "unpaired", "fashion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Applying", "DBNs", "to", "a", "classification", "problem", ",", "feature", "vectors", "from", "data", "samples", "are", "used", "to", "set", "the", "states", "of", "the", "visible", "variables", "of", "the", "lower", "layer", "of", "the", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["We", "will", "also", "discuss", "how", "we", "can", "apply", "it", "to", "CF", "and", "CTR", "prediction", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["For", "the", "OP", "of", "at", "CEU", ",", "the", "EHS", "-", "CNOMA", "with", "MRC", "provides", "lower", "OP", "than", "HS", "-", "CNOMA", "with", "SC", "for", "MRC", "at", "CEU", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "selection combining"}, {"tokens": ["In", "sum", ",", "the", "results", "show", "that", "ECS", "-", "DBN", "method", "significantly", "outperforms", "other", "competing", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["For", "baseline", "comparisons", ",", "we", "will", "use", "the", "following", "combinations", "of", "feature", "extraction", "and", "classification", "methods", ":", "HMLBP", "+", "SVM", "MPCA", "+", "SVM", "HOG", "+", "SRCFor", "more", "details", "into", "these", "approaches", "and", "the", "parameters", "used", "for", "our", "experimentation", ",", "please", "see", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "histogram of oriented gradient"}, {"tokens": ["On", "the", "other", "hand", ",", "CUB", "demonstrates", "its", "largest", "performance", "advantage", "over", "our", "implementation", "(", "ours", "has", "0.78x", "the", "throughput", "of", "CUB", "'s", ")", "for", "key", "-", "only", "sorts", "on", "Tesla", "K40c", "(", "ECC", "off", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["New", "ranks", "of", "techniques", "based", "on", "Mean", "Rank", "Score", "and", "their", "comparison", "with", "HerboldMethod", "ranks", "Standard", "deviation", "in", "ranks", "of", "techniques", "calculated", "using", "Mean", "Rank", "Score", "of", "AUC", ",", "F", "-", "Score", "and", "MCC", "metrics"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["[", "The", "IB", "curve", "is", "piecewise", "linear", "in", "deterministic", "scenarios", "]", "Let", "be", "a", "random", "variable", "and", "be", "a", "deterministic", "function", "of", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["table*[t]Accuracy", "on", "Target", "SP", "Stringsets", "Early", "Stoppingtab", ":", "resultsSPES4.5pttabularcccccccccc2c2Training", "&", "2Test", "&", "3cLSTM", "&", "3cs", "-", "RNN", "&", "2RPNI", "&", "&", "&", "10", "&", "30", "&", "100", "&", "10", "&", "30", "&", "100", "&", "6SP2", "&", "21k", "&", "1", "&", "0.871", "(", "0.04", ")", "&", "0.954", "(", "0.05", ")", "&", "0.992", "(", "0.00", ")", "&", "0.910", "(", "0.05", ")", "&", "0.994", "(", "0.01", ")", "&", "0.992", "(", "0.01", ")", "&", "1.000", "&", "&", "2", "&", "0.960", "(", "0.03", ")", "&", "0.989", "(", "0.02", ")", "&", "0.998"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Among", "the", "non", "variational", "methods", ",", "the", "VCC", "theory", "constitutes", "a", "robust", "way", "to", "get", "precision", "out", "of", "small", "spaces", "with", "a", "computational", "cost", "sharply", "increasing", "with", "the", "level", "of", "excitations", "exponentially", "deployed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vibrational coupled cluster"}, {"tokens": ["Therefore", ",", "we", "adapt", "the", "GP", "to", "our", "case", "that", "can", "take", "into", "account", "various", "noise", "levels", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["eqnarrayIn", "an", "NP", "paradigm", "(", "see", "Appendix", "subsec", ":"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["*", "urka-", "MP", "gurg", "NP", "gurg", "'", "wolf'PIr", "*", "urpa", "-", "ka-"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Moreover", ",", "the", "BA", "with", "APO", "is", "also", "observed", "to", "overfit", "in", "the", "noisy", "sequences", "while", "Classic+NL", "with", "APO", "yields", "the", "best", "measures", "in", "both", "sequences", "of", "Gauss", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "black and anandan"}, {"tokens": [",", "we", "compare", "the", "performance", "of", "CEIB", "for", "predicting", "the", "ACE", "against", "several", "existing", "baselines", "as", "intLouizos", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "average causal effect"}, {"tokens": ["For", "LR", "models", "the", "conditional", "probability", "for", "given", "its", "feature", "vector", "and", "the", "weight", "vector", "is", "given", "by", "eq", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Here", ",", "the", "unpersonalized", "MP", "approach", "even", "reaches", "a", "recommendation", "accuracy", "of", "0.000", "for", "all", "metrics", ",", "thus", "not", "recommending", "a", "single", "relevant", "service", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "most popular"}, {"tokens": ["The", "contribution", "of", "this", "research", "is", "our", "ability", "to", "exploit", "a", "legitimate", "flatbed", "scanner", "to", "establish", "a", "covert", "channel", "between", "a", "CC", "server", "and", "a", "malware", "(", "previously", "installed", "in", "the", "organization", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "covert channels"}, {"tokens": ["In", "GP", "regression", "for", "mono", "channel", "audio", "signals", ",", "instead", "of", "estimating", "parameters", "of", "fixed", "-", "form", "functions", "where", "the", "time", "input", "variable", ",", "we", "model", "the", "whole", "function", "as", "a", "GP", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["In", "this", "experiment", ",", "a", "DBN", "with", "two", "RBM", "based", "hidden", "layers", "trained", "with", "Bernoulli", "hidden", "and", "visible", "units", "has", "been", "implemented", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["This", "work", "showed", "encouraging", "results", ",", "but", "the", "model", "produces", "only", "the", "mask", "as", "output", "while", "the", "physician", "would", "be", "interested", "in", "viewing", "the", "FS", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "fully sampled"}, {"tokens": ["However", ",", "the", "processing", "at", "the", "EC", "is", "less", "efficient", "since", "the", "number", "of", "its", "accommodated", "DUs", "is", "less", "than", "that", "at", "the", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "central cloud"}, {"tokens": ["Process", "arrival", "time", "estimationThe", "PAP", "collective", "communication", "algorithms", "require", "some", "knowledge", "about", "the", "PATs", "for", "their", "execution", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["The", "concluding", "thought", "is", "that", "the", "further", "investigation", "of", "language", "mikolov1,mikolov2,glove", ",", "sensembed", "and", "knowledge", "modeling", "tatec", ",", "transe", ",", "riedel2013,ntn", ",", "trescal", "and", "powerful", "deep", "neural", "architectures", "with", "self", "-", "regulating", "abilities", "(", "attention", ",", "memory", ")", "as", "well", "as", "implicit", "or", "explicit", "joint", "models", "will", "continue", "to", "push", "the", "state", "of", "the", "art", "in", "QA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "question answering"}, {"tokens": ["Setting", "S2", ":", "Train", "networks", "on", "generated", "LR", "images", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["The", "review", "of", "the", "literature", "suggests", "many", "choices", "of", "architectures", "in", "the", "domain", "of", "deep", "learning", "were", "applied", "to", "for", "RV", "segmentation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "right ventricle"}, {"tokens": ["However", ",", "all", "the", "above", "literature", "concerning", "PA", "does", "not", "belong", "to", "the", "scope", "of", "DM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["TS", "-", "RF", "reduces", "the", "number", "of", "features", "by", "62", "while", "improving", "classification", "accuracy", "sufficiently", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["figure[Key", "-", "only", ":", "K40c", "(", "ECC", "on", ")", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["optimization_problem_intro", ",", "where", "the", "equivalence", "between", "the", "decision", "rules", "and", "the", "selection", "of", "the", "thresholds", "is", "essentially", "the", "same", "as", "for", "the", "DI", "case", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "direct inspection"}, {"tokens": ["The", "figure", "also", "includes", "a", "special", "curve", "for", "the", "case", "where", "the", "number", "of", "transmit", "antennas", "of", "the", "eavesdropper", "node", "corresponding", "to", "the", "case", "where", "does", "not", "send", "any", "AN", "to", "the", "legitimate", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["We", "use", "the", "function", "to", "create", "a", "list", "of", "DSA", "skills", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["It", "follows", "the", "maximum", "probability", "to", "look", "for", "similar", "RV", "over", "can", "be", "reduced", "to", "measuring", "the", "maximum", "correlation", "among", "all", "variables", "given", "(", "see", "Eq", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["Asymptotically", ",", "our", "OT", "extension", "matches", "the", "KK13", "protocol", "in", "every", "respect", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["An", "alternative", "Poisson", "model", "for", "which", "similar", "spatial", "integrals", "can", "be", "performed", "analytically", "within", "the", "sparse", "GP", "approximation", "(", "limited", "to", "squared", "exponential", "kernels", "and", "rectangular", "domains", ")", "is", "based", "on", "a", "quadratic", "link", "functionlloyd2015variational", ",", "flaxman2017poisson", ",", "john2018large", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Greedy", "Update", "Frontier", "SelectionWe", "use", "this", "frontier", "-", "based", "approach", "to", "implement", "several", "existing", "schedulings", "on", "the", "GPU", ",", "specifically", "LBP", ",", "RBP", ",", "and", "RS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "residual splash"}, {"tokens": ["Logical", "expressions", "in", "FCA", "are", "implications", "between", "attributes", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "formal concept analysis"}, {"tokens": ["rohitash.chandra@usp.ac.fj", "Mobile", "Application", "for", "Dengue", "Fever", "Monitoring", "and", "Tracking", "via", "GPS", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "global positioning system"}, {"tokens": ["Furthermore", ",", "we", "also", "simulate", "a", "more", "realistic", "scenario", ",", "in", "which", "each", "macrocell", "UE", "randomly", "selects", "a", "targeted", "received", "power", "level", "among", ",", ",", ",", "and", "with", "equal", "probability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "terms", "of", "achieving", "an", "effective", "recommendation", ",", "CF", "approach", "requires", "either", "ratings", "on", "an", "item", "or", "a", "large", "number", "of", "ratings", "from", "a", "user", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["This", "is", "because", "the", "AP", "and", "STAs", "are", "set", "to", "have", "the", "same", "traffic", "load", ",", "and", "more", "importantly", ",", "the", "frame", "aggregation", "scheme", "(", "AP", "'s", ",", "STA", "'s", ")", "counteracts", "the", "STAs", "'", "collective", "advantage", "on", "the", "channel", "access", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "idea", "is", "to", "add", "an", "offset", "(", "the", "negative", "value", "of", "the", "interference", "that", "is", "known", "at", "the", "AP", ")", "to", "the", "transmitted", "signal", ",", "which", "hints", "that", "(", "1", ")", "the", "AP", "has", "to", "know", "the", "interference", "in", "advance", ",", "and", "(", "2", ")", "the", "AP", "always", "has", "available", "codewords", ",", "i.e.", ",", "infinite", "length", "of", "codewords", ",", "which", "make", "DPC", "not", "suitable", "for", "practical", "use", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["What", "if", "we", "do", "n't", "have", "the", "large", "-", "scale", "annotated", "SAR", "images", "to", "pre", "-", "train", "a", "deep", "network", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["PA", "-", "RTC", ":", "sequent", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "peano 's arithmetics"}, {"tokens": ["The", "central", "database", "has", "pre", "-", "installed", "parking", "zones", "'", "information", "(", "e.g.", ",", "the", "capacity", "and", "GPS", "coordinates", "of", "parking", "zones", ")", ",", "which", "are", "used", "to", "identify", "illegal", "parking", "vehicles", "and", "empty", "parking", "spaces", "from", "the", "received", "sonar", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["When", ",", "the", "slope", "is", "less", "than", "the", "other", "cases", "showing", "that", "the", "higher", "the", "is", ",", "the", "less", "capable", "RS", "is", "of", "mitigating", "the", "SI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["A", "final", "argument", "to", "support", "that", "the", "proposed", "fee", "structure", "is", "sufficient", "to", "deter", "stockpiling", "is", "the", "following", ":", "If", "the", "fee", "of", "a", "/32", "is", "3,000", "US", ",", "then", "getting", "the", "whole", "IPv6", "address", "space", "would", "imply", "a", "total", "amount", "of", "US", "(", "compared", "to", "the", "world", "Gross", "Domestic", "Product", ",", "GDP", "which", "is", "US", ")", "making", "it", "impossible", "for", "any", "party", "to", "even", "get", "hold", "of", "a", "significant", "chunk", "of", "the", "IPv6", "address", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gross domestic product"}, {"tokens": ["In", "the", "context", "of", "medical", "imaging", ",", "our", "priors", "enforce", "the", "synthesised", "HR", "images", "to", "be", "anatomically", "meaningful", "while", "minimising", "a", "traditional", "image", "reconstruction", "loss", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["Ablation", "on", "the", "number", "of", "components", "of", "GMM", "for", "the", "mIoU", "performance", "using", "the", "Open", "Images", "as", "the", "weak", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["proposed", "multi", "-", "objective", "PSO", "(", "MPSO", ")", "for", "solving", "the", "ELD", "problems", "of", "the", "risk", "-", "based", "wind", "-", "integrated", "power", "system", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["PSO"], "acronym_pos": [1], "long_form": "particle swarm optimization"}, {"tokens": ["Using", "instantaneous", "CSI", "and", "Eq", ":", "g_end_PureRS", ",", "rate", "-", "selective", "RS", "chooses", "between", "direct", "(", "non", "-", "relay", "assisted", ")", "and", "relay", "-", "assisted", "transmission", "based", "on", "the", "following", "criterionAs", "shown", "in", ",", "the", "MGF", "of", "can", "be", "obtained", "using", "the", "of", "pure", "RS", "aswhere", "is", "a", "RV", "with", "CDF", "given", "by", "which", "can", "be", "obtained", "using", "inverse", "sampling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random variable"}, {"tokens": ["While", "the", "students", "encounter", "the", "concepts", "of", "state", "machines", ",", "abstraction", "and", "composition", "at", "other", "IS", "courses", "(", "such", "as", "modeling", "and", "design", ")", ",", "aspects", "related", "to", "working", "with", "formal", "specifications", "are", "not", "covered", "elsewhere", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["The", "former", "utilizes", "the", "MAC", "random", "mechanism", "to", "decide", "which", "STAs", "are", "allowed", "for", "data", "transmissions", ",", "while", "the", "latter", "employs", "the", "AP", "to", "schedule", "STAs", "'", "uplink", "access", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Unlike", "conventional", "GP", ",", "however", ",", "measurements", "we", "obtain", "have", "various", "noise", "levels", "based", "on", "which", "altitude", "the", "measurements", "were", "observed", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Semantic", "role", "labeling", "(", "SRL", ")", "is", "a", "form", "of", "shallow", "semantic", "parsing", "that", "annotates", "predicates", "and", "their", "arguments", "in", "sentences", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["Matrix", "FactorizationMF", "is", "a", "canonical", "algorithm", "for", "CF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "collaborative filtering"}, {"tokens": ["To", "further", "maximize", "the", "sum", "rate", "in", "WPCNs", ",", "jointly", "optimized", "BS", "broadcasting", "power", "and", "the", "time", "sharing", "among", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Maximising", "a", "posteriori", "(", "MAP", ")", "estimation", "givesJust", "like", "most", "solutions", "on", "CF", "recommendation", "and", "CTR", "estimation", ",", "in", "this", "discriminative", "framework", ",", "is", "only", "concerned", "with", "the", "mapping", "from", "the", "features", "to", "the", "labels", "(", "the", "conditional", "probabilities", ")", "rather", "than", "modelling", "the", "prior", "distribution", "of", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["MINT", "-", "FEC", ":"], "acronym_pos": [0, 0, 1, 0], "long_form": "forward error correction"}, {"tokens": ["The", "DCNN", "and", "MCNet", "are", "two", "baselines", "for", "the", "proposed", "method", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["The", "architecture", "of", "heatmap", "confidence", "discriminator", "is", "identical", "to", "the", "one", "used", "in", "high", "to", "low", "discriminator", ",", "except", "the", "input", "is", "an", "LR", "image", "concatenated", "with", "the", "heatmap", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["tab", ":", "state", "tabularlccccc", "Model", "&", "AP", "&", "AP1", "&", "AP0.5", "&", "AP0.25", "&", "AP0.125", "MLP", "baseline", "&", "3.60.5", "&", "1.50.4", "&", "0.80.3", "&", "0.20.1", "&", "0.00.0"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["http://dx.doi.org/10.1016/S0031-3203(96)00142-2CrossRef]Hand", ",", "D.J.", ";", "Till", ",", "R.J.A", "simple", "generalisation", "of", "the", "area", "under", "the", "ROC", "curve", "for", "multipleclass", "classification", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["In", "contrast", ",", "for", "example", ",", "the", "GP", "and", "HP", "models", "relied", "primarily", "on", "BOW", "and", "Brown", "clustering", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "hawkes processes"}, {"tokens": ["To", "evaluate", "the", "remaining", "ISP", "stages", ",", "we", "compare", "the", "performance", "of", "ISP", "configurations", "with", "incrementally", "more", "stages", "added", "until", "arriving", "at", "a", "full", "ISP", "pipeline(Informed", "by", "expert", "knowledge", ",", "we", "restrict", "the", "space", "of", "possible", "ISP", "configurations", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "image signal processor"}, {"tokens": ["We", "further", "found", "that", "data", "augmentation", "on", "text", "-", "based", "QA", "training", "examples", "can", "improve", "SQA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Acknowledging", "that", "existing", "TS", "corpora", "are", "inappropriate", "for", "learning", "to", "decompose", "sentences", "into", "shorter", ",", "syntactically", "simplified", "components", ",", "as", "they", "contain", "only", "a", "small", "number", "of", "split", "examples", ",", "Narayan2017", "lately", "compiled", "the", "first", "TS", "dataset", "that", "explicitly", "addresses", "the", "task", "of", "sentence", "splitting", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["The", "number", "of", "convex", "equality", "constraints", "(", ")", "is", "very", "similar", "to", "those", "of", "DC", "-", "OPF", ",", "but", "there", "is", "also", "a", "great", "number", "of", "the", "non", "-", "convex", "equality", "constraints", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Because", "routes", "are", "created", "instantaneously", "and", "incrementally", "by", "each", "agent", ",", "by", "identifying", "local", "D2DR", "and", "D2DMHR", "using", "proximity", "services", ",", "the", "complexity", "is", "based", "on", "the", "actual", "number", "of", "D2DR", "and", "D2DMHR", "that", "the", "agent", "in", "each", "device", "must", "communicate", "with", ",", "whenever", "it", "is", "needed", "(", "e.g.", "in", "order", "to", "become", "D2DR", "by", "connecting", "to", "an", "existing", "D2DMHR", "UE", "in", "our", "algorithm", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["It", "can", "be", "suppressed", "without", "loss", "in", "the", "original", "signal", ",", "by", "a", "high", "-", "pass", "digital", "filter", "or", "by", "the", "use", "of", "a", "standard", "Wavelet", "Transform", "(", "WT", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "wavelet transform"}, {"tokens": ["As", "mentioned", "earlier", ",", "SAD", "is", "used", "to", "evaluate", "the", "quality", "of", "estimated", "endmember", "with", "ground", "truth", "by", "measuring", "angle", "distance", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["A", "computation", "-", "cost", "analysis", "shows", "that", "utilizing", "an", "ISP", "improves", "system", "efficiency", "compared", "to", "a", "baseline", "with", "no", "image", "processing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Combining", "Instance", "-", "Based", "Learning", "and", "LRThe", "LR", "model", "specifies", "the", "probability", "of", "binary", "output", "given", "the", "input", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["In", "Section", ",", "we", "propose", "the", "BN", "-", "SV", "-", "MR", "based", "SA", "that", "can", "provide", "the", "comprehensive", "study", "on", "how", "the", "MR", "over", "each", "part", "of", "the", "end", "-", "to", "-", "end", "production", "process", "impacts", "on", "the", "risk", "analysis", "and", "the", "CPPs", "/", "CQAs", "criticality", "assessment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "model risk"}, {"tokens": ["shows", "the", "performance", "of", "MP", "based", "hypothesis", "testing", "algorithm", "when", "the", "two", "types", "of", "random", "variables", "have", "different", "variances", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "message passing"}, {"tokens": ["Using", "EO", "data", ",", "the", "area", "of", "each", "crop", "can", "be", "estimated", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "earth observation"}, {"tokens": ["Therefore", ",", "with", "its", "automatically", "hierarchical", "feature", "learning", "ability", ",", "DBN", "is", "chosen", "as", "the", "base", "classifier", "for", "this", "real", "-", "world", "application", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["based", "speaker", "diarization", "system", "consists", "of", "2", "passes", "of", "the", "IB", "diarization", "as", "given", "below", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["RAID", "-", "X", "proposed", "in", "has", "a", "similarity", "to", "GRD", "as", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "group rotate declustering"}, {"tokens": ["These", "smart", "contracts", "are", "stored", "on", "block", "-", "chains", "and", "BC", "is", "an", "ideal", "technology", "to", "store", "these", "contracts", "because", "of", "its", "immutability", "and", "security", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["The", "exception", "to", "this", "rule", "are", "the", "meta", "models", "with", "the", "SVM", "relevator", "(", "depicted", "in", "the", "top", "left", "graph", "of", "the", "Figure", ")", "that", "fail", "to", "outperform", "the", "baseline", "DE", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Our", "benchmark", "results", "will", "guide", "future", "adoption", "of", "these", "cryptosystems", "in", "the", "selection", "of", "adequate", "SMCs", "for", "FL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "federated learning"}, {"tokens": ["Providing", "a", "consistent", "and", "easy", "to", "reference", "identifier", "such", "as", "FEC", "or", "EIN", "for", "each", "sponsor", "enables", "us", "to", "better", "study", "sponsors", "in", "Google", "and", "Twitter", "'s", "archive", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federal election candidate"}, {"tokens": ["Furthermore", ",", "increasing", "the", "number", "of", "relay", "station", "antennas", ",", "RS", "appears", "to", "be", "more", "efficacious", "due", "to", "imperfect", "CSIT", ",", "since", "SI", "decreases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["Each", "SP", "within", "an", "SM", "shares", "an", "instruction", "unit", ",", "dedicated", "to", "the", "management", "of", "the", "instruction", "flow", "of", "the", "threads", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "streaming processors"}, {"tokens": ["In", "order", "for", "computational", "AA", "to", "propose", "an", "alternative", "to", "costly", "and", "demanding", "manual", "author", "indexing", "methods", "and", "possibly", "challenge", "previous", "identifications", "of", "authorship", ",", "effective", "open", "-", "set", "classification", "strategies", "are", "required", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["Classification", "error", "rates", "over", "ANN", "-", "evaluations", "on", "the", "Two", "-", "Spirals", "dataset", "using", "the", "DE", "-", "variants", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["For", "the", "regression", "model", ",", "we", "consider", "a", "Gaussian", "likelihood", "distribution", "with", "a", "fixed", "noise", "parameter", "and", "a", "Matern", "kernel", "function", "for", "the", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["To", "test", "efficiency", "and", "scalability", "of", "our", "MapReduce", "based", "parallel", "partitioning", "approach", ",", "we", "modified", "and", "tested", "selected", "set", "of", "four", "partitioning", "algorithms", ",", "namely", "BSP", ",", "SLC", ",", "BOS", "and", "STR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["Independent", "Rician", "fading", "channel", "coefficients", "of", "BS", "-", "to", "-", "CCU", "(", "Link", "1", ")", ",", "BS", "-", "to", "-", "CEU", "(", "Link", "2", ")", ",", "and", "CCU", "-", "to", "-", "CEU", "(", "Link", "4", ")", "are", "denoted", "as", ",", ",", "and", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["runPSO(s", ",", "MyFunction", ")", ";", "DestroySearchSpace(&s", ",", "_", "PSO", "_", ")", ";", "return", "0;As", "one", "can", "observe", ",", "it", "is", "quite", "simple", "to", "execute", "PSO", ",", "since", "we", "need", "to", "call", "five", "main", "functions", "only", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["A", "performance", "reporting", "script", "accesses", "the", "FA", "tool", "'s", "database", "and", "lists", "all", "the", "questions", "in", "a", "particular", "set", "with", "the", "strict", "and", "lenient", "redundancy", "for", "selected", "engines", "and", "configurations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["All", "figures", "are", "plotted", "for", "the", "parameters", ",", "and", "due", "to", "Rician", "fading", "channel", "[", "25,27].EE", "w.r.t", "transmit", "SNR", "is", "demonstrated", "in", "Figure", "8", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "[", "22].", "Parameters", ",", ",", ",", ",", ",", ",", "and", "are", "set", "during", "the", "simulation", "purpose", "as", "before", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["When", "viewed", "on", "the", "SDD", ",", "scaling", "the", "image", "to", "full", "screen", "reduced", "readability", "to", "words", "in", "100pt", "font", "or", "greater", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["RA", "Architecture", "."], "acronym_pos": [1, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["The", "architecture", "of", "the", "PNN", "model", "is", "illustrated", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["We", "measure", "the", "quality", "of", "a", "model", "by", "its", "overall", "ROC", ":", "thus", ",", "wewould", "like", "to", "compare", "their", "un", "-", "altered", "ROC", "curves", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "IB", "approach", "is", "in", "part", "representative", "of", "MBA", "as", "well", ",", "though", "MBA", "explicitly", "states", "that", "it", "is", "not", "compatible", "with", "neural", "network", "dynamics", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imaginary batches"}, {"tokens": ["CONCLUSIONSWe", "presented", "two", "machine", "learning", "approaches", "to", "model", "a", "medical", "eMNS", ",", "namely", "using", "RF", "and", "ANN", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "interference", "from", "cellular", "users", "to", "the", "typical", "BS", "in", "-th", "band", "is", "shown", "byAlso", ",", "the", "interference", "from", "D2D", "users", "to", "the", "typical", "BS", "in", "-th", "band", "is", "shown", "bySimilar", "to", "other", "studies", ",", "i.e.", ",", ",", ",", "in", "the", "rest", "of", "this", "study", ",", "the", "performance", "of", "the", "system", "is", "studied", "under", "the", "interference", "-", "limited", "regime", ",", "where", "the", "interference", ",", "which", "is", "introduced", "by", "spectrum", "sharing", "between", "large", "number", "of", "users", ",", "is", "dominating", "the", "noise", "power", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["First", ",", "the", "LSTMs", "'", "performance", "was", "generally", "worse", "in", "the", "SP", "experiments", "than", "in", "the", "SL", "ones", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["This", "proposed", "scheme", "can", "enhance", "the", "capacity", "of", "the", "CNOMA", "with", "PS", "SWIPT", "protocol", "without", "any", "interference", "and", "this", "scheme", "does", "not", "any", "required", "additional", "resources", "(", "e.g.", "time", "slot", "or", "frequency", "band", ")", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Note", "that", ",", "the", "average", "delay", "remains", "at", "a", "relatively", "low", "level", "when", "the", "system", "is", "in", "the", "non", "-", "saturated", "condition", ",", "for", "example", ",", "the", "average", "delay", "of", "STAs", "when", "and", "the", "average", "delay", "of", "the", "AP", "when", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "stochastic", "block", "model", "(", "SBM", ")", "is", "by", "far", "the", "most", "used", "generative", "model", "of", "graphs", "with", "communities", "(", "see", "Section", "and", "references", "therein", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["We", "use", "TensorFlow", "'s", "implementation", "of", "stochastic", "gradient", "descent", "with", "cross", "-", "entropy", "loss", "function", "to", "train", "/", "fine", "-", "tune", "the", "ANN", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "mode", "is", "inband", "D2D.", "Access", "BS", "by", "WiFi", "(", "if", "distance", "is", "short", ")", "so", "the", "D2D", "Relay", "is", "connected", "to", "a", "BS", "and", "shares", "WiFi", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "iPad", "featured", "an", "assisted", "GPS", ",", "accelerometers", ",", "magnetometers", ",", "advanced", "graphics", "chipset", "(", "PowerVR", "SGX535", ")", ",", "enabling", "the", "possibilities", "to", "create", "efficient", "AR", "application", "on", "tablet", "computer", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["We", "proposed", "an", "algorithm", "that", "can", "adjust", "the", "duty", "cycle", "of", "LTE", "-", "U", "based", "on", "the", "presence", "of", "Wi", "-", "Fi", "APs", "inferred", "by", "the", "detected", "energy", "in", "the", "medium", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "above", "example", "is", "a", "simulation", "from", "a", "simple", "SBM", ",", "in", "which", "there", "are", "two", "essential", "components", ",", "both", "of", "which", "will", "be", "explained", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["The", "smart", "meters", "were", "simulated", "from", "regular", "processes", "that", "would", "connect", "to", "the", "MDC", "component", "(", "see", "Section", "sec", ":", "components", "for", "details", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "metering data collector"}, {"tokens": ["Color", "and", "TIR", "cameras", ",", "GPS", ",", "IMU", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["The", "individual", "target", "objects", "were", "presented", "on", "a", "40", "inch", "LCD", "TV", "immediately", "adjacent", "to", "the", "TDW", ",", "as", "well", "as", "on", "a", "laptop", "sitting", "adjacent", "to", "the", "SDD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "standard desktop display"}, {"tokens": ["And", "the", "class", "probabilities", "of", "a", "sample", ",", "symbolized", "by", ",", "is", "calculated", "by", "the", "softmax", "function", ":", "where", "is", "the", "number", "of", "classes", "and", "represents", "the", "DCNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["V.", "Sathya", ",", "M.", "Mehrnoush", ",", "M.", "Ghosh", ",", "and", "S.", "Roy", ",", "\"", "Analysis", "of", "CSAT", "performance", "in", "Wi", "-", "Fi", "and", "LTE", "-", "U", "coexistence", "\"", ",", "in", "IEEE", "ICC", "Workshops", ",", "pp", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["To", "the", "best", "of", "our", "knowledge", ",", "we", "are", "the", "first", "to", "understand", "the", "impact", "of", "the", "ISP", "on", "training", "CNNs", "for", "ImageNet", "-", "size", "problems", ",", "using", "both", "compact", "MobileNet", "models", "and", "deep", "ResNet", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["In", "table", ",", "we", "show", "the", "slope", "of", "CC", "between", "Indian", "-", "Indians", "(", "I", "-", "I", ")", ",", "Indian", "-", "Foreign", "(", "I", "-", "F", ")", ",", "Indian", "with", "all", "(", "I", "-", "IF", ")", ",", "for", "different", "journals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaboration coefficient"}, {"tokens": ["It", "is", "not", "easy", "for", "CF", "techniques", "to", "recommend", "items", "with", "few", "ratings", "or", "to", "give", "recommendations", "to", "the", "users", "with", "few", "ratings", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Results", "and", "Data", "AnalysisThe", "ROM", "and", "physical", "parameters", ",", "such", "as", "joint", "positions", ",", "orientations", "and", "relative", "angles", "were", "captured", "by", "the", "Kinect", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "range of motion"}, {"tokens": ["In", "Figure", "we", "show", "our", "results", "for", "two", "particularizations", "of", "the", "convex", "IB", "Lagrangians", ":", "the", "power", "IB", "Lagrangians(Note", "when", "we", "have", "the", "squared", "IB", "functional", "from", ".", ")", ":", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Results", "for", "both", "astronomers", "and", "non", "-", "astronomers", "indicate", "that", "the", "SDD", "is", "generally", "perceived", "as", "difficult", "for", "this", "kind", "of", "search", "while", "the", "TDW", "is", "generally", "perceived", "as", "easy", "to", "use", "for", "the", "same", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["By", "applying", "knowledge", "the", "geometry", "of", "the", "system", "(", "the", "location", "of", "clusters", "and", "the", "users", ")", ",", "we", "suppose", "that", "the", "BS", "does", "not", "need", "to", "estimate", "the", "channels", "of", "all", "users", "and", "selects", "users", "based", "only", "on", "the", "location", "of", "users", "and", "clusters", "in", "the", "area", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["proposed", "a", "regularised", "SBM", "which", "extends", "the", "DC", "-", "SBM", "to", "control", "the", "desired", "level", "of", "assortativeness", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Distribution", "of", "social", "(", "above", "line", ")", "and", "spatial", "(", "bottom", "line", ")", "metrics", "for", "the", "CNS", "and", "MDC", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["Finally", ",", "a", "bivariate", "histogram", "based", "feature", "vector", "is", "computed", "from", "the", "marginal", "probability", "functions", "and", "independency", "distributions", "of", "the", "normalized", "GM", "and", "LoG", "maps", ",", "resulting", "to", "a", "fixed", "-", "size", "feature", "representation", "vector", "of", "40", "dimensions", "for", "an", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient magnitude"}, {"tokens": ["The", "population", "size", "used", "in", "DE", "and", "CMA", "-", "ES", "depends", "on", "the", "problem", "and", "the", "choice", "of", "the", "optimization", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["In", "Stage", "2", ",", "PIN", "ranks", "the", "proposals", "and", "chooses", "a", "subset", "for", "which", "complex", "analysis", "is", "performed", "in", "later", "stages", "by", "IRN", "and", "PRN", "subnetworks", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["We", "review", "the", "relevant", "background", "in", "the", "main", "contribution", "areas", "of", "this", "work", ":", "SAR", "for", "learning", "(", "Section", ")", "and", "SAR", "for", "personalization", "(", "Section", ")", ",", "both", "with", "a", "particular", "emphasis", "on", "the", "ASD", "context", ",", "given", "particular", "challenges", "and", "opportunities", "for", "SAR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "socially assistive robots"}, {"tokens": ["eMBMS", "introduces", "PTM", "support", "with", "small", "changes", "on", "the", "existing", "radio", "and", "core", "network", "infrastructures", "and", "protocols", "of", "LTE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "long term evolution"}, {"tokens": ["Generalized", "second", "price", "(", "GSP", ")", "auction", "is", "a", "family", "of", "auction", "mechanisms", "that", "has", "been", "popularly", "used", "by", "today", "'s", "search", "engines", ",", "which", "ranks", "ads", "according", "to", "the", "products", "of", "their", "bid", "prices", "and", "quality", "scores", ";", "and", "charges", "a", "clicked", "ad", "by", "the", "minimum", "bid", "price", "to", "maintain", "its", "current", "rank", "position", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized second price"}, {"tokens": ["However", ",", "the", "gain", "of", "a", "perfect", "classifier", "is", "primarily", "governed", "by", "the", "size", "of", "the", "reduced", "OPF", "problem", "compared", "to", "the", "full", "problem", "and", "it", "roughly", "depends", "on", "the", "ratio", "of", "the", "number", "of", "inequality", "constraints", "and", "number", "of", "all", "constraints", "of", "the", "full", "OPF", "formulation", "(", "assuming", "that", "only", "a", "fraction", "of", "inequality", "constraints", "are", "actually", "active", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["We", "are", "particularly", "interested", "in", "understanding", "how", "well", "LSTMS", "can", "learn", "SP", "languages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["In", "the", "Alcedo", "project", ",", "a", "prototype", "was", "developed", "using", "a", "lightweight", "quadrotor", "UAV", "equipped", "with", "GPS", "to", "help", "in", "finding", "lost", "persons", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["In", "the", "SAR", "context", ",", "the", "speaker", "is", "the", "robot", ",", "the", "hearer", "is", "the", "human", "user", ",", "and", "the", "direction", "of", "fit", "is", "either", "action", "-", "to", "-", "state", ",", "where", "the", "objective", "is", "to", "make", "the", "robot", "'s", "action", "match", "the", "state", "of", "the", "intervention", ",", "or", "state", "-", "to", "-", "action", ",", "where", "the", "objective", "is", "to", "make", "the", "state", "of", "the", "intervention", "match", "what", "is", "expressed", "through", "the", "robot", "'s", "action", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["One", "black", "-", "box", "approach", "is", "based", "on", "predicting", "the", "optimal", "OPF", "solution", "through", "regression", "techniques", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["SDD", "contains", "videos", "shot", "from", "a", "drone", ",", "where", "each", "frame", "is", "annotated", "with", "objects", "of", "six", "categories", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stanford drone dataset"}, {"tokens": ["The", "ANN", "model", "performed", "better", "than", "the", "RF", "model", "for", "all", "evaluation", "metrics", "in", "all", "scenarios", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["This", "is", "reflected", "in", "the", "results", "shown", "in", "Table", "as", "both", "algorithms", ",", "MP", "and", "CF", ",", "provide", "the", "worst", "results", "across", "all", "use", "cases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["We", "can", "define", "the", "relay", "selection", "criterion", "as", "This", "relay", "selection", "strategy", "is", "suitable", "for", "practical", "scenarios", ",", "wherein", "the", "far", "users", "are", "much", "farther", "away", "from", "the", "BS", "in", "comparison", "with", "near", "users", "and", "thus", "have", "the", "poor", "channel", "conditions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "total", ",", "the", "proposed", "scheme", "executes", "a", "total", "of", "5", "hash", "functions", "and", "6", "ECC", "-", "based", "multiplicative", "operations", ",", "against", "a", "total", "of", "5", "and", "(", "k+3", ")", "operations", "respectively", "by", "the", "existing", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["We", "take", "the", "posterior", "predictive", "distribution", "from", "GP", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Error", "probability", "of", "MP", "based", "hypothesis", "testing", "algorithm", "in", "log", "scale", "as", "the", "number", "of", "measurements", "is", "varied", "on", "various", "values", ",", "when", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "message passing"}, {"tokens": ["This", "is", "especially", "interesting", "since", "in", "deterministic", "scenarios", "we", "know", "the", "shape", "of", "the", "IB", "curve", "(", "Theorem", ")", "and", "since", "the", "convex", "IB", "Lagrangians", "allow", "for", "the", "exploration", "of", "the", "IB", "curve", "(", "Theorem", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["app4", "Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs", "where", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["Classification", "Performance", "Comparison", "Global", "FS", "-", "Figures", "and", "shows", "the", "and", "M", "comparison", "of", "LR", "models", "with", "-norm", "and", "-norm", "regularization", "combined", "with", "various", "feature", "selection", "methods", "discussed", "in", "Section", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["proposed", "a", "new", "algorithm", "based", "on", "greedy", "layer", "-", "wise", "training", "to", "overcome", "the", "\u201c", "diminishing", "gradient", "problem", "\u201d", "which", "leads", "to", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["The", "value", "of", "is", "inversely", "proportional", "to", "the", "highest", "BC", "of", "the", "network", "and", "BC", "of", "a", "node", "is", "proportional", "to", "its", "degree", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["They", "applied", "what", "they", "called", "belief", "propagation", "in", "their", "EM", "algorithm", ",", "in", "order", "to", "approximate", "from", ",", "which", "is", "derived", "for", "both", "DC", "-", "SBM", "and", "its", "original", "counterpart", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "informativeness", "of", "generated", "summaries", "improves", "when", "AR", "is", "used", "before", "summarization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "anaphora resolution"}, {"tokens": ["However", ",", "our", "proposed", "method", "limits", "the", "damage", "due", "to", "inaccurate", "label", "predictions", "with", "the", "help", "of", "the", "SC", "score", "which", "is", "based", "on", "the", "image", "features", "of", "each", "annotation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "self consistency"}, {"tokens": ["Notably", "that", "most", "related", "session", "-", "based", "works", "did", "n't", "compare", "with", "DNN", "and", "CNN", "models", "previously", "and", "they", "only", "choose", "more", "CF", "-", "based", "methods", "as", "baselines", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "syntax", "of", "STL", "is", "given", "by", ",", "where", "is", "an", "atomic", "proposition", ",", "conjunction", "and", "negation", "are", "the", "standard", "Booleanconnectives", ",", "is", "a", "real", "positive", "dense", "interval", "with", "and", "is", "the", "bounded", "until", "operator", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "signal temporal logic"}, {"tokens": ["Therefore", ",", "the", "expected", "loss", "is", "upper", "and", "lower", "bounded", "by", "In", "summary", ",", "the", "LS", "and", "LMMSE", "estimators", "are", "more", "suitable", "to", "linear", "systems", "due", "to", "their", "simplicity", "and", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["Since", "previously", "compiled", "TS", "corpora", "(", "PWKP", ",", "EW", "-", "SEW", ",", "and", "Newsela", ")", "contain", "only", "a", "small", "number", "of", "split", "examples", ",", "they", "are", "ill", "-", "suited", "for", "learning", "to", "decompose", "sentences", "into", "shorter", ",", "syntactically", "simplified", "components", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "target syntactic"}, {"tokens": ["A", "new", "tractable", "genetic", "algorithm", "based", "iterative", "algorithm", ",", "NN", "-", "RSSD", "algorithm", "is", "developed", "for", "sequentially", "solving", "the", "SCP", "central", "plant", "and", "the", "RSSD", "output", "feedback", "optimization", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["Now", "recall", "that", ",", "a", "restriction", "that", "comes", "from", "the", "KK13", "OT", "extension", "(", "due", "to", "the", "fact", "that", "contains", "codewords", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Additive", "GPs", "generalize", "both", "Generalized", "Additive", "Models", ",", "and", "the", "standard", "GP", "models", "which", "use", "squared", "-", "exponential", "kernels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "discussed", "several", "aspects", "of", "an", "EMS", ",", "such", "as", "information", "modeling", ",", "querying", "and", "analysis", ",", "and", "data", "ingestion", ",", "and", "also", "presented", "our", "work", "on", "location", "uncertainty", "reasoning", "and", "event", "disambiguation", "in", "more", "detail", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "event management system"}, {"tokens": ["b", ")", "Unlike", "CMI", ",", "limiting", "the", "ratio", "is", "coarse", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "conditional mutual information"}, {"tokens": ["Several", "models", "are", "proposed", "to", "capture", "even", "more", "general", "behavior", "than", "RUM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "random utility modelwe"}, {"tokens": ["So", ",", "the", "achievable", "capacity", "of", "and", "can", "be", "achieved", "as", "below", "for", "the", "OMA", "-", "OAM", "scheme", "[", "8,19", "-", "20]Furthermore", ",", "the", "achievable", "capacity", "of", "by", "OAM", "beam", "can", "be", "acquired", "as", "below", "for", "OMA", "-", "OAM", "scheme", "[", "16", "-", "20]So", ",", "the", "SC", "of", "OMA", "-", "OAM", "scheme", "can", "be", "achieved", "by", "the", "following", "equation", "[", "8,19", "-", "20]where", "E[.", "]", "represents", "the", "expectation", "operator", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["Satisfiability", "is", "thus", "reducible", "to", "the", "nonemptiness", "of", "PA", ",", "which", "is", "decidableSSM08", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "presburger arithmetic"}, {"tokens": ["PriorUsing", "the", "definition", "of", "GPs", "introduced", "at", "the", "beginning", "of", "this", "section", ",", "andknowing", "that", "we", "have", "a", "finite", "set", "of", "corrupted", "observations", ",", "then", "the", "finite", "set", "of", "GP", "function", "evaluation", "values", "follows", "a", "normal", "marginal", "distribution", "conditioned", "on", "the", "hyper", "-", "parameters", ",", "whose", "mean", "is", "zero", "and", "whose", "covariance", "is", "defined", "by", "a", "Gram", "matrix", ",", "this", "is", "aligne.prior_model1p(f", ")", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["For", "that", "reason", ",", "we", "aim", "to", "demonstrate", "that", "the", "continual", "GP", "approach", "is", "able", "to", "predict", "in", "an", "online", ")", "classification", "task", "similarly", "as", "the", "IHGP", "model", "does", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["only", "applies", "to", "the", "Con", "-", "TS", "-", "RTP", "algorithm", "with", "the", "daily", "optimization", "(", "line", ")", "subject", "to", "Constraint", "Set", "A."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["LTE", "has", "other", "examples", "where", "cross", "-", "layer", "reconfiguration", "improves", "user", "experience", "such", "as", "downlink", "and", "uplink", "packet", "scheduling", ",", "which", "relies", "on", "feedback", "for", "the", "UE", "about", "CSI", "to", "perform", "time", "-", "domain", "and", "frequency", "-", "domain", "scheduling", "(", "deciding", "the", "set", "of", "users", "that", "will", "transmit", "in", "a", "particular", "time", "slot", "and", "the", "RBs", "that", "will", "be", "assigned", "to", "each", "one", "of", "those", "users", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "this", "context", "it", "is", "therefore", "appropriate", "investigating", "how", "the", "use", "of", "NS", "could", "lead", "to", "an", "evolution", "of", "profiling", "practices", "grounded", "on", "the", "collection", "of", "habits", "and", "preferences", ",", "in", "the", "light", "the", "unprecedented", "capacity", "of", "online", "platforms", "to", "collect", "digital", "footprints", "left", "by", "individuals", "fuller2018privacy", ",", "acquisti2008identity", ",", "even", "considering", "constraints", "such", "as", "clustering", "limitation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "network science"}, {"tokens": ["The", "locations", "of", "the", "sparse", "GP", "could", "in", "principle", "be", "optimised", "as", "well", ",", "but", "we", "keep", "them", "fixed", "and", "position", "them", "on", "a", "regular", "grid", "over", "the", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Comparing", "to", "cellular", "networks", ",", "(", "1", ")", "WLANs", "consist", "of", "fewer", "STAs", ",", "(", "2", ")", "WLAN", "STAs", "are", "more", "stable", "in", "terms", "of", "moving", "speeds", "and", "residing", "environments", ",", "and", "(", "3", ")", "the", "AP", "is", "usually", "less", "powerful", "than", "the", "base", "station", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Many", "interesting", "questions", "remain", "open", "for", "future", "work", ":", "Can", "we", "detach", "the", "MR", "avatar", "from", "the", "actual", "robot", "so", "that", "even", "though", "the", "physical", "robot", "is", "abruptly", "changing", "position", ",", "the", "MR", "avatar", "starts", "turning", "in", "advance", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "mixed reality"}, {"tokens": ["The", "augmented", "reality", "user", "can", "distinguish", "the", "superimposed", "virtual", "objects", "and", "hence", "able", "to", "turn", "on", "or", "turn", "off", "selected", "AR", "functions", ",", "which", "may", "be", "related", "to", "certain", "objects", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Note", "that", "MQ", "denotes", "the", "main", "question", "and", "BQ", "denotes", "the", "basic", "question", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["Both", "the", "EC", "and", "CC", "are", "equipped", "with", "the", "DUs", "which", "have", "different", "maximum", "capacity", "of", "hosting", "CPs", "and", "UPs", "given", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Such", "procedure", "gives", "1", "AP", "improvement", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0], "long_form": "average precision"}, {"tokens": ["To", "solve", "problem", "sys0eq2", ",", "we", "adopt", "the", "FL", "algorithm", "of", ",", "which", "is", "summarized", "in", "Algorithm", "1", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["The", "ANN", "model", "showed", "better", "performance", "than", "the", "RF", "model", "across", "all", "current", "levels", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "idea", "consists", "in", "implementing", "a", "recurrent", "neural", "network", "as", "a", "multilingual", "sequence", "labeling", "tool", "(", "we", "investigate", "POS", "tagging", "and", "SST", "tagging", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Hence", ",", "using", "Remark", "1", ",", "after", "the", "offline", "localization", ",", "the", "BS", "can", "build", "up", "the", "matrix", "at", "the", "beginning", "of", "each", "time", "-", "slot", ",", "as", "the", "following", "where", "where", "and", "can", "be", "calculated", "by", "the", "distances", "obtained", "in", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Note", "that", "we", "use", "MA", "-", "DDPG", ",", "not", "MA", "-", "BDDPG", "in", "the", "IB", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "imaginary batches"}, {"tokens": ["Section", "presents", "the", "system", "model", ",", "and", "Section", "formulates", "the", "UE", "selection", "problem", "and", "NPC", "minimization", "problem", "along", "with", "the", "complexity", "analysis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "two", "techniques", ",", "WF", "and", "WPR", ",", "leverage", "the", "integration", "with", "three", "state", "-", "of", "-", "the", "-", "art", "deep", "frameworks", ":", "the", "light", "-", "weight", "residual", "learning", "-", "based", "CNN", "model", "in", "(", "our", "baseline", ")", "for", "frame", "-", "level", "feature", "extraction", ";", "the", "key", "-", "points", "detector", "for", "detecting", "the", "human", "joints", ",", "also", "used", "in", ";", "the", "deformable", "GAN", "model", "in", "for", "its", "ability", "to", "learn", "the", "global", "human", "body", "transformations", "across", "cameras", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "weighted fusion"}, {"tokens": ["The", "Locally", "Threshold", "Testable", "(", "LTT", ")", "class", "was", "introduced", "and", "studied", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "locally threshold testable"}, {"tokens": ["Whereas", ",", "in", "reality", ",", "an", "open", "-", "domain", "QA", "system", "is", "required", "to", "pinpoint", "answers", "from", "a", "massive", "article", "collection", ",", "such", "as", "Wikipedia", "or", "the", "entire", "web", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["We", "use", "-dimensional", "fused", "i", "-", "vectors", "for", "LA", "and", "for", "PA", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "physical access"}, {"tokens": ["SRL", "loss", "is", "computed", "by", "joint", "log", "-", "likelihood", "of", "emissions", "with", "transition", "parameters", "in", "CRF", "from", "Equation", "and", "entity", "loss", "is", "computed", "using", "standard", "cross", "-", "entropy", "loss", "from", "softmax", "output", "in", "Equation", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["Once", "the", "set", "of", "active", "users", "has", "been", "determined", ",", "the", "receiver", "BS", "estimates", "the", "channels", "of", "the", "selected", "users", "and", "the", "users", "transmit", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["When", "the", "number", "of", "clusters", "is", "less", "than", "the", "number", "of", "BS", "antennas", "and", "all", "clusters", "are", "shared", "between", "the", "users", ",", "it", "is", "impossible", "to", "achieve", "the", "maximum", "multiplexing", "gain", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "RT", "and", "BT", "protocols", "can", "find", "near", "-", "optimal", "solutions", ",", "while", "the", "RB", "protocol", "finds", "a", "solution", "with", "gain", ",", "which", "is", "far", "from", "the", "optimum", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random target"}, {"tokens": ["On", "the", "training", "and", "test", "set", ",", "DE", "and", "DE", "-", "INV", "-", "SB", "mean", "results", "are", "not", "statistical", "significantly", "different", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["fig", ":", "settyfigure*figuretabularcccF", "-", "score", "&", "Domain", "1", "&", "Domain", "2", "MGM", "GAN", "&", "0.98", "&", "0.99", "GAN", "&", "0.27", "&", "0.47", "Cycle", "GAN", "&", "0.44", "&", "0.46", "Random", "weights", "&", "0.45", "&", "0.50", "tabularThe", "F", "-", "scores", "for", "all", "of", "the", "models", "on", "MNIST", "show", "that", "the", "MGM", "GAN", "is", "the", "only", "model", "that", "can", "preserve", "similarities", "between", "datasets", "while", "being", "robust", "to", "changes", "in", "density", "along", "the", "manifold", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["PNN", "Context", "Encoderpnn", "-", "context", "-", "encoderThe", "foundational", "element", "of", "the", "ARNN", "is", "the", "PNN", "context", "encoder", "that", "models", "user", "-", "contextual", "preference", "by", "capturing", "high", "-", "order", "interactions", "between", "user", "contexts", "and", "previous", "items", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Similarly", ",", "Proposition", "states", "that", "the", "IB", "curve", "follows", "the", "equation", "if", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Convergence", "curves", "for", "regression", "by", "DE", "(", "left", ")", "and", "CMA", "-", "ES", "(", "right", ")", "using", "the", "syn5", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["This", "GMM", "has", "mixture", "components", ",", "with", "each", "corresponding", "to", "an", "unseen", "class", "and", "is", "initialized", "by", "the", "estimated", "parameters", "of", "unseen", "classes", "in", "the", "inductive", "setting", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Existing", "patient", "with", "prior", "interactions", "with", "primary", "care", "doctors", "For", "existing", "patients", "that", "have", "previously", "visited", "family", "doctors", ",", "we", "can", "leverage", "interaction", "data", "and", "simply", "perform", "CF", "to", "find", "doctors", "also", "visited", "by", "the", "patients", "who", "visit", "the", "same", "doctor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["A", "significant", "body", "of", "SAR", "research", "has", "focused", "on", "user", "learning", ",", "with", "a", "specific", "focus", "on", "developing", "personalized", "robot", "tutors", "for", "young", "children", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Interestingly", "the", "CM", "of", "the", "RF", "model", "is", "essentially", "the", "same", "as", "that", "of", "the", "ANN", "model", ",", "with", "two", "additional", "cases", "correctly", "predicted", "relative", "to", "the", "RF", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "confusion matrix"}, {"tokens": ["Mixed", "Decoding", "(", "MD", ")"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "mixed decoding"}, {"tokens": ["From", "this", "figure", ",", "the", "FL", "procedure", "contains", "three", "steps", "at", "each", "iteration", ":", "Local", "computation", "at", "each", "user", "(", "using", "several", "local", "iterations", ")", ",", "local", "FL", "parameter", "transmission", "for", "each", "user", ",", "and", "result", "aggregation", "and", "broadcast", "at", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["To", "reduce", "the", "leakage", "of", "the", "confidential", "messages", "power", "for", "desired", "user", "to", "eavesdropper", ",", "a", "leakage", "-", "based", "TAS", "method", "is", "proposed", "for", "secure", "SM", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["When", "the", "goal", "is", "to", "generate", "a", "large", "number", "of", "OTs", "which", "is", "usually", "the", "case", "for", "the", "applications", "of", "OT", ",", "the", "amortized", "cost", "of", "generating", "a", "single", "OT", "via", "OT", "extensions", "turns", "out", "to", "be", "a", "constant", "number", "of", "symmetric", "-", "key", "operations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["dB", "over", "IID", "Nakagami-", "fading", "channels", "with", "different", "values", "of", ":", "(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["In", "Figure", "6", ",", "the", "SC", "w.r.t", "is", "plotted", "for", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["For", "MS", "COCO", ",", "similar", "phenomenon", "of", "AR", "is", "also", "observedvia", "Table", "tab", ":", "grand_coco", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average recall"}, {"tokens": ["The", "Independent", "component", "analysis", "(", "ICA", ")", "will", "capture", "more", "variations", "in", "the", "images", "than", "the", "current", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["We", "note", "that", "a", "few", "recent", "works", "proposed", "similar", "algorithms", "extending", "MPs", "to", "general", "smooth", "objective", "functions", ",", "although", "with", "less", "general", "convergencerates", "and", "without", "studying", "the", "algorithms", "in", "the", "larger", "context", "of", "MP", "and", "FW", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["This", "work", "is", "later", "extended", "in", "and", "to", "use", "a", "full", "-", "duplex", "HAP", "to", "transmit", "energy", "and", "receive", "user", "data", "simultaneously", ",", "where", "the", "key", "challenge", "is", "to", "overcome", "the", "self", "-", "interference", "caused", "by", "the", "full", "-", "duplex", "operation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "hybrid access point"}, {"tokens": ["The", "Random", "Utility", "ModelWe", "first", "investigate", "the", "performance", "of", "random", "forests", "when", "the", "training", "data", "is", "generated", "by", "RUM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "random utility modelwe"}, {"tokens": ["For", "with", "arbitrary", "values", "for", "'s", "and", "following", "a", "similar", "analysis", "as", "for", "the", "derivation", "of", "Eq", ":", "CDF_gEND_MRD_Distinct_C", ",", "a", "closed", "-", "form", "expression", "for", "can", "be", "obtained", "asRepetitive", "with", "SDAlternatively", "to", "MRD", ",", "may", "use", "a", "time", "-", "diversity", "version", "of", "SD", "to", "combine", "the", "signals", "from", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal ratio diversity"}, {"tokens": ["As", "evident", "from", "Table", ",", "there", "is", "a", "substantial", "drop", "in", "accuracy", "compared", "to", "training", "and", "testing", "on", "IFD", "(", "see", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "icelandic frequency dictionary"}, {"tokens": ["/", "s", "on", "Tesla", "K40c", "(", "ECC", "off", ")", ",", "and", "18.93"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["Stacked", "bars", "differentiate", "types", "of", "navigation", ":", "details", "(", "DE", ",", "blue", ")", ",", "direct", "click", "(", "DC", ",", "orange", ")", ",", "direct", "URL", "(", "DU", ",", "green", ")", ",", "expand", "(", "EX", ",", "red", ")", ",", "external", "link", "(", "EL", ",", "purple", ")", ",", "external", "search", "(", "ES", ",", "brown", ")", "and", "local", "search", "(", "LS", ",", "pink", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "local search"}, {"tokens": ["Deep", "Belief", "Network", "(", "DBN", ")", "is", "a", "machine", "learning", "technique", "that", "is", "effective", "in", "classification", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["We", "train", "binary", "one", "-", "versus", "-", "rest", "regularized", "LR", "classifiers", "for", "each", "of", "the", "leaf", "categories", ",", "ignoring", "the", "hierarchical", "structure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["The", "best", "results", "are", "obtained", "with", "combination", "of", "simple", "projection", "and", "RNN", "which", "confirms", "(", "as", "for", "POS", "tagging", ")", "that", "both", "approaches", "are", "complementary", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["On", "the", "right", ",", "we", "see", "how", "the", "SBM", "finds", "only", "the", "roles", "if", "the", "number", "of", "clusters", "is", "fixed", "at", "in", "advance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "nodes", "with", "maximum", "BC", "values", "are", "the", "most", "congested", "nodes", "in", "the", "network", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["The", "Medusa", "GPU", "graph", "-", "processing", "framework", "also", "implements", "a", "BSP", "model", "and", "allows", "computation", "on", "both", "edges", "and", "vertices", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bulk synchronous parallel"}, {"tokens": ["Again", ",", "there", "is", "some", "agreement", "of", "our", "Gravel", "hotspots", "with", "the", "open", "-", "cell", "MCC", "regions", "highlighted", "by", "but", "as", "with", "Flowers", "their", "algorithm", "picks", "up", "many", "more", "open", "cells", "in", "higher", "latitudes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mesoscale cellular convection"}, {"tokens": ["In", "its", "classical", "form", ",", "the", "IB", "principle", "is", "defined", "only", "for", "discrete", "random", "variables", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Fourth", ",", "we", "introduce", "the", "multiple", "description", "structural", "similarity", "distance", "loss", ",", "which", "implicitly", "regularizes", "the", "diversified", "multiple", "description", "generations", ",", "to", "explicitly", "supervise", "multiple", "description", "diversified", "decoding", "in", "addition", "to", "MD", "reconstruction", "loss", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["We", "empirically", "studied", "this", "conjecture", "by", "artificially", "injecting", "noise", "in", "the", "training", "sets", "of", "WikiQA", "and", "TREC", "-", "QA", ",", "by", "randomly", "sampling", "questions", "-", "answer", "pairs", "from", "the", "training", "set", "and", "switching", "their", "label", "values", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "different", "sizes", "of", "red", "arrows", "indicate", "SIB", "attaches", "different", "compression", "to", "each", "channel", "according", "to", "their", "significance", ",", "while", "the", "standard", "IB", "compress", "each", "channel", "equally", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["that", "more", "favorable", "fading", "conditions", "and", "larger", "increase", "the", "decoding", "probability", ",", "thus", "both", "repetitive", "transmission", "schemes", "become", "unavailing", "for", "larger", ",", "whereas", "the", "gains", "from", "RS", "increase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Although", "RS", "requires", "only", "two", "time", "slots", "for", "transmission", "(", "the", "repetitive", "scheme", "needs", "as", "many", "time", "slots", "as", "the", "number", "of", "decoding", "relays", ")"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["We", "report", "this", "performance", "in", "Figure", ",", "where", "it", "can", "be", "seen", "that", "the", "GAT", "surrogate", "outperforms", "LS", "on", "7", "out", "of", "9", "datasets", ",", "although", "admittedly", "the", "difference", "is", "small", "and", "only", "statistically", "significant", "on", "3", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "least squares"}, {"tokens": ["The", "fine", "-", "tuning", "of", "ANN", "is", "essential", "for", "the", "current", "recording", "as", "we", "are", "interested", "in", "discriminating", "the", "speakers", "in", "that", "recording", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Moreover", ",", "legacy", "MC", "is", "found", "to", "result", "in", "lower", "latency", "compared", "to", "the", "proposed", "algorithm", ",", "since", "the", "proposed", "algorithm", "prioritizes", "resource", "efficiency", "by", "operating", "users", "which", "can", "accommodate", "additional", "retransmissions", "in", "SC", "mode", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "single connectivity"}, {"tokens": ["Given", "such", "values", "of", "and", ",", "the", "gains", "assure", "the", "robust", ",", "finite", "-", "time", "stability", "of", "the", "origin", "of", "the", "STA", "STA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["Here", "again", ",", "it", "took", "roughly", "one", "minute", "to", "produce", "the", "CSG", "scores", "(", "after", "having", "trained", "the", "embedding", ")", "and", "4", "days", "for", "the", "CNN", "error", "rates", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["@X", "rrrrr@", "&", "N", "&", "&", "&", "&", "CNS", "&", "850", "&", "16", "s", "&", "24", "months", "&", "10", "m", "&", "0.84", "MDC", "&", "185", "&", "60", "s", "&", "19", "months", "&", "100", "-", "200", "m", "&", "0.73", "Characteristics", "of", "the", "mobility", "datasets", "considered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["To", "our", "knowledge", ",", "the", "gain", "design", "problem", "for", "OCC", "has", "not", "been", "completely", "convexified", "in", "the", "way", "we", "have", "done", "in", "this", "paper", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "output constrained covariance"}, {"tokens": ["For", "this", "reason", ",", "new", "approaches", "tailored", "to", "FL", "have", "been", "proposed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Finally", ",", "we", "present", "a", "system", "-", "level", "analysis", "of", "the", "cost", "trade", "-", "offs", "of", "different", "ISP", "configurations", ",", "and", "find", "that", "all", "considered", "use", "cases", "benefit", "from", "an", "ISP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "image signal processor"}, {"tokens": ["A", "discretized", "version", "of", "the", "OT", "divergence", "is", "employed", "as", "an", "additional", "regularization", "to", "the", "loss", ":", "where", "the", "non", "-", "positive", "serves", "as", "a", "proxy", "for", "the", "coupling", "and", "satisfies", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Furthermore", ",", "the", "total", "SBS", "power", "consumption", "of", "the", "entire", "fractal", "small", "-", "cell", "network", "is", "given", "asSince", "the", "network", "energy", "efficiency", "is", "defined", "as", "a", "ratio", "of", "the", "average", "rate", "to", "the", "total", "SBS", "power", "consumption", ",", "it", "can", "be", "calculated", "asSimulation", "Results", "and", "DiscussionIn", "this", "section", ",", "simulation", "results", "on", "the", "average", "achievable", "rate", "and", "network", "energy", "efficiency", "of", "the", "fractal", "small", "-", "cell", "networks", "are", "analyzed", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["In", "the", "downlink", "multiuser", "scenario", ",", "we", "set", "the", "number", "of", "the", "antennas", "at", "the", "BS", "as", "and", "each", "user", "is", "equipped", "with", "antennas", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "the", "PTB", "(", "English", ")", "CoordNPs", "are", "flat", "structures", "bearing", "an", "'", "NP", "'", "label", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "noun phrase"}, {"tokens": ["OP_FSDF_Equalm", "over", "INID", "and", "IID", "Nakagami-", "fading", "channels", ",", "respectively", ",", "with", "integer", "fading", "parameters", ",", "the", "end", "-", "to", "-", "end", "OP", "of", "pure", "RS", "is", "easily", "obtained", "asFor", "rate", "-", "selective", "RS", ",", "a", "closed", "-", "form", "expression", "for", "over", "INID", "Nakagami-", "fading", "with", "arbitrary", "'s", "can", "be", "easily", "obtained", "by", "substituting", "Eq", ":", "Gamma_CDF", "and", "Eq", ":", "CDF_gbest_SD_Distinct_C", "to", ",", "yieldingASEP", ":", "Following", "the", "MGF", "-", "based", "approach", "and", "using", "the", "expressions", "for", "pure", "RS", "given", "by", "Eq", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["On", "dynamic", "modeling", "of", "PCM", "-", "controlled", "converters", "-", "buck", "converter", "as", "an", "example", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "peak current mode"}, {"tokens": ["Therefore", ",", "SAR", "intervention", "efficacy", "must", "be", "analyzed", "in", "real", "-", "world", "learning", "settings", ",", "involving", "user", "learning", "in", "various", "spatial", "and", "social", "contexts", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["itemizeGenerally", ",", "QA", "systems", "allow", "the", "users", "to", "search", "for", "information", "using", "a", "natural", "language", "interface", ",", "and", "return", "short", "answers", "to", "the", "users", "'", "questionVoorhees2006", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Instead", ",", "we", "examine", "the", "impact", "of", "attacks", "on", "the", "dimension", "of", "user", "classes", "by", "looking", "into", "the", "aggregate", "mean", "values", "computed", "across", "CF", "models", "on", "the", "two", "datasets", "we", "adopted", "in", "our", "experimental", "evaluation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Fetching", "the", "content", "from", "the", "CC", "experiences", "more", "delay", "than", "other", "cases", "due", "to", "the", "higher", "distance", "between", "the", "CC", "and", "the", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Consequently", ",", "in", "lower", "layers", "the", "transitive", "transferring", "via", "multi", "-", "source", "makes", "an", "effort", "of", "generalizing", "the", "features", "to", "OpenSAR", "to", "improve", "the", "performance", "of", "SAR", "target", "recognition", "task", "while", "in", "high", "-", "level", "layer", "the", "discrepancy", "dominates", "the", "transferability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Many", "SAR", "and", "HRI", "studies", "have", "found", "a", "robot", "'s", "embodiment", "to", "augment", "learning", "in", "a", "variety", "of", "settings", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["While", "the", "RNNs", "performed", "above", "chance", "in", "all", "of", "our", "experiments", ",", "they", "struggled", "learning", "the", "two", "most", "complex", "SP", "languages", "as", "compared", "to", "the", "matched", "SL", "languages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Moreover", ",", "having", "a", "MIMO", "relaying", "in", "the", "scene", ",", "we", "test", "RS", "in", "the", "basic", "scenario", "of", "just", "HD", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["The", "sliding", "variable", "is", "a", "polynomial", "composition", "of", ",", "which", "is", "a", "very", "common", "design", "for", "a", "higher", "order", "system", "like", "example", "controlled", "by", "a", "relatively", "lower", "sliding", "mode", "control", "such", "as", "STA", "STA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["(", "WF)The", "WF", "scheme", "(", "Figure", ")", "is", "based", "on", "aggregating", "(", "by", "average", "pooling", ")", "the", "frame", "-", "level", "features", "of", "a", "real", "sequence", "separately", "from", "the", "frame", "-", "level", "features", "of", "the", "corresponding", "generated", "sequence", "of", "canonical", "poses", ",", "in", "order", "to", "exploit", "the", "complementarity", "of", "their", "contributions", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "weighted fusion"}, {"tokens": ["Second", ",", "for", "all", "feasible", "parameters", ",", "we", "present", "an", "encoding", "matrix", "for", "systematic", "Exact", "-", "MBR", "codes", "via", "the", "partially", "systematic", "Reed", "-", "Solomon", "codes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Hence", ",", "the", "well", "-", "established", "theories", "on", "which", "the", "FEM", "is", "built", ",", "e.g.", ",", "the", "calculus", "of", "variations", ",", "are", "applicable", "to", "the", "presented", "method", "just", "as", "much", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["This", "observation", "confirms", "that", "the", "presence", "of", "AN", "can", "highly", "affect", "the", "secrecy", "outage", "performance", "of", "the", "legitimate", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Further", "investigations", "on", "comparing", "the", "LTE", "eMBMS", "with", "other", "terrestrial", "broadcasting", "standards", "are", "also", "needed", ",", "in", "order", "to", "provide", "a", "comprehensive", "gap", "analysis", "on", "current", "PTM", "technologies", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["A", "survey", "on", "deep", "FER", "including", "datasets", "and", "algorithms", "is", "given", "in", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["[", "PVI", "]", "Perpendicular", "Vegetation", "Index", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "perpendicular vegetation index"}, {"tokens": ["So", ",", "the", "matrix", "is", "a", "function", "of", "the", "distance", "from", "the", "BS", "to", "users", ",", "the", "distance", "of", "the", "BS", "from", "clusters", "and", "from", "users", "to", "the", "centre", "of", "the", "VR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "can", "see", "that", "a", "GP", "with", "a", "first", "-", "order", "additive", "kernel", "is", "an", "example", "of", "a", "GAM", ":", "Each", "function", "drawn", "from", "this", "model", "is", "a", "sum", "of", "orthogonal", "one", "-", "dimensional", "functions", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["For", "TFN", ",", "LMF", ",", "and", "MFM", ",", "we", "re", "-", "did", "experiments", "with", "using", "our", "features", "for", "a", "fair", "comparison", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low - rank multimodal fusion"}, {"tokens": ["paper_MIB_cv_oct10_n200-eps", "-", "converted", "-", "to", "paper_MB_cv_oct10_n200-eps", "-", "converted", "-", "to", "fig", ":", "app6", "Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs", "where", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["Under", "the", "OMv", "conjecture", "for", "any", ",", "there", "exists", "no", "algorithm", "with", "preprocessing", "time", ",", "update", "time", "and", "query", "time", "for", "the", "following", "problems", ":", "compactenum", "Decremental", "/", "incremental", "-SubConn", "in", "undirected", "graphs", "with", "sensitivity", "decremental", "/", "incremental", "-reach", "in", "directed", "graphs", "with", "sensitivity", ",", "decremental", "/", "incremental", "BP", "-", "Match", "in", "undirected", "bipartite", "graphs", "with", "sensitivity", ",", "and", "decremental", "/", "incremental", "SC", "in", "directed", "graphs", "with", "sensitivity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "strongly connected"}, {"tokens": ["Further", ",", "with", "both", "the", "classifiers", ",", "ACO", "achieved", "overall", "fifth", "rank", ";", "performing", "better", "than", "GA", "and", "only", "two", "PSO", "variants", ",", "ErFS", "and", "PSO-42", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["@X", "rrrrr@", "&", "PC", "0", "&", "PC", "1", "&", "PC", "2", "&", "PC", "3", "&", "PC", "4", "CNS", "&", "0.53", "&", "0.21", "&", "0.13", "&", "0.10", "&", "0.04", "MDC", "&", "0.56", "&", "0.19", "&", "0.13", "&", "0.07", "&", "0.04", "Variance", "explained", "by", "principal", "components", "(", "only", "spatial", "data", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["Similarity", "3", "-", "10", "&", "&", "Enron", "&", "GRQC", "&", "Blog", "&", "Wiki", "&", "Enron", "&", "GRQC", "&", "Blog", "&", "Wiki", "3*node2vec", "&", "GPA", "&", "0.9579", "&", "0.9933", "&", "0.9816", "&", "0.9325", "&", "0.9665", "&", "0.9947", "&", "0.9887", "&", "0.9438", "2", "-", "10", "&", "HARP", "&", "0.9209", "&", "0.9621", "&", "0.9708", "&", "0.9210", "&", "0.9418", "&", "0.9846", "&", "0.9618", "&", "0.9258", "2", "-", "10", "&", "Random", "&", "0.9136", "&", "0.9533", "&", "0.9631", "&", "0.9117", "&", "0.9309", "&", "0.9817", "&", "0.9587", "&", "0.9217", "3*DeepWalk", "&", "GPA", "&", "0.9702", "&", "0.9937", "&", "0.9820", "&", "0.9315", "&", "0.9691", "&", "0.9958", "&", "0.9879", "&", "0.9411", "2", "-", "10", "&", "HARP", "&", "0.9352", "&", "0.9625", "&", "0.9717", "&", "0.9178", "&", "0.9449", "&", "0.9842", "&", "0.9658", "&", "0.9354", "2", "-", "10", "&", "Random", "&", "0.9218", "&", "0.9430", "&", "0.9535", "&", "0.9024", "&", "0.9355", "&", "0.9764", "&", "0.9517", "&", "0.9276", "3*LINE", "&", "GPA", "&", "0.7849", "&", "0.9852", "&", "0.9436", "&", "0.8175", "&", "0.5790", "&", "0.9665", "&", "0.9274", "&", "0.8356", "2", "-", "10", "&", "HARP", "&", "0.7484", "&", "0.9526", "&", "0.9298", "&", "0.7849", "&", "0.5372", "&", "0.9471", "&", "0.9016", "&", "0.8126", "2", "-", "10", "&", "Random", "&", "0.7414", "&", "0.9411", "&", "0.9127", "&", "0.7658", "&", "0.5237", "&", "0.9392", "&", "0.8836", "&", "0.8028", "tabulartable*In", "this", "section", ",", "we", "demonstrate", "that", "the", "proposed", "graph", "partition", "based", "algorithm", ",", "dubbed", "as", "GPA", ",", "outperforms", "the", "state", "-", "of", "-", "the", "-", "art", ",", "i.e.", ",", "HARPhbys18", ",", "as", "well", "as", "the", "randomized", "method", ",", "denoted", "by", "Random", ",", "on", "various", "datasets", "and", "over", "different", "tasks", ",", "such", "as", "link", "prediction", "and", "node", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["Current", "RIR", "allocation", "policies", "promote", "aggregation", "through", "the", "preferred", "use", "of", "PA", "addresses", ",", "but", "they", "still", "allow", "PI", "allocations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider aggregatable"}, {"tokens": ["They", "also", "introduced", "a", "PSO", "-", "BP", "neutral", "network", "model", "to", "assist", "the", "PALM", "algorithm", "in", "accurately", "predicting", "future", "traffic", "demands", "and", "reducing", "the", "power", "consumption", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Previous", "WorksThe", "literature", "of", "RV", "segmentation", "is", "less", "abundant", "as", "compared", "to", "that", "of", "the", "LV", "segmentation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["ACA", "-", "ATo", "maximize", "secrecy", "rates", "for", "the", "sources", "while", "guaranteeing", "the", "cheat", "-", "proof", "property", "of", "the", "FJ", "power", "allocation", ",", "the", "authors", "in", "employed", "the", "ACA", "-", "A", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["Therefore", ",", "it", "is", "not", "possible", "to", "detect", "a", "fake", "AP", "by", "comparing", "the", "clock", "skew", "alone", ",", "with", "a", "reasonable", "degree", "of", "certainty", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "LTE", "network", "is", "comprised", "of", "two", "components", ":", "CN", "and", "Evolved", "Universal", "Terrestrial", "Radio", "Access", "Network"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Moreover", ",", "we", "showed", "how", "DMD", "(", "like", "ICA", "-", "family", "methods", ")", "can", "successfully", "solve", "the", "cocktail", "party", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["document", "QA", ",", "knowledge", "base", "QA", "and", "visual", "QA", ",", "and", "showed", "that", "the", "answerability", "scores", "assigned", "by", "humans", "did", "not", "correlate", "well", "with", "existing", "metrics", "."], "acronym_pos": [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Average", "precision", "(", "AP", ")", "gap", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Finally", ",", "we", "analytically", "demonstrate", "the", "CC", "property", "which", "is", "the", "key", "idea", "behind", "why", "our", "method", "works", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "core connected"}, {"tokens": ["We", "can", "conclude", "that", "the", "simpler", "NP", "models", "perform", "well", "across", "domain", ",", "type", "and", "medium", "and", "that", "even", "without", "language", "specific", "tools", "and", "lexicons", "they", "are", "competitive", "to", "the", "more", "complex", "LSTM", "based", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural pooling"}, {"tokens": ["If", "GI", "is", "then", "the", "polynomial", "hierarchy", "collapses", "to", "the", "second", "level", ",", "that", "is", ",", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph isomorphism"}, {"tokens": ["curvesfigure*Raw", "Image", "Representation", "sec", ":", "representationThe", "mapping", "of", "mosaic", "images(Images", "not", "processed", "with", "the", "demosaic", "ISP", "stage", ",", "i.e.", "still", "in", "a", "Bayer", "pattern", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["After", "an", "extensive", "empirical", "analysis", ",", "we", "can", "summarize", "our", "findings", "as", "follows", ":", "RQ1", "The", "number", "of", "learning", "sources", "positively", "affects", "the", "effectiveness", "of", "a", "learned", "deep", "music", "representation", ",", "although", "representations", "based", "on", "a", "single", "learning", "source", "will", "already", "be", "effective", "in", "specialized", "cases", "(", "e.g.", "BPM", "and", "the", "Ballroom", "dataset", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "beat per minute"}, {"tokens": ["The", "running", "sum", "(", "RS", ")", "is", "written", "to", "help", "illustrate", "the", "mechanics", "of", "the", "data", "set", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "running sum"}, {"tokens": ["More", "interestingly", ",", "sensitivity", "shows", "that", "ET", "and", "TC", "regions", "might", "be", "underrepresented", "in", "our", "predicted", "segmentations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["In", "addition", "to", "retaining", "a", "better", "population", "and", "solution", ",", "DE", "uses", "the", "same", "structure", "as", "Genetic", "Algorithm", "such", "as", "crossover", "and", "mutation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["This", "approach", "is", "compatible", "with", "current", "practices", "of", "some", "grid", "operators", "to", "solve", "OPF", ",", "where", "the", "transmission", "security", "constraints", "are", "enforced", "through", "an", "iterative", "procedure", "in", "which", "the", "solution", "at", "each", "iteration", "is", "checked", "against", "the", "base", "-", "case", "and", "contingency", "constraints", ":", "all", "violated", "constraints", "are", "added", "to", "the", "model", ",", "and", "the", "procedure", "continues", "until", "no", "more", "violations", "are", "found", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["b", ")", ",", "with", "the", "FN", "component", ",", "AN", "'s", "attention", "regions", "for", "the", "last", "two", "characters", "are", "rectified", ",", "and", "consequently", "FAN", "outputs", "the", "correct", "text", "string", "\"", "83KM", "\"", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["For", "AC", "-", "OPF", "the", "performance", "was", "more", "moderate", "due", "to", "the", "large", "number", "of", "non", "-", "convex", "equality", "constraints", ",", "which", "are", "responsible", "for", "the", "majority", "of", "the", "computational", "cost", "of", "the", "OPF", "calculation", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Despite", "the", "smoothing", "effect", "of", "the", "low", "-", "level", "controllers", "in", "the", "car", ",", "the", "more", "stringent", "costs", "associated", "with", "the", "larger", "target", "speed", "cause", "the", "noisiness", "of", "the", "DMD", "-", "MPC", "update", "to", "manifest", "in", "the", "car", "'s", "performance", "when", "using", "a", "step", "size", "of", "1", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["In", "summary", ",", "there", "are", "several", "promising", "approaches", "with", "the", "help", "of", "PSO", "in", "smart", "grid", "technologies", "for", "further", "progress", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Inside", "of", "PI", ",", "the", "application", "of", "to", "requires", "the", "solution", "of", "a", "multigroup", "linear", "system", "that", "looks", "like", "a", "fixed", "source", "problem", ",", "PI", "'s", "convergence", "can", "be", "very", "slow", "for", "problems", "of", "interest", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["Evaluation", "MetricsThe", "automatic", "evaluation", "of", "the", "proposed", "QA", "system", "is", "based", "on", "the", "correspondence", "between", "the", "generated", "answer", "and", "gold", "standard", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Dataset", "&", "k", "&", "Asso", "&", "&", "NaiveCol", "&", "topFiberMChess", "&", "1", "&", "0.497", "&", "0.447", "&", "0.119", "&", "0.610", "&", "2", "&", "0.574", "&", "0.506", "&", "0.177", "&", "0.625", "&", "5", "&", "0.628", "&", "0.621", "&", "0.323", "&", "0.667", "&", "10", "&", "0.703", "&", "0.710", "&", "0.461", "&", "0.724", "DBLP", "&", "1", "&", "0.111", "&", "0.131", "&", "0.111", "&", "0.187", "&", "2", "&", "0.217", "&", "0.238", "&", "0.217", "&", "0.293", "&", "5", "&", "0.475", "&", "0.468", "&", "0.475", "&", "0.495", "&", "10", "&", "0.738", "&", "0.692", "&", "0.738", "&", "0.738Firewall", "1", "&", "1", "&", "0.726", "&", "0.688", "&", "0.651", "&", "0.724", "&", "2", "&", "0.818", "&", "0.841", "&", "0.804", "&", "0.847", "&", "5", "&", "0.908", "&", "0.951", "&", "0.932", "&", "0.953", "&", "10", "&", "0.917", "&", "0.979", "&", "0.976", "&", "0.980", "Mushroom", "&", "1", "&", "0.226", "&", "0.131", "&", "0.129", "&", "0.253", "&", "2", "&", "0.323", "&", "0.235", "&", "0.234", "&", "0.305", "&", "5", "&", "0.461", "&", "0.504", "&", "0.398", "&", "0.425", "&", "10", "&", "0.555", "&", "0.613", "&", "0.512", "&", "0.522", "Paleo", "&", "1", "&", "0.027", "&", "0.027", "&", "0.027", "&", "0.027", "&", "2", "&", "0.047", "&", "0.047", "&", "0.047", "&", "0.049", "&", "5", "&", "0.105", "&", "0.106", "&", "0.105", "&", "0.106", "&", "10", "&", "0.182", "&", "0.181", "&", "0.182", "&", "0.182Count", "best", "&", "&", "5", "&", "4", "&", "3", "&", "16", "Coverage", "of", "low", "ranks", "(", "DBP", "view", ")", ",", "bold", "values", "are", "the", "best", "in", "row", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "discrete base problem"}, {"tokens": ["CF", "Models", "."], "acronym_pos": [1, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["As", "the", "is", "invertible", "by", "the", "first", "condition", "of", "the", "MBR", "encoding", "matrix", ",", "the", "decoding", "formula", "is", "formulated", "aswhich", "is", "the", "transpose", "of", "the", "desired", "fragment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["We", "also", "take", "into", "account", "four", "relaying", "schemes", ";", "two", "based", "on", "repetitive", "transmission", "and", "the", "other", "two", "based", "on", "relay", "selection", "(", "RS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "rate - selective"}, {"tokens": ["The", "combination", "with", "SMC", "and", "the", "quantitative", "semantics", "has", "been", "explored", "earlier", "for", "STL", "in", "TCS2015", "and", "applied", "to", "tasks", "like", "system", "design", "and", "parameter", "synthesisTCS2015,silvetti16,silvetti18", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "signal temporal logic"}, {"tokens": ["As", "soon", "as", "the", "AP", "received", "expected", "CTSs", ",", "it", "sends", "data", "frames", "to", "the", "listed", "STAs", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["tableStructure", "of", "a", "document", "in", "the", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["The", "parameter", "is", "much", "bigger", "in", "parallel", "ring", "architecture", "than", "it", "in", "PS", ",", "which", "indicates", "that", "parallel", "ring", "architecture", "is", "lower", "than", "PS", "in", "transfer", "speed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["In", "the", "case", "of", "Dice", "-", "WT", ",", "our", "method", "is", "very", "close", "to", "the", "results", "obtained", "by", "the", "top", "performing", "methods", "while", ",", "again", ",", "our", "method", "achieves", "rather", "low", "Dice", "-", "ET", "and", "Dice", "-", "TC", "metrics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "whole tumor"}, {"tokens": ["Also", ",", "in", "the", "absence", "of", "ground", "-", "truth", "spatial", "locations", "of", "the", "phrases(weakly", "-", "supervised", ")", ",", "we", "propose", "knowledge", "transfer", "mechanisms", "that", "leverages", "the", "framework", "of", "PIN", "module", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "proposal indexing network"}, {"tokens": ["The", "context", "is", "a", "one", "-", "way", "communication", "channel", "between", "the", "TP", "of", "an", "Expert", "and", "the", "TP(s", ")", "of", "the", "Expert(s", ")", "below", "it", "in", "the", "hierarchy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["Moreover", ",", "since", "the", "IB", "functional", "is", "concave", "(", "Lemma", "5", "of", ")"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["MAD", "unit", "is", "a", "side", "branch", "taking", "the", "feature", "maps", "in", "the", "highest", "level", "as", "input", "and", "generates", "a", "column", "vector", ",", "whose", "length", "corresponds", "to", "two", "times", "as", "the", "number", "of", "channels", "in", "maps", "that", "MAD", "enforces", "on", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["A", "SC", "score", "based", "on", "image", "features", "that", "best", "separate", "different", "training", "data", "quantifies", "the", "reliability", "and", "accuracy", "of", "each", "annotation", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "self consistency"}, {"tokens": ["Almost", "all", "previous", "state", "-", "of", "-", "the", "-", "art", "QA", "and", "RC", "models", "find", "answers", "by", "matching", "passages", "with", "questions", ",", "aka", "inter", "-", "sentence", "matching", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Among", "all", "research", "studies", "had", "been", "done", ",", "according", "to", "the", "ABC", ",", "BA", ",", "BCO", "and", "HBMO", "are", "found", "the", "most", "useful", "application", ",", "from", "the", "highest", "number", "to", "the", "lowest", "number", ",", "in", "large", "scale", "engineering", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bee algorithm"}, {"tokens": ["denotes", "the", "transmit", "beamforming", "vector", "for", "controlling", "the", "confidential", "message", "to", "the", "desired", "direction", "and", "is", "the", "projection", "matrix", "leading", "AN", "to", "the", "undesired", "direction", ",", "where", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Experimental", "evaluation", "of", "the", "proposed", "learning", "model", "\u2019s", "performance", "against", "different", "DCNN", "architectures", "on", "different", "benchmark", "datasets", "such", "as", "MNIST", ",", "CIFAR-10", ",", "CIFAR-100", "and", "SVHN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["For", "languages", "with", "varf", ":", "NP", "barf", ",", "it", "is", "assumed", "that", "the", "loan", "is", "from", "Middle", "Persian", ",", "or", "some", "period", "predating", "the", "change", "of", "MP", "w-", "to", "NP", "b-", ";", "for", "instance", ",", "derives", "Gazi", "varf", "'", "snow", "'", "from", "MP", "varf"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["proposed", "a", "fuzzy", "controlled", "parallel", "PSO", "(", "FCP", "-", "PSO", ")", "algorithm", "for", "solving", "large", "-", "scale", "non", "-", "convex", "ED", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["On", "the", "contrary", ",", "means", "that", "AN", "does", "not", "work", ",", "which", "is", "unacceptable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["Matthews", "Correlation", "Coefficient", "(", "MCC", ")", "measures", "the", "correlation", "between", "the", "actual", "and", "the", "predicted", "classifications", ",", "ranging", "between", "-1", "and", "+1", ",", "where", "-1", "indicates", "total", "disagreement", ",", "+1", "indicates", "perfect", "agreement", ",", "and", "0", "indicates", "no", "correlation", "at", "all", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["If", "possible", ",", "a", "deep", "network", "pre", "-", "trained", "with", "a", "large", "-", "scale", "annotated", "SAR", "scene", "dataset", "is", "a", "good", "source", "to", "transfer", "and", "we", "have", "released", "the", "resource", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Obviously", ",", "there", "is", "no", "-nd", "round", "channel", "access", "when", "the", "AP", "has", "antenna", ",", "which", "is", "why", "the", "results", "keep", "constant", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["After", "this", "threshold", ",", "the", "MINT", "-", "FEC", "starts", "to", "increase", "the", "amount", "of", "redundancy", "to", "improve", "the", "video", "quality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["It", "can", "be", "observed", "that", "the", "local", "data", "is", "not", "accessed", "by", "the", "BS", ",", "so", "as", "to", "protect", "the", "privacy", "of", "users", ",", "as", "is", "required", "by", "FL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["NP", "bahana", "'", "reason", ",", "pretext'PIr"], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["The", "DT", "method", "uses", "symbols", "for", "equality", "and", "inequalities", ",", "while", "in", "our", "method", "all", "the", "extracted", "rules", "use", "only", "and", ",", "and", "not", "or", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["The", "proposed", "algorithm", "named", "FAPSO", "-", "VDE", "considers", ",", "the", "fuzzy", "rules", "to", "adjust", "parameters", "adaptively", ",", "the", "PSO", "to", "maintain", "population", "diversity", "of", "the", "population", "and", "the", "DE", "to", "optimize", "the", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["a", ")", "shows", "AP", "of", "each", "class", "on", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["This", "enables", "us", "to", "generate", "datasets", "with", "a", "variety", "of", "ISP", "configurations", "and", "settings", ",", "which", "we", "then", "use", "to", "train", "state", "-", "of", "-", "the", "-", "art", "CNN", "models", "-", "from", "compact", "width", "-", "scalable", "MobileNets", "mobilenetv1", ",", "which", "are", "suited", "to", "mobile", "devices", ",", "to", "larger", "depth", "-", "scalable", "ResNets", "resnet", ",", "which", "are", "employed", "in", "applications", "such", "as", "automotive", "-", "to", "formulate", "hypotheses", "on", "the", "impact", "of", "ISP", "design", "on", "CNN", "classification", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["End", "-", "to", "-", "end", "OP", ",", ",", "of", "RS", "versus", "the", "average", "transmit", "SNR", "per", "bit", ",", ",", "for", "relay", "nodes", "over", "INID"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["The", "text", "data", "from", "these", "sources", "are", "more", "colloquial", "and", "idiomatic", "and", "much", "shorter", "in", "length", "compared", "to", "historical", "texts", ",", "making", "stylometric", "features", "such", "as", "word", "and", "character", "n", "-", "grams", "more", "effictive", "measures", "for", "AA", "research", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["The", "reason", "for", "that", "is", "a", "STA", "transmits", "less", "frequently", "than", "the", "AP", "in", "the", "non", "-", "saturated", "condition", ",", "which", "results", "in", "a", "lower", "conditional", "collision", "probability", "for", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["The", "four", "techniques", "compared", "in", "this", "article", "are", "examples", "of", "possible", "combination", "of", "the", "described", "techniques", "for", "an", "IPv6", "only", "ISP", "network", "with", "shared", "IPv4", "adresses", ":", "DS", "-", "Lite", ",", "MAP", "-", "E", "e", "MAP", "-", "T", ",", "464XLAT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "internet service providers"}, {"tokens": ["In", "addition", ",", "some", "new", "neighbour", "nodes", "appear", "when", "indirect", "links", "are", "counted", "and", "this", "changes", "the", "score", "of", "RV", "strategy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random vaccination"}, {"tokens": ["The", "output", "of", "GSP", "is", "normalized", "by", "it", "'s", "mean", "and", "standard", "deviation", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global statistics pooling"}, {"tokens": ["The", "reward", "function", "returns", "a", "value", "equivalent", "to", "the", "LoC", ",", "unless", "the", ";", "then", ",", "returns", "the", "inverse", "of", "LoC.wherePersonalization", "of", "the", "Level", "of", "Feedback", "and", "applied", "the", "concept", "of", "graded", "cueing", "to", "adapt", "feedback", "in", "the", "context", "of", "SAR", "interventions", "for", "children", "with", "ASD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Classifier", "Chains", "(", "CC", ")", ":"], "acronym_pos": [0, 0, 0, 1, 0, 0], "long_form": "classifier chain"}, {"tokens": ["The", "existing", "QA", "systems", "are", "a", "black", "box", "which", "do", "not", "provide", "any", "explanation", "for", "their", "inference", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["These", "methods", "need", "to", "produce", "depth", "synthesis", "for", "poorly", "reconstructed", "areas", "in", "SFM", ",", "which", "is", "challenging", "for", "intricate", "structures", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "structure from motion"}, {"tokens": ["The", "cover", "complexity", "(", "CC", ")", "is", "The", "CD", "is", "defined", "as", "the", "difference", "between", "the", "mean", "of", "SC", "and", "the", "mean", "of", "MC", ",", "since", "each", "category", "occurs", "with", "the", "same", "probability", "(", ")", "in", "the", "data", "sets", "mostly", "used", "in", "practice", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "self cover"}, {"tokens": ["Rather", "than", "explicitly", "specifying", "physical", "states", "as", "in", "a", "classical", "SSM", ",", "we", "use", "a", "deep", "network", "to", "automatically", "extract", "latent", "state", "features", "and", "constrain", "these", "through", "optimisation", "to", "follow", "the", "linear", "-", "like", "relation", "in", "Equation", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state space model"}, {"tokens": ["Furthermore", ",", "a", "bisection", "UE", "selection", "algorithm", "is", "proposed", "to", "guarantee", "the", "feasibility", "of", "the", "problem", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Specifically", ",", "when", "the", "AP", "receives", "a", "first", "RTS", ",", "it", "will", "wait", "for", "a", "time", "period", "of", "to", "recruit", "a", "second", "RTS", "for", "double", "-", "frame", "receptions", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["To", "our", "knowledge", "there", "is", "no", "dataset", "which", "can", "be", "used", "for", "evaluating", "incremental", "dialogue", "state", "trackers", ",", "so", "it", "would", "be", "beneficial", "to", "collect", "the", "word", "-", "level", "annotations", "so", "one", "can", "evaluate", "incremental", "DST", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["In", "the", "context", "of", "QA", ",", "Pizzato", "pizzato", "employs", "blind", "RF", "using", "the", "AQUAINT", "corpus", "in", "an", "attempt", "to", "improve", "performance", "when", "answering", "factoid", "questions", "on", "personal", "names", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["@X", "rrrrrrrrrr", "@", "&", "PC", "0", "&", "PC", "1", "&", "PC", "2", "&", "PC", "3", "&", "PC", "4", "&", "PC", "5", "&", "PC", "6", "&", "PC", "7", "&", "PC", "8", "&", "PC", "9", "CNS", "&", "0.39", "&", "0.17", "&", "0.12", "&", "0.08", "&", "0.07", "&", "0.06", "&", "0.04", "&", "0.03", "&", "0.03", "&", "0.01", "MDC", "&", "0.43", "&", "0.14", "&", "0.13", "&", "0.08", "&", "0.07", "&", "0.06", "&", "0.04", "&", "0.03", "&", "0.02", "&", "0.01", "Variance", "explained", "by", "principal", "components", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["DE", "with", "better", "exploitation", "ability", "leads", "to", "better", "convergence", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["We", "believe", "HOG", "features", "are", "helpful", "in", "observing", "edges", "and", "therefore", "distinguishing", "real", "and", "false", "limbs", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "histogram of gradients"}, {"tokens": ["Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs", "where", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["All", "of", "the", "experiments", "in", "this", "paper", "were", "performed", "using", "the", "standard", "GPML", "toolbox(Available", "at", "http://www.gaussianprocess.org/gpml/code/", ")", ";", "code", "to", "perform", "all", "experiments", "is", "available", "at", "the", "author", "'s", "website.(Example", "code", "available", "at", ":", "http://mlg.eng.cam.ac.uk/duvenaud/)Related", "WorkPlate", "constructs", "a", "form", "of", "additive", "GP", ",", "but", "using", "only", "the", "first", "-", "order", "and", "th", "order", "terms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "authors", "showed", "that", "the", "transmit", "power", "of", "the", "BS", "scales", "by", "as", "the", "number", "of", "reflector", "units", "goes", "to", "infinity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["That", "is", ",", "approach", "can", "be", "implemented", "using", "GP", "regression", "[", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "above", "allows", "the", "receiver", "to", "unmask", "and", "learn", "its", "intended", "message", "for", "each", "extended", "OT", "but", "nothing", "more", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["A", "natural", "extension", "of", "sufficient", "condition", "(", "Symmetry", "condition", "SC", ")", "in", "cost", "sensitive", "case", "when", "used", "with", "weighted", "-", "loss", "can", "be", "written", "as", "follows", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "symmetry condition"}, {"tokens": ["Moreover", ",", "recently", "showed", "how", "in", "deterministic", "scenarios", "(", "such", "as", "many", "classification", "problems", "where", "an", "input", "belongs", "to", "a", "single", "particular", "class", ")", "the", "IB", "Lagrangian", "could", "not", "explore", "the", "IB", "curve", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "CCC", "values", "on", "the", "Validation", "set", "(", "averaged", "across", "listeners", ")", "are", "displayed", "in", "the", "fourth", "column", "of", "Table", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["Therefore", ",", "the", "total", "complexity", "imposed", "by", "the", "CDP", "method", "across", "all", "trellis", "stages", "may", "be", "quantified", "in", "terms", "of", "the", "number", "of", "dominance", "comparisons", ",", "which", "is", "formulated", "as", "follows", ":", "where", "we", "have", "exploited", "the", "property", "of", "the", "sum", "of", "squared", "numbers", ",", "where", "we", "have", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classical dynamic programming"}, {"tokens": ["Several", "popular", "open", "-", "source", "frameworks", "exist", ",", "such", "as", "Caffe", ",", "Torch", ",", "Theano", ",", "and", "TensorFlow", ",", "but", "implementing", "new", "methods", "requires", "an", "extensive", "programming", "background", "and", "DL", "knowledge", ",", "holding", "back", "DL", "democratization", "in", "RS", "community", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "remote sensing"}, {"tokens": ["As", "an", "input", "to", "the", "models", ",", "only", "the", "2D", "stack", "LR", "images", "are", "used", ",", "which", "is", "a", "commonly", "used", "acquisition", "protocol", "for", "cardiac", "imaging", ",", "and", "the", "segmentation", "is", "performed", "only", "on", "the", "ED", "phase", "of", "the", "sequences", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "dates", "for", ",", "and", "reflect", "the", "probability", "to", "have", ",", "at", "this", "time", ",", "a", "good", "estimator", "of", "cropland", "area", ",", "crop", "area", "and", "crop", "yield", ",", "using", "EO", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "earth observation"}, {"tokens": ["In", "adaptive", "DE", ",", "each", "individual", "has", "its", "associated", "crossover", "probability", "instead", "of", "a", "fixed", "value", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Classification", "results", "produced", "by", "the", "ANN", "and", "RF", "models", "show", "that", "they", "can", "capture", "most", "of", "the", "underlying", "patterns", "of", "rupture", "propagation", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "capability", "of", "the", "SoC", "integrator", "can", "also", "include", "state", "-", "of", "-", "the", "-", "art", "FA", "tools", "and", "netlist", "reverse", "engineering", "software", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["We", "use", "the", "ground", "truth", "community", "membership", "in", "generatingthe", "SBM", "graphs", "when", "evaluating", "the", "accuracies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["adopted", "randomized", "benchmarking", "techniques", "to", "obtain", "a", "process", "tomography", "protocol", "that", "is", "robust", "towards", "state", "preparation", "and", "measurement", "errors", "(", "SPAM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "state preparation and measurement errors"}, {"tokens": ["The", "temperature", "in", "MD", "simulations", "was", "controlled", "by", "the", "standard", "v", "-", "rescale", "algorithm", "for", "both", "benchmarks", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["To", "do", "this", ",", "we", "performed", "leave", "-", "one", "-", "out", "cross", "-", "validation", "across", "the", "provided", "stories", ",", "training", "on", "four", "of", "the", "stories", "and", "computing", "the", "CCC", "for", "the", "held", "-", "out", "story", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["We", "propose", "a", "constrained", "Thompson", "sampling", "heuristic", ",", "Con", "-", "TS", "-", "RTP", ",", "that", "accounts", "for", "various", "possible", "aggregator", "objectives", "(", "e.g.", ",", "to", "reduce", "demand", "at", "peak", "hours", ",", "integrate", "more", "intermittent", "renewable", "generation", ",", "track", "a", "desired", "daily", "load", "profile", ",", "etc", ")", "and", "takes", "into", "account", "the", "operational", "constraints", "of", "a", "distribution", "system", "to", "avoid", "potential", "grid", "failures", "as", "a", "result", "of", "uncertainty", "in", "the", "customers", "'", "response", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["In", "the", "special", "case", "of", "parity", "objectives", ",", "even", "strong", "MD", "determinacy", "holds", "for", "any", "threshold", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["In", "Section", ",", "we", "develop", "a", "performance", "models", "for", "distributed", "training", "for", "PS", ",", "P2P", ",", "and", "RA", "architectures", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["We", "report", "this", "performance", "in", "Figure", ",", "where", "it", "can", "be", "seen", "that", "the", "GAT", "surrogate", "outperforms", "LS", "on", "7", "out", "of", "9", "datasets", ",", "although", "admittedly", "the", "difference", "is", "small", "and", "only", "statistically", "significant", "on", "3", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "least squares"}, {"tokens": ["Speech", "InterfaceInterfacing", "speech", "to", "QA", "systems", "has", "become", "a", "focus", "of", "research", "for", "a", "long", "time", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "value", "of", "can", "be", "directly", "derived", "from", "LTE", "protocol", "parameters", ",", "whereas", "and", "can", "be", "obtained", "by", "fitting", "the", "LTE", "rate", "curve", "generated", "from", "link", "-", "level", "simulations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["A", "Gaussian", "Mixture", "Model", "(", "GMM", ")", "is", "used", "to", "model", "the", "foreground", "and", "the", "background", ",", "whose", "initialization", "is", "dependent", "on", "the", "user", "specified", "cues", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["ibAbI", "represents", "another", "approach", "for", "creating", "multi", "-", "turn", "QA", "datasetsLi:2017:CAN:3097983.3098115", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["[", "]", "Comparison", "of", "the", "indexing", "platforms", "and", "data", "structures", "used", "by", "different", "QA", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["One", "interesting", "phenomenon", "was", "observed", "when", "we", "initialized", "MLconv", "and", "LR", "with", "a", "pre", "-", "trained", "CNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "low rank"}, {"tokens": ["However", ",", "DTP", "does", "far", "better", "than", "FA", "across", "the", "scenarios", ",", "although", "its", "lacks", "the", "ability", "to", "train", "from", "zero", "initialization", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "difference target propagation"}, {"tokens": ["In", "contrast", "to", "previous", "methods", ",", "the", "compression", "parameter", "in", "the", "IB", "framework", "allows", "for", "a", "task", "-", "dependent", "adjustment", "of", "the", "latent", "dimensionality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Notice", "that", "the", "proposed", "solution", "attains", "similar", "outage", "performance", "as", "MC", ",", "while", "maintaining", "similar", "average", "latency", "as", "the", "SC", "case", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "single connectivity"}, {"tokens": ["table[ht]3pttabularllccccccccccccccccc", "Task", "type", "&", "Task", "&", "a", "&", "aE", "&", "DE", "&", "dM", "&", "d", "&", "EPD", "&", "e", "&", "eR", "&", "fM", "&", "i", "&", "R", "&", "SE", "&", "s", "&", "v", "&", "x", "4*Dataset", "&", "Variable", "types", "&", "&", "x", "&", "x", "&", "x", "&", "x", "&", "&", "x", "&", "&", "x", "&", "x", "&", "&", "x", "&", "x", "&", "x", "&", "&", "Dimensions", "&", "&", "x", "&", "x", "&", "x", "&", "x", "&", "x", "&", "&", "&", "x", "&", "x", "&", "&", "x", "&", "&", "x", "&", "&", "Other", "info", "&", "&", "&", "x", "&", "&", "&", "&", "&", "&", "&", "x", "&", "&", "&", "&", "x", "&", "&", "Compare", "datasets", "&", "x", "&", "&", "&", "&", "&", "&", "&", "&", "x", "&", "x", "&", "&", "&", "&", "x", "&", "5*Validity", "&", "Missing", "values", "&", "&", "x", "&", "x", "&", "x", "&", "x", "&", "x", "&", "x", "&", "&", "x", "&", "x", "&", "&", "x", "&", "x", "&", "x", "&", "x", "&", "Redundant", "col", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dataexplorer"}, {"tokens": ["c", "c", "c", "c", "c", "c", "c", "&", "3cDice", "&", "3cHausdorff", "&", "ET", "&", "WT", "&", "TC", "&", "ET", "&", "WT", "&", "TC", "Development", "set", "&", "0.671", "&", "0.869", "&", "0.685", "&", "7.145", "&", "6.410", "&", "9.584", "Validation", "set", "&", "0.714", "&", "0.877", "&", "0.637", "&", "5.434", "&", "8.343", "&", "11.173Results", "for", "BraTS", "2017", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "whole tumor"}, {"tokens": ["Illustration", "of", "an", "envisioned", "application", "of", "MR", "agents", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mixed reality"}, {"tokens": ["Hence", ",", "the", "proposed", "NOMA", "-", "OAM", "-", "MDMA", "scheme", "with", "a", "higher", "provides", "significantly", "higher", "SC", "than", "other", "compared", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["Introduction", "Stereoscopic", "AR", "Predictive", "Display", "(", "SARPD", ")"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["In", "order", "to", "adjust", "the", "FEC", "redundancy", "and", "the", "transmission", "rate", ",", "the", "receivers", "periodically", "send", "the", "packet", "error", "rate", "information", "to", "the", "Access", "Point", "(", "AP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["PS", "drives", "use", "Advanced", "Technology", "Attachment", "-", "ATA", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "personal storage"}, {"tokens": ["A", "set", "of", "orthogonal", "training", "sequences", "are", "assigned", "to", "STAs", "by", "the", "AP", "to", "facilitate", "the", "channel", "estimation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["The", "results", "also", "showed", "high", "levels", "of", "demand", "for", "DSA", "skills", ",", "particularly", "'", "technically", "rigorous", "'", "DSA", "skills", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["DCNN", "also", "includes", "sigmoid", "or", "rectified", "linear", "units", "for", "non", "-", "linearity", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["This", "brand", "of", "GP", "-", "based", "AI", "system", "would", "be", "useful", "for", "automatically", "launching", "new", "analyses", ",", "but", "less", "useful", "for", "recommending", "particular", "algorithm", "configurations", "to", "the", "user", "because", "GP", "does", "not", "provide", "a", "notion", "of", "the", "\"", "next", "best", "\"", "solution", "to", "attempt", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["This", "first", "version", "of", "the", "GCP", "is", "restricted", "to", "simple", "graphs", "(", "no", "more", "than", "one", "edge", "between", "two", "given", "vertices", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph compression problem"}, {"tokens": ["Figure", "a", ")", ",", "comparing", "the", "FEM", "result", "to", "the", "RB", "for", "various", "number", "of", "basis", "elements", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["The", "probability", "that", "a", "node", "will", "be", "selected", "through", "PA", "is", "defined", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "preferential attachment"}, {"tokens": ["A", "fault", "analysis", "(", "FA", ")", "based", "key", "-", "gate", "insertion", "algorithm", "has", "already", "been", "proposed", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["Figure", "shows", "the", "fit", "of", "the", "GMM", "of", "the", "measurement", "noise", "compared", "to", "the", "empirical", "distribution", "attained", "from", "a", "Monte", "-", "Carlo", "simulation", "with", "samples", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Moreover", ",", "the", "open", "issues", "of", "LTE", "vehicular", "networks", "were", "discussed", "to", "promote", "potential", "solutions", "for", "future", "vehicular", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["As", "betweenness", "centrality", "(", "BC", ")", "is", "one", "important", "parameter", "to", "find", "out", "congestion", "at", "a", "node", "in", "the", "network", "hence", ",", "we", "have", "considered", "BC", "-", "BC", "correlation", "for", "routing", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["ELD", "using", "classical", "PSO", "Park", "et", "al", ".", ","], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["The", "IS", "Logic", "Toolbox"], "acronym_pos": [0, 1, 0, 0], "long_form": "information systems"}, {"tokens": ["In", "some", "other", "scenarios", ",", "where", "there", "are", "abundant", "wireless", "resource", ",", "maximizing", "the", "number", "of", "admitted", "UEs", "in", "each", "time", "slot", "may", "not", "be", "a", "good", "option", "in", "reducing", "NPC", ",", "and", "dynamically", "scheduling", "the", "UE", "in", "different", "time", "slots", "may", "further", "reduce", "NPC", ",", "which", "will", "be", "left", "for", "future", "work", ".", ")", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Subtracting", "the", "results", "for", "the", "SDD", "from", "the", "TDW", "produces", "a", "simple", "comparison", "of", "the", "two", "environments", ",", "as", "seen", "in", "Figure", "for", "the", "10", "non", "-", "astronomers", "(", "top", "panel", ")", ",", "12", "astronomers", "(", "middle", "panel", ")", "and", "eight", "collaborative", "pairs", "of", "non", "-", "astronomers", "(", "bottom", "panel", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["From", "the", "SAD", "results", ",", "it", "is", "clear", "that", "the", "proposed", "method", "achieves", "the", "best", "performance", "compared", "to", "the", "baselines", "and", "a", "improvement", "is", "introduced", "over", "the", "second", "best", "result", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["However", ",", "our", "results", "also", "show", "that", "both", "MP", "and", "CF", "provide", "poor", "results", "for", "UC4", "being", "the", "most", "complex", "use", "case", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "most popular"}, {"tokens": ["The", "nodes", "with", "high", "PRR", "are", "not", "scheduled", ",", "however", ",", "they", "still", "consume", "energy", "on", "channel", "competitions", "in", "RCAP", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "packet reception rate"}, {"tokens": ["This", "projection", "is", "passed", "to", "the", "SP", "of", "the", "next", "Experts", "in", "the", "hierarchy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial pooler"}, {"tokens": ["There", "are", "two", "primary", "shortcomings", "to", "RBP", "and", "RS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "residual splash"}, {"tokens": ["AA", "&", "Affine", "arithmetic", "."], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "affine arithmetic"}, {"tokens": ["With", "the", "weighted", "summation", "of", "ACE", "and", "the", "interval", "score", ",", "the", "C", "Wan", "'s", "cost", "function", "is", "as", "follows", ":"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average coverage error"}, {"tokens": ["Computational", "Time", "AnalysisTable", "reports", "the", "average", "computational", "time", "of", "11", "different", "regression", "algorithms", ",", "i.e.", ",", "DBNMS", ",", "DBN", ",", "GB", ",", "ELM", ",", "SVM", ",", "RR", ",", "Lasso", ",", "AdaBoost", ",", "SGD", ",", "EN", "and", "LAR", "over", "10", "runs", "on", "gun", "drilling", "dataset", "with", "time", "windowing", "processing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Once", "a", "STA", "finishes", "transmitting", "ahead", "of", "the", "other", "one", ",", "the", "AP", "immediately", "sends", "an", "ACK", "with", "the", "updated", "MPR", "vacancy", "information", "through", "the", "additional", "channel", "to", "allow", "other", "STAs", "to", "compete", "for", "the", "newly", "available", "MPR", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["The", "team", "believes", "that", "the", "system", "has", "already", "managed", "the", "most", "stable", "GPS", "-", "free", "flight", "to", "date", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["/darr/", "NP", "darr-", "'", "to", "rend", ",", "tear", "up'darrah*us"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["The", "case", "where", "there", "are", "more", "workers", "than", "jobs", ",", "or", "vice", "versa", ",", "is", "referred", "to", "as", "a", "Rectangular", "LAP", "or", "RLAP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "linear assignment problem"}, {"tokens": ["Simulation", "ResultsIn", "this", "section", ",", "we", "showcase", "the", "ability", "of", "our", "approach", "to", "dynamically", "switch", "between", "a", "DI", "receiver", "(", "scanning", "receiver", ")", "and", "a", "GT", "approach", ",", "based", "on", "the", "expected", "occupancy", "(", "the", "vector", "of", "priors", ")", ",", "the", "time", "available", ",", "the", "minimum", "SNR", "threshold", "and", "the", "number", "of", "resources", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "direct inspection"}, {"tokens": ["We", "also", "investigate", "whether", "visual", "context", "surrounding", "a", "target", "object", "or", "its", "overlapping", "boxes", "can", "improve", "the", "upper", "bound", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "average precision"}, {"tokens": ["For", "each", "attribute", ",", "we", "generate", "continuations", "for", "each", "of", "its", "values", ",", "and", "compare", "to", "BS", "and", "TS", "systems", "with", "the", "same", "number", "of", "outputs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature - based sampling"}, {"tokens": ["For", "the", "former", "set", ",", "we", "have", "three", "baselines", ":", "View", "-", "pop", ",", "Edit", "-", "pop", ",", "and", "CF", "-", "based", ",", "while", "for", "the", "latter", ",", "we", "only", "have", "View", "-", "pop", "and", "Edit", "-", "pop", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["To", "derive", "the", "property", "LTS", "of", "a", "given", "actor", "model", "and", ",", "AML", "specifications", "of", "the", "actors", "are", "transform", "into", "a", "set", "of", "processes(This", "encoding", "is", "available", "at", "http://fghassemi.adhoc.ir/AGcode.zip", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["6cStep", "2", "R1", "&", "&", "300", "&", "5", "&", "7", "&", "33", "BS", "-", "67", "RS", "R2", "&", "Subset", "of", "&", "88", "&", "10", "-", "20", "&", "7", "&", "92", "BS", "-", "8", "RS", "VR", "&", "&", "300", "&", "5", "&", "4", "&", "33"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "randomly sampled"}, {"tokens": ["benchmark_results_g_mean_acc_byalg_overall.eps", "Comparison", "of", "the", "overall", "G", "-", "mean", "and", "accuracy", "across", "7", "algorithms", ",", "i.e.", "ECS", "-", "DBN", ",", "DBN", ",", "ADASYN", "-", "DBN", ",", "SMOTE", "-", "DBN", ",", "SMOTE", "-", "borderline1-DBN", ",", "SMOTE", "-", "borderline2-DBN", "and", "SMOTE", "-", "SVM", "-", "DBN", ",", "on", "58", "benchmark", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["We", "show", "the", "AP", "property", "of", "the", "scheme", "by", "proving", "that", "it", "preserves", "the", "divergence", "free", "constraint", "in", "the", "zero", "Mach", "number", "limit", "when", "starting", "from", "well", "prepared", "initial", "data", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "asymptotic preserving"}, {"tokens": ["When", "a", "fine", "-", "tuning", "is", "applied", ",", "the", "accuracy", "of", "FER", "increases", "considerably", "and", "it", "achieves", "86.36", "as", "shown", "in", "the", "Confusion", "matrix", "of", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Here", ",", "blockchain", "'s", "distributed", "ledger", "is", "employed", "for", "transaction", "execution", "in", "distributed", "V2", "G", "environments", "while", "ECC", "is", "used", "for", "hierarchical", "authentication", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["In", "OT", "Extension", "Phase", "I", ",", "sends", "bits", "to", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "IB", "system", "showed", "an", "average", "(", "over", "all", "datasets", ")", "error", "of", "2.2", "in", "estimating", "a", "correct", "number", "of", "speakers", ",", "whereas", "the", "TPIB", "and", "TPIB", "-", "ITL", "showed", "a", "similar", "average", "error", "of", "1.15", "speakers", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "this", "paper", ",", "FCA", "application", "scope", "is", "the", "challenge", "of", "sportsbetting", ",", "specifically", ",", "the", "forecasting", "of", "soccer", "league", "'s", "results", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "formal concept analysis"}, {"tokens": ["As", "can", "be", "seen", "from", "the", "ContF0", "and", "MVF", "prediction", ",", "the", "proposed", "system", "also", "has", "voicing", "errors", ",", "which", "typically", "result", "in", "false", "voicing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["IntroductionSemantic", "Role", "Labeling", "(", "SRL", ")"], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "semantic role labeling"}, {"tokens": ["For", "instance", ",", "if", "the", "traffic", "load", "of", "a", "STA", "is", "Mbps", "and", "there", "are", "STAs", ",", "the", "traffic", "load", "of", "the", "AP", "will", "be", "Mbps", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "selection", "attribute", "problem", "based", "on", "FCA", "-", "based", "reasoning", "system", "for", "sport", "forecasting", "is", "analysed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "formal concept analysis"}, {"tokens": ["Although", "the", "feature", "tensor", ",", "as", "well", "as", "the", "importance", "-", "indicator", "maps", "can", "be", "separately", "generated", "by", "three", "structure", "-", "similar", "networks", "in", "the", "MD", "multi", "-", "scale", "-", "dilated", "encoder", "network", ",", "the", "input", "is", "shared", "by", "these", "networks", "to", "produce", "these", "tensors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["SSIM", "measure", "assesses", "the", "correlation", "of", "local", "structures", "and", "is", "less", "sensitive", "to", "image", "noise", "than", "PSNR", "which", "is", "not", "used", "in", "our", "experiments", "since", "small", "misalignments", "between", "LR", "-", "HR", "image", "pairs", "could", "introduce", "large", "errors", "in", "the", "evaluation", "due", "to", "pixel", "by", "pixel", "comparisons", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["Namely", ",", "instead", "of", "sending", "a", "CTS", "after", "the", "first", "RTS", "round", ",", "the", "AP", "waits", "for", "an", "extra", "round", "to", "recruit", "more", "RTSs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["OEC", "identifies", "three", "clusters", "in", "this", "dataset", "which", "correspond", "to", "normal", "days", ",", "high", "wind", "before", "the", "snow", "and", "the", "snow", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["Given", "the", "advantages", "of", "the", "ACA", "-", "A", "scheme", ",", "the", "authors", "in", "employed", "this", "auction", "for", "the", "joint", "subcarrier", "and", "FJ", "power", "allocation", "to", "improve", "the", "uplink", "secrecy", "rate", "in", "cellular", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["presents", "the", "sum", "-", "rate", "with", "RS", "versus", "the", "SNR", "for", "increasing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["Shared", "Task", "Corpus", "(", "CMI", "=", "11.65", ")", "and", "ICON", "2015"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "code - mixed index"}, {"tokens": ["Multi", "-", "resolution", "terrain", "rendering", "with", "TS", "are", "going", "to", "be", "further", "analyzed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "tessellation shader"}, {"tokens": ["MP", "gyag", "NP", "jah", "'", "place'Generally", "speaking", ",", "PIr"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["In", "particular", ",", "approaches", "that", "increase", "the", "number", "of", "communication", "rounds", "can", "hinder", "the", "applicability", "of", "FL", ",", "as", "they", "augment", "the", "training", "time", "and", "amount", "of", "data", "exchanged", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["In", "particular", ",", "the", "authors", "analyzed", "AIRs", "for", "CM", "schemes", "with", "bit", "-", "wise", "and", "symbol", "-", "wise", "decoding", "(", "suitable", "for", "binary", "and", "nonbinary", "codes", ",", "respectively", ")", "considering", "both", "SDD", "and", "what", "the", "authors", "referred", "to", "as", "HDD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "coded modulation"}, {"tokens": ["We", "then", "analysed", "the", "DSA", "categories", "according", "to", "each", "of", "these", "five", "variables", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["The", "OT", "metric", "between", "two", "joint", "probability", "distributions", "supported", "on", "two", "metric", "spaces", "is", "defined", "as", "the", "solution", "of", "the", "linear", "program", ":", "where", "is", "a", "coupling", ";", "is", "the", "set", "of", "couplings", "that", "consists", "of", "joint", "distributions", "over", "the", "product", "space", "with", "marginals", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["We", "consider", "a", "scenario", "with", "of", "outdoor", "users", "modeled", "according", "to", "Cox", "process", "driven", "by", "the", "PLP", "and", "of", "indoor", "users", "modeled", "according", "to", "a", "spatial", "PPP", ",", "with", "an", "average", "cell", "throughput", "of", "30Mbps", "and", "a", "fixed", "transmission", "rate", "of", "500kbps", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["Therefore", ",", "training", "neural", "network", "by", "using", "ICA", "algorithms", "in", "figure", "not", "only", "has", "a", "higher", "speed", ",", "but", "also", "it", "conducts", "better", "in", "training", "data", "by", "comparison", "with", "GA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imperialist competitive algorithm"}, {"tokens": ["AUC", "and", "AP", "performance", "on", "high", "dimensional", "datasets", "[", "h]1", "AUC"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["After", "feature", "transformation", ",", "softmax", "layer", "is", "as", "the", "output", "layer", "of", "DBN", "to", "perform", "classification", "predictions", "with", "parameterized", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": [":", "Integer", "variable", "indexing", "the", "DU", "hosting", "UPs", "of", "UE", "at", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "central cloud"}, {"tokens": ["An", "intuitive", "approach", "is", "collaborative", "filtering", "(", "CF", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Every", "block", "in", "BC", "contains", "a", "hash", "of", "the", "previous", "block", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["LTE", "Wi", "-", "Fi", "Co", "-", "existence", "Experimental", "Setup", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Mintsis", ",", "G.", ",", "Basbas", ",", "S.", ",", "Papaioannou", ",", "P.", ",", "Taxiltaris", ",", "C.", ",", "Tziavos", ",", "I.:Applications", "of", "GPS", "technology", "in", "the", "land", "transportation", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["As", "can", "be", "seen", "from", "the", "MCC", "scores", "-", "and", "probably", "not", "surprisingly", "-", "our", "classifier", "is", "most", "effective", "if", "all", "studied", "feature", "groups", "are", "taken", "into", "consideration", "(", "i.e.", ",", "feature", "set", "\"", "BCTVY", "\"", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["Using", "this", "method", ",", "SEM", "or", "LOM", "images", "are", "classified", "pixel", "-", "wise", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["We", "measure", "itsquality", "using", "the", "Calibration", "set", "by", "its", "ROC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["We", "use", "the", "common", "phone", "set", "(", "CPS", ",", ")", "to", "work", "with", "the", "languages", "of", "interest", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "common phone set"}, {"tokens": ["The", "information", "can", "range", "from", "video", "characteristics", ",", "such", "as", "frame", "type", ",", "motion", "activity", "and", "play", "-", "out", "time", ",", "and", "network", "information", ",", "such", "as", "delay", "and", "link", "quality", ",", "to", "FEC", "-", "related", "details", ",", "for", "example", ",", "what", "is", "the", "minimum", "number", "of", "packets", "needed", "to", "reconstruct", "the", "original", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Objectives", "correspond", "to", "non", "-", "stochastic2-player", "reachability", "games", ",", "which", "are", "strongly", "MD", "-", "determinedZielonka:1998", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["Earlier", ",", "proposed", "a", "similar", "method", "that", "after", "clustering", "the", "dataset", "by", "using", "-means", ",", "instances", "that", "are", "close", "to", "the", "centroid", "of", "the", "cluster", ",", "which", "they", "belong", "to", ",", "were", "pruned", ",", "and", "LDOF", "was", "used", "merely", "on", "instances", "that", "were", "away", "from", "the", "centroid", ",", "i.e.", ",", "outside", "of", "a", "predefined", "radius", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "local distance - based outlier factor"}, {"tokens": ["The", "CHs", ",", "RNs", ",", "and", "BS", "constitute", "the", "upper", "layer", "building", "blocks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Benchmark", "for", "Three", "Categories", "of", "SepsisWe", "report", "the", "first", "benchmark", "of", "three", "different", "ML", "methods", "i.e.", "LR", ",", "XGB", "and", "RF", "and", "three", "rule", "-", "based", "methods", "i.e.", "SOFA", ",", "qSOFA", ",", "MEWS", "on", "all", "three", "categories", "of", "sepsis", "for", "detection", "and", "prediction", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["[", "Downlink", "-", "dominant", ":", "STA", "Mbps", ",", "AP", "Mbps][PP", "Scenario", ":", "STA", "Mbps", ",", "AP", "Mbps]-st", "round", "collision", "probability", "against", "Figure", "shows", "the", "-nd", "round", "collision", "probability", "against", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["We", "also", "compare", "against", "importance", "sampling", "as", "presented", "in", ",", "which", "we", "refer", "to", "as", "IS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "importance sampling"}, {"tokens": ["show", "that", "for", "the", "API", "and", "intent", "type", "files", ",", "the", "LR", "attack", "performs", "much", "better", "than", "the", "other", "algorithms", "(", "i.e.", ",", "for", "each", "of", "the", "four", "selected", "samples", ",", "the", "LR", "attack", "can", "modify", "the", "features", "of", "one", "of", "them", "in", "such", "a", "way", "to", "fool", "the", "classifier", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["SEM", "uses", "several", "core", "classes", ",", "types", "and", "constrains", "to", "describe", "events", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simple event model"}, {"tokens": ["Rule", "extraction", "over", "all", "the", "data", "points", "using", "a", "DT", "overfitted", "in", "the", "dataset", ",", "using", "the", "features", "as", "input", "and", "the", "anomalous", "/", "non", "-", "anomalous", "labels", "as", "target", "variable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["Figure", "f.samples_kernel_expqua", "shows", "two", "different", "realizations", "sampled", "from", "a", "GP", "with", "kernel", ",", "these", "functions", "evolve", "smoothly", "without", "any", "periodic", "or", "harmonic", "properties", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "also", "evaluate", "how", "well", "our", "model", "is", "performing", "for", "individual", "patients", ";", "our", "model", "exhibits", "relative", "increase", "in", "patient", "-", "wise", "accuracy", "on", "the", "SC", "-", "task", "and", "increase", "on", "the", "RS", "-", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "random split"}, {"tokens": ["OPF", "problems", "are", "typically", "solved", "through", "interior", "-", "point", "methods", ",", "also", "known", "as", "barrier", "methods", "(", "Figure", ",", "left", "panel", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["For", "simplicity", "we", "only", "use", "the", "neural", "networks", "as", "the", "underlying", "ML", "model", "in", "our", "FL", "framework", "for", "illustration", "and", "evaluation", ",", "however", ",", "the", "our", "HybridAlpha", "supports", "various", "ML", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Nevertheless", ",", "DADA", "allows", "to", "significantly", "reduce", "the", "data", "transfers", "with", "respect", "to", "HEFT", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["More", "recently", ",", "other", "authors", "have", "proposed", "and", "studied", "sensing", "strategies", "that", "would", "reduce", "the", "required", "number", "of", "CSS", "measurements", "to", "the", "sparsity", "of", "the", "signal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "compressive spectrum sensing"}, {"tokens": ["On", "the", "other", "hand", ",", "EO", "data", "allow", "to", "produce", "exhaustive", "map", "of", "crop", "areas", "and", "yield", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "earth observation"}, {"tokens": ["An", "ablation", "study", "on", "the", "individual", "stages", "of", "the", "ISP", "reveals", "that", "the", "tone", "mapper", "has", "the", "greatest", "impact", "on", "performance", "for", "models", "trained", "on", "HDR", "images", ",", "providing", "an", "average", "of", "5.8", "accuracy", "improvement", "alone", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["DC", "is", "very", "similar", "to", "JI", ",", "except", "it", "values", "TP", "twice", "as", "much", "as", "FP", "and", "FN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["Another", "disadvantage", "is", "that", "the", "mass", "spring", "system", "has", "less", "stability", "and", "requires", "the", "numerical", "integrator", "to", "take", "small", "time", "stepsBW92", "than", "FEM", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "finite element method"}, {"tokens": ["Even", "the", "low", "transferfootprint", "of", "both", "DADA", "(", ")", "is", "not", "able", "to", "sustain", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["The", "inputs", "of", "DBN", "are", "preprocessed", "data", "calculated", "by", "presence", "and", "past", "signals", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["IC2011)If", "is", "a", "finitely", "branching", "reachability", "game", "then", "there", "is", "an", "MD", "strategy", "that", "is", "optimal", "minimizing", "in", "every", "state(i.e", ".", ",", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["In", "ECS", "-", "DBN", ",", "each", "chromosome", "represents", "misclassification", "costs", "for", "each", "class", ",", "and", "the", "final", "evolved", "best", "chromosome", "is", "chosen", "as", "the", "misclassification", "costs", "for", "ECS", "-", "DBN", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["UDP", "silver", "POS", "and", "topic", "information", "use", "the", "same", "corpus", ",", "taken", "from", "the", "100", "longest", "articles", "in", "Wikipedia", "randomly", "partitioned", "in", "a", "70/10/20", "train", "/", "dev", "/", "test", "split", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Formally:*where", "is", "the", "set", "of", "DSA", "skills", ",", "and", "is", "the", "set", "of", "job", "ads", "associated", "with", "the", "occupation", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["Note", "that", "because", "OPF", "is", "a", "constrained", "optimization", "problem", ",", "the", "solution", "is", "not", "a", "smooth", "function", "of", "the", "grid", "parameters", ",", "so", "properly", "training", "such", "regression", "models", "requires", "substantial", "training", "data", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["The", "intermediate", "layer", "consists", "of", "the", "PNN", "/", "RNN", "that", "we", "pretrained(as", "decribed", "in", "Sections", "pnn", "-", "context", "-", "encoder", "and", "rnn", "-", "session", "-", "model", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["The", "explores", "the", "UNet", "model", "for", "RV", "segmentation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "right ventricle"}, {"tokens": ["f", ")", "Siemens", "SX1", "AR", "game", "\"", "Mozzies", "\"", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["In", "CV", "systems", ",", "it", "is", "not", "clear", "what", "the", "role", "of", "the", "ISP", "is", ",", "or", "if", "it", "is", "even", "required", "at", "all", "for", "accurate", "prediction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["The", "research", "found", "that", "in", "2017", "DSA", "jobs", "earned", "a", "wage", "premium", "of", "more", "than", "US8,700", "and", "DSA", "job", "postings", "were", "projected", "to", "grow", "15", "by", "2020", ",", "which", "is", "significantly", "higher", "than", "average", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["The", "SSIM", "average", "value", "(", "when", "the", "FEC", "schemes", "were", "not", "used", ")", "was", "0.33", "and", "the", "VQM", "value", "was", "8.68", ",", "representing", "low", "-", "quality", "levels", "and", "confirming", "what", "was", "found", "in", "the", "subjective", "assessment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["For", "example", ",", "applied", "DCNN", "to", "map", "meanings", "of", "words", "that", "constitute", "a", "sentence", "to", "that", "of", "documents", "for", "summarization", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic convolutional neural network"}, {"tokens": ["Morphological", "richness", "(", "MR", ")", "is", "calculated", "in", "a", "local", "neighbourhood", "of", "each", "pixel", "with", "a", "radius", "of", "3", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "morphological richness"}, {"tokens": ["This", "was", "caused", "by", "the", "fact", "that", "CDA", "'s", "name", "was", "presented", "unabbreviated", ":", "Christen", "Democratisch", "Appel", ",", "which", "was", "the", "only", "party", "with", "a", "special", "character", "(", "e", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "christen democratisch appel"}, {"tokens": ["Using", "a", "wide", "range", "of", "DC-", "and", "AC", "-", "OPF", "problems", "we", "demonstrate", "that", "optimizing", "this", "meta", "-", "loss", "objective", "results", "in", "a", "classifier", "that", "significantly", "outperforms", "conventional", "loss", "functions", "used", "to", "train", "neural", "network", "classifiers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["It", "receives", "a", "transaction", "packet", "for", "the", "delivery", "operation", "that", "contains", "the", "GPS", "coordinates", "and", "the", "identifier", "of", "a", "package", "docking", "device", "associated", "with", "the", "order", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["While", "BSP", "is", "reasonably", "fast", ",", "we", "also", "include", "it", "in", "our", "experiments", "to", "compare", "its", "performance", "with", "other", "approaches", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["2", ")", "For", "OLS", ",", "the", "first", "atom", "selected", "is", ",", "since", "OMP", "and", "OLS", "are", "the", "same", "in", "the", "first", "iteration", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["We", "shall", "defer", "actual", "inference", "to", "Section", ",", "and", "first", "examine", "the", "extensions", "and", "variants", "of", "SBM", "in", "the", "following", "section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["We", "show", "that", "a", "reachability", "game", "is", "strongly", "MD", "-", "determined", "if", "any", "of", "the", "properties", "listed", "above", "is", "not", "satisfied", ":", "theoremthm", ":", "reachabilityFinitely", "branching", "games", "with", "reachability", "objectivesare", "strongly", "MD", "-", "determined", ",", "provided", "that", "at", "least", "one", "of", "the", "followingconditions", "holds", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["If", "Satisfactory", ":", "ACCEPT", "Else", ":", "REJECT", "tabularPseudocode", "describing", "the", "acceptance", "and", "rejection", "rules", "in", "the", "SCF", "algorithmTBLpseudocodetableIn", "this", "algorithm", ",", "a", "proposal", "(", "with", ")", "will", "only", "beaccepted", "if", "the", "SBM", "-", "acceptance", "succeeds", "and", "if", "the", "satisfies", "the", "constraint", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["For", "comprehensive", "performance", "comparison", ",", "FAN", "is", "compared", "with", "18", "existing", "methods", "and", "the", "AN", "model", "implemented", "with", "a", "ResNet", "-", "based", "encoder", ",", "which", "is", "taken", "as", "the", "baseline", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["Nevertheless", ",", "it", "is", "still", "possible", "that", "some", "sites", "find", "it", "attractive", "to", "obtain", "PI", "blocks", "in", "the", "secondary", "market", ",", "and", "negatively", "impacting", "the", "global", "routing", "table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["Similar", "to", ",", "the", "user", "selects", "the", "BS", "with", "the", "highest", "SNR", "in", "the", "candidate", "BSs", "caching", "the", "requested", "files", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "additional", "information", "transmission", "by", "different", "OAM", "modes", "boosts", "up", "the", "SC", "of", "the", "proposed", "scheme", "than", "other", "schemes", "significantly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["and", ",", "and", "mean", "reward", "performance", "in", "RL", "(", "using", "PPO", ")", "per", "episode", "after", "2", "millions", "steps", ",", "with", "standard", "error", "for", "each", "SRL", "method", "in", "mobile", "robot", "with", "random", "target", "environment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["The", "fundamental", "building", "block", "of", "DBN", "is", "an", "RBM", "which", "consists", "of", "one", "visible", "layer", "and", "one", "hidden", "layer", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["However", ",", "in", "our", "case", ",", "there", "is", "not", "a", "traditional", "PAP", ",", "because", "there", "is", "no", "central", "authority", "managing", "the", "policies", ",", "being", "each", "one", "of", "the", "document", "keepers", "managers", "of", "their", "own", "documents", ",", "working", "as", "a", "distributed", "PAP", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "policy administration point"}, {"tokens": ["We", "observe", "the", "change", "of", "FP", "rate", "and", "TP", "rate", "with", "the", "number", "of", "acquaintances", "consulted", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["Since", "differs", "only", "slightly", "in", "the", "amplitude", "from", "the", "general", "pattern", ",", "these", "dictionaries", "seem", "insufficient", "to", "capture", "this", "fine", "dissimilarity", ":", "while", "Self", "and", "DI", "dictionaries", "simply", "do", "not", "contain", "enough", "elements", ",", "UI", "dictionary", "is", "to", "simple", "to", "capture", "this", "difference", "(", "it", "shares", "this", "feature", "with", "DI", "dictionary", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "uniform indicator"}, {"tokens": ["Define", "for", "each", "as", "the", "set", "of", "unfixed", "nodes", "that", "play", "in", "the", "SSS", "for", "and", "play", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "stochastically stable states"}, {"tokens": ["We", "compared", "different", "strategies", "to", "predict", "the", "MVF", "in", "the", "experiments", "and", "found", "that", "the", "U", "/", "V", "information", "can", "be", "useful", "as", "prior", "knowledge", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["The", "related", "definitions", "for", "the", "LB", "divergence", "are", "briefly", "summarized", "as", "follows", ":"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": [":", "This", "is", "an", "operation", "system", "specific", "problem", ",", "and", "can", "not", "be", "solved", "for", "any", "OS", "at", "once", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "operating system"}, {"tokens": ["if", "we", "integrate", "the", "right", "-", "left", "and", "down", "-", "top", "directional", "sequences", "of", "features", "to", "generate", "the", "final", "feature", "sequence", ",", "the", "visual", "features", "of", "'", "p", "'", "and", "'d", "'", "will", "be", "frame", "-", "wisely", "mixed", "up", "due", "to", "the", "weighting", "mechanism", "of", "FG", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "filter gate"}, {"tokens": ["To", "keep", "the", "number", "of", "computational", "parameters", "low", "compared", "to", "other", "traditional", "DCNN", "approaches", "like", "AlexNet", "and", "VGGNet", ",", "we", "have", "used", "only", "and", "convolutional", "filters", "in", "this", "implementation", "(", "inspired", "by", "the", "NiN", "and", "Squeeze", "Net", "models", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["In", "short", ",", "the", "proposed", "ECS", "-", "DBN", "approach", "is", "both", "efficient", "and", "effective", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["A", "student", "distilled", "from", "a", "robust", "teacher", "is", "more", "robust", "than", "a", "naturally", "trained", "network", ",", "but", "ARD", "produces", "a", "more", "robust", "network", "than", "either", "and", "closely", "mimics", "the", "teacher", "'s", "decision", "boundary", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Decoding", "probability", ",", ",", "versus", "the", "number", "of", "relay", "nodes", ",", ",", "over", "IID", "Nakagami-", "fading", "channels", "with", "different", "values", "of", "and", ":", "(", "A", ")", "Repetitive", "and", "(", "B", ")", "RS", "-", "based", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Optimization", "without", "a", "meta", "-", "model", "(", "DE", ")", "and", "a", "meta", "-", "model", "with", "different", "surrogate", "-", "relevator", "pairs", "(", "each", "column", "corresponds", "to", "one", "of", "the", "methods", "for", "learning", "the", "relevator", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Experimental", "results", "demonstrate", "the", "effectiveness", "and", "superior", "classification", "accuracy", "of", "the", "proposed", "DDE", "-", "MGM", "in", "an", "online", "setting", "as", "compared", "to", "the", "state", "-", "of", "-", "the", "-", "art", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Note", "that", "the", "run", "time", "of", "DDE", "-", "MGM", "in", "the", "online", "testing", "is", "longer", "than", "that", "in", "the", "offline", "testing", "because", "the", "offline", "testing", "performs", "training", "and", "testing", "each", "on", "half", "of", "the", "dataset", ",", "while", "the", "online", "testing", "trains", "and", "tests", "alternatively", "on", "the", "whole", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["OT", "Extension", "Phase", "II", ":", "sends", "the", "input", "of", ",", "namely", "(", "such", "that", "each", ")", "to", "functionality", "on", "behalf", "of", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "GENIA", "corpus", "is", "similar", "to", "the", "LSC", "in", "terms", "of", "the", "content", "of", "texts", ",", "both", "contain", "the", "abstracts", "of", "scientific", "papers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["The", "main", "feature", "of", "CSS", "is", "that", "signals", "with", "different", "SFs", "can", "be", "distinguished", "and", "received", "simultaneously", ",", "even", "if", "they", "are", "transmitted", "at", "the", "same", "time", "on", "the", "same", "channel", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "chirp spread spectrum"}, {"tokens": ["The", "pad", "used", "to", "mask", "the", "th", "message", "in", "th", "extended", "OT", "is", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["What", "'s", "more", ",", "the", "number", "of", "cooperative", "SBSs", "of", "UE", "is", "calculated", "byThe", "average", "number", "of", "cooperative", "SBSs", "is", "further", "calculated", "byLetting", ",", "the", "average", "achievable", "rate", "with", "distance", "constraint", "considering", "the", "same", "number", "of", "cooperative", "SBSs", "is", "expressed", "aswithThe", "increment", "in", "the", "average", "achievable", "rate", "compared", "the", "received", "signal", "power", "constraint", "with", "the", "distance", "constraint", "considering", "same", "number", "of", "cooperative", "SBSs", "is", "given", "byNetwork", "Energy", "EfficiencyThe", "average", "achievable", "rate", "can", "be", "improved", "by", "adopting", "SBS", "cooperation", "strategies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["This", "study", "resembles", "previous", "work", "on", "shilling", "attacks", "on", "CF", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Recently", ",", "a", "combination", "of", "low", "-", "rank", "approximations", "and", "Kronecker", "algebra", "was", "proposed", "to", "scale", "MT", "-", "GPR", "to", "whole", "brain", "neuroimaging", "data", "kia2018normative", ",", "kia2018scalable", ",", "which", "reduces", "the", "computational", "complexity", "with", "respect", "to", "the", "number", "of", "tasks", "by", "one", "order", "of", "magnitude", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process regression"}, {"tokens": ["In", "essence", ",", "OT", "metric", "maps", "the", "comparison", "of", "two", "distributions", "on", "high", "-", "dimensional", "feature", "space", "onto", "a", "lower", "dimension", "space", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["The", "CH", "is", "connected", "with", "a", "set", "of", "nodes", "and", "for", "that", "set", "it", "acts", "like", "a", "bridge", ",", "re", "-", "broadcasting", "the", "firing", "signals", "from", "the", "single", "nodes", "to", "all", "the", "nodes", "it", "has", "in", "its", "communication", "range", ":", "in", "this", "way", ",", "the", "CH", "basically", "emulates", "an", "all", "-", "to", "-", "all", "connected", "network", "among", "the", "nodes", "it", "communicates", "with", ",", "generating", "a", "clique", "in", "the", "graph", "topology", "of", "our", "network", ".", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cluster head"}, {"tokens": ["Note", "that", "in", "scenario", "(", "b", ")", ",", "each", "MS", "just", "maintains", "own", "queue", "that", "backlogs", "the", "packets", "to", "be", "sent", "directly", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["In", "the", "2D", "wireframe", "depiction", ",", "the", "diagrammatic", "syntax", "used", "specifies", "that", "the", "CD", "corresponds", "to", "the", "CG", "in", "that", ",", "for", "each", "edge", "there", "is", "a", "corresponding", "line", ",", "and", "for", "each", "vertex", "there", "is", "a", "corresponding", "corner", "or", "line", "ending", "in", "the", "CD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "chemical diagram"}, {"tokens": ["c", "Strategy", "&", "AR@100", "&", "AR@S", "&", "AR@M", "&", "AR@L", "Baseline", "&", "68.51", "&", "49.07", "&", "62.93", "&", "75.64", "dyTrainScale", "&", "72.58", "&", "53.41", "&", "66.34", "&", "78.83", "equilibrium", "&", "69.85", "&", "50.49", "&", "63.55", "&", "76.88", "grayCls", "&", "69.77", "&", "50.21", "&", "63.19", "&", "77.04", "ZIP", "+", "all", "&", "74.22", "&", "54.39", "&", "68.47", "&", "81.53", "ZIP", "+", "all", "+", "MAD", "&", "76.51", "&", "57.28", "&", "70.05", "&", "84.21", "blackspatial", "MAD", "&", "76.50", "&", "57.11", "&", "70.13", "&", "84.09"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["The", "preventive", "performance", "of", "RV", "strategy", "with", "this", "range", "of", "vaccination", "rate", "is", "very", "poor", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["&", "&", "UCSD", "to", "&", "Mall", "to", "Method", "&", "Mall", "&", "UCSD", "FA", "&", "7.47", "&", "4.44", "HGP", "&", "4.36", "&", "3.32", "GPA", "&", "4.18", "&", "2.79", "GPTL", "&", "3.55", "&", "2.91", "Bidirectional", "ConvLSTM", "&", "2.63", "&", "1.82", "-2em"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process adaptation"}, {"tokens": ["Also", ",", "as", "it", "can", "be", "seen", ",", "in", "a", "dense", "blocking", "environment", ",", "typical", "UE", "is", "served", "more", "likely", "by", "LOS", "SBS", "and", "as", "the", "density", "of", "blocking", "are", "decreasing", ",", "the", "probability", "that", "typical", "UE", "is", "associated", "by", "LOS", "MBS", "is", "more", "than", "LOS", "SBS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["OUTIS", "provides", "an", "architecture", "for", "differential", "privacy", "that", "does", "not", "need", "any", "trusted", "third", "party", "data", "curator", "like", "the", "CDP", "but", "still", "achieves", "the", "accuracy", "guarantees", "and", "algorithmic", "expressibility", "like", "in", "the", "CDP", "approach", ",", "which", "gives", "the", "possibility", "of", "\"", "best", "of", "both", "the", "world", "\"", "in", "LDP", "and", "CDP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "centralized differential privacy"}, {"tokens": ["Area", "Under", "the", "ROC", "Curve", "is", "very", "useful", "as", "performance", "metric", "for", "class", "imbalance", "problems", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["zequationLet", "us", "perform", "the", "partial", "derivative", "of", "with", "respect", "to", "weights", "and", "bias", "where", "represents", "the", "ANN", "output", "layer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Results", "discussed", "in", "section", "show", "that", "TS", "outperformed", "all", "other", "feature", "selection", "method", "by", "improving", "classifier", "accuracy", "sufficiently", "at", "reduced", "feature", "space", "by", "60", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["The", "authors", "proposed", "a", "novel", "delay", "-", "sensitive", "approach", "by", "associating", "the", "delay", "-", "sensitive", "users", "to", "the", "macro", "BS", "and", "the", "other", "users", "to", "either", "the", "macro", "BS", "or", "DBSs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "Section", "III", ",", "the", "PA", "strategy", "for", "Max", "-", "SR", "is", "proposed", "and", "its", "closed", "-", "form", "expression", "is", "given", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["AR", "system", "needs", "to", "deal", "with", "vast", "amount", "of", "information", "that", "exists", "in", "the", "real", "world", "which", "requires", "very", "quick", "and", "portable", "hardware", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Dropout", "DetailsWe", "make", "two", "relatively", "simple", "extensions", "of", "dropout", "for", "NLM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "neural language modelling"}, {"tokens": ["table*[t]Accuracy", "on", "Target", "SP", "Stringsets", "after", "100", "Epochstab", ":", "resultsSP4.5pttabularcccccccccc2c2Training", "&", "2Test", "&", "3cLSTM", "&", "3cs", "-", "RNN", "&", "2RPNI", "&", "&", "&", "10", "&", "30", "&", "100", "&", "10", "&", "30", "&", "100", "&", "6SP2", "&", "21k", "&", "1", "&", "0.847", "(", "0.06", ")", "&", "0.935", "(", "0.07", ")", "&", "0.952", "(", "0.07", ")", "&", "0.910", "(", "0.05", ")", "&", "0.999", "(", "0.00", ")", "&", "0.999", "(", "0.00", ")", "&", "1.000", "&", "&", "2", "&", "0.873", "(", "0.10", ")", "&", "0.951", "(", "0.08", ")", "&", "0.947", "(", "0.08", ")", "&", "0.976", "(", "0.01", ")", "&", "1.000", "(", "0.00", ")", "&", "1.000", "(", "0.00", ")", "&", "1.000", "3", "-", "10", "&", "210k", "&", "1", "&", "0.734", "(", "0.12", ")", "&", "0.673", "(", "0.04", ")", "&", "0.720", "(", "0.03", ")", "&", "0.937", "(", "0.13", ")", "&", "0.960", "(", "0.08", ")", "&", "0.972"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["because", "(", "a", ")", "CMI", "directly", "considers", "the", "dependency", "between", "the", "selection", "and", "multiple", "-", "possible", "text", "while", "limiting", "the", "ratio", "aims", "at", "finding", "the", "single", "most", "salient", "parts", "for", "each", "source", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "conditional mutual information"}, {"tokens": ["We", "build", "GBM", "classifiers", "for", "all", "the", "feature", "sets", "explained", "in", "Section", "tran", "and", "trad", "using", "GBM", "implementation", "inspired", "by", "Becker:2013", ",", "with", "parameters", ":", "shrinkage", "factor", "and", "sampling", "factor", "set", "to", "0.5", ",", "maximum", "tree", "depth", "=", "2", "and", "number", "of", "iterations", "=", "200", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["That", "work", "found", "that", "drivers", "'", "awareness", ",", "use", ",", "and", "perceived", "safety", "of", "BSD", "was", "greater", "than", "that", "of", "ACC", ",", "and", "contributed", "to", "a", "greater", "understanding", "of", "driver", "preparation", "and", "acceptance", "of", "ADAS", ",", "and", "how", "drivers", "learn", "and", "prefer", "to", "learn", "about", "ADAS", ",", "and", "what", "their", "expectations", "are", "regarding", "ADAS", "and", "vehicle", "automation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adaptive cruise control"}, {"tokens": ["Adversarial", "examples", "created", "with", "the", "same", "technique", "also", "degrade", "mAP", "of", "Objects", "to", "32.9", "and", "AP", "of", "text", "localization", "to", "20.9", ",", "and", "with", "barely", "4.1", "accuracy", "in", "recognizing", "words", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["All", "figures", "are", "plotted", "for", "the", "parameters", ",", "and", "due", "to", "Rician", "fading", "channel", "[", "25,27].", "CCU", "(", ")", "capacity", "behavior", "with", "respect", "to", "(", "w.r.t", ")", "transmit", "SNR", "is", "demonstrated", "in", "Figure", "3", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "[", "22].", "Parameters", ",", ",", ",", ",", ",", ",", "and", "are", "set", "during", "the", "simulation", "purpose", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["However", ",", "COLS", "iteratively", "select", "each", "of", "the", "atom", "as", "the", "first", "atom", "and", "remaining", "atoms", "are", "selected", "based", "on", "OLS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "orthogonal least square"}, {"tokens": ["In", "addition", ",", "the", "proposed", "method", "can", "be", "applied", "to", "detect", "human", "keypoints", "in", "LR", "in", "order", "to", "improve", "skeletal", "action", "recognition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Quite", "a", "few", "recent", "works", "built", "upon", "the", "DC", "-", "SBM", "in", "various", "ways", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Conclusion", "and", "Future", "WorkIn", "this", "paper", ",", "we", "took", "a", "pragmatic", "view", "of", "computational", "AA", "to", "highlight", "the", "critical", "role", "it", "could", "play", "in", "authorship", "attribution", "studies", "involving", "historical", "texts", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["So", "the", "main", "gap", "between", "the", "CDP", "and", "the", "LDP", "approach", "is", "mainly", "of", "four", "kinds", ",", "like", "-", "differencein", "necessary", "amount", "of", "data", "to", "produce", "a", "good", "population", "distri", "-", "bution", "statistics", ",", "storage", "of", "data", ",", "difference", "in", "speed", ",", "last", "but", "not", "the", "least", "difference", "in", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["Problem", "FormulationIn", "some", "application", "scenarios", "where", "the", "power", "consumption", "of", "the", "AP", "is", "of", "great", "concern"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Given", "the", "DC", "-", "OPF", "is", "a", "linear", "problem", "we", "can", "draw", "some", "qualitative", "conclusions", "regarding", "the", "system", "size", "and", "gain", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["One", "possible", "remedy", "for", "this", "problem", "is", "to", "approximate", "the", "posterior", "distribution", "of", "a", "probabilistic", "model", "with", "hidden", "variables", "in", "the", "stochastic", "variational", "inference", "framework", "hoffman2013stochastic.talvarez2010efficient", "made", "the", "first", "effort", "in", "employing", "variational", "inference", "in", "MT", "-", "GPR", "by", "introducing", "the", "variational", "inducing", "kernels", "that", "achieves", "a", "linear", "time", "complexity", "with", "respect", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process regression"}, {"tokens": ["Illustration", "of", "chromosome", "encoding", "and", "evolution", "process", "in", "ECS", "-", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "directed belief net"}, {"tokens": ["DispatcherIn", "our", "scenario", ",", "the", "Dispatcher", "works", "as", "a", "gateway", ",", "passing", "along", "the", "measurements", "received", "from", "the", "MDC", "application", "to", "the", "message", "bus", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "metering data collector"}, {"tokens": ["The", "lower", "layer", ",", "executed", "at", "10", "s", "resolution", ",", "has", "the", "objective", "of", "pursuing", "an", "accurate", "tracking", "of", "the", "dispatch", "plan", "at", "the", "GCP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "grid connection point"}, {"tokens": ["IDC", ":", "in", "-", "degree", "centrality", ",", "BC", ":", "betweenness", "centrality", ",", "CC", ":", "closeness", "centrality", ",", "EC", ":", "eigenvector", "centrality", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "closeness centrality"}, {"tokens": ["Accordingly", ",", "almost", "all", "of", "the", "convolutional", "layers", "can", "be", "shared", "in", "the", "MD", "multi", "-", "scale", "-", "dilated", "encoder", "network", "except", "for", "the", "last", "layers", ",", "to", "create", "different", "kinds", "of", "tensors", "(", "See", "the", "MD", "multi", "-", "scale", "-", "dilated", "encoder", "network", "in", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["Next", ",", "it", "computes", "and", "using", "ECC", "point", "multiplication", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["If", "this", "polynomial", "is", ",", "then", "the", "corresponding", "MVF", "consists", "of", "the", "vectors", "and", "vectors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching vector families"}, {"tokens": ["Pattern", "search", "MDS", "is", "formulated", "as", "an", "instance", "of", "the", "wider", "family", "of", "GPS", "methods", ",", "thus", "providing", "theoretical", "guarantees", "of", "convergence", "up", "to", "a", "fixed", "point", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["However", ",", "this", "prior", "work", "ignored", "the", "computation", "delay", "of", "local", "FL", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["Secondly", ",", "we", "use", "the", "training", "set", "to", "train", "a", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["They", "simply", "imply", "a", "pattern", "in", "the", "congestion", "rates", "of", "the", "corresponding", "ISP", "and", "ASN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "internet service providers"}, {"tokens": ["This", "work", "considered", "the", "problem", "of", "computational", "personalization", "in", "the", "context", "of", "long", "-", "term", "real", "-", "world", "SAR", "interventions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["It", "is", "revealed", "that", "RS", "provides", "an", "increase", "in", "the", "range", "of", "SI", "over", "which", "FD", "outperforms", "HD", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["Classification", "error", "rates", "over", "ANN", "-", "evaluations", "on", "the", "Digits", "dataset", "using", "the", "DE", "-", "variants", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["In", "other", "words", ",", "each", "dot", "in", "Fig", "represents", "the", "required", "GP", "number", "of", "iterations", "for", "a", "specific", "BPSO", "iteration", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["We", "maximize", "the", "dual", "concave", "IB", "Lagrangian", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["From", "the", "rate", "curve", "we", "select", "the", "C", "-", "rate", "of", "the", "CC", "phase", "SOC", "boundary", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["UE", "is", "a", "popular", "game", "engine", "and", "has", "a", "broad", "influence", "in", "the", "game", "industry", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "unreal engine"}, {"tokens": ["This", "is", "unlike", "in", "the", "-", "PS", "queue", "approximation", "where", "two", "customers", "arriving", "at", "the", "same", "time", "have", "positively", "associated", "delays", "as", "both", "of", "them", "will", "be", "competing", "for", "the", "same", "spectrum", "resource", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "processor sharing"}, {"tokens": ["Beside", "the", "PAP", "monitoring", "and", "estimation", "functions", "the", "additional", "thread", "can", "be", "used", "for", "other", "purposes", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["The", "latter", "adopts", "error", "correction", ",", "which", "can", "be", "ARQ", "or", "FEC", "and", "a", "combination", "between", "both", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Data", "consist", "of", "samples", "from", "the", "underlying", "density", "sampled", "from", "the", "GP", "density", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Any", "opinions", ",", "findings", ",", "conclusions", ",", "or", "recommendations", "expressed", "in", "this", "material", "are", "those", "of", "the", "authors", "and", "do", "not", "necessarily", "reflect", "the", "views", "of", "the", "NSF", ",", "the", "TRI", ",", "any", "other", "Toyota", "entity", ",", "or", "others", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "toyota research institute"}, {"tokens": ["The", "upper", "bound", "AP", "on", "COCO", "is", "about", "78.2", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "main", "feature", "of", "CSS", "is", "that", "signals", "with", "different", "SFs", "can", "be", "distinguished", "and", "received", "simultaneously", ",", "even", "if", "they", "are", "transmitted", "at", "the", "same", "time", "on", "the", "same", "channel", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "chirp spread spectrum"}, {"tokens": ["As", "discussed", "earlier", "that", "the", "design", "of", "other", "BC", "technologies", "runs", "the", "smart", "contracts", "on", "all", "the", "peers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["It", "has", "been", "shown", "that", "binary", "hashing", "based", "ANN", ",", "which", "indexes", "data", "points", "into", "binary", "codes", "and", "retrieves", "data", "points", "in", "Hamming", "space", ",", "often", "has", "good", "enough", "performance", "for", "many", "real", "world", "applications", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "approximate nearest neighbor"}, {"tokens": ["It", "is", "not", "possible", "to", "combine", "ML", "-", "BPNN", "and", "HOMER", "(", "which", "is", "described", "by", "META", "-", "MLC4", ")", "because", "of", "a", "constraint", "of", "the", "MEKA", "software", ",", "which", "allows", "justBR", ",", "CC", "and", "LP", "as", "the", "algorithms", "at", "the", "multi", "-", "label", "base", "level", "of", "HOMER", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classifier chain"}, {"tokens": ["An", "experiment", "is", "set", "up", "to", "evaluate", "the", "duty", "cycle", "adaptation", "algorithm", "performance", "considering", "LTE", "-", "U", "and", "Wi", "-", "Fi", "coexistence", "on", "the", "same", "unlicensed", "20", "MHz", "channel", "in", "the", "5", "GHz", "band", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "addition", ",", "we", "find", "that", "the", "most", "difficult", "case", ",", "i.e.", ",", "random", "labeled", "data", ",", "leads", "to", "quite", "large", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "cover complexity"}, {"tokens": ["It", "is", "evident", "from", "these", "experiments", "that", "networks", "trained", "with", "HR", "images", "or", "subsampled", "images", "are", "not", "effective", "for", "real", "life", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["is", "transmitting", "from", "BS", "to", "in", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Hsieh", "and", "Su", ",", "proposed", "a", "new", "PSO", "algorithm", "based", "on", "Q", "-", "learning", "for", "solving", "the", "ELD", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["We", "are", "inspired", "by", "these", "works", "in", "sense", "that", "OT", "metric", "is", "favorably", "competitive", "to", "measure", "the", "divergence", "between", "two", "distributions", "supported", "on", "low", "-", "dimensional", "manifolds", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Conclusions", "and", "Future", "WorkIn", "this", "paper", ",", "we", "propose", "five", "different", "attack", "algorithms", ":", "a", "trivial", "algorithm", ",", "a", "benign", "distribution", ",", "KNN", ",", "LR", ",", "and", "a", "bio", "-", "inspired", "method", "based", "on", "the", "ant", "colony", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["To", "show", "the", "potential", "of", "our", "approach", ",", "we", "investigate", "two", "sequence", "labeling", "tasks", ":", "cross", "-", "language", "POS", "tagging", "and", "multilingual", "Super", "Sense", "Tagging", "(", "SST", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["This", "paper", "presents", "a", "comprehensive", "survey", "of", "the", "application", "of", "PSO", "in", "solving", "ELD", "problems", "in", "electric", "power", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Point", "CloudsThere", "are", "some", "airborne", "instruments", "that", "can", "give", "direct", "or", "indirect", "point", "-", "cloud", "measurements", "e.g.", "the", "laser", "scanner", "and", "SAR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["In", "Algorithm", "1", ",", "we", "can", "see", "that", ",", "at", "every", "FL", "iteration", ",", "each", "user", "downloads", "the", "global", "FL", "model", "parameters", "from", "the", "BS", "for", "local", "computing", ",", "while", "the", "BS", "periodically", "gathers", "the", "local", "FL", "model", "parameters", "from", "all", "users", "and", "sends", "the", "updated", "global", "FL", "model", "parameters", "back", "to", "all", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["SLAtlas", "produces", "reconstructions", "looking", "convincing", "on", "first", "sight", "but", "when", "looking", "at", "them", "on", "the", "2D", "view", "we", "can", "see", "that", "it", "involves", "severe", "oversegmentation", "(", "e.g.", "segmenting", "gray", "matter", "and", "non", "-", "brain", "area", "for", "the", "CST", ")", "and", "slightly", "shifted", "tracts", "(", "e.g.", "CA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "corticospinal tract"}, {"tokens": ["Surprisingly", ",", "LOM", "can", "achieve", "a", "pixel", "accuracy", "of", "matrix", "with", "94.11", "which", "is", "comparable", "to", "the", "SEM", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Based", "on", "the", "built", "GP", ",", "we", "can", "select", "the", "next", "point", "via", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Related", "WorkComputational", "AA", "has", "offered", "compelling", "analyses", "of", "well", "-", "known", "documents", "with", "unknown", "or", "disputed", "attribution", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["We", "established", "a", "communication", "channel", "between", "the", "CC", "computer", "and", "the", "Intel", "Edison", "SoC", "using", "its", "WiFi", "interface", "over", "a", "hot", "-", "spot", "that", "was", "opened", "from", "a", "mobile", "phone", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "covert channels"}, {"tokens": ["A", "new", "node", "is", "chosen", "if", "it", "shows", "disassortativeness", "with", "the", "node", "and", "having", "less", "BC", "value", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["shortagesThis", "research", "has", "found", "evidence", "of", "DSA", "skill", "shortages", "for", "the", "'", "Data", "Scientists", "and", "Advanced", "Analysts", "'"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["The", "barrier", "-", "to", "-", "exit", "for", "a", "RS", "as", "a", "whole", "we", "define", "as", "the", "average", "of", "the", "BtE", "scores", "for", "all", "represented", "categories", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["The", "Con", "-", "TS", "-", "RTP", "algorithm", "permits", "day", "-", "varying", "target", "load", "profiles", "and", "takes", "into", "account", "the", "actual", "operational", "constraints", "of", "a", "distribution", "system", "to", "ensure", "that", "the", "customers", "receive", "adequate", "service", "and", "to", "avoid", "potential", "grid", "failures", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Our", "null", "results", "stand", "in", "contrast", "to", "studies", "of", "GM", "foods", "and", "nanotechnology", ",", "where", "trust", "in", "institutions", "that", "develop", "and", "regulate", "the", "technology", "is", "associated", "with", "greater", "support", "for", "the", "technology", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "genetically modified"}, {"tokens": ["For", "an", "ENF", "signal", ",", "CF", "is", "measured", "as", "the", "ratio", "of", "the", "peak", "value", "to", "the", "root", "mean", "square", "(", "rms", ")", "value", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "crest factor"}, {"tokens": ["A", "DBN", "based", "framework", "with", "automatic", "feature", "learning", "is", "a", "typical", "deep", "learning", "approach", "solution", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["For", "short", "-", "axis", "images", ",", "LV", ",", "myocardium", "and", "RV", "were", "manually", "annotated", "by", "experienced", "image", "analysts", "at", "ED", "and", "ES", "frames", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["Results", "w/o", "a", "part", "of", "our", "proposed", "methods", ",", "TSGD", ",", "QA", ",", "and", "SE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "quantum annealing"}, {"tokens": ["AR", "vs", "Number", "of", "Proposals", "is", "shown", "in", "Figure", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average recall"}, {"tokens": ["The", "reports", "from", "the", "UE", "include", "detected", "cells", "and", "CSI", "to", "facilitate", "rate", "adaptation", ",", "cell", "selection", "and", "MC", "configuration", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Without", "additional", "modifications", ",", "the", "performance", "of", "FA", "was", "substantially", "worse", "than", "BP", "in", "contrast", "to", "the", "earlier", "experiments", "on", "fully", "-", "connected", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["The", "results", "indicate", "that", "the", "methods", "can", "be", "used", "complementary", ",", "and", "that", "such", "a", "combination", "has", "a", "large", "positive", "impact", "on", "QA", "performance", ",", "and", "also", "facilitates", "additional", "features", "such", "as", "data", "exploration", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "fitness", "function", "computation", "of", "GA", "-", "SCP", "is", "given", "in", "Algorithm-1", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["Since", "the", "number", "of", "nodes", "communicating", "with", "the", "BS", "in", "a", "short", "time", "is", "small", "in", "NAP", "scenario", ",", "we", "increase", "the", "data", "payload", "to", "300", "KB", "in", "order", "to", "explore", "the", "limits", "of", "the", "scheduling", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["For", "each", "of", "these", "users", ",", "we", "calculated", "a", "unique", "participation", "token", "that", "would", "allow", "us", "to", "identify", "them", "when", "they", "took", "the", "questionnaire", ",", "so", "that", "we", "could", "give", "them", "their", "pre", "-", "calculated", "CF", "recommendations", "when", "they", "participated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["For", "EAP", ",", "takes", "normally", "a", "higher", "value", ",", "i.e.", ",", "often", "between", "and", "percentile", "of", "the", "pairwise", "similarity", "values", "in", ",", "than", "AP", "where", "is", "normally", "equal", "to", "the", "median", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["However", ",", "we", "observe", "very", "low", "values", "in", "real", "-", "world", "scenarios", ":", "in", "our", "case", ",", "considered", ",", "PS", "ranges", "from", "0.047", "to", "0.15", ",", "which", "we", "argue", "is", "not", "enough", "to", "promote", "or", "demote", "products", "attacked", "by", "the", "spammers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "prediction shift"}, {"tokens": ["It", "is", "likely", "that", ",", "in", "the", "next", "generation", "802.11", "standard", ",", "an", "extended", "RTS", "/", "CTS", "exchange", "will", "be", "used", "to", "signal", "and", "protect", "MU", "-", "MIMO", "frames", ",", "which", "would", "mean", "the", "AP", "-", "coordinated", "approach", "will", "be", "adopted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["As", "a", "result", ",", "the", "SC", "of", "the", "proposed", "system", "is", "also", "enhanced", "significantly", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["The", "analysis", "of", "both", "spectral", "and", "spatial", "features", "leads", "to", "a", "CCR", "increase", "of", "at", "least", "20", "when", "compared", "to", "previous", "algorithms", "in", "the", "unlabeled", "image", "scenario", ",", "and", "a", "CCR", "drop", "smaller", "than", "3", "when", "compared", "to", "HOSVD", "analysis", "with", "prior", "labeling", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["Phase", "change", "memory", "(", "PCM", ")", "can", "also", "be", "another", "alternative", "for", "secured", "NVM", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phase change memory"}, {"tokens": ["TS", "-", "RF", "achieved", "better", "accuracy", "at", "less", "number", "of", "features", "as", "compared", "to", "GA", "-", "LR", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["For", "example", ",", "MOOSE", "is", "the", "initially", "proposed", "CF", "-", "based", "tracking", "method", ",", "which", "uses", "grayscale", "images", "to", "train", "the", "regression", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correlation filter"}, {"tokens": ["The", "smartphone", "'s", "UI", "system", "consists", "of", "a", "number", "of", "threads", "running", "concurrently", "with", "a", "shared", "address", "space", ",", "and", "we", "aim", "to", "verify", "that", "as", "a", "whole", "it", "satisfies", "the", "security", "requirement", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user interface"}, {"tokens": ["According", "to", "3GPP", ",", "it", "is", "expected", "that", "the", "LTE", "-", "U", "BS", "will", "adjust", "its", "duty", "cycle", "from", "33", "to", "50", "when", "one", "of", "the", "APs", "is", "turned", "off", ",", "and", "vice", "versa", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["It", "can", "be", "hypothesized", "that", "possibly", ",", "the", "super", "-", "resolved", "images", "do", "not", "lie", "in", "the", "same", "space", "of", "images", "using", "which", "HR", "-", "LD", "was", "trained", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["With", "the", "th", "row", "of", "the", "matrix", ",", "the", "sender", "creates", "pads", "for", "the", "messages", "in", "the", "th", "extended", "OT", "as", "follows", ":", "where", "is", "a", "random", "oracle", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["In", "the", "NNNF", "strategy", "the", "nearest", "user", "to", "the", "BS", "is", "selected", "as", "a", "near", "user", "where", "increasing", "will", "not", "change", "its", "position", "notably", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "self", "preference", "in", "conjunction", "with", "the", "consistency", "constraint", ",", "which", "motivates", "compact", "clusters", ",", "acts", "as", "a", "soft", "initial", "guidance", "for", "AP", "to", "determine", "the", "number", "of", "clusters", "needed", "for", "the", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["African", "swine", "fever", "(", "ASF", ")", "is", "a", "highly", "contagious", "infection", "that", "poses", "as", "a", "threat", "for", "the", "pork", "industry", "due", "to", "its", "high", "mortality", "and", "no", "effective", "vaccine", "or", "cure", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "african swine fever"}, {"tokens": ["We", "observe", "that", "selection", "through", "GMM", "has", "higher", "gain", "in", "small", "amount", "of", "weakly", "labeled", "images", ",", "while", "selection", "with", "scoring", "heuristics", "is", "better", "when", "using", "more", "that", "20000", "weakly", "labeled", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["It", "is", "likely", "the", "case", "that", "sources", "such", "as", "The", "New", "York", "Times", ",", "Vox", ",", "NPR", ",", "The", "Huffington", "Post", ",", "and", "The", "Guardian", "simply", "have", "a", "larger", "audience", "(", "particularly", "on", "social", "media", ")", "than", "AP", "and", "PBS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "associated press"}, {"tokens": ["Meanwhile", ",", "in", "practice", ",", "the", "achievable", "rate", "-", "distortion", "regions", "gradually", "approach", "the", "boundaries", "of", "theoretical", "MDC", "rate", "-", "distortion", "regions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["From", "Left", "to", "Right", ":", "FS", "image", ",", "ZF", "image", ",", "GAN", "reconstructed", "image", ",", "Recon", "-", "GLGAN", "reconstructed", "image", ","], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fully sampled"}, {"tokens": ["The", "GMM", "approximations", "agree", "well", "with", "the", "empirical", "distributions", "from", "Monte", "-", "Carlo", "simulations", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["We", "observed", "that", ":", "For", "a", "fixed", "number", "of", "processors", ",", "when", "number", "of", "applications", "increase", ",", "the", "difference", "between", "LB", "and", "makespan", "time", "decreases", "i.e.", "efficiency", "in", "time", "increases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lower bound"}, {"tokens": ["Sum", "rate", "vs.", "maximal", "transmission", "power", "of", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["In", "Bayesian", "inference", ",", "the", "posterior", "distribution", "of", "given", "observed", "data", "with", "iscomputed", "from", "the", "GP", "prior", "and", "the", "likelihood", "asThe", "likelihood", "is", "given", "byPractical", "inference", "for", "this", "problem", ",", "however", ",", "is", "non", "-", "trivial", ",", "because", "(", "i", ")", "the", "posterior", "is", "non", "-", "Gaussianand", "(", "ii", ")", "the", "likelihood", "involves", "an", "integral", "of", "over", "the", "whole", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "the", "initialization", "phase", ",", "GPA", "first", "computes", "a", "partitioning", "of", "by", "the", "graph", "partitioning", "algorithm", ",", "which", "produces", "disjoint", "subsets", "of", ",", "where", "is", "a", "user", "-", "defined", "number", "and", "will", "be", "discussed", "in", "Section"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["The", "RS", "code", "is", "one", "of", "the", "most", "widely", "used", "FEC", "-", "based", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Here", ",", "the", "PEP", "is", "the", "intermediate", "negotiator", "that", "intercepts", "the", "users", "'", "requests", "and", "enforces", "the", "PDP", "'s", "decision", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "policy decision point"}, {"tokens": ["[", "IB", "Lagrangian]Let", "and", "be", "statistically", "dependent", "variables", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Hence", ",", "this", "experiment", "was", "designed", "to", "showcase", "the", "convex", "IB", "Lagrangian", "can", "explore", "the", "IB", "curve", "in", "stochastic", "scenarios", "for", "regression", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "eMBMS", "specification", "allows", "for", "two", "modes", "of", "operation", "at", "the", "physical", "layer", ",", "i.e.", ",", "MBSFN", "and", "SC", "-", "PTM", ",", "which", "are", "introduced", "in", "the", "following", "subsectionsMBMS", "over", "Single", "Frequency", "NetworkThe", "multi", "-", "cell", "solution", "for", "LTE", "broadcasting", "is", "called", "MBSFN", ",", "which", "performs", "a", "synchronized", "transmission", "of", "the", "same", "content", "to", "a", "group", "of", "cells", "over", "the", "same", "frequency", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["luf/", "NP", "aluh", "'", "eagle'PIr", "*", "jarnu", "-", "mani-", "'", "gold", "neck", "'", "NP", "dal", "-", "man", "'", "black", "eagle'PIr", "*"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Moreover", ",", "the", "average", "packet", "travel", "time", "is", "reduced", "compared", "with", "the", "routing", "approach", "through", "(", "max", ")", "and", "by", "choosing", "a", "random", "shortest", "path", "(", "SP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "shortest path"}, {"tokens": ["The", "DCNN", "learned", "convolution", "filters", "at", "both", "the", "sentence", "and", "document", "level", ",", "hierarchically", "learning", "to", "capture", "and", "compose", "low", "-", "level", "lexical", "features", "into", "high", "-", "level", "semantic", "concepts", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic convolutional neural network"}, {"tokens": ["BS", "transmits", "additional", "symbols", "to", "the", "and", "by", "different", "OAM", "modes", "to", "the", "users", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "particular", ",", "we", "investigate", "the", "robustness", "of", "the", "RS", "method", "in", "realistic", "massive", "MIMO", "FD", "settings", "suffering", "from", "both", "pilot", "contamination", "and", "SI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["Relation", "to", "Prior", "Generalizations", "of", "MP", "ShalevShwartz:2010wq", ",", ",", "and", "propose", "and", "study", "algorithms", "similar", "to", "Algorithm", "-although", "using", "the", "objective", "function", "directly", "in", "the", "update", "step", "instead", "of", "a", "quadratic", "upper", "bound", "-", "for", "the", "optimization", "of", "smooth", "functions", "on", "Banach", "spaces", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["The", "authors", "introduced", "a", "new", "wrapper", "-", "based", "feature", "selection", ",", "to", "that", "end", ",", "named", "Global", "Local", "PSO", "(", "GLBPSO", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["EQv", ")", "to", "theweighted", "variant", "of", "the", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "stochastic block model"}, {"tokens": ["For", "particle", "filtering", "the", "total", "error", "for", "every", "ESS", "value", "is", "averaged", "over", "5", "sequences", "generated", "from", "the", "HMM", ";", "in", "addition", ",", "for", "each", "sequence", "we", "reran", "the", "particle", "filter", "5", "times", "(", "thus", "25", "runs", "total", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "effective sample size"}, {"tokens": ["Exact", "-", "MBR", "codes", "and", "partial", "downloading", "schemeThis", "section", "reviews", "the", "Exact", "-", "MBR", "codes", "at", "(", ")", "through", "product", "-", "matrix", "framework", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Furthermore", ",", "they", "can", "apply", "tools", "used", "for", "FA", "to", "extract", "the", "key", "value", "for", "logic", "obfuscation", "or", "FSM", "locking", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["In", "order", "to", "enforce", "the", "relationshipregardless", "of", "the", "reduced", "coefficients", ",", "the", "basis", "functions", "are", "asserted", "to", "have", "the", "fluctuation", "property", ",", "i.e.", ",", "for", "For", "now", ",", "the", "RB", "is", "assumed", "to", "be", "given", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["After", "obtaining", "the", "CSI", ",", "the", "AP", "sends", "a", "Notifying", "-", "CTS", "(", "N", "-", "CTS", ")", "to", "inform", "the", "selected", "STAs", "to", "transmit", "frames", "in", "parallel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Figure", "5", "shows", "SC", "behavior", "w.r.t", "transmit", "SNR", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["Classification", "Error", "Rate", "(", "CER", ")", "obtained", "on", "speaker", "-"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "classification error rate"}, {"tokens": ["In", "the", "proposed", "algorithm", ",", "the", "chaotic", "sequence", "provides", "a", "high", "exploration", "ability", "in", "the", "whole", "search", "space", ",", "whereas", ",", "the", "fine", "-", "tuning", "of", "the", "final", "results", "are", "obtained", "by", "the", "IF", "in", "the", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "power system operations"}, {"tokens": ["Evaluation", "of", "our", "models", "for", "MD", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "morphological disambiguation"}, {"tokens": ["We", "obtain", "experimental", "results", "using", "a", "gimbal", "based", "DCC", "mounted", "on", "a", "custom", "quadrotor", "platform", ",", "and", "evaluate", "the", "relative", "performance", "of", "SCCs", "and", "DCCs", "in", "a", "large", "outdoor", "environment", "with", "a", "variety", "of", "static", "and", "gimballed", "camera", "configurations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "static camera clusters"}, {"tokens": ["The", "results", "of", "our", "experiments", "on", "the", "MS", "COCO", "captions", "benchmark", "dataset", "show", "that", "CNet", "-", "NIC", "is", "competitive", "with", "or", "outperforms", "the", "state", "-", "of", "-", "the", "-", "art", "image", "captioning", "systems", "on", "several", "of", "the", "commonly", "used", "performance", "measures", "(", "BLEU", ",", "METEOR", ",", "ROUGE", "-", "L", ",", "all", "of", "which", "are", "measures", "designed", "originally", "for", "evaluating", "machine", "translation", "systems", "as", "opposed", "to", "image", "captioning", "systems", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural image caption"}, {"tokens": ["Table", "demonstrates", "the", "structure", "of", "a", "document", "in", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["It", "only", "shows", "the", "case", "on", "level", ",", "where", "maps", "from", "two", "streams", ",", "are", "leveraged", "by", "a", "MAD", "vector", "to", "generate", "the", "attention", "maps", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["Hence", ",", "the", "following", "fronthaul", "capacity", "constraint", "follows", ":", "where", "is", "an", "indicator", "function", ",", "defined", "as", "denotes", "the", "total", "transmission", "power", "from", "RRH", "to", "UE", ",", "is", "the", "maximum", "capacity", "that", "can", "be", "supported", "by", "the", "th", "fronthaul", "link", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "this", "study", ",", "we", "developed", "a", "custom", "hybrid", "DCNN", "inspired", "from", "widely", "used", "U", "-", "Net", "and", "full", "-", "resolution", "residual", "network", "(", "FRRnet", ")", "for", "the", "localization", "of", "scleral", "spur", ",", "and", "the", "segmentation", "of", "the", "anterior", "segment", "structures", "(", "iris", ",", "corneo", "-", "sclera", "shell", ",", "anterior", "chamber", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["We", "use", "the", "SRL", "system", "from", "AllenNLP", "Gardner2017AllenNLP", "to", "automatically", "obtain", "predicates", "for", "the", "continuations", "in", "our", "training", "set", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["The", "city", "name", "which", "constitute", "the", "important", "answer", "type", "is", "not", "recognised", "by", "the", "QA", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["Among", "these", "algorithms", ",", "PSO", "has", "shown", "great", "potential", "in", "solving", "ELD", "problems", "efficiently", "and", "effectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Four", "integrating", "schemes", "were", "tested", "in", "HMC", "and", "MD", "simulations", ":", "velocity", "Verlet", "(", "a", "dashed", "line", ")", ",", "the", "two", "-", "stage", "integrator", "BCSS", "(", "a", "dotted", "line", ")", ",", "the", "HOH", "-", "integrator", "of", "Predescu", "et", "al", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["That", "would", "require", "the", "MoD", "providing", "12", "million", "in", "the", "DL", "monitoring", "contract", "up", "-", "front", ";", "if", "they", "were", "not", "prepared", "to", "do", "this", "then", "there", "would", "be", "little", "assurance", "that", "they", "would", "abide", "by", "the", "terms", "of", "the", "smart", "contract", "-", "the", "SC", "might", "ask", "them", "to", "pay", ",", "but", "they", "could", "decide", "not", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "smart contract"}, {"tokens": ["Generalization", "for", "Multi", "-", "task", "ModelsRegarding", "the", "applicability", "of", "continual", "GP", "priors", "to", "high", "dimensional", "output", "settings", ",", "we", "study", "how", "to", "adapt", "the", "previous", "results", "to", "sequences", "of", "multiple", "output", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["ECS", "-", "DBN", "outperforms", "DBN", "and", "a", "group", "of", "resampling", "methods", "on", "34", "out", "of", "58", "benchmark", "datasets", "."], "acronym_pos": [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["The", "Dice", "coefficient", "was", "used", "to", "assess", "the", "similarity", "between", "the", "manual", "segmentation", "and", "DCNN", "segmentation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Finally", ",", "we", "would", "like", "to", "explore", "if", "the", "CC", "property", "can", "be", "used", "to", "solve", "other", "known", "difficult", "problems", "in", "network", "science", "like", "community", "detection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "core connected"}, {"tokens": ["Misclassified", "Bangla", "handwritten", "digits", "using", "DBN", "technique", "are", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["While", "the", "proposals", "chosen", "in", "PIN", "have", "fairly", "high", "accuracy", ",", "they", "still", "do", "not", "consider", "any", "relative", "attributes", "and", "relationships", "while", "ranking", "the", "proposals", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["For", "the", "second", "comparative", "experiment", ",", "we", "test", "our", "continual", "GP", "on", "the", "two", "datasets", "used", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["First", ",", "we", "choose", "BPR", "-", "MF", "model", "representing", "CF", "-", "based", "approaches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "adaptive", "mechanisms", "(", "uavFEC", ",", "CLM", "-", "UEP", ",", "and", "MINT", "-", "FEC", ")", "allow", "a", "better", "use", "of", "the", "network", "resources", ",", "as", "also", "shown", "in", "Figure", "fig"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["To", "answer", "this", "question", ",", "we", "re", "-", "trained", "a", "GCNN", "model", "using", "the", "same", "amount", "of", "data", "as", "for", "the", "competitors", ",", "that", "is", ",", "250,000", "candidate", "variables", "for", "training", ",", "and", "100,000", "for", "validation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["The", "transmission", "links", "from", "the", "RRHs", "in", "to", "UE", "are", "called", "the", "candidate", "serving", "links", ",", "which", "are", "represented", "in", "red", "solid", "arrows", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["On", "the", "contrary", ",", "whenever", "the", "fading", "conditions", "of", "the", "relay", "to", "destination", "channels", "are", "similar", "to", "the", "direct", "one", ",", "non", "-", "relay", "assisted", "transmission", "results", "in", "lower", "than", "that", "of", "the", "RS", "-", "based", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["The", "improvement", "of", "ECS", "-", "DBN", "comparing", "with", "DBN", "in", "terms", "of", "AUC", "is", "quite", "significant", "which", "indicates", "the", "propose", "ECS", "-", "DBN", "could", "improve", "the", "robustness", "of", "the", "diagnostic", "module", "for", "tool", "state", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Section", "sets", "out", "all", "pre", "-", "processing", "steps", "in", "creation", "process", "and", "the", "structure", "of", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["For", "performance", "comparison", ",", "simulation", "results", "for", "CCU", "(", ")", "capacity", ",", "CEU", "(", ")", "capacity", "and", "SC", "of", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "are", "also", "provided", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["b", ")", ":", "NAVSTAR", "-", "GPS", "goes", "live", "in", "1993", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["MD", "ModelIn", "this", "section", ",", "we", "describe", "our", "model", "for", "morphological", "disambiguation", "which", "is", "based", "on", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "morphological disambiguation"}, {"tokens": ["A", "value", "of", "for", "means", "that", "the", "affinity", "is", "not", "taken", "into", "account", ":", "DADA", "is", "thena", "basic", "dual", "-", "approximation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["These", "two", "state", "-", "of", "-", "the", "-", "art", "rule", "-", "based", "structural", "TS", "approaches", "primarily", "target", "reader", "populations", "with", "reading", "difficulties", ",", "such", "as", "people", "suffering", "from", "dyslexia", ",", "aphasia", "or", "deafness", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["Code", "-", "Mixing", "Index", "(", "CMI", ")", "introduced", "by", "indicates", "us", "the", "amount", "of", "code", "-", "mixing", "found", "in", "discourse", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "code - mixed index"}, {"tokens": ["Note", "that", "can", "be", "easily", "implemented", "in", "LTE", "-", "A", "systems", "as", "the", "existing", "power", "control", "for", "D2D", "communications", "in", "LTE", "-", "A", "ensures", "the", "interference", "from", "D2D", "communications", "to", "the", "serving", "BSs", "to", "be", "at", "fixed", "tolerable", "levels", ",", "which", "are", "configured", "by", "the", "BSs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "table", "compares", "the", "results", "for", "LR", "and", "RF", "with", "all", "features", ",", "and", "features", "selected", "by", "a", "wrapper", "feature", "selector", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Architecture", "of", "the", "proposed", "Consensus", "Attention", "Sum", "Reader", "(", "CAS", "Reader", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "consensus attention sum"}, {"tokens": ["The", "parameters", "we", "need", "to", "optimise", "include", "the", "recognition", "model", "weights", "(", "and", ")", ",", "variational", "parameters", ",", ",", "and", "the", "hyper", "-", "parameters", "for", "the", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["In", "the", "proposed", "DTVCN", "model", ",", "the", "value", "of", "the", "highest", "BC", "is", "lesser", "than", "the", "other", "models", "hence", ",", "it", "gives", "approximately", "and", "higher", "value", "of", "than", "TVCN", "model", "and", "BA", "model", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["The", "less", "-", "strict", "AP", "metrics", "(", "which", "measure", "large", "mistakes", ")", "improve", "with", "more", "iterations", ",", "while", "the", "very", "strict", "AP98", "and", "AP99", "metrics", "consistently", "worsen", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["In", "addition", "to", "producing", "small", "models", "with", "high", "test", "accuracy", "like", "conventional", "distillation", ",", "ARD", "also", "passes", "the", "superior", "robustness", "of", "large", "networks", "onto", "the", "student", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Empirically", ",", "Fast", "-", "ARD", "produces", "less", "robust", "students", "than", "the", "full", "ARD", "above", ",", "but", "it", "produces", "higher", "robust", "accuracy", "compared", "to", "models", "with", "identical", "architectured", "trained", "using", "existing", "accelerated", "free", "adversarial", "training", "methods", "as", "seen", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Additionally", ",", "several", "enhancement", "techniques", "have", "been", "proposed", "for", "the", "ARQ", "methods", "Tsai2009,Han2010,Hassan2010", ",", "including", "some", "in", "combination", "with", "FEC", "-", "based", "schemes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Effect", "of", "the", "amount", "of", "budgetRelationship", "between", "the", "budget", "and", "the", "performance", "metric", "for", "a", "point", "in", "case", "of", "GP", "-", "UCB", "with", "current", "and", "future", "variances", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["From", "the", "simulation", "results", ",", "we", "see", "that", "the", "error", "floor", "phenomenon", "occurs", "in", "the", "absence", "of", "AN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "artificial noise"}, {"tokens": ["report", "the", "results", "of", "the", "persistence", "analysis", ",", "the", "multiple", "regression", "analysis", ",", "and", "the", "correlation", "analysis", "for", "the", "MDC", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["The", "RF", "and", "ANN", "models", "were", "independently", "trained", "on", "these", "training", "subsets", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Prior", "work", "has", "established", "that", "applying", "syntactic", "TS", "as", "a", "preprocessing", "step", "can", "improve", "the", "performance", "of", "a", "variety", "of", "applications", ",", "including", "Machine", "Translation", ",", "Open", "Information", "Extraction", ",", "or", "Text", "Summarization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "target syntactic"}, {"tokens": ["The", "minimum", "values", "of", "and", "are", "required", "to", "deal", "with", "the", "non", "-", "differentiable", "partition", ",", "guaranteeing", "the", "robustness", "during", "the", "adaptation", "of", "STA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["htb", "]", "0.12", "0.28", "Original", "images", "0.28", "Stitched", "segmented", "patches", "0.28", "Classification", "after", "max", "-", "voting", "Examples", "of", "applying", "a", "max", "-", "voting", "scheme", "to", "stitched", "and", "segmented", "SEM", "patches", "for", "different", "microstructure", "classes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["EMDlei2007fault", ",", "Bispectrumyang2002third", ",", "AR", "Frequency", "Spectrawang2008fault", ",", "NNwang2001fault", ",", "yam2001intelligent", ",", "huang2007residual", ",", "HMMocak2007online", ",", "zhang2010hidden", ",", "Fuzzy", "logicsatish2005fuzzy", ",", "GAfeng2009ga", ",", "ARMAgalati2006application", ",", "Stochastic", "Modelli2000stochastic", ",", "wang2002model", ",", "PCAzhang2005integratedGear", "&", "Manufacturing", "error", ",", "tooth", "missing", ",", "tooth", "pitting", "/", "spall", ",", "gear", "crack", ",", "gear", "fatigue", "/", "wear", "&", "High", "noise", ";", "high", "dynamics", ";", "signal", "modulated", "with", "other", "factors", ";", "gear", "specs", "need", "to", "be", "known", "&", "Vibration", ",", "oil", "debris", ",", "acoustic", "emission", "&", "Time", "domain", "statistical", "features", ",", "vibration", "signature", "frequencies", ",", "oil", "debris", "quantity", "and", "chemical", "analysis", "&", "FTchoy1996analysis", ",", "STFTkar2006technical", ",", "bartelmus2009vibration", ",", "WTpeng2004application", ",", "suh1999machinery", ",", "EMDloutridis2004damage", ",", "wang2007gearbox", ",", "liu2006gearbox", ","], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "auto - regression"}, {"tokens": ["The", "CTC", "module", "has", "become", "the", "bottleneck", "in", "sequence", "-", "based", "approaches", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["shows", "the", "two", "possible", "frame", "structures", "for", "a", "single", "RB", "with", "LTE", "-", "eMBMS", "and", "NR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["For", "example", ",", "as", "BSP", "implicitly", "try", "to", "avoid", "a", "skewed", "partitioning", ",", "the", "impact", "of", "higher", "sampling", "rate", "is", "not", "significant", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["Both", "methods", "construct", "the", "RV", "by", "discretizing", "the", "azimuth", "and", "elevation", "angles", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "range view"}, {"tokens": ["The", "DCNN", "model", "used", "to", "extract", "deep", "convolutional", "features", "is", "identical", "to", "the", "one", "which", "was", "employed", "in", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Here", "we", "compare", "the", "orginal", "GP", "-", "SSM", "with", "multiple", "particles", "(", "GP", "-", "SSM", "-", "SMC", ")", "and", "that", "augmented", "by", "HSMC", "(", "GP", "-", "SSM", "-", "HSMC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "the", "massive", "MIMO", "systems", ",", "the", "BS", "is", "equipped", "with", "hundreds", "of", "antennas", "and", "the", "heavy", "use", "of", "the", "high", "resolution", "phase", "shifters", "may", "result", "in", "huge", "power", "consumption", "and", "hardware", "cost", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "energy", "mode", "in", "this", "work", "also", "incorporates", "the", "effect", "of", "packets", "transmitted", "by", "a", "RN", "to", "BS", "on", "behalf", "of", "other", "RNs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["after", "some", "algebraic", "manipulations", ",", "a", "closed", "-", "form", "expression", "for", "of", "repetitive", "transmission", "with", "SD", "in", "IID", "Nakagami-", "fading", "channels", "with", "integer", "is", "obtained", "aswhere", "function", ",", "with", "and", "being", "positive", "integers", ",", "is", "given", "byRS", "-", "based", "TransmissionWhen", "RS", "-", "based", "transmission", "is", "utilized", ",", "RS", "is", "first", "performed", "to", "obtain", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["The", "BT", "and", "SF", "protocols", "are", "also", "viable", "in", "terms", "of", "providing", "near", "-", "optimal", "solutions", ",", "while", "the", "RB", "protocol", "should", "not", "be", "used", "due", "to", "its", "poor", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random beamforming"}, {"tokens": ["In", "this", "section", ",", "we", "experiment", "using", "ANN", "networks", "trained", "with", "different", "levels", "of", "dropout", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Impact", "of", ",", "and", "on", "CCU", "capacity", ",", "CEU", "capacity", "and", "SC", "of", "the", "proposed", "system", "is", "shown", "in", "this", "part", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["Table", "shows", "the", "KNN", "-", "MSE", "for", "the", "different", "SRL", "approaches", "on", "the", "implemented", "environments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["TP", ",", "FP", ",", "TN", ",", "FN", "are", "respectively", "True", "Positive", ",", "False", "Positive", ",", "True", "Negative", ",", "False", "Negative", "samples", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true negative"}, {"tokens": ["Our", "results", "show", "that", "RA", "achieves", "high", "throughput", "and", "low", "latency", "compared", "to", "PS", "and", "P2P", "systems", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["The", "ARA", "Architecture", "Our", "aim", "is", "to", "build", "a", "CDP", "system", "that", "is", "cheap", ",", "fast", ",", "robust", "and", "less", "complex", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["For", "example", ",", "Hamiltonicity", ",", "the", "property", "of", "having", "a", "cycle", "that", "includes", "each", "vertex", ",", "is", "an", "-complete", "property", "on", "GI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "graph isomorphism"}, {"tokens": ["For", "our", "purposes", ",", "we", "extend", "FJ", "by", "adding", "interfaces", ",", "with", "multiple", "inheritance", ",", "-expressions", ",", "and", "intersection", "types", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "featherweight java"}, {"tokens": ["By", "employing", "standard", "methods", "for", "BF", "(", "Particle", "Filters", ")", ",", "online", "inference", "with", "identifying", "observations", "can", "be", "performed", "(", "sequential", ",", "update", ",", "and", "prediction", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian filtering"}, {"tokens": ["Average", "Precision", "(", "AP", ")", "for", "different", "intersection", "-", "over", "-", "union", "thresholds", "for", "a", "predicted", "bounding", "box", "to", "be", "considered", "correct", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Figure", "5", "shows", "SC", "behavior", "w.r.t", "transmit", "SNR", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["the", "set", "of", "selected", "relays", ",", "ii", ")", "their", "PS", "ratios", ",", "and", "iii", ")", "their", "transmit", "power", "levels", "in", "order", "to", "maximize", "data", "rate", "-", "based", "utilities", "over", "multiple", "coherent", "time", "slots", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["However", ",", "a", "GP", "with", "an", "additive", "kernel", "can", "learn", "both", "to", "ignore", "irrelevant", "variables", ",", "and", "to", "ignore", "certain", "orders", "of", "interaction", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["MD", ",", "NN", "and", "LR", "stands", "for", "modality", "dependent", ",", "neural", "networks", "and", "linear", "regression", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear regression"}, {"tokens": ["The", "support", "of", "the", "spectrum", "of", "the", "PAF", ",", "where", "is", "the", "temporal", "angular", "sampling", "frequency", "and", "is", "the", "spatial", "angular", "frequency", "over", "each", "of", "the", "observed", "axis", ",", "lays", "inside", "a", "hypercone", ":", ",", "where", "is", "the", "celerity", "of", "sound", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "plenacoustic function"}, {"tokens": ["In", "our", "CSS", "scenario", ",", "multiple", "SUs", "sense", "the", "licensed", "sub", "-", "channels", "independently", ",", "and", "the", "PUs", "'", "activities", "can", "be", "predicted", "by", "the", "AP", "using", "the", "collected", "sensing", "results", "of", "SUs", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cooperative spectrum sensing"}, {"tokens": ["Meanwhile", ",", "there", "is", "an", "eavesdropper", "that", "aims", "to", "intercept", "the", "critical", "control", "signals", "transmitted", "by", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["The", "corresponding", "LR", "structures", "are", "denoted", "as", "LR26", ",", "LR53", "and", "LR106", ",", "where", "the", "number", "denotes", "the", "value", "of", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low rank"}, {"tokens": ["Algorithm", "without", "having", "Line", "12", "is", "this", "GP", "-", "UCB", "version", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["All", "the", "LR", "faces", "in", "TinyFace", "are", "collected", "from", "the", "web", "(", "PIPA", "and", "MegaFace2", ")", "across", "diverse", "imaging", "scenarios", ",", "captured", "under", "uncontrolled", "viewing", "conditions", "in", "pose", ",", "illumination", ",", "occlusion", "and", "background", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Moreover", ",", "we", "obtained", "closed", "-", "form", "expressions", "for", "the", "OP", "and", "the", "ASEP", "performance", "of", "the", "RS", "and", "repetitive", "schemes", "when", "MRD", "or", "SD", "are", "employed", "at", "the", "destination", "node", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal ratio diversity"}, {"tokens": ["Evaluating", "the", "performance", "of", "cross", "-", "domain", "FER", "systems", "is", "a", "challenging", "topic", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["The", "output", "of", "GSP", "is", "normalized", "by", "it", "'s", "mean", "and", "standard", "deviation", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global statistics pooling"}, {"tokens": ["PS", "is", "both", "and", "under", "linear", "preferences", "but", "this", "is", "no", "longer", "true", "under", "general", "partial", "preferences", ",", "as", "the", "impossibility", "result", "in", "Proposition", "shows", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["Regarding", "the", "LR", "attack", ",", "LR", "takes", "at", "most", "a", "dataset", "space", "to", "randomly", "select", "features", "in", "the", "benign", "dataset", "and", "occupy", "space", "to", "find", "10", "of", "nearest", "malware", "dataset", "to", "the", "discriminator", "."], "acronym_pos": [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["However", ",", "the", "susceptibility", "of", "the", "aforementioned", "memories", "against", "the", "side", "-", "channel", "analysis", ",", "or", "other", "types", "of", "probing", "(", "for", "example", ",", "EBIC", "/", "EBAC", ")", ",", "or", "microscopy", "(", "for", "example", ",", "spin", "-", "SEM", ")", "should", "be", "evaluated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Alongside", "throughput", "enhancement", ",", "5", "G", "NR", "extends", "LTE", "DC", "towards", "improved", "reliability", "by", "using", "data", "duplication", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Whereas", ",", "the", "fair", "QA", "system", "is", "not", "biased", "based", "on", "the", "certain", "characteristics", "of", "the", "data", "publisher", ",", "or", "the", "targeted", "end", "user", "(", "e.g.", ",", "region", ",", "race", ",", "social", "or", "political", "rank", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["While", "the", "current", "policies", "do", "impose", "a", "number", "of", "requirements", "on", "end", "sites", "requesting", "PI", "block", ",", "these", "requirements", "are", "usually", "in", "the", "form", "of", "a", "plan", "or", "a", "prevision", "regarding", "the", "number", "of", "hosts", "/", "sites", "in", "the", "near", "future", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["The", "ROC", "is", "the", "measure", "of", "the", "area", "above", "the", "straight", "line", "from", "(", "0,0)to", "(", "1,1", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["This", "is", "mainly", "because", "WiFi", "MAC", "protocol", "is", "distributed", "and", "contention", "-", "based", ",", "which", "incurs", "much", "channel", "access", "overhead", "(", "e.g.", ",", "random", "backoff", ")", ";", "whereas", "LTE", "MAC", "is", "centralized", "where", "the", "network", "schedules", "resources", "for", "each", "device", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Furthermore", ",", "the", "MAD", "unit", "can", "actively", "attend", "important", "neuron", "activations", "and", "we", "verify", "its", "effectiveness", "via", "the", "last", "experiment", ":", "enhancing", "AR", "to", "76.51", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["We", "also", "try", "the", "excitation", "recalibration", "idea", "to", "replace", "MAD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "map attention decision"}, {"tokens": ["We", "show", "that", "in", "deterministic", "scenarios", "(", "and", "other", "scenarios", "where", "the", "IB", "curve", "shape", "is", "known", ")", "one", "can", "use", "the", "convex", "IB", "Lagrangian", "to", "obtain", "a", "desired", "level", "of", "performance", "with", "a", "single", "optimization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["We", "consider", "ISP", "configurations", "with", "all", "stages", "enabled", ",", "no", "stages", "enabled", ",", "and", "stages", "selectively", "enabled", "/", "disabled", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Denoting", "as", "the", "beam", "-", "vector", "at", "RRH", "for", "UE", "on", "SC", ",", "the", "transmitted", "signal", "of", "RRH", "on", "SC", "iswhere", "is", "the", "data", "symbol", "for", "UE", "on", "SC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "results", "show", "inferior", "performance", "using", "LOM", "instead", "of", "SEM", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Furthermore", ",", "since", "the", "LSTMs", "are", "\"", "unaffected", "\"", "by", "the", "\"", "fundamental", "deep", "learning", "problem", ",", "\"", "we", "may", "expect", "that", "the", "LSTM", "performance", "on", "the", "SP", "experiments", "to", "be", "comparable", "to", "the", "ones", "on", "the", "SL", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Then", "the", "corresponding", "RDM", "is", "plotted", "by", "computing", "the", "pairwise", "dissimilarity", "of", "the", "values", "of", "features", "associated", "with", "each", "pair", "of", "images", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "representational dissimilarity matrix"}, {"tokens": ["ASPO", "-", "AUC", "decreased", "the", "feature", "dimension", "and", "selected", "top", "140", "features", "out", "of", "686", "SPAM", "attributes", "and", "363", "features", "out", "of", "548", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subtractive pixel adjacency matrix"}, {"tokens": ["CD", "can", "tolerate", "up", "to", "disk", "failures", ",", "as", "long", "as", "there", "are", "no", "consecutive", "disks", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["The", "results", "obtained", "on", "two", "well", "-", "known", "AS2", "datasets", ",", "WikiQA", "and", "TREC", "-", "QA", ",", "show", "an", "impressive", "improvement", "over", "the", "state", "of", "the", "art", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Caudell", "and", "Mizell", "discuss", "the", "advantages", "of", "AR", "versus", "VR", "such", "as", "requiring", "less", "processing", "power", "since", "less", "pixels", "have", "to", "be", "rendered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Moreover", ",", "(", "iii", ")", "when", "the", "IB", "curve", "is", "not", "known", ",", "we", "saw", "how", "we", "can", "exploit", "the", "value", "convergence", "issue", "of", "the", "convex", "IB", "Lagrangian", "to", "approximately", "obtain", "a", "specific", "compression", "level", "for", "both", "known", "and", "unknown", "IB", "curve", "shapes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["can", "be", "computed", "as", "the", "sum", "of", "interference", "from", "each", "macrocell", "UE", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["However", ",", "what", "can", "be", "concluded", "without", "hesitation", "is", "that", "sampling", "in", "molecular", "simulations", "of", "atomistic", "constrained", "systems", "with", "HMC", "and", "MD", "benefits", "from", "integrators", "that", "guarantee", "the", "best", "possible", "conservation", "of", "energy", ",", "as", "is", "the", "case", "with", "AIA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["OS", "\"", "is", "the", "output", "stride", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0], "long_form": "output stride"}, {"tokens": ["shows", "the", "values", "of", "both", "indices", "for", "the", "OEC", "algorithm", "applied", "to", ",", "which", "identifies", "all", "the", "clusters", "correctly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["BKT", "has", "been", "successfully", "applied", "in", "SAR", ";", "and", "used", "it", "to", "adapt", "to", "user", "age", "and", "experience", ",", "leading", "to", "increased", "learning", "gains", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["In", "an", "RDM", "corresponding", "to", "a", "perfect", "model", ",", "the", "representations", "of", "the", "objects", "of", "the", "same", "category", "have", "low", "dissimilarities", "(", "i.e.", ",", "highly", "correlated", ")", ",", "whereas", "objects", "of", "different", "categories", "are", "represented", "highly", "dissimilarly", "(", "i.e.", ",", "uncorrelated", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "representational dissimilarity matrix"}, {"tokens": ["In", "these", "simulations", ",", "we", "use", "MP", "based", "hypothesis", "testing", "algorithm", "and", "compare", "it", "against", "LT", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "message passing"}, {"tokens": ["PassingImproved", "Global", "DiscoveryThe", "constraint", "in", "AP", "aim", "to", "enforce", "that", "chooses", "only", "one", "exemplar", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["The", "error", "from", "PI", "is", "reduced", "in", "each", "iteration", "by", "a", "factor", "of", "'s", "dominance", "ratio", ",", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["Table", "I.", "Rate", "A", "denotes", "the", "average", "achievable", "rate", "adopting", "SBS", "strategy", "with", "a", "distance", "constraint", ",", "and", "Rate", "B", "denotes", "the", "average", "achievable", "rate", "adopting", "SBS", "strategy", "with", "the", "received", "signal", "power", "constraint", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["Accuracy", "results", "of", "AN", "and", "FAN", "on", "unconstrained", "benchmarks", "with", "the", "image", "-", "encoder", "released", "by", "Shi", "shi2016robust", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["ROC", "Curves", "and", "AUC", ":"], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["As", "a", "matter", "of", "fact", "the", "SC", "is", "also", "improved", "as", "well", "for", "the", "proposed", "scheme", "with", "higher", "compared", "to", "NOMA", "-", "OAM", "-", "MDMA", "(", ")", ",", "conventional", "NOMA", ",", "OMA", "-", "OAM", "-", "MDMA", "(", ")", ",", "and", "OMA", "-", "OAM", "-", "MDMA", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["Hence", ",", "we", "can", "perform", "approximate", "inference", "in", "a", "time", "complexity", "of", "instead", "of", "by", "evaluating", "the", "covariance", "function", "of", "the", "GP", "on", "the", "auxiliary", "variables", "instead", "of", "the", "entire", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["This", "ROC", "study", "was", "performed", "using", "a", "random", "10:1", "train", ":", "test", "split", "(", "training", "on", "7,317", "and", "validation", "on", "813", "profiles", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["With", "high", "-", "resolution", "DTI", ",", "greater", "FA", "reductions", "in", "caudal", "(", "than", "in", "middle", "or", "rostral", ")", "regions", "of", "the", "SN", "were", "identified", ",", "distinguishing", "PD", "from", "controls", "with", "100", "sensitivity", "and", "specificityvaillancourt2009high", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fractional anisotropy"}, {"tokens": ["The", "iPad", "featured", "an", "assisted", "GPS", ",", "accelerometers", ",", "magnetometers", ",", "advanced", "graphics", "chipset", "(", "PowerVR", "SGX535", ")", ",", "enabling", "the", "possibilities", "to", "create", "efficient", "AR", "application", "on", "tablet", "computer", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Offsetting", "GPSA", "GPS", "with", "high", "frequency", "refresh", "rate", "is", "advisable", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["SelectionThe", "PSO", "technique", "is", "proposed", "to", "carry", "out", "the", "bandwidth", "selection", "for", "better", "approximation", "of", "kernel", "density", "estimation", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "hardware", "setup", "contains", "the", "BS", ",", "WPT", "transmitter", "and", "sensor", "node", "with", "RFBee", "transceiver", "(", "for", "data", "transmission", "in", "2.4", "GHz", ")", "and", "WPT", "receiver", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["applied", "evidence", "theory", "(", "ET", ")", "to", "fuse", "hybrid", "uncertain", "factors", "on", "the", "solutions", "of", "uncertain", "power", "flow", "and", "optimal", "power", "flow", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "evidence theory"}, {"tokens": ["Typically", ",", "temporal", "dynamics", "was", "added", "in", "CF", "methods", "to", "discover", "temporal", "evolving", "features", "and", "many", "other", "sophisticated", "NN", "models", "were", "proposed", ",", "like", "time", "gates", ",", "point", "process", ",", "multi", "-", "task", "etc", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["e", ")", ":", "Indoor", "AR", "guidance", "system", "by", "Wagner", "and", "Schmalstieg", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Some", "of", "the", "definitions", "of", "AR", "has", "already", "been", "described", ",", "but", "its", "definition", "in", "context", "of", "virtual", "reality", "can", "be", "formed", "and", "compared", "with", "the", "definition", "of", "virtual", "reality", "itself", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["DAC", "(", "the", "left", "column", ")", "matches", "the", "conditional", "expectation", "curves", "better", "than", "PDP", "(", "the", "right", "column", ")", "by", "a", "substantial", "margin", "for", "different", "data", "distributions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial dependence plots"}, {"tokens": ["Moreover", ",", "Figure", "7", "shows", "that", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "provides", "better", "SC", "than", "other", "schemes", "for", "different", "values", "of", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["TTP", "retrieves", "the", "the", "set", "of", "reference", "signatures", "for", "the", "signed", "-", "in", "entity", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "trusted third party"}, {"tokens": ["Tok", ",", "...", ",", "Tok", "[", "SEP", "]", "Tok", ",", "...", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "separator"}, {"tokens": ["The", "first", "work", "of", "this", "nature", "was", "by", ",", "who", "proposed", "a", "GCNN", "model", "for", "learning", "greedy", "heuristics", "on", "several", "collections", "of", "combinatorial", "optimization", "problems", "defined", "on", "graphs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["Accompanied", "by", "the", "moves", "described", "above", "for", "modelling", "and", "inferring", ",", "they", "found", "that", "this", "nested", "SBM", "managed", "to", "overcome", "the", "underfitting", "issue", ",", "while", "discovering", "a", "hierarchical", "structure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["However", ",", "even", "with", "the", "same", "learning", "algorithm", ",", "the", "better", "one", "can", "vary", "depending", "on", "the", "scenario", ",", "e.g.", ",", "for", "LR", ",", "incremental", "modeling", "is", "better", "for", "3", "out", "of", "the", "5", "performance", "indicators", "while", "the", "retrained", "one", "is", "better", "for", "the", "rest", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear regression"}, {"tokens": ["The", "change", "in", "cosine", "similarity", "for", "CC", "from", "degrees", "(", "using", "varifolds", ")", "to", "degrees", "(", "using", "functional", "varifolds", ")", "while", "for", "CST", "(", "R", ")", "from", "degrees", "to", "degrees", ",", "reflect", "more", "drop", "in", "cosine", "similarity", "if", "along", "tract", "signal", "profiles", "are", "not", "similar", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "corpus callosum"}, {"tokens": ["Interestingly", ",", "this", "behavior", "does", "not", "depend", "on", "distilling", "from", "a", "high", "-", "capacity", "network", "to", "a", "low", "capacity", "network", ";", "distilling", "Resnet18", "onto", "itself", "and", "MobileNetV2", "onto", "itself", "using", "ARD", "results", "in", "far", "better", "robustness", "than", "adversarial", "training", "alone", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Readers", "may", "refer", "to", "the", "prior", "studies", "for", "more", "details", "on", "VSM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "vector space model"}, {"tokens": ["if", "is", "an", "participating", "sensor", "node", "in", "mission", "and", "receives", "power", "from", "ET", "located", "at", "landmark", "at", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "energy transmitters"}, {"tokens": ["We", "report", "out", "-", "of", "-", "sample", "clustering", "NMI", "performance", "in", "Table", ";", "note", "that", "SC", "can", "not", "be", "executed", "out", "-", "of", "-", "sample", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral clustering"}, {"tokens": ["However", ",", "at", "the", "level", "of", "dyads", ",", "the", "TIs", "'", "spatial", "entropy", "are", "independent", "on", "their", "frequency", ",", "as", "illustrated", "by", "two", "aforementioned", "(", "TI", "1", ",", "TI", "2", ")", "in", "Figure", "(", "a", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["we", "compare", "the", "dimensioning", "results", "for", "3", "models", ":", "Outdoor", "users", "according", "to", "Cox", "process", "driven", "by", "PLP", ",", "outdoor", "users", "according", "to", "a", "spatial", "PPP", "model", "and", "indoor", "users", "with", "spatial", "PPP", "model", "(", "having", "the", "same", "intensities", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["Besides", ",", "a", "high", "-", "resolution", "SAR", "land", "cover", "annotated", "dataset", ",", "collected", "from", "TerraSAR", "-", "X", "horizontally", "polarized", "(", "HH", ")", ",", "multi", "-", "look", "ground", "range", "detected", "(", "MGD", ")", "products", ",", "is", "applied", "for", "SAR", "land", "cover", "classification", "task", "in", "our", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["As", "is", "explained", "in", "the", "previous", "section", ",", "the", "recovery", "ability", "of", "OLS", "is", "always", "better", "than", "OMP", "in", "terms", "of", "the", "least", "square", "error", "under", "the", "same", "condition", "(", "i.e.", "the", "same", "sparsity", "level", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["adaptive", "DE", "are", "the", "same", "with", "those", "in", "Section", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Compared", "to", "blindly", "modelling", "to", "determine", ",", "it", "is", "relatively", "easier", "to", "measure", "its", "maximum", "probability", "of", "success", "in", "getting", "a", "similar", "RV", "within", "a", "maximum", "achievable", "distance", "among", "all", "possible", "distributions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["SEM", "and", "CEM", "methods", "captures", "similar", "ratio", "of", "changes", "in", "ECG", "peaks", "with", "different", "accuracies", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "squared entropy measurement"}, {"tokens": ["The", "size", "of", "the", "change", "this", "will", "have", "on", "the", "IS", "landscape", "of", "the", "enterprise", "as", "a", "whole", ",", "for", "example", "will", "it", "affect", "everyone", "within", "the", "enterprise", ",", "or", "a", "small", "team", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["Linear", "Assignment", "Problem", "(", "LAP", ")"], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "linear assignment problem"}, {"tokens": ["itemizeIf", "a", "game", "is", "strongly", "MD", "-", "determined"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["Note", "that", "while", "GP", "-", "ARD", "increases", "the", "lengthscale", "of", "the", "irrelevant", "variables", ",", "GP", "-", "AS", "reduces", "the", "signal", "variance", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["As", "introductory", "section", "of", "Wikipedia", "articles", "are", "not", "actual", "abstracts", "of", "papers", ",", "the", "average", "length", "of", "documents", "are", "different", "than", "average", "length", "of", "abstracts", ":", "178", "words", "for", "the", "LSC", "and", "approximately", "524", "words", "for", "the", "DBpedia", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Few", "parameters", "are", "required", "to", "adjust", ",", "and", "enable", "PSO", "easy", "to", "implement", ",", "make", "popular", "stochastic", "and", "yet", "powerful", "swarm", "-", "based", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Penney", "penney_chilling_2016", "also", "starts", "with", "an", "ITS", "model", "to", "understand", "the", "impact", "of", "the", "Edward", "Snowden", "revelations", "on", "page", "views", "to", "\"", "terrorism", "-", "related", "\"", "Wikipedia", "articles", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interrupted time series"}, {"tokens": ["However", ",", "unlike", "VAE", "-", "GAN", "that", "uses", "different", "networks", "for", "discriminator", "and", "encoder", ",", "IAN", "combines", "the", "discriminator", "and", "encoder", "into", "a", "single", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "introspective adversarial network"}, {"tokens": ["Since", "differs", "only", "slightly", "in", "the", "amplitude", "from", "the", "general", "pattern", ",", "these", "dictionaries", "seem", "insufficient", "to", "capture", "this", "fine", "dissimilarity", ":", "while", "Self", "and", "DI", "dictionaries", "simply", "do", "not", "contain", "enough", "elements", ",", "UI", "dictionary", "is", "to", "simple", "to", "capture", "this", "difference", "(", "it", "shares", "this", "feature", "with", "DI", "dictionary", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "uniform indicator"}, {"tokens": ["The", "sparse", "likelihood", "is", "optimised", "by", "minimising", "the", "Kullback", "-", "Leibler", "divergenceA", "short", "computation", "(", "Appendix", ")", "shows", "that", "where", "the", "conditional", "expectation", "is", "with", "respect", "to", "the", "GP", "prior", "measure", "given", "the", "function", "at", "the", "inducing", "points", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["As", "a", "comparison", "with", "regular", "radix", "sort", "performance", ",", "on", "Tesla", "K40c", "(", "ECC", "on", ")", ",", "RB", "-", "sort", "outperforms", "radix", "sort", "up", "to", "almost", "32k", "keys", "and", "16k", "key", "-", "value", "pairs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["A", "widely", "studied", "problem", "in", "finance", "is", "stock", "portfolio", "diversification", "and", "such", "problems", "are", "closely", "connected", "to", "DE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "dimension estimation"}, {"tokens": ["Real", "-", "time", "SRL", ":"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "state representation learning"}, {"tokens": ["T=30", ",", "Distribution", "of", "social", "(", "above", "line", ")", "and", "spatial", "(", "bottom", "line", ")", "metrics", "for", "the", "CNS", "and", "MDC", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["SBM", "with", "topic", "modelling"], "acronym_pos": [1, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["At", "InterDigital", ",", "he", "has", "worked", "on", "the", "standardization", "of", "3GPP", "LTE", "and", "LTE", "-", "Advanced", ",", "advanced", "relaying", "schemes", ",", "coexistence", "in", "unlicensed", "spectrum", ",", "and", "waveform", "design", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["ISP", "Stage", "Ablation", "."], "acronym_pos": [1, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["table*[htb]tabularccccccccDimension", "&", "Category", "&", "BSP", "&", "FG", "&", "SLC", "&", "BOS", "&", "STR", "&", "HC"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["For", "more", "balanced", "PAPs", ",", "where", "the", "delay", "is", "below", "5ms", "the", "proposed", "algorithms", "perform", "worse", "than", "the", "ring", ",", "it", "is", "especially", "visible", "for", "SLT", "(", "about", "25", "slower", ")", ",", "however", "PRR", "shows", "only", "slight", "difference", "(", "below", "5", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pre - reduced ring"}, {"tokens": ["In", "Figure", "we", "show", "the", "training", "and", "prediction", "time", "comparison", "of", "large", "datasets", "(", "DMOZ-2010", "and", "DMOZ-2012", ")", "between", "flat", "LR", "and", "the", "TD", "HC", "approach", "with", "(", "and", "without", ")", "feature", "selection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["(", "AP", ")"], "acronym_pos": [0, 1, 0], "long_form": "associated press"}, {"tokens": ["Compared", "to", "the", "linear", "estimators", ",", "e.g.", ",", "the", "LS", "and", "LMMSE", "estimators", ",", "the", "DL", "estimator", "is", "more", "flexible", "and", "has", "a", "larger", "potential", "to", "combat", "distortion", "and", "some", "other", "unknown", "detrimental", "effects", "in", "real", "world", "communication", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["For", "fault", "diagnosis", ",", "a", "cost", "-", "sensitive", "deep", "belief", "network", "(", "namely", "ECS", "-", "DBN", ")", "is", "applied", "to", "deal", "with", "the", "imbalanced", "data", "problem", "for", "tool", "state", "estimation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Each", "FM", "block", "consists", "of", "one", "mixing", "function", "and", "some", "basis", "functions", ",", "which", "are", "implemented", "as", "parallel", "DCNN", "based", "subnets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["In", "this", "article", "we", "introduced", "a", "general", "family", "of", "Lagrangians", "which", "allow", "to", "(", "i", ")", "achieve", "varying", "levels", "of", "performance", "in", "any", "scenario", ",", "and", "(", "ii", ")", "pinpoint", "a", "specific", "Lagrange", "multiplier", "to", "optimize", "for", "a", "specific", "performance", "level", "in", "known", "IB", "curve", "scenarios", ";", "e.g.", ",", "deterministic", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "CF", "tasks", "we", "only", "have", "two", "features", "-", "corresponding", "to", "users", "and", "items", "-", "with", "corresponding", "embedding", "matrices", "and", ",", "respectively", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Otherwise", ",", "the", "unlimited", "unlabeled", "SAR", "images", "are", "also", "helpful", "especially", "using", "transitive", "transfer", "proposed", "in", "this", "paper", "to", "transfer", "knowledge", "from", "large", "-", "scale", "dataset", "to", "small", "-", "scale", "one", ",", "with", "closer", "distance", "to", "SAR", "target", "recognition", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["In", "PLOS", "One", ",", "where", "most", "of", "the", "articles", "in", "their", "study", "came", "from", ",", "a", "policy", "was", "enacted", "in", "2014", "to", "require", "a", "DAS", "from", "each", "accepted", "paper", ",", "even", "if", "it", "was", "simply", "category", "1", "(", "\"", "data", "is", "available", "on", "request", "\"", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data availability statement"}, {"tokens": ["If", "we", "are", "able", "to", "reduce", "the", "complexity", "of", "the", "ISP", "by", "removing", "unneeded", "functions", ",", "that", "would", "lead", "to", "lower", "latency", "and", "lower", "energy", "consumption", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["If", "the", "best", "sum", "rate", "is", "to", "connect", "to", "BS"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "base station"}, {"tokens": ["Original", "while", "LDOF", "with", "APO", "yields", "the", "best", "result", "in", "sequence", "Frank", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "large displacement optical flow"}, {"tokens": ["the", "covariance", "parameters", "of", "the", "GP", ",", "(", "ii", ")", "the", "locations", "of", "the", "inducing", "points", ",", "and", "(", "iii", ")", "the", "prior", "parameters", "for", "the", "maximal", "intensity", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["DAG", "is", "recently", "adopted", "in", "IOTA", "a", "public", "BC", "having", "no", "mining", "fee", ",", "designed", "for", "IoT", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["Our", "experimental", "results", "show", "that", "the", "proposed", "algorithm", "achieves", "state", "of", "the", "art", "CCR", "for", "the", "analysis", "of", "unlabeled", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["w", "s", "g", "&", "Special", "English", "&", "c", "w", "a", "&", "E", "-", "Prime", "&", "c", "w", "g", "&", "Plain", "Language", "2132", "&", "c", "s", "d", "g", "&", "CAA", "Phraseology", ",", "FAA", "Phraseology", ",", "ICAO", "Phraseology", ",", "PoliceSpeak", ",", "SEASPEAK", "2133", "&", "c", "w"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "civil aviation authority"}, {"tokens": ["We", "used", "for", "(", "a", ",", "b", ")", ",", "but", "found", "the", "same", "dynamics", "class", "inadequate", "for", "walker", ",", "reducing", "walker", "experiments", "to", "reduces", "the", "improvement", "MVE", "has", "to", "offer", "over", "DDPG", ",", "but", "it", "still", "exhibits", "greater", "robustness", "to", "the", "poor", "model", "fit", "than", "IB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "imaginary batches"}, {"tokens": ["a", "hand", "-", "held", "mobile", "AR", "system", "for", "urban", "design", "and", "urban", "planning", "site", "visits", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Remark", "3", ":", "When", "there", "is", "no", "direct", "transmission", "between", "the", "BS", "and", "the", "MS", "over", "which", "the", "RIS", "has", "no", "control", ",", "intelligent", "reflection", "allows", "one", "to", "completely", "eliminate", "the", "Doppler", "effect", ",", "by", "carefully", "compensating", "the", "Doppler", "phase", "shifts", "through", "the", "RIS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["TS", "with", "temperature", "corresponds", "to", "transforming", "probabilities", "as", "follows", ":", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature - based sampling"}, {"tokens": ["METAIO", "presents", "a", "commercial", "mobile", "AR", "museum", "guide", "using", "natural", "feature", "tracking", "or", "a", "six", "-", "month", "exhibition", "on", "Islamic", "art", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Set", "1", "&", "PiB", "Angular", "L", "/", "R", "&", "PiB", "Cingulum", "Ant", "L", "/", "R", "&", "PiB", "Cingulum", "Post", "L", "/", "R", "&", "PiB", "Frontal", "Med", "Orb", "L", "/", "R", "&", "PiB", "Precuneus", "L", "/", "R", "&", "PiB", "Temporal", "Sup", "L", "/", "R", "&", "PiB", "Temporal", "Mid", "L", "/", "R", "&", "PiB", "SupraMarginal", "L", "Set", "2", "&", "FA", "Cerebral", "peduncle", "R", "&", "FA", "Cerebral", "peduncle", "L", "&", "MD", "Corticospinal", "tract", "R", "&", "MD", "Corticospinal", "tract", "L", "&", "Trail", "-", "Making", "Test", "Part"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean diffusivity"}, {"tokens": ["Another", "possibility", "is", "installing", "the", "micro", "-", "controller", "on", "a", "drone", "to", "improve", "the", "sight", "of", "the", "target", "laser", "and", "control", "the", "micro", "-", "controller", "remotely", "using", "GSM", "communication", "from", "the", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "covert channels"}, {"tokens": ["TS", "-", "RF", "wrapper", "exploits", "Tabu", "search", "metaheuristic", "algorithm", "for", "feature", "search", "/", "feature", "weighting", "and", "Random", "forest", "as", "a", "learning", "algorithm", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["In", "a", "WRFET", ",", "ET", "nodes", "are", "responsible", "for", "wirelessly", "recharging", "sensor", "nodes", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy transmitters"}, {"tokens": ["Conversely", ",", "FAR", "computes", "complete", "paths", ",", "but", "has", "a", "limited", "gridlock", "breaking", "procedure", "that", "can", "lead", "to", "failure", "in", "particularly", "congested", "problems", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "flow annotation replanning"}, {"tokens": ["A", "realization", "of", "Cox", "Point", "Process", "driven", "by", "PLP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "poisson line process"}, {"tokens": ["All", "steps", "to", "process", "the", "LSC", ",", "build", "LScD", "and", "the", "basic", "statistics", "with", "characteristics", "of", "words", "in", "the", "LScD", "are", "presented", "in", "the", "later", "sections", "of", "this", "paper", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["In", "Sections", "section_performance", ",", "section_optimization", ",", "and", "section_equilibirum", ",", "we", "present", "our", "contributions", "in", "UE", "data", "rate", "derivation", ",", "SSAUA", "design", ",", "and", "SPS", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "surcharge pricing scheme"}, {"tokens": ["We", "believe", "that", "these", "lines", "of", "research", "in", "QA", "could", "be", "the", "next", "yellow", "brick", "yellowbrick", "in", "the", "road", "to", "true", "AI", ",", "which", "has", "fascinated", "humanity", "since", "the", "ancient", "tales", "of", "Talos", "and", "Yan", "Shi", "'s", "mechanical", "men", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "receiver", "operating", "characteristic", "(", "ROC", ")", "curve", "is", "a", "well", "known", "detection", "performance", "evaluation", "methodology", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Additionally", ",", "each", "individual", "CDFNet", "view", "model", "outperforms", "manual", "raters", "for", "segmenting", "the", "complex", "VAT", "and", "accomplishes", "equivalent", "results", "on", "SAT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["In", "section", ",", "we", "briefly", "review", "the", "literature", "of", "the", "RV", "segmentation", "covering", "the", "traditional", "and", "deep", "learning", "based", "approaches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["To", "implement", "Algorithm", "3", ",", "the", "BS", "needs", "to", "gather", "the", "information", "of", ",", ",", ",", ",", ",", "and", ",", "which", "can", "be", "uploaded", "by", "all", "users", "before", "the", "FL", "process", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["illustrates", "of", "the", "considered", "relaying", "schemes", "with", "both", "repetitive", "and", "RS", "-", "based", "transmission", "as", "a", "function", "of", "for", "average", "transmit", "SNR", "dB", "over", "IID", "Nakagami-", "fading", "channels", "with", "different", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Now", ",", "if", "we", "integrate", "both", "sides", "of", "Equation", "(", ")", "over", "all", "we", "obtain", "where", "is", "the", "Lagrange", "multiplier", "from", "the", "IB", "Lagrangian", "and", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["MP", "based", "hypothesis", "testing", "algorithmWe", "further", "design", "a", "message", "passing", "based", "method", "to", "discover", "general", "abnormal", "random", "variables", ",", "even", "if", "the", "abnormal", "random", "variables", "have", "the", "same", "mean", "as", "the", "regular", "random", "variables", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "message passing"}, {"tokens": ["Although", "some", "raw", "image", "datasets", "do", "exist", ",", "they", "are", "typically", "intended", "for", "research", "on", "ISP", "demosaicing", "and", "denoising", "algorithms", "raise", ",", "mcmaster", "and", "are", "not", "suitable", "for", "training", "modern", "CNNs", ",", "as", "they", "are", "too", "small", "and", "unlabeled", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["[", "In", "deterministic", "scenarios", ",", "the", "IB", "curve", "can", "not", "be", "explored", "using", "the", "IB", "Lagrangian", "]", "Let", "be", "a", "random", "variable", "and", "be", "a", "deterministic", "function", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "results", "show", "that", "the", "GBM", "simulation", "data", "can", "achieve", "near", "85", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric brownian motion"}, {"tokens": ["Although", "MVF", "is", "time", "-", "variant", ",", "our", "h", "-", "NSF", "chooses", "one", "of", "the", "two", "pre", "-", "defined", "MVF", "values", "(", "i.e.", ",", "the", "cut", "-", "off", "frequency", "of", "FIR", "filters", ")", "according", "to", "the", "voicing", "status", "of", "the", "sound", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["Beyond", "those", "issues", "arising", "from", "the", "application", "of", "differential", "privacy", ",", "the", "team", "building", "the", "DAS", "has", "also", "faced", "by", "the", "fluid", "nature", "of", "the", "decennial", "census", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "disclosure avoidance system"}, {"tokens": ["This", "is", "performed", "using", "a", "software", "model", "of", "an", "ISP", "and", "a", "model", "of", "an", "imaging", "sensor", "to", "enable", "the", "study", "of", "relevant", "application", "domains", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["A", "single", "POS", "skeleton", "is", "the", "list", "of", "part", "of", "speech", "tags", "for", "a", "single", "slogan", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "first", "contribution", "of", "this", "work", "is", "the", "proposed", "GP", "model", "for", "contour", "estimation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "ASVspoof", "2019", "LA", "and", "PA", "datasets", "were", "released", "as", "part", "of", "this", "year", "'s", "challenge", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["Therefore", ",", "the", "traffic", "load", "of", "the", "AP", "is", "set", "to", "be", "the", "same", "as", "that", "of", "each", "STA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["It", "is", "clear", ",", "and", "straightforward", "to", "analytically", "prove", "from", "the", "closed", "-", "form", "stability", "region", "boundary", "expressions", ",", "that", "the", "stability", "region", "for", "the", "RA", "scheme", "with", "priorities", "encloses", "the", "stability", "region", "of", "the", "RA", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random access"}, {"tokens": ["Then", ",", "we", "use", "this", "technique", "to", "maximize", "a", "lower", "bound", "on", "the", "convex", "IB", "Lagrangians", "by", "applying", "the", "functions", "to", "the", "estimate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["IACF", "of", "the", "drift", "of", "the", "toxin", "to", "the", "preferred", "interfacial", "location", "evaluated", "as", "a", "function", "of", "and", "in", "HMC", "tests", "(", "left", ")", "and", "as", "a", "function", "of", "in", "MD", "runs", "(", "right", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["Moreover", ",", "the", "continual", "single", "-", "output", "GP", "model", "could", "be", "used", "as", "a", "latent", "baseline", "in", "the", "multivariate", "time", "series", "imputation", "method", "of", ",", "which", "uses", "a", "GP", "to", "capture", "temporal", "dependencies", "between", "real", "-", "valued", "latent", "variables", "that", "are", "later", "connected", "to", "a", "deep", "sequential", "variational", "autoencoder", "(", "VAE", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "DOE", "is", "designed", "as", "a", "distorted", "phase", "gratings", ",", "also", "referred", "to", "as", "a", "multifocal", "gratings", "(", "MFG", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "diffractive optical element"}, {"tokens": ["Among", "the", "control", "variables", ",", "gender", "is", "a", "significant", "predictor", "of", "spatial", "behaviour", "in", "the", "CNS", "dataset", ":", "Females", "display", "higher", "level", "of", "routine", "diversity", "and", "propensity", "towards", "exploration", ",", "in", "accordance", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["Since", "the", "IFD", "corpus", "mainly", "contains", "literary", "work", "(", "see", "Section", ")", ",", "these", "texts", "are", "not", "necessarily", "characteristic", "of", "texts", "that", "have", "to", "be", "tagged", "for", "language", "technology", "or", "research", "purposes", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "icelandic frequency dictionary"}, {"tokens": ["Let", "GI", "denote", "the", "equivalence", "relation", "consisting", "of", "all", "pairs", "of", "isomorphic", "graphs", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph isomorphism"}, {"tokens": ["the", "base", "grid", "mesh", "is", "going", "to", "be", "displaced", "accordingly", "to", "the", "heightmap", "in", "the", "Vertex", "Shader", ",", "the", "base", "grid", "mesh", "geometry", "is", "going", "to", "be", "refined", "with", "TS", "based", "on", "visibility", ",", "the", "terrain", "is", "rasterized", ",", "once", "we", "have", "the", "terrain", "curvature", ",", "in", "the", "FS", ",", "lighting", "and", "color", "blending", "are", "going", "to", "be", "applied", ",", "the", "terrain", "is", "rendered", ",", "through", "user", "interaction", "the", "LOD", "is", "going", "to", "be", "dynamically", "applied", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tessellation shader"}, {"tokens": ["ROC", "curves", "and", "their", "area", "under", "the", "curves", "(", "AUC", "\u2019s", ")", "on", "this", "development", "set", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["On", "a", "consumer", "grade", "GPU", ",", "the", "tool", "-", "tracking", "is", "computed", "in", "real", "-", "time", "and", "the", "AR", "rendering", "pipeline", "is", "able", "to", "support", "two", "1080p", "displays", ",", "each", "running", "above", "30fps", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Models", "performance", "represented", "by", "the", "ROC", "curves", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["As", "evident", "from", "Table", ",", "our", "protocol", "when", "used", "to", "compute", "-out", "-", "of-", "OTs", "with", "short", "inputs", "of", "the", "sender", "outperforms", "all", "the", "known", "actively", "secure", "OT", "extensions", "and", "secures", "the", "second", "best", "spot", "among", "all", "the", "OT", "extension", "protocols", "listed", "in", "Table", "closely", "trailing", "KK13", "which", "is", "the", "overall", "winner", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "performance", "of", "HKL", "is", "consistent", "with", "the", "results", "in", ",", "performing", "competitively", "but", "slightly", "worse", "than", "SE", "-", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["stages.]fig", ":", "partialpartial", "-", "isp.epsAblation", "study", "of", "ISP", "stages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "image signal processor"}, {"tokens": ["-out", "-", "of-", "OT", "given", "in", "is", "used", "to", "transform", "their", "extended", "OTs", "to", "-out", "-", "of-", "OTs", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["This", "OCC", "constraint", "is", "non", "-", "convex", ";", "to", "our", "knowledge", ",", "this", "paper", "offers", "the", "first", "convexification", "of", "the", "OCC", "criteria", "into", "an", "LMI", "framework", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "output constrained covariance"}, {"tokens": ["Compared", "to", "functions", "drawn", "from", "the", "higher", "-", "order", "GP", ",", "draws", "from", "the", "first", "-", "order", "GP", "have", "more", "long", "-", "range", "structure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "fast", "Reed", "-", "Solomon", "erasure", "coding", "algorithms", "can", "be", "applied", "on", "the", "Exact", "-", "MBR", "codes", "to", "reduce", "the", "time", "complexities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Using", "a", "variance", "-", "preserving", "initialization", "method", "(", "Figure", ")", ",", "this", "condition", "allows", "us", "to", "evaluate", "the", "effectiveness", "of", "FA", "without", "the", "need", "for", "additional", "mechanisms", "to", "normalize", "the", "backward", "weights", "as", "the", "forward", "weights", "change", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["Meta", "-", "optimization", "requires", "solving", "OPF", "multiple", "times", "(", "as", "the", "predictor", "changes", ")", "and", "is", "therefore", "computationally", "demanding", ":", "with", "meta", "-", "training", "samples", ",", "PSO", "particles", "and", "meta", "-", "optimization", "steps", ",", "full", "OPF", "problems", "with", "warm", "-", "start", "must", "be", "solved", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["We", "concluded", "that", "only", "NCE", "successfully", "evaluated", "the", "global", "and", "local", "diversity", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["We", "also", "evaluate", "some", "of", "the", "recent", "state", "of", "the", "art", "methods", "for", "text", "classification", "on", "the", "above", "datasets", "naive", "bayes", "features", "in", "bag", "of", "words", "followed", "by", "Logistic", "Regression", "(", "NB", "-", "LR", ")", "inversion", "of", "distributed", "language", "representation", "(", "W2V", "inversion", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["In", "round", ",", "DMD", "applies", "the", "following", "update", "rule", ":", "where", "(", "which", "can", "be", "replaced", "by", "unbiased", "sampling", "if", "is", "an", "expectation", ")", ",", "is", "called", "the", "shift", "model,(In", "Hall", "-", "DMD", ",", "is", "called", "a", "dynamical", "model", ",", "but", "it", "is", "not", "the", "same", "as", "the", "dynamics", "of", "our", "control", "system", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["linear", "discriminant", "analysis", "&", "&", "9lMAP", ":", "maximum", "a", "posteriori", ",", "CC", ":", "cross", "correlation", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "cross - correlation"}, {"tokens": ["Under", "a", "construction", "of", "this", "form", ",", "the", "joint", "distribution", ",", "simplified", "for", "a", "single", "output", "sample", ",", "factorises", "aswhere", "can", "be", "any", "valid", "likelihood", "model", "and", ",", "are", "conditional", "and", "marginal", "GP", "priors", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "addition", "to", "improving", "modeling", "efficacy", ",", "the", "additive", "GP", "also", "improves", "model", "interpretability", ":", "the", "order", "variance", "hyperparameters", "indicate", "which", "sorts", "of", "structure", "are", "present", "in", "our", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["fig", ":", "heartCMED", "-", "TS", "and", "fig", ":", "heartCMED", "-", "KL", ")", "and", "PIMA", "Indians", "Diabetes", "dataset", "(", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["NP", "barfPIr"], "acronym_pos": [1, 0], "long_form": "new persian"}, {"tokens": ["The", "performance", "of", "the", "MMSE", "MUD", "scheme", "improves", "as", "the", "number", "of", "AP", "'s", "antennas", "increases", ",", "and", "degrades", "as", "the", "network", "scales", "up", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Deep", "learning", "(", "DL", ")", "is", "a", "growing", "trend", "in", "big", "data", "analysis", ",", "and", "had", "a", "breakthrough", "impact", "in", "the", "last", "few", "years", "on", "such", "diverse", "domains", "like", "Computer", "Vision", ",", "Speech", "Recognition", ",", "Image", "Processing", ",", "and", "Remote", "Sensing", "(", "RS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "remote sensing"}, {"tokens": ["We", "also", "plot", "the", "median", "temperature", "for", "CC", "-", "CV", "and", "DLC", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "constant charging"}, {"tokens": ["The", "adjacency", "matrices", "showing", "the", "clusterings", "found", "by", "the", "SCF", "(", "left", ")", "and", "SBM", "(", "middle", ")", "on", "the", "3x3", "network", "(", "Figure", "FIGlayout3x3", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Block", "Krylov", "SolverTraditionally", ",", "the", "multigroup", "solve", "has", "been", "done", "with", "GS", ",", "which", "is", "iterative", "in", "energy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gauss seidel"}, {"tokens": ["Evaluation", "Metrics", ":", "To", "evaluate", "CNet", "-", "NIC", ",", "we", "use", "4", "metrics", ":", "BLEU@", ",", "METEOR", ",", "ROUGE", "-", "E", ",", "and", "CIDEr", "-", "D."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural image caption"}, {"tokens": ["Not", "surprisingly", "the", "AA", "prediction", "performance", "improves", "as", "the", "document", "length", "increases", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["HKL(Code", "for", "HKL", "available", "at", "http://www.di.ens.fr/fbach/hkl/", ")", "was", "run", "using", "the", "all", "-", "subsets", "kernel", ",", "which", "corresponds", "to", "the", "same", "set", "of", "kernels", "as", "considered", "by", "the", "additive", "GP", "with", "a", "squared", "-", "exp", "base", "kernel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "also", "observe", "that", "LDOF", "gives", "good", "results", "even", "without", "APO", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "large displacement optical flow"}, {"tokens": ["Although", "SCCs", "have", "provided", "promising", "results", "thus", "far", ",", "the", "features", "observed", "by", "this", "configuration", "are", "directly", "coupled", "to", "the", "motion", "of", "the", "camera", "cluster", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "static camera clusters"}, {"tokens": ["It", "turns", "out", "out", "that", "some", "device", "models", "use", "CC", "charging", "after", "the", "CV", "phase", "and", "this", "third", "phase", "begins", "after", "the", "battery", "is", "charged", "to", "95", "and", "the", "remaining", "5", "is", "charged", "at", "a", "higher", "constant", "rate", "than", "the", "first", "phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant charging"}, {"tokens": ["The", "charging", "controller", "applies", "the", "charging", "algorithm", ",", "such", "as", "CC", "-", "CV", ",", "and", "uses", "the", "fuel", "gauge", "provided", "information", "to", "control", "the", "charging", "current", ",", "voltage", ",", "and", "to", "terminate", "the", "charging", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant charging"}, {"tokens": ["IS", "of", "DCGAN", "is", "reported", "in", ",", "and", "the", "result", "of", "Improved", "GAN(wl", ")", "is", "reported", "in", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["speedup_k_k40_on.pdf[Key", "-", "only", ":", "K40c", "(", "ECC", "off", ")", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["compares", "MVE", "to", "the", "IB", "approach", "of", "MA", "-", "DDPG", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "imaginary batches"}, {"tokens": ["Convergence", "of", "our", "AlgorithmNow", "that", "we", "have", "homogenized", "the", "notation", "framework", "as", "well", "as", "have", "expressed", "the", "proposed", "algorithm", "as", "a", "GPS", "method", "one", "can", "utilize", "the", "theorems", "stated", "in", "Section", "to", "prove", "the", "convergence", "properties", "of", "the", "proposed", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["Co", "-", "DA", "and", "DIRT", "-", "T", "propose", "to", "solve", "this", "problem", "by", "incorporate", "the", "locally", "-", "Lipschitz", "constraint", "via", "virtual", "adversarial", "training", "(", "VAT", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["As", "a", "method", "wise", ",", "CC", "method", "performing", "slight", "over", "the", "LC", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classifier chain"}, {"tokens": ["We", "implement", "LBP", ",", "RBP", ",", "and", "RS", "using", "Nvidia", "'s", "CUDA", "library", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["To", "make", "matters", "even", "worse", ",", "it", "is", "not", "quite", "clear", "whether", "AP", "has", "started", "to", "saturate", ",", "whether", "progress", "is", "significant", ",", "and", "more", "importantly", "how", "far", "we", "can", "improve", "following", "the", "current", "path", ",", "making", "one", "wonder", "maybe", "we", "have", "reached", "the", "peak", "of", "performance", "using", "deep", "learning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Thus", ",", "we", "conduct", "the", "BN", "-", "SV", "-", "MR", "sensitivity", "analysis", "to", "get", "the", "comprehensive", "information", "on", "how", "the", "BN", "model", "risk", "impacts", "on", "the", "criticality", "assessment", "for", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "model risk"}, {"tokens": ["The", "hHRL", "framework", "assumes", "that", "SAR", "interventions", "can", "be", "characterized", "by", "five", "abstract", "action", "categories", ":", "1", ")", "instructions", ",", "2", ")", "promises", ",", "3", ")", "feedback", ",", "4", ")", "disclosures", ",", "and", "5", ")", "inquiries", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Also", ",", "the", "queue", "length", "of", "the", "AP", "is", "set", "to", "quadratically", "increase", "with", "the", "number", "of", "STAs", "(", ")", "to", "statistically", "guarantee", "that", "there", "are", "enough", "frames", "destined", "to", "different", "STAs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["An", "Order", "-", "Theoretic", "Characterisation", "of", "the", "Polytime", "Functionss", ":", "iccWe", "now", "present", "the", "application", "of", "polynomial", "path", "ordersin", "the", "context", "of", "implicit", "computational", "complexity", "(", "ICC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "implicit computational complexity"}, {"tokens": ["Using", "the", "model", "in", ",", "the", "authors", "in", "applies", "the", "Vickrey", "auction", "for", "the", "joint", "bandwidth", "and", "FJ", "power", "allocation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": [",", "the", "BS", "aggregates", "the", "nodes", "and", "channel", "information", "in", "the", "RCAP", "in", "order", "to", "schedule", "the", "transmissions", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "output", "of", "the", "contextual", "layer", "is", "fed", "into", "following", "layers", "of", "QA", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "Unsupervised", "Learning", "FrameworksIn", "this", "section", ",", "two", "unsupervised", "learning", "frameworks", "based", "on", "the", "LB", "divergence", "and", "the", "associated", "algorithms", "are", "proposed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["On", "the", "other", "hand", ",", "some", "BPM", "languages", "focus", "on", "representing", ",", "in", "a", "lower", "-", "level", "of", "abstraction", ",", "the", "process", "execution", "details", ",", "e.g.", ",", "BPEL", "(", "process", "implementation", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "business process modelling"}, {"tokens": ["The", "generation", "of", "output", "images", "information", "includes", "origin", ",", "spacing", ",", "size", ",", "and", "additional", "RS", "metadata", "e.g.", "projection", "reference", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["The", "workers", "compute", "the", "gradients", "and", "push", "the", "results", "to", "the", "PS", "that", "aggregates", "the", "gradients", "after", "the", "majority", "of", "the", "nodes", "communicate", "their", "gradients", "and", "a", "new", "result", "will", "be", "pulled", "from", "the", "workers", "for", "the", "next", "iteration", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["These", "results", "suggest", "that", "MVF", "can", "be", "predicted", "reasonably", "well", "by", "summing", "the", "U", "/", "V", "with", "a", "residual", "signal", "predicted", "from", "the", "input", "acoustic", "features", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["The", "final", "data", "set", "for", "SPAM", "and", "CC", "-", "PEV", "involves", "160", "and", "500", "features", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subtractive pixel adjacency matrix"}, {"tokens": ["The", "other", "gain", "is", "adjusted", "by", "the", "above", "gain", "to", "guarantee", "the", "robustness", "of", "the", "STA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["In", "this", "paper", "we", "introduced", "a", "method", "for", "predicting", "active", "sets", "of", "constraints", "of", "OPF", "problems", "using", "neural", "network", "based", "classifiers", "and", "meta", "-", "optimization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Each", "user", "harvests", "energy", "when", "the", "BS", "transmits", "information", "to", "other", "users", ",", "i.e.", ",", "user", "harvests", "energy", "within", "the", "time", "fraction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Both", "the", "codes", "of", "the", "FEM", "and", "of", "the", "RB", "method", "are", "fairly", "efficient", "in", "-", "house", "C", "/", "C++", "developments", "and", "perform", "exact", "line", "searches", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["is", "the", "TAS", "matrix", "constituted", "by", "the", "specifically", "selected", "columns", "determined", "by", "of", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["By", "employing", "the", "proposed", "quality", "function", ",", "we", "found", "that", "most", "deep", "features", "extracted", "by", "the", "ImageNet", "pretrained", "DCNN", "are", "less", "discriminative", "for", "visual", "tracking", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["We", "introduce", "the", "Manifold", "Geometry", "Matching", "Generative", "Adversarial", "Network", "(", "MGM", "GAN", ")", ",", "which", "adds", "two", "novel", "mechanisms", "to", "facilitate", "GANs", "sampling", "from", "the", "geometry", "of", "the", "manifold", "rather", "than", "the", "density", "and", "then", "aligning", "two", "manifold", "geometries", ":", "(", "1", ")", "an", "importance", "sampling", "technique", "that", "reweights", "points", "based", "on", "their", "density", "on", "the", "manifold", ",", "making", "the", "discriminator", "only", "able", "to", "discern", "geometry", "and", "(", "2", ")", "a", "penalty", "adapted", "from", "traditional", "manifold", "alignment", "literature", "that", "explicitly", "enforces", "the", "geometry", "to", "be", "preserved", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["ACE", "strategy", "is", "used", "to", "simulate", "the", "received", "signal", "and", "generate", "electrodograms", "from", "speech", "data", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "advanced combined encoder"}, {"tokens": ["So", ",", "the", "achievable", "capacity", "of", "and", "can", "be", "achieved", "as", "below", "for", "the", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "technique", "[", "5,27,33", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["In", "DCNN", "-", "DCF", "based", "tracking", "approaches", ",", "convolutional", "neural", "networks", "are", "only", "utilized", "as", "feature", "extractor", ",", "where", "the", "fully", "connected", "layers", "of", "the", "networks", "are", "dropped", ",", "only", "convolution", ",", "activation", "and", "pooling", "layers", "are", "kept", "for", "extracting", "deep", "features", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["There", "are", "a", "number", "of", "alternative", "DE", "methods", "and", "many", "additions", "have", "been", "made", "to", "the", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["All", "FEC", "techniques", "add", "some", "type", "of", "redundant", "information", "which", "is", "sent", "along", "with", "the", "original", "data", "set", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Semantic", "Parsing", "Results", "SP", "results", "are", "summarized", "in", "Table", "2", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic parsing"}, {"tokens": ["Although", "the", "error", "rates", "reported", "by", "TPIB", "system", "are", "better", "than", "the", "IB", "system", ",", "the", "RTF", "is", "high", "mainly", "due", "to", "the", "increased", "time", "for", "training", "the", "artificial", "neural", "network", "(", "ANN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Analysis", "and", "ablation", "experimentsIn", "this", "Section", "we", "present", "results", "towards", "characterizing", "the", "image", "domains", "of", "the", "datasets", "we", "used", "and", "perform", "ablation", "experiments", "on", "the", "number", "of", "components", "of", "the", "GMM", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "BC", "distribution", "follow", "power", "law", "and", "BC", "is", "related", "to", "degree", "as", "where", ",", "is", "BC", "exponent", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["(", "dB", ")", "of", "LTE", "eMBMS", "and", "5", "G", "NR", "for", "AWGN", ",", "ideal", "channel", "estimation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "conclusion", ",", "the", "results", "of", "two", "problems", "show", "that", "our", "method", "with", "the", "TSGD", ",", "QA", ",", "and", "SE", "synthesizes", "highly", "-", "accurate", "trajectories", ",", "while", "effectively", "getting", "out", "of", "local", "minima", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "quantum annealing"}, {"tokens": ["Let", "the", "IB", "curve", "in", "the", "information", "plane", "be", "and", "let", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Overall", ",", "this", "yields", "an", "NP", "algorithm", "for", "checking", "whether", "a", "Rabin", "(", "or", "Streett", ",", "Muller", ")", "automaton", "is", "DBP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "determinisable by pruning"}, {"tokens": ["[", "p", "]", "Wasserstein", "distance", "between", "GMM", "clusters", "of", "input", "gradient", "first", "principal", "components", "with", "under", "overlay", "image", "BP", "attacks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "weights", "of", "MLconv", "were", "initialized", "with", "CP", "decomposition", "using", "canonical", "alternating", "least", "square", "method", ",", "while", "for", "the", "LR", "structure", "we", "followed", "the", "calculation", "proposed", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low rank"}, {"tokens": ["PSO", "has", "succeeded", "at", "finding", "optimal", "regions", "of", "the", "search", "space", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Moreover", ",", "we", "find", "that", "the", "advantage", "of", "RL", "over", "RS", "is", "larger", "in", "this", "case", "(", "RL", "achieves", "1.54", "better", "validation", "accuracy", "than", "RS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random search"}, {"tokens": ["The", "goal", "of", "NP", "is", "to", "learn", "the", "distribution", "of", "s", "from", "pairs", "in", "via", "learning", "the", "distribution", "of", "a", "global", "latent", "variable", "in", "the", "variational", "inference", "framework", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["Above", "we", "concentrated", "on", "practically", "efficient", "OT", "extension", "literature", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["On", "both", "the", "LA", "and", "PA", "tasks", ",", "model", "G", "(", "IMFCC", ")", "outperforms", "model", "F", "(", "MFCC", ")", ",", "suggesting", "that", "a", "focus", "on", "higher", "frequency", "information", "is", "beneficial", "as", "it", "might", "not", "be", "perfectly", "generated", "by", "the", "TTS", "and", "VC", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["PILCO", "with", "priors", "uses", "simulated", "data", "(", "from", "running", "PILCO", "in", "the", "simulator", ")", "to", "create", "a", "GP", "prior", "for", "the", "dynamics", "and", "then", "performs", "policy", "search", "with", "PILCO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": [":", "Integer", "variable", "denoting", "number", "of", "active", "DUs", "at", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "central cloud"}, {"tokens": ["A", "/48", "PI", "allocation", "fee", "is", "in", "the", "range", "of", "a", "few", "hundreds", "of", "US", "(", "between", "US", "100", "and", "US", "800", ",", "depending", "on", "the", "RIR", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["Time", "varying", "acceleration", "factors", "of", "PSO", "Earlier", ",", "the", "values", "of", "acceleration", "factors", "and", "of", "PSO", "were", "considered", "to", "be", "equal", "to", "2", ",", "but", "later", ",", "it", "was", "observed", "that", "varying", "acceleration", "factors", "with", "time", "(", "iteration", ")", "provide", "a", "better", "solution", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Here", "are", "the", "steps", "of", "PSO", "algorithm", "to", "find", "the", "optimal", "bandwidth", ";", "where", "is", "the", "potential", "solution", "of", "the", "particle", "at", "iteration", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["If", "one", "RS", "runs", "out", "of", "energy", "and", "turns", "down", ",", "there", "will", "be", "a", "hole", "and", "the", "whole", "throughput", "will", "bedecreased", "dramatically", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["FR", "and", "XGB", "denote"], "acronym_pos": [1, 0, 0, 0], "long_form": "faster r - cnn"}, {"tokens": ["The", "partial", "dependence", "plots", "(", "PDP", ")", "in", "Figures", "and", "show", "the", "marginal", "effect", "of", "the", "top", "three", "important", "features", "of", "the", "yield", "of", "groundnut", "and", "millet", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial dependence plots"}, {"tokens": ["After", "this", "encoding", ",", "the", "total", "number", "of", "input", "fields", "required", "for", "the", "PNN", "was", "368", "for", "XING", "and", "4", "for", "TMALL", ",", "including", "the", "field", "kept", "for", "embedding", "the", "previous", "items", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["To", "compare", "the", "emerged", "languages", "and", "agents", "with", "a", "baseline", "without", "cultural", "and", "genetic", "evolution", ",", "we", "cross", "-", "pair", "senders", "and", "receivers", "trained", "in", "the", "LTE", "with", "baseline", "senders", "and", "receivers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "language transmission engine"}, {"tokens": ["If", "we", "find", "the", "automaton", "is", "DBP", ",", "we", "can", "remove", "the", "useless", "transitions", ",", "and", "obtain", "an", "equivalent", "DCA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["We", "minimize", "the", "dual", "convex", "IB", "Lagrangian", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["VGI", "can", "be", "seen", "as", "a", "special", "case", "of", "SC", ",", "where", "contributors", "are", "volunteers", "and", "the", "goal", "of", "the", "task", "is", "to", "collect", "or", "verify", "geo", "-", "spatial", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "special case"}, {"tokens": ["Thus", ",", "jointly", "maximizing", "and", "minimizing", "is", "a", "good", "choice", "both", "in", "terms", "of", "performance", "in", "the", "available", "dataset", "and", "in", "new", ",", "unseen", "data", ",", "which", "motivates", "studies", "on", "the", "IB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "information bottleneck"}, {"tokens": ["We", "observe", "that", "the", "number", "of", "requested", "PRBs", "by", "users", "is", "always", "higher", ",", "for", "every", "target", "value", "of", "the", "congestion", "probability", ",", "when", "users", "are", "modeled", "by", "Cox", "process", "driven", "by", "PLP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "poisson line process"}, {"tokens": ["The", "same", "group", "also", "compared", "the", "effects", "of", "\"", "VEGF", "overexpression", "\"", "model", "and", "WT", "using", "SRCT", "and", "also", "found", "little", "difference", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "wild type"}, {"tokens": ["@X", "rrrrr", "@", "&", "PC", "0", "&", "PC", "1", "&", "PC", "2", "&", "PC", "3", "&", "PC", "4", "CNS", "&", "0.57", "&", "0.21", "&", "0.10", "&", "0.08", "&", "0.04", "MDC", "&", "0.55", "&", "0.24", "&", "0.12", "&", "0.06", "&", "0.03", "T=30"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["WF", "Age", "Estimator", ";", "[", "-", ">", "]"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "white females"}, {"tokens": ["The", "proposed", "model", "has", "been", "solved", "using", "an", "improved", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "power system operations"}, {"tokens": ["We", "then", "applied", "this", "method", "to", "identify", "the", "DSA", "skills", "set", "and", "DSA", "occupations", ",", "organising", "these", "occupations", "into", "common", "DSA", "categories", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["In", "practice", ",", "we", "introduce", "a", "bias", "fix", "to", "the", "original", "OT", "distance", "in", "Eqn", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["The", "first", "one", "is", "the", "cross", "-", "layer", "adaptive", "video", "-", "aware", "FEC", "mechanism", "(", "uavFEC", ")", ",", "in", "Section", ",", "and", "the", "second", "is", "the", "Motion", "INTensity", "and", "video", "-", "aware", "mechanism", "(", "MINT", "-", "FEC", ")", ",", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "the", "following", ",", "DADA", "(", ")", "represents", "DADA", "parametrized", "by", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["Goodput", "and", "lossfigure*Random", "mobilityIn", "the", "scenario", "where", "nodes", "move", "at", "random", "and", "consumers", "do", "not", "always", "have", "a", "path", "to", "the", "content", "producer", ",", "intermediate", "nodes", "should", "take", "a", "store", "and", "forward", "approach", ",", "which", "is", "naturally", "done", "in", "NDN", "and", "in", "TCP", "/", "IP", "this", "is", "implemented", "via", "delay", "-", "tolerant", "network", "(", "DTN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "delay tolerant networks"}, {"tokens": ["Therefore", ",", "the", "aforementioned", "memory", "technologies", "are", "protected", "against", "the", "conventional", "charge", "probing", "techniques", "like", "SKPM", ",", "SCM", ",", "PVC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "scanning capacitance microscopy"}, {"tokens": ["Besides", ",", "rare", "and", "unknown", "word", "problem", "as", "an", "important", "issue", "should", "be", "considered", "in", "NLP", "tasks", ",", "especially", "for", "QA", "task", ",", "where", "the", "words", "that", "we", "are", "mainly", "interested", "in", "are", "usually", "named", "entities", "which", "are", "mostly", "unknown", "or", "rare", "words", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["from", "the", "SP", ",", "the", "TP", "learns", "to", "predict", "to", "which", "cluster", "the", "next", "input", "will", "belong", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial pooler"}, {"tokens": ["In", "fact", ",", "s", "-", "RNNs", "outperform", "LSTMs", "on", "many", "of", "the", "SP", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["The", "multiplexing", "and", "scrambling", "operations", "are", "the", "same", "than", "in", "4", "G", "LTE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "long term evolution"}, {"tokens": ["Hence", ",", "CC", "is", "a", "reliable", "measure", "for", "the", "difficulty", "of", "a", "data", "set", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cover complexity"}, {"tokens": ["Constraint", "asso", "is", "to", "ensure", "that", "each", "ground", "user", "can", "be", "associated", "with", "one", "BS", "over", "one", "RB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "resource blocks"}, {"tokens": ["st/", "NP", "bistPIr"], "acronym_pos": [0, 1, 0], "long_form": "new persian"}, {"tokens": ["Tagging", "a", "Different", "Gold", "StandardIn", "the", "previous", "sections", ",", "we", "have", "described", "the", "tagging", "process", "and", "compared", "the", "results", "to", "previous", "taggers", "using", "the", "same", "splits", "on", "IFD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "icelandic frequency dictionary"}, {"tokens": ["However", ",", "there", "is", "no", "reason", "to", "expect", "NP", "b-", "in", "a", "reflex", "of", "a", "Middle", "Persian", "word", "with", "an", "initial", "syllable", "of", "the", "shape"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["In", "the", "amplification", "model", "they", "provide", "a", "differential", "privacy", "algorithm", "that", "will", "be", "satisfied", "by", "any", "-", "invariant", "algorithm", "in", "the", "LDP", "as", "well", "as", "in", "the", "CDP", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["But", "for", "expressions", "involving", "it", "will", "make", "sense", "to", "use", "and", "to", "distinguish", "between", "the", "(", "normalized", ")", "probability", "distribution", "of", "the", "SBM", "andthe", "(", "non", "-", "normalized", ")", "function", "for", "the", "SCF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["ICC", "distributions", "are", "shown", "for", "all", "features", "(", "a", ")", "and", "for", "features", "acquired", "using", "a", "uniform", "spacing", "of", "1", "mm", "(", "b", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["StemmingAnother", "problem", "of", "CER", "is", "that", "all", "types", "of", "errors", "are", "treated", "the", "same", ":", "a", "one", "-", "letter", "difference", "in", "inflection", ",", "such", "as", "kingkings", "or", "camecome", ",", "would", "be", "treated", "identically", "to", "an", "error", "that", "changes", "the", "meaning", "of", "the", "word", "(", "bidsbeds", ")", "or", "results", "in", "a", "non", "-", "word", "(", "creaturecryature", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["NP", "gard(un", ")"], "acronym_pos": [1, 0, 0], "long_form": "new persian"}, {"tokens": ["GMM", "is", "detailed", "in", "alg", ":", "gmm", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["Different", "from", "the", "FPM", "reconstruction", "process", "of", "the", "conventional", "SA", "method", ",", "only", "central", "LR", "images", "are", "used", "in", "the", "mcFPM", ",", "since", "these", "LR", "images", "contain", "mainly", "information", "of", "the", "sample", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["If", "the", "UAV", "spends", "the", "time", "more", "than", "(", "Line", "2", ")", ",", "the", "algorithm", "terminates", "and", "the", "UAV", "finds", "from", "learned", "GP", "for", "the", "USV", "to", "sample", "from", "this", "location", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["AA", "has", "contributed", "to", "conversations", "about", "the", "authorship", "of", "the", "disputed", "Federalist", "papers", ",", "the", "Shakespearean", "authorship", "controversy", ",", "the", "author", "of", "New", "Testament", "and", "the", "author", "of", "The", "Dark", "Tower", "to", "name", "a", "few", "examples", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["Therefore", ",", "a", "new", "DCNN", "architecture", "was", "introduced", "to", "tackle", "this", "problem", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["The", "results", "indicate", "that", "ECS", "-", "DBN", "outperforms", "other", "competing", "methods", "and", "excels", "especially", "in", "terms", "of", "G", "-", "mean", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["3", "illustrates", "the", "average", "achievable", "rate", "with", "respect", "to", "the", "number", "of", "cooperative", "SBSs", "considering", "different", "intensities", "of", "SBSs", "when", "the", "SBS", "cooperation", "strategy", "with", "distance", "constraint", "is", "adopted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["The", "ideal", "point", "on", "the", "ROC", "curve", "would", "be", "(", "0,100", ")", ",", "that", "is", "all", "positive", "instances", "are", "classified", "correctly", "and", "no", "negative", "instances", "are", "misclassified", "as", "positive", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["It", "plots", "the", "features", "dependence", "learned", "by", "all", "models", "for", "the", "UK", "(", "LHS", ")", "and", "the", "US", "(", "RHS", ")", "for", "changes", "in", "GDP", ",", "private", "debt", "and", "broad", "money", "in", "terms", "of", "their", "Shapley", "contributions", "for", "each", "observation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gross domestic product"}, {"tokens": ["When", "performing", "training", "and", "testing", "on", "the", "same", "image", ",", "HOSVD", "achieved", "a", "CCR", "of", "89.13", ",", "which", "is", "2.49", "less", "than", "the", "CCR", "reported", "in", "the", "original", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["We", "ran", "experiments", "with", "the", "following", "infrastructure", ":", "the", "implementations", "of", "the", "OCSVM", "algorithm", ",", "the", "K", "-", "Means++", "clustering", "and", "the", "DT", "algorithms", "are", "based", "on", "Scikit", "-", "Learn", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["The", "packet", "based", "scheduling", "algorithms", "utilize", "the", "packet", "queueing", "status", "at", "the", "AP", "as", "the", "scheduling", "metric", "to", "assemble", "multiple", "packets", "for", "MU", "-", "MIMO", "downlink", "transmissions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Therefore", ",", "the", "OPA", "parameter", "is", "and", "the", "maximum", "secrecy", "rate", "is", ",", "i.e.", ",", "all", "power", "of", "Alice", "is", "employed", "to", "transmit", "confidential", "information", "and", "the", "AN", "fails", "to", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["As", "soon", "as", "the", "AP", "receives", "all", "successful", "CTSs", ",", "it", "precodes", "the", "outgoing", "signals", "and", "sends", "multiple", "data", "frames", "simultaneously", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["(", "ECC", "on", ")", "&", "Our", "Histogram", "&", "28.0", "&", "22.1", "&", "18.4", "&", "14.6", "&", "11.9", "&", "9.0", "&", "7.7", "&", "7.3", "&", "&", "CUB", "&", "8.7", "&", "6.8", "&", "6.2", "&", "5.8", "&", "5.7", "&", "5.5", "&", "5.2", "&", "4.8", "&", "&", "Speedup", "vs.", "CUB", "&", "3.21x", "&", "3.26x", "&", "2.96x", "&", "2.51x", "&", "2.09x", "&", "1.63x", "&", "1.50x", "&", "1.51x", "2", "-", "11", "&", "3*Tesla", "K40c"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["OT", "'s", "advantage", "over", "BS", "was", "in", "the", "color", "distributions", ",", "which", "is", "not", "surprising", "as", "its", "matches", "are", "nearly", "permutations", ",", "while", "BS", "had", "a", "match", "cardinality", "of", "in", "practice", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bidirectional similarity"}, {"tokens": ["In", "the", "modeling", "stage", "of", "DDE", "-", "MGM", ",", "there", "are", "totally", "three", "parameters", "-", "delay", "step", ",", "embedding", "dimension", "and", "cell", "size", "of", "the", "discretized", "embedding", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["the", "dependency", "between", "the", "two", "tasks", ",", "the", "weights", "of", "the", "user", "features", "and", "publisher", "features", "in", "CTR", "task", "are", "assumed", "to", "be", "generated", "from", "the", "counterparts", "in", "CF", "task", "(", "as", "a", "prior):where", "is", "the", "assumed", "variance", "of", "the", "Gaussian", "generation", "process", "between", "each", "pair", "of", "feature", "weights", "of", "CF", "and", "CTR", "tasks", "and", "the", "weight", "generation", "is", "assumed", "to", "be", "independent", "across", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "authors", "in", "applied", "the", "share", "auction", "for", "the", "FJ", "power", "allocation", "to", "optimize", "the", "secrecy", "capacity", "for", "sources", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["Substituting", "(", ")", "into", "(", ")", ",", "the", "system", "power", "loss", "can", "be", "finally", "expressed", "as", ":", "Next", ",", "we", "will", "apply", "the", "hybrid", "ET", "and", "EAA", "approach", "to", "formulate", "the", "uncertainty", "of", "system", "power", "loss", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "evidence theory"}, {"tokens": ["However", ",", "no", "quantitative", "evaluation", "of", "this", "approach", "was", "offered", "(", "only", "a", "few", "hand", "-", "picked", "examples", "based", "on", "the", "Italian", "texts", "from", "the", "Gutenberg", "Project", ")", ",", "and", "thus", "it", "is", "unclear", "whether", "TRI", "is", "any", "better", "than", "other", "distributional", "models", "for", "the", "task", "of", "semantic", "shift", "detection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal random indexing"}, {"tokens": ["In", "the", "first", "step", ",", "we", "carry", "out", "fault", "diagnosis", "where", "ECS", "-", "DBN", "is", "used", "to", "handle", "imbalanced", "data", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["If", "we", "compare", "the", "computational", "time", "required", "between", "the", "evolutionary", "algorithm", "to", "estimate", "the", "misclassification", "cost", ",", "and", "the", "DBN", "training", ",", "the", "former", "is", "very", "small", "and", "negligible", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["It", "can", "be", "seen", "from", "Figure", ",", "that", "the", "presented", "system", ",", "sssynth", "preforms", "better", "than", "DeepConvSep", "and", "FASST", "in", "terms", "of", "the", "SIR", "metric", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "source to interferences ratio"}, {"tokens": ["Semantic", "Correlation", "Maximization", "(", "SCM", ")", "maximizes", "the", "correlation", "between", "different", "modalities", "by", "seamlessly", "integrating", "semantic", "label", "into", "the", "hashing", "learning", "for", "large", "-", "scale", "data", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic correlation maximization"}, {"tokens": ["For", "instance", ",", "the", "traffic", "to", "a", "cell", "can", "be", "partially", "processed", "at", "the", "CC", "so", "that", "the", "midhaul", "bandwidth", "requirement", "can", "be", "relaxed", ",", "then", "the", "remaining", "processing", "could", "be", "done", "at", "the", "EC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Recently", ",", "demonstrated", "that", "a", "RV", "method", "can", "be", "both", "efficient", "and", "obtain", "state", "-", "of", "-", "the", "-", "art", "performance", "when", "trained", "on", "a", "significantly", "large", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "range view"}, {"tokens": ["Also", ",", "as", "the", "output", "power", "increases", ",", "the", "DC", "value", "of", "gradually", "declines", "from", "OCC", "voltage", "to", "MPP", "voltage", ",", "and", "the", "amount", "of", "100", "Hz", "ripple", "seen", "in", "and", "tends", "to", "increase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "open circuit condition"}, {"tokens": ["The", "BQ", "has", "in", "recent", "years", "received", "much", "attention", "in", "the", "probabilistic", "numerics", "community", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian quadrature"}, {"tokens": ["MINT", "-", "FEC", ":", "preformance", ",", "attested", "that", "the", "proposed", "mechanism", "outperforms", "the", "other", "mechanisms", "in", "the", "experiments", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["From", "Yahoo", "Finance", ",", "the", "daily", "highs", "over", "the", "past", "year", "from", "for", "stocks", "in", "the", "Standards", "Poors", "500", "(", "SP", "500", ")", "were", "downloaded", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "standards poors"}, {"tokens": ["The", "workflow", "is", "then", "instantiated", "and", "executed", "efficiently", "in", "RT", "using", "parameters", "values", "selected", "by", "the", "SA", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "region template"}, {"tokens": ["Random", "vaccination", "(", "RV", ")"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "random vaccination"}, {"tokens": ["This", "work", "also", "discussed", "the", "potential", "of", "combining", "MBSFN", "and", "SC", "-", "PTM", "with", "5", "G", "candidate", "techniques", "such", "as", "massive", "MIMO", "and", "mmWave", ",", "serving", "as", "a", "useful", "guidance", "to", "improve", "the", "current", "LTE", "eMBMS", "PTM", "technologies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["TS", "does", "very", "well", "in", "terms", "of", "diversity", ",", "and", "this", "diversity", "enables", "it", "to", "produce", "higher", "max", "scores", "than", "BS", ",", "but", "it", "has", "lower", "averages", "when", "using", "small", "numbers", "of", "continuations", "(", "3", "or", "5", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature - based sampling"}, {"tokens": ["We", "find", "that", "more", "newswire", "-", "like", "services", "such", "as", "AP", "and", "PBS", "are", "not", "as", "highly", "shared", "as", "those", "that", "copy", "from", "them", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "associated press"}, {"tokens": ["FAST", "(", "red", ")", "and"], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "features from accelerated segment test"}, {"tokens": ["A", "recent", "work", "used", "SRL", "as", "the", "auxiliary", "task", "with", "Opinion", "Role", "Labeling", "as", "the", "main", "task", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["Cardiac", "Cine", "-", "MR", "Image", "Segmentation"], "acronym_pos": [0, 0, 0, 1, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["Moreover", ",", "further", "knee", "extension", "is", "essential", "to", "enable", "forward", "propulsion", "in", "late", "MS", "and", "TS", ",", "which", "may", "be", "insufficient", "in", "case", "of", "a", "decreased", "range", "of", "motion", "in", "the", "knee", "joint", "and/or", "a", "lack", "of", "muscle", "strength", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "terminal stance"}, {"tokens": ["ID", "refers", "to", "Item", "Description", "based", "word2vec", "embeddings", "directly", "used", "to", "generate", "recommendations", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "item description"}, {"tokens": ["Additionally", ",", "we", "have", "improved", "the", "quantum", "-", "assisted", "process", "of", "for", "identifying", "the", "Pareto", "-", "optimal", "routes", ",", "so", "that", "it", "becomes", "capable", "of", "\"", "remembering", "\"", "the", "OPF", "identified", "in", "the", "previous", "trellis", "stages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal pareto front"}, {"tokens": ["Figure", "shows", "the", "CCR", "under", "different", "conditions", "of", "our", "proposed", "body", "-", "part", "approach", ",", "the", "approach", "that", "uses", "the", "whole", "-", "body", "(", "without", "body", "segmentation", ")", "and", "the", "View", "-", "Invariant", "Multiscale", "Gait", "Recognition", "method", "(", "VI", "-", "MGR", ")", "representing", "the", "most", "recent", "introduced", "method", "to", "deal", "with", "the", "problem", "view", "-", "angle", "variations", "based", "on", "the", "idea", "of", "estimating", "the", "pose", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["What", "'s", "more", ",", "the", "network", "energy", "efficiency", "of", "fractal", "small", "-", "cell", "networks", "adopting", "the", "SBS", "cooperation", "strategy", "with", "the", "received", "signal", "power", "constraint", "is", "analyzed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["Design", "a", "generic", "transformation", "to", "convert", "an", "Algorithm", "to", "its", "GDP", "variant", ":", "We", "design", "a", "generic", "transformation", "to", "convert", "a", "candidate", "algorithm", "to", "its", "generalized", "differentially", "private", "variant", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["A", "sample", "rule", "for", "non", "-", "anomalous", "data", "points", "for", "dataset", "4", "using", "the", "DT", "surrogate", "methodLimitations", "of", "our", "ApproachOur", "method", "can", "only", "be", "used", "if", "there", "is", "a", "minimum", "number", "of", "data", "points", "(", "at", "least", "one", "point", "per", "vertex", "for", "the", "hypercube", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["To", "this", "end", ",", "here", "we", "introduce", "deep", "normative", "modeling", ",", "which", "utilizes", "an", "NP", "-", "based", "mixed", "-", "effect", "modeling", "and", "involves", "following", "three", "steps", ":", "enumerate[leftmargin=*]Encoding", "phase", ":", "where", "an", "encoder", "is", "learned", "to", "transfer", "the", "covariates", ",", ",", "and", "the", "estimated", "fixed", "-", "effects", "on", "randomly", "drawn", "samples", "from", "the", "training", "set", ",", ",", "to", "the", "parameters", "of", "the", "global", "latent", "variable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["[", "noitemsep]*huarnah-/*farnah-", "MP", "xwarrah", "NP", "farr"], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "new persian"}, {"tokens": ["We", "use", "three", "popular", "metrics", "to", "compare", "the", "resulting", "networks", ":", "PCC", ",", "CCC", ",", "and", "RMSE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["When", "Split", "happens", "in", "between", ",", "the", "function", "above", "the", "split", "are", "placed", "at", "CC", "and", "function", "below", "the", "split", "are", "placed", "at", "EC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["This", "generalized", "vocabulary", "can", "be", "further", "used", "to", "integrate", "different", "components", "and", "web", "services", "within", "a", "QA", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "ReHabgame", "successfully", "calibrated", "the", "ROM", "of", "the", "players", ",", "muscle", "activities", ",", "linear", "and", "angular", "motions", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "range of motion"}, {"tokens": ["Let", "the", "IB", "curve", "in", "the", "information", "plane", "be", "known", ";", "i.e.", ",", "is", "known", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["We", "then", "use", "the", "same", "context", "to", "calculate", "the", "losses", "separately", "for", "NER", "and", "MD", "as", "explained", "in", "Sections", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "morphological disambiguation"}, {"tokens": ["Even", "if", "we", "restrict", "the", "SBM", "to", "consider", "only", ",", "then", "it", "again", "divides", "the", "nodes", "into", "central", "and", "periphery", "nodes", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Average", "achievable", "rate", "adopting", "the", "SBS", "cooperation", "strategy", "with", "distance", "constraintIn", "the", "traditional", "isotropic", "path", "loss", "model", ",", "the", "path", "loss", "decreases", "with", "the", "decrease", "of", "the", "distance", "between", "a", "UE", "and", "a", "SBS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "the", "case", "of", "without", "correlation", "constraints", ",", "the", "average", "accuracy", "of", "CorrNet", "w/o", "CC", "is", "about", "higher", "than", "BB8", "in", "ADDI", "metric", ",", "and", "about", "higher", "in", "the", "2D", "reprojection", "error", "metric", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correlation constraints"}, {"tokens": ["Recently", ",", "presented", "results", "testing", "FA", "on", "CIFAR-10", "and", "ImageNet", "architectures", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["In", "this", "paper", "we", "therefore", "derive", "an", "AIR", "of", "a", "CM", "scheme", "with", "HDD", "using", "the", "Hamming", "metric", "for", "both", "bit", "-", "wise", "and", "symbol", "-", "wise", "decoders", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "coded modulation"}, {"tokens": ["Figure", "shows", "the", "transposed", "convergence", "curves", "for", "the", "optimization", "runs", "(", "minimum", "of", "10", "restarts", ")", "without", "using", "a", "meta", "-", "model", "(", "DE", ")", "and", "using", "a", "meta", "-", "model", "with", "different", "surrogate", "-", "relevator", "pairs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["The", "spectral", "density", "of", "the", "GP", "with", "kernel", "e.ker_expcua", "contains", "only", "low", "frequency", "components", "and", "does", "not", "have", "any", "harmonic", "structure"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Making", "phishing", "URL", "harder", "to", "distinguish", ",", "e.g", "by", "camouflaging", "the", "misspellings", "using", "reduced", "contrast", ",", "distracting", "patterns", "or", "by", "derailing", "attention", "towards", "less", "suspicious", "UI", "elementsThrough", "these", "avenues", "we", "can", "explore", "opportunities", "for", "user", "confusion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user interface"}, {"tokens": ["Our", "model", "extends", "PNN", "with", "the", "ability", "to", "use", "helpful", "modules", "selectively", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "progressive neural networks"}, {"tokens": ["What", "Network", "Three", "networks", "of", "AConvNet", "which", "has", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "MSTAR", "recognition", ",", "HNet", "which", "is", "also", "well", "-", "performed", "on", "MSTAR", "using", "the", "stacked", "convolutional", "auto", "-", "encoders", "to", "learn", "hierarchical", "layers", "with", "unlabeled", "SAR", "images", "and", "transfer", "to", "SAR", "targets", ",", "and", "AlexNet", "which", "is", "the", "breakthrough", "in", "large", "-", "scale", "image", "classification", "with", "deep", "neural", "network", ",", "are", "explored", "in", "this", "section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["On", "the", "other", "hand", ",", "in", "PSO", ",", "each", "particle", "has", "its", "own", "velocity", "which", "improves", "the", "'", "exploration", "'", "of", "search", "space", "and", "consequently", "translates", "into", "better", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["CD", "and", "EMD", "are", "heavily", "influenced", "by", "the", "outliers", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "chamfer distance"}, {"tokens": ["However", ",", "foundry", "can", "perform", "black", "box", "analysis", "of", "structural", "obfuscated", "chip", "and", "exploit", "the", "Oracle", "-", "guided", "(", "for", "example", ",", "SAT", ",", "bypass", ",", "and", "SPS", "attacks", ")", "and", "Oracle", "-", "less", "(", "for", "instance", "SAIL", ",", "and", "desynthesize", "attacks", ")", "attacks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "signal probability skey"}, {"tokens": ["We", "are", "currently", "working", "on", "integrating", "QAmp", "(", "our", "approach", ")", "with", "the", "GERBIL", "QA", "benchmarking", "framework", "DBLP", ":", "journals", "/", "semweb", "/", "UsbeckRHCHNDU19", ",", "which", "will", "not", "only", "make", "evaluation", "against", "existing", "but", "also", "future", "KGQA", "approaches", "easier", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["When", "the", "LTE", "communication", "technologies", "have", "been", "integrated", "into", "vehicular", "networks", ",", "the", "interference", "cuts", "down", "the", "performance", "of", "LTE", "vehicular", "networks", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Intermediate", "columns", "show", "the", "predictive", "perfomance", "of", "the", "GP", "over", "the", "past", "visited", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["a", ")", ",", "while", "the", "knowledge", "of", "the", "PAP", "and", "procedure", "of", "sorting", "the", "processes", "by", "their", "arrival", "times", "make", "the", "delayed", "process", "to", "be", "the", "last", "one", "in", "the", "pipeline", "and", "cause", "the", "whole", "operation", "time", "to", "be", "decreased", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["Robustness", "was", "assessed", "using", "the", "intraclass", "correlation", "coefficient", "(", "ICC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["This", "current", "level", "of", "labour", "supply", "is", "insufficient", "to", "meet", "the", "future", "demands", "for", "ICT", "professionals", "generally", ",", "and", "DSA", "occupations", "specifically", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["mAP", "is", "the", "model", "AP", "over", "all", "IOUs", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["In", "a", "similar", "manner", ",", "as", "in", "the", "kernel", "function", "of", "any", "GP", "prior", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Thus", ",", "data", "augmentation", "is", "very", "important", "in", "the", "proposed", "FER", "framework", "and", "more", "data", "can", "give", "a", "more", "accurate", "FER", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["The", "predicted", "labels", "in", "DST", "task", "depend", "not", "only", "on", "the", "last", "turn", ",", "but", "on", "the", "dialogue", "full", "history", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["can", "not", "be", "secondary", "from", "earlier", "*", "b-", "in", "the", "forms", "given", "above", ",", "since", "most", "of", "the", "languages", "mentioned", "show", "b-", "for", "original", "PIr", "*", "b-.(Lenition", "often", "affects", "earlier", "intervocalic", "labial", "consonants", ",", "e.g.", ",", "Qohrudi", "vixova", "NP", "be", "-", "xvab", "'", "sleeplessness", "'", ",", "NP", "be-", "MP", "abe", "*", "apa", "-", "ika-", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["See", "BMR09", "for", "an", "overview", "on", "ICC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0], "long_form": "implicit computational complexity"}, {"tokens": ["This", "period", "can", "perhaps", "be", "explained", "by", "(", "1", ")", "the", "higher", "levels", "of", "job", "openings", "being", "posted", "online", "earlier", "in", "the", "dataset", "and", "(", "2", ")", "the", "early", "stages", "of", "DSA", "skills", "demanded", "by", "occupations", ",", "particularly", "for", "the", "more", "technically", "rigorous", "occupations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["More", "interesting", ",", "thanks", "to", "its", "affinity", "criteria", "DADA", "can", "introducecommunication", "in", "the", "scheduling", "without", "too", "precise", "communication", "cost", "modelwhich", "are", "required", "in", "HEFT", "to", "predict", "the", "completion", "time", "of", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["In", "the", "first", "pass", ",", "standard", "IB", "based", "diarization", "is", "performed", "followed", "by", "Kullback", "-", "Leibler", "hidden", "Markov", "model", "(", "KL", "-", "HMM", ")", "based", "realignment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["These", "results", "indicate", "that", ",", "by", "considering", "the", "available", "dataset", ",", "the", "LOM", "is", "not", "as", "useful", "as", "the", "SEM", "because", "of", "the", "feature", "size", "of", "the", "objects", "in", "this", "microstructural", "classification", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["RB", ":", "coefficients", ",", "would", "be", "dominated", "by", "these", "nearly", "singular", "points", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["To", "actualize", "this", "loss", ",", "we", "use", "the", "KL", "-", "divergence", "as", "our", "distance", "function", ",", "and", "we", "choose", "the", "adversarial", "noise", "vector", ",", "proposed", "in", "VAT", ",", "as", "our", "noise", "vector", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["However", ",", "the", "gain", "for", "the", "GT", "approach", "over", "the", "DI", ",", "happens", "in", "complementary", "ranges", ":", "when", "for", "spectrum", "sensing", "application", ",", "and", "when", "in", "the", "RADAR", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "direct inspection"}, {"tokens": ["For", "completeness", ",", "in", "Figures", "(", "-i", ")", "and", "(", "j", ")", "we", "also", "display", "the", "results", "from", "using", "kurtosis", "-", "based", "ICA", "to", "unmix", "the", "signals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["For", "the", "nonlinear", "-", "IB", "calculations", "we", "estimated", "the", "gradients", "of", "both", "and", "the", "cross", "entropy", "with", "the", "same", "mini", "-", "batch", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["2013", ")", ",", "NER", "-", "CR", "-", "NEL", "(", "Durrett", "and", "Klein", ",", "2014", ")", "and", "CCR", "-", "NEL", "(", "Dutta", "et", "al", ".", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cross - document coreference resolution"}, {"tokens": ["Comparing", "under", "the", "same", "aggregation", "level", "1", ",", "NR", "requires", "about", "2.8", "dB", "less", "than", "LTE", "to", "achieve", "this", "criterion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["This", "could", "contribute", "to", "the", "strong", "feature", "learning", "ability", "of", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["For", "example", ",", "the", "demands", "for", "DSA", "skills", "are", "expected", "to", "increase", "for", "'", "Economists", "'", "due", "to", "the", "growing", "amounts", "of", "economic", "data", "that", "are", "being", "made", "available", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["In", "SecSDN", ",", "the", "authors", "introduced", "an", "enhanced", "PSO", "multi", "-", "class", "(", "E", "-", "PSO", ")", "routing", "protocol", ",", "which", "takes", "three", "parameters", "into", "consideration", "namely", ":", "node", "congestion", ",", "link", "congestion", "and", "delay", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Under", "open", "access", ",", "the", "UE", "is", "handed", "-", "off", "to", "connect", "to", "the", "femtocell", "BS", "and", "disconnects", "from", "the", "original", "macrocell", "BS", ";", "the", "UE", "is", "then", "referred", "to", "as", "an", "open", "access", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["Where", ",", ",", ",", "and", "represent", "-core", "score", "of", "node", ",", "-core", "score", "of", "node", ",", "BC", "of", "node", "and", "BC", "of", "node", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["In", "the", "case", "of", "the", "FBD", "prior", ",", "BF", "results", "support", "the", "Steppe", "origin", "hypothesis", "for", "all", "the", "datasets", ",", "except", ",", "for", "the", "B1", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayes factor"}, {"tokens": ["ResultsDevelopment", "set", "Table", "presents", "the", "results", "on", "the", "original", "development", "set", "for", "both", "LA", "and", "PA", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "physical access"}, {"tokens": ["The", "robustness", "analysis", "in", "surveys", "shows", "that", "Item", "-", "kNN", "is", "more", "robust", "than", "User", "-", "kNN", "and", "model", "-", "based", "CF", "are", "generally", "more", "resistant", "to", "shilling", "attacks", "than", "conventional", "nearest", "neighbor", "-", "based", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "predictive", "method", "is", "validated", "by", "FEM", "simulation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "finite element method"}, {"tokens": ["In", "this", "paper", "we", "argue", "that", "instead", "of", "Logic", "'s", "exclusion", "from", "the", "IS", "curriculum", ",", "a", "significant", "adaptation", "of", "the", "contents", ",", "as", "well", "as", "teaching", "methodologies", ",", "is", "required", "for", "an", "alignment", "with", "the", "needs", "of", "IS", "practitioners", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information systems"}, {"tokens": ["They", "may", "occur", "in", "terms", "selected", "for", "blind", "RF", "(", "non", "-", "blind", "RF", "is", "not", "applicable", "to", "the", "TREC", "QA", "task", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "results", "from", "the", "survey", "indicate", "that", "most", "participants", "felt", "the", "TDW", "was", "easier", "to", "use", "than", "the", "SDD", ",", "as", "well", "as", "being", "more", "suitable", "to", "the", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["In", "detail", ",", "the", "input", "LR", "image", "is", "passed", "first", "through", "the", "predictor", "network", "and", "then", "the", "extracted", "codes", "are", "fed", "to", "the", "decoder", "network", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Output", "Covariance", "Constrained", "(", "OCC", ")"], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "output constrained covariance"}, {"tokens": ["The", "capacities", "of", "CCU", ",", "CEU", ",", "and", "SC", "of", "the", "proposed", "NOMA", "-", "OAM", "-", "MDMA", "are", "analyzed", "and", "compared", "with", "conventional", "NOMA", ",", "and", "OMA", "-", "OAM", "-", "MDMA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["Statistically", "significant", "difference", "between", "improvement", "and", "worsening", ",", "MRD", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "mean rank difference"}, {"tokens": ["Theoretic", "approach", "on", "new", "agents", "features", "for", "Android", "applicationsSeveral", "common", "features", "for", "Multi", "Agent", "Systems", "and", "an", "Android", "application", "are", ":", "Concurrency", ":", "the", "Android", "components", "are", "activated", "by", "intents", "(", "decentralized", "events", "trigger", "an", "agent", "behavior", "or", "the", "Yellow", "Pages", "service", "provided", "by", "the", "DF", "special", "JADE", "agent", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "direction facilities"}, {"tokens": ["Evaluating", "TCR", "on", "Common", "Landmarks"], "acronym_pos": [0, 1, 0, 0, 0], "long_form": "transductive cascaded regression"}, {"tokens": ["The", "base", "station", "will", "raise", "an", "alert", "if", "the", "MDR", "is", "higher", "than", "a", "false", "MDR", "assigned", "to", "a", "normal", "UAV", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "message dropping rate"}, {"tokens": ["A", "reduced", "OPF", "problem", "has", "the", "same", "objective", "function", "as", "the", "full", "problem", ",", "but", "only", "retains", "those", "constraints", "that", "were", "predicted", "to", "be", "binding", "by", "the", "classifier", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Numerical", "results", "show", "that", "the", "proposed", "algorithms", "canreduce", "up", "to", "25.6", "delay", "and", "37.6", "energy", "consumption", "compared", "to", "conventional", "FL", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["This", "restriction", "would", "not", "impose", "a", "real", "restriction", "in", "the", "operations", "of", "ISPs", "using", "the", "/32", "for", "PA", "allocations", ",", "but", "would", "negatively", "affect", "the", "intermediaries", "that", "want", "to", "resell", "PI", "allocations", "out", "of", "a", "/32", ",", "since", "it", "would", "prevent", "all", "the", "end", "sites", "obtaining", "an", "allocation", "out", "of", "a", "single", "/32", "to", "use", "different", "origin", "ASes", "in", "their", "ROAs", "(", "which", "is", "what", "they", "would", "naturally", "do", "when", "announcing", "a", "PI", "block", "in", "the", "interdomain", "routing", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["In", "this", "paper", "we", "address", "these", "questions", "in", "the", "context", "of", "the", "IS", "curriculum", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information systems"}, {"tokens": ["The", "comparison", "among", "an", "SC", "-", "decoded", "MLPC", "system", ",", "an", "SC", "-", "decoded", "BIPCM", "system", ",", "both", "with", ",", "LTE", "turbo", "coded", "system", "with", ",", "an", "SCL", "-", "decoded", "MLPC", "system", ",", "and", "an", "SCL", "-", "decoded", "BIPCM", "system", ",", "both", "with", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "successive cancellation"}, {"tokens": ["However", ",", "even", "when", "using", "ground", "truth", "bounding", "boxes", ",", "our", "models", "still", "outperform", "other", "current", "approaches", "that", "are", "tested", "with", "ground", "truth", "bounding", "boxes", "(", "e.g.", ")", "based", "on", "the", "IS", "and", "FID", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["Theoretic", "approach", "on", "new", "agents", "features", "for", "Android", "applicationsSeveral", "common", "features", "for", "Multi", "Agent", "Systems", "and", "an", "Android", "application", "are", ":", "Concurrency", ":", "the", "Android", "components", "are", "activated", "by", "intents", "(", "decentralized", "events", "trigger", "an", "agent", "behavior", "or", "the", "Yellow", "Pages", "service", "provided", "by", "the", "DF", "special", "JADE", "agent", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "direction facilities"}, {"tokens": ["Recall", "that", "as", "long", "as", "the", "input", "length", "of", ",", "namely", "satisfies", "the", "relation", ",", "theoretically", "KK13", "OT", "extension", "(", "and", "our", "proposed", "OT", "extension", ")", "gives", "better", "communication", "complexity", "for", "producing", "than", "IKNP", "protocol", "and", "its", "variants", "(", "cf", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["A", "research", "center", "to", "focus", "on", "AR", "is", "opened", "later", "in", "2010", "in", "Vienna", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Next", ",", "we", "apply", "RS", "in", "the", "second", "link", "by", "designing", "the", "precoder", "of", "the", "private", "and", "common", "messages", ",", "and", "we", "consider", "suitable", "power", "allocation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["Classification", "error", "rates", "over", "ANN", "-", "evaluations", "on", "the", "Two", "-", "Circles", "dataset", "using", "the", "DE", "-", "variants", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["However", ",", "due", "to", "the", "video", "requirement", "of", "a", "timely", "delivery", "of", "a", "considerable", "amount", "of", "data", "Zhou2011a", ",", "along", "with", "the", "shared", "wireless", "channel", "resources", ",", "a", "self", "-", "adaptive", "FEC", "-", "based", "mechanism", "is", "advisable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "truth", "is", "that", "the", "existing", "QA", "systems", "similar", "to", "other", "AI", "applications", "are", "a", "black", "box", "(", "see", "Figure", ")", "meaning", "they", "do", "not", "provide", "any", "supporting", "fact", "(", "explanation", ")", "about", "the", "represented", "answer", "with", "respect", "to", "the", "trustworthiness", "rate", "to", "the", "source", "of", "information", ",", "the", "confidence", "/", "reliability", "rate", "to", "the", "chosen", "answer", ",", "and", "the", "chain", "of", "reasoning", "or", "learning", "steps", "led", "to", "predict", "the", "final", "answer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["To", "compare", "our", "results", "with", "the", "benchmarking", "study", ",", "we", "also", "trained", "our", "models", "on", "DT", "using", "a", "confidence", "interval", "of", "0.30", "with", "pruning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["Basically", ",", "tuning", "these", "parameters", "seems", "important", "for", "FA", "to", "do", "it", "'s", "task", "perfectly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "firefly algorithm"}, {"tokens": ["Given", "a", "quad", "-", "tuple", ",", "by", "supposing", ",", "the", "square", "of", "MMD", "can", "be", "rewritten", "aswhereDeep", "Domain", "Adaptation", "Based", "on", "Transitive", "Transfer", "with", "Multi", "-", "SourceIn", "our", "method", ",", "we", "will", "choose", "a", "variety", "of", "source", "tasks", "with", "diverse", "similarity", "to", "the", "target", "task", "to", "assist", "recognizing", "some", "new", "types", "of", "SAR", "targets", "by", "transitive", "transfer", "learning", "from", "distant", "to", "similar", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["These", "results", "suggest", "that", "with", "proper", "ASR", "and", "MT", "adaptation", "through", "in", "-", "domain", "data", ",", "we", "could", "obtain", "similar", "English", "-", "speaking", "IA", "performance", "on", "machine", "translation", "outputs", "as", "the", "Spanish", "-", "speaking", "IAs", "on", "their", "native", "language", "utterances", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intent analyst"}, {"tokens": ["On", "a", "whole", ",", "BOA", "performs", "similarly", "to", "GA", "and", "DE", "in", "terms", "of", "optimizing", "the", "minimum", "damping", "coefficient", "for", "the", "cotrol", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["At", "the", "same", "time", ",", "it", "is", "a", "metric", "that", "measures", "the", "ability", "of", "a", "RS", "model", "to", "allow", "for", "mutability", "in", "user", "preference", "and"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["The", "Gaussian", "Mixture", "Model", "(", "GMM", ")", "is", "an", "archetypal", "latent", "variable", "model", "for", "real", "-", "valued", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["[", "4", "]", "The", "authors", "report", "a", "\"", "best", "\"", "value", "of", ",", "but", "when", "calculating", "the", "IS", "with", "the", "pretrained", "model", "provided", "by", "the", "authors", "we", "only", "obtain", "an", "IS", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "inception score"}, {"tokens": ["On", "this", "metric", ",", "BMAA", "*", "is", "followed", "up", "by", "WHCA", "*", "with", "a", "goal", "achievement", "time", "of", "and", "FAR", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "flow annotation replanning"}, {"tokens": ["As", "an", "application", "in", "the", "context", "of", "ICC", "we", "provide", "an", "order", "-", "theoretic", "characterisation", "of", "the", "polytime", "computable", "functions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "implicit computational complexity"}, {"tokens": ["ConclusionsIn", "this", "paper", ",", "we", "treated", "a", "broadcast", "network", "with", "a", "BS", "sending", "random", "updates", "to", "interested", "users", "over", "unreliable", "wireless", "channels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["GP", "methods", "aim", "to", "learn", "a", "function", ":", "that", "is", "specified", "through", "a", "mean", "and", "a", "covariance", "(", "or", "kernel", ")", "function", ",", "i.e.", ",", "where", "and", "(", "both", ")", "denote", "rows", "of", "the", "input", "matrix", ";", "for", "a", "detailed", "description", "of", "GPs", ",", "we", "refer", "the", "reader", "to", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "results", "show", "the", "neuralFEC", "mechanism", "obtained", "an", "average", "SSIM", "value", "of", "0,831", "against", "a", "value", "of", "0,819", "for", "the", "video", "-", "aware", "FEC", "mechanism", "and", "0,726", "for", "the", "mechanism", "that", "did", "not", "use", "any", "type", "of", "protection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Qualitative", "Analysis", "of", "CaptionsTable", "presents", "several", "representative", "examples", "of", "captions", "produced", "by", "CNet", "-", "NIC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "neural image caption"}, {"tokens": ["As", "shown", "in", "one", "can", "construct", "a", "continuously", "differentiable", "objective", "function", "and", "a", "GPS", "method", "with", "infinite", "many", "limit", "points", "with", "non", "-", "zero", "gradients", "and", "thus", "even", "Thm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["Caixa", "Postal", "6101", ",", "13083", "-", "970", "-", "Campinas", ",", "SP", ",", "Brasil", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "sao paulo"}, {"tokens": ["Each", "SP", "within", "an", "SM", "shares", "an", "instruction", "unit", ",", "dedicated", "to", "the", "management", "of", "the", "instruction", "flow", "of", "the", "threads", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "streaming processors"}, {"tokens": ["GASF", "-", "CNNIn", "the", "framework", "of", "the", "simulation", "data", ",", "we", "will", "use", "GBM", "model", ",", "which", "is", "one", "of", "the", "financial", "classic", "models", ",", "to", "simulate", "a", "large", "amount", "of", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric brownian motion"}, {"tokens": ["In", "addition", ",", "DDE", "-", "MGM", "realizes", "O", "/", "R", "in", "both", "training", "and", "testing", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["While", "the", "FEM", "has", "not", "yet", "been", "equipped", "with", "a", "Quasi", "-", "Newton", "procedure", ",", "the", "linear", "solver", "makes", "use", "of", "parallelization", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["The", "base", "station", "will", "raise", "an", "alert", "if", "the", "MDR", "is", "higher", "than", "a", "false", "MDR", "assigned", "to", "a", "normal", "UAV", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "message dropping rate"}, {"tokens": ["For", "an", "ENF", "signal", ",", "CF", "is", "measured", "as", "the", "ratio", "of", "the", "peak", "value", "to", "the", "root", "mean", "square", "(", "rms", ")", "value", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "crest factor"}, {"tokens": ["This", "mechanism", "protects", "I-", "and", "P", "-", "frames", "with", "a", "specific", "amount", "of", "redundancy", "according", "to", "the", "importance", "of", "each", "one", ";", "(", "4", ")", "the", "adaptive", "FEC", "-", "based", "mechanism", "(", "AdaptFEC", ")", ",", "which", "takes", "into", "consideration", "several", "video", "characteristics", "and", "the", "network", "state", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["If", "perfect", "CSI", "is", "available", "at", "the", "BS", ",", "and", "assuming", "Gaussian", "input", ",", "the", "ergodic", "capacity", "is", "given", "byrClC", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "maximal ratio diversity"}, {"tokens": ["the", "most", "influential", "DCNN", "architectures", ",", "including", "the", "LeNet", "and", "AlexNet", "we", "mentioned", "earlier", ",", "are", "presented", "in", "chronological", "order", "and", "explained", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Therefore", ",", "in", "this", "section", ",", "we", "propose", "a", "channel", "access", "scheme", "thataligns", "with", "LTE", "frame", "structure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "particular", "the", "number", "of", "strings", "to", "be", "verified", "is", "proportional", "to", "the", "number", "of", "extended", "OTs", "output", "by", "the", "OT", "extension", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "beam", "-", "vectors", "for", "each", "UE", "on", "each", "SC", "are", "merged", "into", "a", "single", "large", "-", "dimension", "vector", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Regarding", "language", "-", "based", "QA", "over", "Linked", "Data", ",", "discuss", "and", "study", "the", "usefulness", "of", "natural", "language", "interfaces", "to", "ontology", "-", "based", "knowledge", "bases", "in", "a", "general", "way", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["We", "denote", "by", "the", "coverage", "area", "of", "an", "active", "BS", "where", "referring", "to", "the", "macrocell", "BS", ",", "MBS", ",", "and", "DBS", "placed", "at", "location", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["With", "the", "group", "-", "based", "GMM", "learning", ",", "as", "the", "statistical", "structures", "of", "NSS", "variations", "in", "natural", "image", "are", "captured", "by", "the", "eigenvectors", "in", ",", "and", "thus", "can", "be", "used", "to", "represent", "the", "structural", "variations", "of", "the", "groups", "in", "that", "component", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Together", "with", "the", "RS", "'s", "current", "energy", ",", "its", "future", "energy", "capacity", "can", "be", "calculatedand", "is", "considered", "its", "potential", "energy", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["FEC", "allows", "robust", "video", "transmission", "through", "redundant", "data", ",", "which", "is", "sent", "along", "with", "the", "original", "set", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["MLconv", "and", "LR", "network", "initialized", "with", "CNN", "marked", "with", "\"", "i", "\"", "at", "lastAfter", "obtaining", "the", "optimal", "hyper", "-", "parameter", "values", ",", "each", "network", "was", "trained", "for", "five", "times", "and", "the", "median", "value", "is", "reported", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low rank"}, {"tokens": ["Methodsec", ":", "methodIn", "this", "section", ",", "we", "present", "an", "approach", "based", "on", "the", "IB", "principle", "for", "estimating", "the", "causal", "effects", "of", "an", "intervention", "with", "incomplete", "covariate", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Thus", "cooperative", "games", "can", "be", "applied", "to", "achieve", "the", "optimal", "solutions", "of", "FJ", "power", "and", "price", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["2013", ")", ",", "NER", "-", "CR", "-", "NEL", "(", "Durrett", "and", "Klein", ",", "2014", ")", "and", "CCR", "-", "NEL", "(", "Dutta", "et", "al", ".", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cross - document coreference resolution"}, {"tokens": ["However", ",", "the", "SBM", "is", "slightly", "less", "accurate", "and", "only", "55", "of", "the", "iterations", "involve", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["In", "Clinical", "Medicine", ",", "we", "also", "find", "an", "MAD", "of", "almost", "percentage", "points", "in", "PP", "(", ")", "when", "switching", "to", "metrics", ",", "although", "in", "this", "UoA", "the", "difference", "with", "the", "bootstrapped", "MADs", "is", "more", "substantial", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "median absolute difference"}, {"tokens": ["It", "is", "based", "on", "the", "following", "second", "order", "system(Here", ",", "the", "conventional", "differential", "equations", "of", "STA", "are", "written", "as", "differential", "inclusion", "STA", "with", "the", "symbol", "\"", "\"", "because", "the", "set", "-", "valued", "essences", "of", "signum", "function", "sgn", "will", "be", "employed", "for", "the", "implicit", "Euler", "integration", "in", "the", "subsequence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["It", "follows", "that", "the", "Reduced", "Basis", "scheme", "is", "a", "Galerkin", "procedure", ",", "taking", "the", "displacement", "fieldscorresponding", "to", "the", "RB", "elements", "as", "both", "ansatz", "and", "test", "functions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["For", "the", "air", "tier", "(", "i.e.", ",", ",", ")", ",", "is", "the", "Rician", "small", "scale", "gain", "between", "HAP", "and", "user", "over", "RB", "with", "Rician", "factor", "equal", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "resource blocks"}, {"tokens": ["In", "particular", ",", "compared", "to", "3DOP", "obtaining", "the", "AP", "of", "88.26", "with", "as", "many", "as", "5,000", "proposals", ",", "Re-3DOP", "achieves", "an", "AP", "of", "88.34", "using", "only", "1,000", "proposals", ",", "indicating", "that", "our", "approach", "selects", "more", "accurate", "proposals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "MGM", "GAN", "preserves", "the", "geometry", "of", "the", "original", "manifold", "as", "much", "as", "possible", "while", "still", "aligning", "it", "to", "the", "target", "manifold", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["Specifically", ",", "overfitting", "was", "observed", "in", "the", "simplest", "SL", "language", "and", "undergeneralization", "was", "observed", "in", "the", "most", "complex", "SP", "language", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["We", "follow", "the", "approach", "of", "ALSZ15", "implementation", "and", "perform", "the", "OT", "extension", "in", "batches", "of", "in", "sequential", "order", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["While", "in", "MD", ",", "the", "knowledge", "is", "from", "the", "more", "complex", "teacher", "network", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "model distillation"}, {"tokens": ["Given", "that", "CF", "models", "only", "rely", "on", "user", "preference", "scores", "(", "i.e.", ",", "ratings", ")", "to", "compute", "recommendation", ",", "we", "hypothesize", "that", "it", "is", "relevant", "to", "investigate", "the", "impact", "of", "different", "attack", "strategies", "with", "respect", "to", "the", "victim", "user", "'s", "level", "of", "activity", ",", "i.e.", "the", "richness", "of", "her", "profile", ",", "calculated", "on", "the", "basis", "of", "the", "number", "of", "ratings", "available", "in", "her", "profile", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["shows", "GPU", "RS", "performance", "on", "our", "three", "benchmarks", "as", "cumulative", "convergence", "graphs", ",", "indicating", "the", "cumulative", "percentage", "of", "the", "set", "of", "input", "graphs", "that", "have", "converged", "as", "a", "function", "of", "time", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["Due", "to", "the", "importance", "of", "reliable", "operation", "of", "the", "distribution", "system", ",", "we", "present", "a", "modification", "to", "the", "Con", "-", "TS", "-", "RTP", "algorithm", "(", "i.e.", ",", "replacing", "Constraint", "Set", "A", "with", "Constraint", "Set", "B", "in", "Algorithm", ")", "to", "increase", "the", "reliability", "of", "the", "selected", "prices", "and", "resulting", "load", "profiles", "with", "respect", "to", "the", "grid", "constraints", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["The", "subscript", "denotes", "BS", "to", "CEU", "link", ",", "denotes", "BS", "to", "CCU", "link", "and", "denotes", "CCU", "to", "CEU", "link", "respectively", "["], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Similarly", ",", "Re", "-", "EB", "achieves", "an", "AP", "of", "when", "using", "1,500", "proposals", ",", "while", "EB", "only", "gives", "even", "using", "5,000", "proposals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "performance", "of", "the", "adapted", "UPSO", "(", "2D", "-", "UPSO", ")", "is", "compared", "with", "GA", "and", "five", "other", "PSO", "based", "feature", "selection", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Delay", "TailsTo", "get", "a", "heuristic", "understanding", "of", "the", "delay", "tails", ",", "one", "would", "be", "tempted", "at", "first", "glance", "to", "approximate", "our", "model", "by", "an", "equivalent", "PS", "queue", "using", "a", "spatial", "-", "fluid", "approximation", "that", "neglects", "randomness", "in", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "processor sharing"}, {"tokens": ["ESA", "and", "its", "implementation", "PROCHLO", "is", "a", "very", "good", "implementation", "of", "CDP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "centralized differential privacy"}, {"tokens": ["b", ")", "Interaction", "model", "between", "a", "user", "and", "a", "RS", "over", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["To", "address", "the", "aforementioned", "issues", "in", "the", "previous", "approaches", ",", "we", "propose", "a", "graph", "partition", "based", "algorithm", ",", "dubbed", "as", "GPA", ",", "which", "first", "divides", "the", "input", "graph", "into", "several", "disjoint", "subsets", "by", "the", "graph", "partition", "algorithmgv98", "that", "minimizes", "the", "edge", "cut", "between", "subsets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["ConclusionIn", "this", "paper", ",", "we", "present", "a", "class", "-", "dependent", "OLS", "-", "based", "classification", "method", "named", "cdOLS", "for", "the", "problem", "of", "hyperspectral", "image", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["Importantly", ",", "the", "ability", "of", "readapting", "conditional", "GP", "priors", "w.r.t", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "NIC", "driver", "automatically", "frees", "the", "memory", "used", "by", "packets", "after", "their", "transmission", ",", "making", "it", "available", "for", "newly", "arrived", "packets", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "network interface card"}, {"tokens": ["eq", ":", "EnergyDepEval", "by", "firstcomputing", "a", "right", "hand", "side", ",", "with", "iteration", "index", ",", "asand", "then", "solving", "the", "linear", "systemwhere", "is", "a", "multi", "-", "group", "-", "sized", "vector", "like", "in", "RQI", "(", "recall", "that", "this", "vectorcovers", "only", "one", "group", "in", "PI", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power iteration"}, {"tokens": ["The", "unidirectional", "covert", "channels", "can", "be", "used", "for", "various", "purposes", "including", ":", "(", "1", ")", "exfiltration", "of", "data", "from", "an", "organization", "(", "2", ")", "infiltration", "of", "data", "to", "an", "infected", "computer", "inside", "the", "organization", "'s", "network", "from", "a", "CC", "server", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "covert channels"}, {"tokens": ["their", "adversarially", "trained", "counterpartsWhile", "20-step", "PGD", "is", "a", "powerful", "attack", ",", "we", "also", "test", "ARD", "against", "other", "attackers", "including", "Momentum", "Iterative", "Fast", "Gradient", "Sign", "Method", ",", "DeepFool", ",", "1000-step", "PGD", ",", "and", "PGD", "with", "random", "restarts", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["In", "this", "section", ",", "we", "will", "use", "ICA", "algorithm", "for", "determining", "neural", "network", "'s", "weights", "and", "biases", "in", "training", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imperialist competitive algorithm"}, {"tokens": ["We", "mix", "them", "orthogonally", ",", "and", "compare", "the", "performance", "of", "ICA", "and", "DMD", "at", "unmixing", "them", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["In", "the", "TS", "the", "geometry", "can", "be", "refined", "depending", "on", "the", "desired", "LOD", ",", "while", "in", "the", "FS", "lightning", "and", "color", "blending", "can", "be", "applied", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tessellation shader"}, {"tokens": ["Number", "of", "topicsUsing", "the", "same", "notation", "as", "in", "Section", "is", "because", "the", "number", "of", "topics", "in", "a", "topic", "model", "is", "analogous", "to", "the", "number", "of", "groups", "in", "an", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "stochastic block model"}, {"tokens": ["Notwithstanding", "this", "impossibility", "result", ",", "our", "main", "message", "is", "positive", ":", "When", "agents", "'", "preferences", "are", "represented", "by", "acyclic", "CP", "-", "nets", ",", "satisfies", ",", ",", ",", "and", ",", "while", "satisfies", ",", ",", "and", ",", "recovering", "the", "properties", "of", "PS", "and", "RP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["However", ",", "the", "RV", "strategy", "requires", "a", "large", "number", "of", "nodes", "to", "be", "vaccinated", "for", "reducing", "outbreak", "size", "below", "1", "K", "infections", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["a", ")", "LR", "input", "(", "256160", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Because", "is", "only", "used", "for", "energy", "harvesting", "for", "PS", "based", "SWIPT", "protocols"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["[", "]", "0.48", "[", "]", "0.48", "Sample", "outputs", "obtained", "by", "training", "with", "HR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "high - resolution"}, {"tokens": ["Another", "work", "that", "lends", "itself", "for", "comparison", "is", ",", "when", "considered", "for", "similar", "BS", "and", "UE", "power", "as", "well", "as", "node", "density", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Figure", "shows", "an", "interesting", "anomaly", "with", "one", "participant", "finding", "the", "SDD", "to", "be", "far", "better", "for", "the", "word", "search", "than", "the", "TDW", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["[", "]", "Implicit", "SRL", "model", "in", "text", "relation", "prediction", "*", "[", "htb", "!", "]"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "statistical relational learning"}, {"tokens": ["The", "mean", "and", "variance", "predictions", "of", "the", "GP", "are", "computed", "using", "a", "kernel", "vector", ",", "and", "a", "kernel", "matrix", ",", "with", "entries", ":", "For", "the", "acquisition", "function", ",", "most", "algorithms", "use", "the", "Expected", "Improvement", ",", "the", "Upper", "Confidence", "Bound", "or", "the", "Probability", "of", "Improvement", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Jpos", ",", "the", "implementation", "of", "the", "RB", "method", "is", "prone", "to", "failure", "as", "soon", "as", "the", "constitutive", "law", "eq", ":", "neohooke", "is", "evaluated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["We", "can", "see", "that", "EAP", "outperforms", "AP", "in", "both", "ceiling", "as", "well", "as", "heuristic", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["In", "CTR", "prediction", "tasks", "we", "are", "predicting", "the", "event", "-", "probability", "of", "a", "click", ",", "which", "can", "also", "be", "viewed", "as", "context", "-", "based", "CF", "with", "binary", "ratings", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["In", "this", "paper", ",", "we", "(", "i", ")", "present", "a", "general", "family", "of", "Lagrangians", "which", "allow", "for", "the", "exploration", "of", "the", "IB", "curve", "in", "all", "scenarios", ";", "(", "ii", ")", "provide", "the", "exact", "one", "-", "to", "-", "one", "mapping", "between", "the", "Lagrange", "multiplier", "and", "the", "desired", "compression", "rate", "for", "known", "IB", "curve", "shapes", ";", "and", "(", "iii", ")", "show", "we", "can", "approximately", "obtain", "a", "specific", "compression", "level", "with", "the", "convex", "IB", "Lagrangian", "for", "both", "known", "and", "unknown", "IB", "curve", "shapes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "proposed", "framework", "allows", "fast", "iteration", "and", "eases", "research", "of", "new", "SRL", "methods", "by", "making", "it", "easy", "to", "produce", "statistically", "relevant", "results", ":", "the", "simulated", "environments", "run", "at", "250", "FPS", "on", "a", "8-core", "machine", "that", "allows", "to", "train", "a", "RL", "agent", "on", "1", "Million", "steps", "in", "only", "1h", "(", "or", "to", "generate", "20k", "samples", "in", "less", "than", "2", "min)(Environments", ",", "code", "and", "data", "are", "available", "at", "https://github.com/araffin/robotics-rl-srl", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["That", "is", ":", "[", "IB", "dual", "functional", "]", "Let", "and", "be", "statistically", "dependent", "variables", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["NP", "bihist", ";", "cf", "."], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["These", "weights", "can", "then", "be", "optimized", "as", "hyperparameters", "using", "the", "meta", "-", "loss", "as", "the", "optimization", "target", "through", "a", "similar", "PSO", "framework", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Effect", "of", "Personalization", "on", "EngagementWe", "found", "that", "our", "SAR", "system", "elicited", "and", "maintained", "participants", "'", "engagement", "throughout", "the", "month", "-", "long", "intervention", ",", "an", "important", "measure", "of", "effectiveness", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Adversarially", "Robust", "Distillation", "(", "ARD", ")", "works", "by", "minimizing", "discrepancies", "between", "the", "outputs", "of", "a", "teacher", "on", "natural", "images", "and", "the", "outputs", "of", "a", "student", "on", "adversarial", "images", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["We", "consider", "the", "AP", "gap", ",", "which", "is", "the", "difference", "between", "the", "AP", "obtained", "by", "using", "deep", "learning", "features", "and", "the", "AP", "obtained", "by", "the", "hand", "-", "crafted", "Ibpphog", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "average", "delay", "of", "the", "AP", "(", "Figure", ")", "is", "much", "lower", "compared", "to", "that", "of", "the", "AP", "in", "Figure", ",", "which", "is", "because", "the", "system", "remains", "in", "the", "non", "-", "saturated", "condition", "by", "employing", "the", "frame", "aggregation", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Several", "extensions", "to", "the", "original", "SBM", "have", "since", "been", "proposed", "(", "for", "a", "survey", "see", "Goldenberg2009", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["However", ",", "the", "two", "eigenvalue", "problems", "solved", "were", "not", "particularly", "challenging", "for", "PI", ",", "meaning", "they", "may", "not", "have", "needed", "preconditioning", "to", "begin", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["Different", "from", "OT", "in", "generative", "models", ",", "we", "deem", "the", "channel", "dimension", "as", "different", "samples", "to", "compare", ",", "instead", "of", "batch", "-", "wise", "manner", "as", "in", ";", "and", "treat", "the", "optimization", "of", "and", "in", "a", "unified", "problem", ",", "as", "opposed", "to", "the", "adversarial", "training", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["The", "difference", "is", "that", "the", "MSE", "is", "calculated", "based", "on", "the", "utterance", "gold", "standard", ",", "and", "the", "CCC", "based", "on", "the", "video", "gold", "standard", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "congruence coefficient correlation"}, {"tokens": ["ROC", "curves", "and", "their", "area", "under", "the", "curves", "(", "AUC", "\u2019s", ")", "for", "our", "model"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["To", "serve", "as", "a", "reference", ",", "the", "corresponding", "clinical", "LR", "and", "HR", "images", "are", "displayed", "together", "with", "the", "upsampled", "images", "that", "are", "anonymised", "for", "a", "fair", "comparison", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Moreover", ",", "we", "find", "that", "the", "advantage", "of", "RL", "over", "RS", "is", "larger", "in", "this", "case", "(", "RL", "achieves", "1.54", "better", "validation", "accuracy", "than", "RS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random search"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "SBM", "select", "4", "clusters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "non", "-", "adaptive", "Video", "-", "aware", "FEC", "mechanism", "had", "an", "overhead", "between", "35", "and", "43", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Following", "the", "methodology", "of", "we", "calculate", "the", "Mean", "Rank", "Score", "of", "a", "technique", "per", "configuration", "using", "F", "-", "Score", ",", "MCC", ",", "and", "AUC", "metric", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["adapt", "a", "CCG", "parser", "using", "only", "POS", "and", "lexical", "categories", ",", "while", "extend", "a", "neural", "phrase", "structure", "parser", "trained", "on", "web", "text", "to", "the", "biomedical", "domain", "with", "a", "small", "number", "of", "partially", "annotated", "examples", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["What", "is", "then", "the", "role", "of", "NS", "in", "the", "light", "of", "the", "platforms", "'", "profiling", "practices", "carried", "out", "in", "order", "to", "detect", "users", "'", "preferences", "and", "to", "nudge", "them", "to", "consumption", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "network science"}, {"tokens": ["W(a)(1+)E", ",", "alignedequationwhich", "is", "the", "ratio", "of", "the", "welfare", "induced", "by", "the", "welfare", "-", "minimizing", "SSS", "to", "the", "optimal", "welfare", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "stochastically stable states"}, {"tokens": ["The", "maximum", "(", "over", ")", "of", "the", "K", "-", "S", "distance", "(", "left", "figure", ")", "and", "the", "average", "deviation", "(", "right", "figure", ")", "between", "proposed", "bounds", "and", "the", "CDF", "of", "CD", "and", "NND", "for", "different", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "contact distance"}, {"tokens": ["The", "algorithm", "may", "be", "used", "for", "both", "AFP", "and", "DBP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "discrete base problem"}, {"tokens": ["Such", "problem", "also", "affects", "QA", ",", "and", ",", "in", "particular", ",", "AS2", "since", "no", "large", "and", "and", "accurate", "dataset", "has", "been", "developed", "for", "it", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["In", ",", "the", "authors", "provide", "an", "analysis", "of", "UAV", "hijacking", "attack", "(", "e.g.", ",", "GPS", "signal", "spoofing", ")", "with", "an", "anatomical", "approach", "and", "outline", "a", "model", "to", "illustrate", ":", "(", "1", ")", "that", "such", "attacks", "can", "be", "observed", "to", "reveal", "their", "vulnerabilities", ";", "(", "2", ")", "how", "to", "exploit", "such", "attacks", ";", "(", "3", ")", "how", "to", "provide", "countermeasures", "and", "risk", "mitigation", ";", "and", "(", "4", ")", "details", "of", "the", "impact", "of", "such", "attacks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Recently", ",", "by", "the", "basic", "idea", "of", "IA", "with", "some", "constraints", "shows", "that", "one", "can", "achieve", "DoF", "for", "the", "fast", "fade", "interference", "channel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interference alignment"}, {"tokens": ["[", "]", "MF", ":", "Matrix", "Factorization", "is", "the", "most", "popular", "CF", "-", "based", "recommendation", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["We", "will", "use", "two", "frameworks", "to", "understand", "shoutcasters", "info", "seeking", ":", "PEAS", "to", "understand", "the", "WHAT", ",", "and", "IFT", "to", "understand", "the", "WHERE", "and", "HOW", "of", "shoutcasters", "'", "info", "seeking", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information foraging theory"}, {"tokens": ["We", "denote", "this", "model", "as", "SE", "-", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["FAR", "also", "detects", "deadlocks", ",", "where", "agents", "would", "wait", "on", "each", "other", "indefinitely", ",", "and", "forces", "them", "to", "move", "away", "from", "their", "current", "nodes", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "flow annotation replanning"}, {"tokens": ["Perhaps", "the", "most", "classic", "method", "in", "this", "domain", "is", "PCA", ",", "and", "a", "detailed", "study", "of", "PCA", "will", "illuminate", "many", "of", "the", "issues", "that", "arise", "when", "performing", "DR", "and", "DE", "with", "autoencoders", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["One", "is", "Zero", "-", "to", "-", "medium", "traffic", "period", "when", "a", "BS", "switches", "to", "the", "RS", "mode", "and", "turns", "off", "all", "its", "high", "-", "power", "consuming", "equipment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["Sequential", "multi", "-", "output", "formulationHaving", "a", "multi", "-", "parameter", "GP", "prior", "with", "the", "aforementioned", "form", ",", "we", "want", "to", "model", "the", "sequential", "observation", "process", "properly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["A", "FEC", "-", "based", "mechanism", "was", "proposed", "to", "enhance", "the", "quality", "of", "video", "streaming", "using", "video", "-", "aware", "techniques", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "Figures", ",", "and", "the", "ROC", "curve", "of", "the", "classifier", "shows", "its", "stabilityagainst", "changing", "the", "true", "-", "positive", "versus", "false", "-", "negative", "rates", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "ANN", "model", "achieved", "even", "better", "modeling", "performance", "than", "the", "RF", "model", ",", "as", "an", "improvement", "over", "the", "LMEM", "was", "over", "80", "as", "opposed", "to", "40", "in", "terms", "of", "field", "-", "magnitude", "RMSE", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["We", "envisioned", "that", "a", "generalized", "vocabulary", "for", "QA", "will", "be", "an", "abstraction", "level", "on", "top", "of", "all", "the", "existing", "QA", "approaches", "and", "will", "provide", "interoperability", "and", "exchangeability", "between", "them", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["If", "UE", "can", "be", "admitted", ",", "the", "optimal", "must", "be", "equal", "to", "one", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Then", "there", "exists", "a", "player", "MD", "strategy", "that", "is", "optimal", "in", "all", "states", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["This", "is", "inline", "with", "the", "AlexNet", "test", "error", "rate", "(", "blue", "line", ")", "although", "it", "took", "less", "than", "5", "minutes", "to", "produce", "the", "CSG", "measures", "and", "5", "days", "the", "AlexNet", "results", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["In", "Table", ",", "only", "the", "SAD", "performance", "is", "reported", "since", "Cuprite", "dataset", "does", "not", "have", "a", "quantitative", "fractional", "abundance", "ground", "truth", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["Supplementary", "materialThe", "visualization", "and", "interactive", "state", "space", "exploration", "tools", "are", "demonstrated", "in", "the", "following", "videos", ":", "S", "-", "RL", "Toolbox", "Showcase", ":", "https://youtu.be/qNsHMkIsqJcS-RL", "Toolbox", "Environments", ":", "https://tinyurl.com/y973vhfyKuka", "robot", "arm", ":", "RL", "running", "PPO", "(", "SRL", "trained", "with", "VAE", ")", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["In", "ref", ",", "authors", "used", "DCNN", "along", "with", "SVM", "and", "were", "able", "to", "achieve", "an", "AUC", "of", "0.94", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["The", "first", "element", "of", "corresponds", "to", "the", "first", "column", ",", "i.e.", "the", "first", "BQ", ",", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["Different", "symbols", "are", "transmitting", "towards", "the", "users", "simultaneously", "from", "the", "base", "station", "by", "utilizing", "different", "OAM", "modes", "on", "the", "time", "slot", "of", "relaying", "(", "CCU", "to", "CEU", ")", "for", "CNOMA", "-", "SWIPT", "-", "PS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "power splitting"}, {"tokens": ["GMM", "-", "DeepVAE", "modelThe", "image", "is", "divided", "into", "patches", ",", "which", "is", "the", "input", "to", "our", "DeepVAE", "model", ",", "and", "we", "extract", "the", "rich", "feature", "embeddings", "from", "the", "network", "for", "GMM", "clustering", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Kooper", "and", "MacIntyre", "create", "the", "RWWW", "Browser", ",", "a", "mobile", "AR", "application", "that", "acts", "as", "an", "interface", "to", "the", "World", "Wide", "Web", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["In", "addition", ",", "relaxes", "the", "UE", "-", "based", "ODE", "to", "a", "one", "-", "level", "optimization", "problem", ",", "enhanced", "by", "with", "a", "convex", "relaxation", "program", "on", "a", "one", "-", "level", "optimization", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equilibrium"}, {"tokens": ["As", "evident", "from", "the", "theoretical", "and", "experimental", "results", "presented", "in", "this", "work", ",", "our", "maliciously", "secure", "OT", "extension", "protocol", "is", "a", "better", "choice", "compared", "to", "the", "existing", "maliciously", "secure", "extension", "protocols", "when", "the", "OTs", "required", "are", "of", "type", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "proposed", "ACNN", "model", "is", "evaluated", "on", "multi", "-", "modal", "cardiac", "datasets", "from", "MR", "and", "US", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["The", "optimal", "features", "generated", "from", "TS", "-", "RF", "are", "compared", "with", "three", "filter", "-", "based", "feature", "selection", "techniques", "i.e.", "Gain", "Ratio", ",", "Chi", "-", "Square", ",", "Pearson", "Correlation", "and", "one", "wrapper", "-", "based", "method", "i.e", "GA", "-", "LR", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["We", "also", "show", "that", "while", "expanding", "retrieval", "set", "(", "from", "to", ",", "where", ")", "has", "no", "gain", "for", "the", "decoding", "based", "on", "standard", "beam", "decoding", "(", "BS", ")", "and", "heuristic", "-", "based", "decoding", "(", "BS++", ")", ",", "the", "performance", "of", "the", "proposed", "decoding", "method", "significantly", "increases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard beam search"}, {"tokens": ["Receiver", "Operating", "Characteristic", "(", "ROC", ")", "curve", "of", "the", "Opinum", "classifier", "for", "financial", "opinions", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["First", ",", "we", "train", "the", "CF", "task", "model", "to", "get", "the", "parameters", "and", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "SRL", "methods", "are", "usually", "only", "compared", "with", "learning", "from", "raw", "observations", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["A", "RT", "data", "instance", "represents", "a", "container", "for", "a", "region", "defined", "by", "a", "spatial", "and", "temporal", "bounding", "box", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "region template"}, {"tokens": ["Jim", "Spohrer", "publishes", "the", "Worldboard", "concept", ",", "a", "scalable", "infrastructure", "to", "support", "mobile", "applications", "that", "span", "from", "low", "-", "end", "location", "-", "based", "services", ",", "up", "to", "high", "-", "end", "mobile", "AR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "augmented reality"}, {"tokens": ["The", "FL", "training", "problem", "can", "be", "formulated"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["However", ",", "it", "must", "be", "noted", "that", "our", "approach", "can", "only", "be", "applied", "to", "a", "subset", "of", "SC", "tasks", ":", "those", "that", "can", "be", "done", "on", "a", "street", "-", "view", "image", "of", "the", "space", ",", "and", "is", "limited", "by", "how", "up", "-", "to", "-", "date", "images", "are", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial crowdsourcing"}, {"tokens": ["Our", "task", "is", "to", "predict", "the", "ACE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0], "long_form": "average causal effect"}, {"tokens": ["It", "shows", "that", "the", "CCR", "of", "our", "method", "is", "marginally", "lower", "in", "the", "normal", "and", "carrying", "conditions", "and", "significantly", "higher", "in", "the", "clothing", "variations", "than", "all", "other", "methods", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["The", "RT", "is", "the", "data", "structure", "provided", "by", "the", "RTF", "for", "inter", "-", "stage", "and", "inter", "-", "task", "communication", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "region template"}, {"tokens": ["Distribution", "system", "constraint", "violations", "across", "the", "entire", "system", "avoided", "by", "using", "Con", "-", "TS", "-", "RTP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Given", "the", "dataset", ",", "the", "output", "of", "BNN", "is", "denoted", "as", "where", "is", "input", "data", "and", "are", "the", "weights", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian neural networks"}, {"tokens": ["The", "MGM", "GAN", "'s", "importance", "sampling", "makes", "it", "robust", "to", "these", "changes", "in", "density", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["We", "assume", "MBSs", "and", "SBSs", "are", "operating", "at", "28", "GHz", "and", "the", "bandwidth", "assigned", "to", "each", "UE", "is", "BW", "=", "1", "GHz", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["For", "instance", ",", "in", "LTE", "DC", ",", "control", "information", "for", "a", "UE", "can", "be", "transferred", "via", "MN", "only", "while", "in", "MR", "-", "DC", ",", "it", "can", "be", "transferred", "via", "MN", "or", "MN", "and", "SN", "both", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Accordingly", ",", "in", "the", "first", "stage", "of", "the", "game", ",", "the", "sources", "determine", "their", "FJ", "power", "demands", "so", "as", "to", "balance", "obtained", "utilities", "among", "them", "through", "guaranteeing", "the", "Kalai", "-", "Smorodinsky", "Bargaining", "Solution", "(", "KSBS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["Let", "be", "the", "point", "process", "of", "all", "other", "macrocell", "UEs", "conditioned", "on", "the", "typical", "UE", ",", "which", "is", "called", "the", "reduced", "Palm", "point", "processSG_Totorial1", "with", "respect", "to", "(", "w.r.t", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "section", "starts", "by", "deriving", "the", "data", "rate", "expression", "of", "the", "system", "using", "the", "PS", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "impact", "is", "estimated", "by", "comparing", "the", "population", "estimates", "performed", "on", "a", "coarse", "administrative", "unit", "to", "known", "population", "counts", "of", "finer", "administrative", "units", "(", "see", "SI", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "satellite imagery"}, {"tokens": ["For", "all", "RV", "over", "a", "family", "of", "distributions", ",", "the", "conditioned", "maximum", "probability", "to", "look", "for", "any", "similar", "RV", "in", "the", "worst", "-", "case", "distribution", "over", "(", "i.e.", "for", "all", ")", "when", "is", "measured", "to", "be", "For", ",", "it", "means", "that", "there", "would", "have", "one", "noisy", "strings", ",", "where", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["The", "EI", "helps", "construct", "a", "transmission", "graph", ",", "and", "the", "TI", "helps", "build", "an", "interval", "graph", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["Authors", "attempted", "to", "propose", "a", "new", "version", "of", "PSO", "to", "solve", "optimization", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Use", "cases", "are", "plotted", "against", "these", "axes", "and", "are", "represented", "by", "a", "point", "whose", "size", "corresponds", "with", "the", "impact", "of", "the", "use", "case", "on", "the", "IS", "landscape", "of", "the", "organisation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["It", "is", "worth", "pointing", "out", "that", "the", "average", "delay", "of", "STAs", "is", "higher", "than", "that", "of", "the", "AP", "when", "becomes", "bigger", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["using", "only", "one", "RB", "."], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "resource blocks"}, {"tokens": ["FEC", "-", "based", "schemes", "send", "redundant", "information", "(", "parity", "bits", ")", "along", "with", "the", "original", "data", "set", ",", "which", "can", "be", "used", "to", "recover", "the", "original", "data", "in", "case", "of", "loss", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["For", "example", ",", "in", "order", "to", "avoid", "a", "man", "-", "in", "-", "the", "-", "middle", "replay", "attacks", ",", "in", "which", "an", "adversary", "has", "managed", "to", "copy", "a", "(", "ciphertext", ")", "recording", "of", "the", "signature", ",", "and", "can", "use", "it", "over", "and", "over", "again", ",", "the", "application", "can", "concatenate", "the", "signing", "time", "to", "the", "signature", "in", "Step", "3", ",", "so", "that", "TTP", "will", "be", "able", "to", "check", "whether", "the", "signature", "was", "signed", "recently", "in", "Step", "4", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "trusted third party"}, {"tokens": ["However", ",", "the", "frequency", "based", "POS", "feature", "negatively", "affected", "classification", "accuracy", ",", "so", "it", "has", "been", "omitted", "from", "the", "feature", "set", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "capability", "of", "each", "foundry", "also", "includes", "access", "to", "the", "state", "-", "of", "-", "the", "-", "art", "FA", "tools", "and", "reverse", "engineering", "capabilities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["As", "expected", ",", "the", "TTP", "required", "monotonically", "increases", "with", "for", "all", "the", "methods", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "total transmit power"}, {"tokens": ["These", "two", "eliminators", "include", "(", "1", ")", "the", "use", "of", "gradient", "initialization", "to", "compute", "the", "initial", "values", "of", "the", "prototype", "vector", "of", "cloud", "type", "node", "(", "denoted", "as", "GI", ")", ";", "(", "2", ")", "staggered", "sample", "selection", "to", "feed", "cloud", "data", "for", "training", "(", "denoted", "as", "SSS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "staggered sample selection"}, {"tokens": ["However", ",", "under", "the", "assumption", "of", "a", "multi", "-", "output", "GP", "model", ",", "the", "recurrent", "evaluation", "of", "expectations", "even", "worsens", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["PAF", "is", "an", "extension", "of", "BF", ",", "with", "the", "expense", "of", "a", "higher", "control", "overhead", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider - aware forwarding"}, {"tokens": ["The", "output", "of", "CTC", "is", "like", "a", "probability", "distribution", "over", "all", "label", "sequence", "including", "blank", "label", "for", "each", "frame", "of", "the", "input", "sequences", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["The", "MINT", "-", "FEC", "mechanism", "uses", "the", "same", "set", "as", "uavFEC", ",", "which", "was", "explained", "in", "Section", "and", "Algorithm", "defines", "it", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Our", "results", "confirm", "that", "there", "is", "indeed", "a", "benefit", ",", "especially", "marked", "for", "compact", "models", ",", "to", "incorporating", "an", "ISP", "in", "CNN", "inference", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["The", "previously", "encountered", "problems", "of", "the", "CCR", "for", "normal", "and", "carrying", "conditions", "are", "shown", "in", "Figure", "and", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct correction rate"}, {"tokens": ["The", "perceptual", "loss", "is", "best", "correlated", "with", "the", "structure", ",", "and", "the", "style", "loss", "with", "IS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "inception score"}, {"tokens": ["This", "is", "performed", "to", "show", "the", "importance", "of", "the", "optimization", "of", "the", "relay", "transmit", "power", "levels", "simultaneously", "with", "the", "PS", "ratios", "and", "its", "impact", "on", "the", "reached", "sum", "-", "rate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Classification", "using", "MVFCNNs", ":", "The", "results", "in", "Table", "shows", "that", "a", "MVFCNN", "approach", "using", "SEM", "images", "achieves", "a", "very", "high", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Then", "she", "derives", "a", "new", "DH", "output", "for", "the", "next", "root", "KDF", "chain", "with", "her", "new", "ratchet", "private", "key", "to", "derive", "a", "new", "RK", "and", "a", "sending", "CK", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "root key"}, {"tokens": ["SAR", "has", "been", "shown", "to", "help", "children", "with", "ASD", "develop", "behavioral", "and", "cognitive", "skills", ",", "specifically", "increased", "attention", ",", "turn", "-", "taking", ",", "social", "interaction", ",", "and", "many", "other", "skills", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "D2D", "relay", "node", "acts", "as", "an", "intermediate", "router", "to", "the", "network", "though", "an", "access", "point", "or", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["the", "decoding", "probability", "is", "plotted", "versus", "for", "both", "repetitive", "and", "RS", "-", "based", "transmission", "over", "IID", "Nakagami-", "fading", "conditions", "for", "the", "source", "to", "relay", "channels", "with", "different", "values", "of", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["VGG", "architecture", "is", "used", "for", "PIN", "to", "be", "comparable", "to", "existing", "approaches", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["Throughout", "this", "work", "we", "assume", "that", "will", "be", "modelled", "as", "a", "GP", "and", "the", "resulting", "process", "is", "called", "sigmoidal", "Gaussian", "Cox", "process", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "use", "the", "AWGN", "channel", "to", "compare", "the", "performance", "of", "LTE", "-", "eMBMS", "and", "NR", "-", "PTP", ",", "but", "for", "TDL", "-", "A", "and", "TDL", "-", "C", "channels", "only", "NR", "has", "been", "considered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Since", "the", "DisSim", "framework", "that", "we", "propose", "is", "aimed", "at", "serving", "downstream", "semantic", "applications", ",", "we", "measure", "if", "an", "improvement", "in", "the", "performance", "of", "NLP", "tools", "is", "achieved", "when", "using", "our", "TS", "approach", "as", "a", "preprocessing", "step", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["Instead", ",", "the", "mid", "level", "features", "specific", "to", "natural", "images", "can", "be", "generalized", "to", "SAR", "target", "by", "transitive", "transfer", "with", "SAR", "related", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["We", "investigate", "the", "suitability", "of", "different", "types", "of", "spectrograms", "and", "constant", "-", "Q", "transforms", "as", "input", "representations", "for", "neural", "networks", "and", "compare", "four", "types", "of", "input", "representations", ":", "spectrograms", "with", "linearly", "spaced", "bins", "S", ",", "spectrograms", "with", "logarithmically", "spaced", "bins", "LS", ",", "spectrograms", "with", "logarithmically", "spaced", "bins", "and", "logarithmically", "scaled", "magnitude", "LM", ",", "as", "well", "as"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logarithmically spaced"}, {"tokens": ["Virtual", "Adversarial", "Training", "(", "VAT", ")", "and", "TRADES", "instead", "use", "as", "a", "loss", "function", "a", "linear", "combination", "of", "cross", "-", "entropy", "loss", "and", "divergence", "between", "the", "network", "'s", "softmax", "output", "from", "clean", "input", "and", "from", "adversarial", "input", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["ET", "&", "Evidence", "theory", "."], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "evidence theory"}, {"tokens": ["The", "results", "support", "the", "claim", "that", "MINT", "-", "FEC", "was", "able", "to", "identify", "the", "motion", "intensity", "video", "sequences", "as", "well", "as", "to", "handle", "arbitrary", "video", "resolutions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["For", "node", "level", "vaccination", ",", "coarse", "-", "grained", "information", "based", "IMV", "strategy", "achieves", "the", "performance", "of", "DV", "strategy", "and", "better", "than", "RV", "strategy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random vaccination"}, {"tokens": ["MP", ":", "max", "-", "pool", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "max pooling"}, {"tokens": ["Making", "binary", "features", "for", "all", "the", "multi", "-", "valued", "features", "resulted", "in", "prohibitively", "high", "-", "dimensional", "input", "to", "the", "PNN", ",", "which", "incurred", "large", "computational", "cost", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Beyond", "using", "GP", "to", "perform", "the", "machine", "learning", "itself", ",", "recent", "work", "has", "shown", "that", "GP", "can", "also", "be", "harnessed", "to", "optimize", "a", "sequence", "of", "existing", "data", "analysis", "and", "machine", "learning", "operations", "on", "a", "dataset", "to", "maximize", "the", "predictive", "performance", "of", "the", "final", "machine", "learning", "model", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["We", "however", "only", "study", "the", "dynamic", "version", "of", "treating", "IAN", "and", "leave", "the", "other", "cases", "for", "future", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interference as noise"}, {"tokens": ["After", "that", ",", "AA", "theory", "was", "developed", "and", "has", "been", "applied", "to", "OPF", "problems", "in", "power", "systems", ",", "which", "can", "take", "the", "correlation", "among", "variables", "into", "account", "and", "yield", "much", "tighter", "lower", "and", "upper", "bounds", "compared", "to", "IA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "interval analysis"}, {"tokens": ["An", "example", "of", "such", "a", "DMP", "executed", "in", "the", "environment", "is", "represented", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic movement primitives"}, {"tokens": ["The", "LSC", "was", "collected", "in", "July", "2018", "and", "contains", "the", "number", "of", "citations", "from", "publication", "date", "to", "July", "2018", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["U", "-", "Net", "is", "trained", "on", "the", "FS", "images", "to", "produce", "multi", "-", "class", "(", "LV", ",", "RV", "and", "MC", ")", "segmentation", "outputs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["Every", "PNN", "has", "1", "embedding", "layer", ",", "1", "product", "layer", "and", "3", "hidden", "layers", "(", "5", "layers", "in", "total", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["However", ",", "it", "failed", "to", "find", "the", "lateral", "projections", "of", "the", "CST", "and", "oversegmented", "the", "Meyer", "'s", "loop", "of", "the", "OR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "corticospinal tract"}, {"tokens": ["In", "fact", ",", "we", "see", "a", "very", "similar", "trend", "compared", "to", "the", "two", "classical", "CF", "settings", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["These", "materials", "should", "enable", "users", "to", "recreate", "the", "computational", "environment", "on", "the", "tested", "XSEDE", "HPC", "resources", "(", "SDSC", "Comet", ",", "PSC", "Bridges", ",", "LSU", "SuperMIC", ")", ",", "prepare", "data", "files", ",", "and", "run", "the", "computational", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["Contrastingly", ",", "when", "sigmoid", "activation", "function", "is", "used", "the", "ratio", "changes", "to", "1", "and", "consequently", "affects", "our", "singular", "value", "proxies", "and", "DE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "dimension estimation"}, {"tokens": ["CO", ",", "PA", ",", "CG", "correspond", "to", "context", "-", "only", "attention", ",", "parallel", "attention", "and", "context", "-", "guided", "attention", ",", "respectively", ";", "and", "the", "-CVAE", "suffix", "indicates", "their", "CVAE", "variant", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parallel attention"}, {"tokens": ["While", "most", "of", "the", "tested", "web", "servers", "accept", "any", "permutation", "of", "CR", "and", "LF", ",", "Apache", "just", "ignores", "the", "CRLF", "sequence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "line feeds"}, {"tokens": ["All", "figures", "are", "plotted", "for", "the", "parameters", ",", "and", "due", "to", "Rician", "fading", "channel", "[", "25,27].EE", "w.r.t", "transmit", "SNR", "is", "demonstrated", "in", "Figure", "8", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "[", "22].", "Parameters", ",", ",", ",", ",", ",", ",", "and", "are", "set", "during", "the", "simulation", "purpose", "as", "before", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["We", "then", "train", "a", "DBN", "with", "the", "training", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["This", "addition", "LSC", ",", "eases", "the", "flow", "of", "information", "across", "groups", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long skip connections"}, {"tokens": ["Actually", ",", "the", "solid", "lines", "correspond", "to", "RS", ",", "while", "the", "dashed", "lines", "represent", "the", "implementation", "of", "NoRS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["We", "formulate", "a", "novel", "learning", "algorithm", "for", "classification", "prediction", "of", "DBN", "that", "handles", "imbalanced", "data", "classification", ";", "We", "show", "how", "ECS", "-", "DBN", "works", "by", "assigning", "appropriate", "misclassification", "costs", "and", "incorporating", "cost", "-", "sensitive", "learning", "with", "deep", "learning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["We", "reduce", "the", "total", "number", "of", "calls", "to", "the", "LAP", "solver", ",", "as", "well", "as", "the", "size", "of", "the", "LAPs", "solved", ",", "by", "taking", "advantage", "of", "several", "unique", "properties", "of", "the", "optimization", "as", "a", "function", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear assignment problem"}, {"tokens": ["The", "ternarized", "results", "(", "win", ",", "draw", "and", "loss", ",", "corresponding", "to", "positive", ",", "zero", "and", "negative", "responses", ")", "for", "all", "three", "comparison", "types", "in", "each", "of", "the", "three", "questions", "can", "be", "seen", "in", "Tables", ",", "and", ",", "showing", "that", "our", "method", "beats", "the", "popularity", "-", "based", "baselines", "for", "both", "conditions", "and", "all", "three", "questions", ",", "while", "the", "CF", "-", "based", "ceiling", "remains", "the", "best", "-", "performing", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["This", "is", "the", "underlying", "motivation", "behind", "replacing", "the", "LR", "with", "an", "SVM", "in", "the", "final", "layer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["SAR", "-", "specific", "controllers", "wait", "for", "activation", "to", "select", "the", "robot", "'s", "action", "based", "on", "a", "simplified", "state", "representation", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["It", "shows", "that", "the", "SRS", "predicted", "from", "LPSRS", "method", "agrees", "well", "with", "the", "SRS", "calculated", "from", "FEM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "finite element method"}, {"tokens": ["Beyond", "those", "issues", "arising", "from", "the", "application", "of", "differential", "privacy", ",", "the", "team", "building", "the", "DAS", "has", "also", "faced", "by", "the", "fluid", "nature", "of", "the", "decennial", "census", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "disclosure avoidance system"}, {"tokens": ["This", "led", "to", "a", "situation", "where", "although", "CSIS", "might", "have", "one", "value", ",", "a", "DT", "could", "amend", "this", "data", "on", "a", "Base", "Inventory", "System", "otherwise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "delivery teams"}, {"tokens": ["To", "reduce", "residual", ",", "we", "achieve", "a", "good", "estimation", "of", "the", "group", "sparse", "coefficients", "of", "the", "original", "image", "by", "the", "NSS", "prior", "of", "natural", "images", "based", "on", "GMM", "learning", "and", "the", "group", "sparse", "coefficients", "of", "noisy", "input", "image", "is", "exploited", "to", "approximate", "this", "estimation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "ISP", "software", "model", "allows", "stages", "to", "be", "optionally", "enabled", "or", "disabled(Limited", "to", "valid", "combinations", "of", "ISP", "stages", "to", "ensure", "compatible", "data", "types", "and", "image", "representations", ".", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Increased", "accuracy", "is", "achieved", "when", "the", "number", "of", "GMM", "components", "is", "expanded", "(", "GMM", "-", "UBM", "based", "method", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Olsen", "CM", ",", "Knight", "LL", ",", "Green", "AC", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "centroid methods"}, {"tokens": ["However", ",", "a", "large", "number", "of", "traditional", "MDC", "methods", "face", "many", "difficult", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["Chained", "Declustering", "(", "CD", ")"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "consecutive disks"}, {"tokens": ["The", "two", "chosen", "series", "of", "temporal", "interactions", "are", "labeled", "as", "TI", "1", "and", "TI", "2", "with", "frequency", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["Simpler", "forms", "of", "QA", "can", "also", "be", "achieved", "in", "other", "ways", ",", "however", ",", "approaches", "without", "formal", "translation", "can", "not", "express", "certain", "constraints", "(", "e.g.", "comparison", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["For", "the", "long", "-", "range", "contextual", "information", ",", "we", "develop", "a", "bidirectional", "MTL", "RNN", "that", "inherently", "learns", "the", "anatomic", "structure", "in", "a", "data", "-", "driven", "manner", "and", "exploits", "the", "contextual", "information", "among", "vertebral", "samples", "during", "testing", "phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multi - task learning"}, {"tokens": ["It", "also", "gives", "better", "area", "under", "the", "ROC", "curve", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Interestingly", ",", "for", "RS", "-", "based", "transmission", ",", "as", "and/or", "increase", ",", "the", "improvement", "of", "pure", "compared", "with", "rate", "-", "selective", "RS", "increases", ";", "as", "shown", "in", "Eq", ":", "SSDF_criterion", ",", "rate", "-", "selective", "RS", "might", "choose", "the", "direct", "transmission", "even", "in", "cases", "where", "the", "received", "SNR", "from", "the", "best", "relay", "is", "larger", "that", "from", "the", "source", "node", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["For", "GRD", "or", "RAID0/1", "instead", "of", "using", "in", "Eq", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group rotate declustering"}, {"tokens": ["2013", ")", ",", "NER", "-", "CR", "-", "NEL", "(", "Durrett", "and", "Klein", ",", "2014", ")", "and", "CCR", "-", "NEL", "(", "Dutta", "et", "al", ".", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cross - document coreference resolution"}, {"tokens": ["The", "LFGWO", "extracted", "84", "out", "of", "686", "and", "89", "out", "of", "1000", "features", "from", "SPAM", "and", "AlexNet", "extracted", "features", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "subtractive pixel adjacency matrix"}, {"tokens": ["ARD", "can", "produce", "networks", "more", "robust", "than", "their", "teacherIn", "some", "experiments", ",", "ARD", "student", "networks", "are", "more", "robust", "than", "their", "teacher", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["The", "superiority", "of", "the", "AIA", "method", "is", "clearly", "demonstrated", "in", "both", "HMC", "and", "MD", ",", "since", "AIA", "makes", "the", "toxin", "reach", "the", "target", "destination", "earlier", "than", "the", "rest", "of", "the", "integration", "schemes", "do", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["On", "the", "other", "hand", ",", "over", "1200", "m", ",", "due", "to", "harsher", "conditions", ",", "the", "MINT", "-", "FEC", "mechanism", "starts", "to", "increase", "the", "redundancy", "providing", "a", "considerably", "higher", "QoE", "than", "the", "other", "mechanisms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["MDCN", "obtained", "approximately", "all", "highest", "accuracies", "across", "the", "entire", "range", "of", "IoU.", "Especially", "for", "Car", "and", "Cyclist", ",", "MDCN", "-", "I2", "gets", "10", "higher", "AP", "than", "SSD", ",", "proving", "it", "works", "better", "when", "detecting", "hard", "objects", "and", "is", "robust", "in", "complicated", "scenes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "future", "works", "cover", "the", "following", "topics", ":", "evaluation", "of", "the", "method", "for", "a", "wider", "range", "of", "interconnecting", "network", "speeds", "and", "larger", "number", "of", "nodes", "using", "a", "simulation", "tool", "e.g.", ",", "expansion", "of", "the", "method", "for", "other", "collective", "communication", "algorithms", ",", "e.g.", "all", "-", "gather", ",", "a", "framework", "for", "automatic", "PAP", "detection", "and", "proper", "algorithm", "selection", ",", "e.g.", "providing", "a", "regular", "ring", "for", "balanced", "PAPs", "and", "PRR", "for", "imbalanced", "ones", ",", "introduction", "of", "the", "presented", "PAT", "estimation", "method", "for", "other", "purposes", "e.g.", "asynchronous", "SDG", "training", "or", "deadlock", "and", "race", "detection", "in", "distributed", "programs", ",", "deployment", "of", "the", "solution", "in", "a", "production", "environment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["These", "techniques", "provide", "robust", "video", "transmission", "through", "redundant", "information", "that", "is", "sent", "along", "with", "the", "original", "data", "set", "(", "FEC", "-", "based", ")", ",", "or", "by", "resending", "the", "lost", "packets", "(", "ARQ", "-", "based", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "advantage", "of", "FEM", "model", "is", "that", "it", "gives", "more", "realistic", "deformation", "result", "than", "mass", "-", "spring", "system", "because", "the", "physics", "are", "more", "accurate", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element methodgm97"}, {"tokens": ["Moreover", ",", "when", "comparing", "Figures", "and", ",", "the", "results", "indicate", "that", "the", "best", "way", "to", "deal", "with", "noisy", "sensors", "is", "by", "training", "the", "ANN", "with", "reasonable", "levels", "of", "noise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["MethodsData", "description", "and", "pre", "-", "processingOur", "study", "is", "based", "on", "high", "resolution", "trajectories", "and", "call", "records", "of", "participants", "in", "a", "months", "longitudinal", "experiment", ",", "the", "Copenhagen", "Networks", "Study", "(", "CNS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["However", ",", "achieving", "good", "accuracy", "is", "challenging", "due", "to", "complex", "AAT", "structures", ",", "a", "wide", "variety", "of", "VAT", "shapes", ",", "large", "anatomical", "differences", "across", "subjects", ",", "and", "the", "inherent", "properties", "of", "the", "Dixon", "images", ":", "low", "intensity", "contrast", "between", "adipose", "tissue", "classes", ",", "inhomogeneous", "signals", ",", "and", "potential", "organ", "motion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["The", "resulting", "structure", "is", "the", "same", "of", "ClumpFind", "(", "i.e.", ",", "CAA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "clump assignment array"}, {"tokens": ["The", "models", "with", "ANNs", "generally", "have", "a", "better", "ACC", ",", "RMSE", "and", "KS", "statistic", "than", "the", "No", "-", "ANN", "model", ",", "but", "most", "differences", "in", "the", "mean", "bias", "were", "not", "found", "to", "be", "statistically", "significant", "(", "see", "text", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "anomaly correlation coefficient"}, {"tokens": ["The", "calculation", "of", "and", "updates", "to", "are", "done", "using", "specific", "incremental", "clustering", "algorithms", "such", "as", "sk", "-", "means", "or", "OEC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "online elliptical clustering"}, {"tokens": ["In", "this", "paper", ",", "we", "introduce", "a", "Gaussian", "process", "model", "that", "generalizes", "both", "GAMs", "and", "the", "SE", "-", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["this", "section", ",", "the", "considered", "FL", "algorithm", "that", "is", "implemented", "over", "wireless", "networks", "is", "introduced", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["For", "this", "task", "developed", "a", "DCNN", "architecture", "in", "1998", ",", "the", "LeNet-5", ",", "which", "we", "will", "inspect", "more", "closely", "later", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["The", "authors", "in", "considered", "the", "sum", "learning", "and", "transmission", "energy", "minimization", "problem", "for", "FL", ",", "for", "a", "case", "in", "which", "all", "users", "transmit", "learning", "results", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["1c2*Quality", "-", "Based", "&", "LF", "-", "Test", "&", "24.48", "&", "51.86", "&", "86.21", "&", "17.52", "2", "-", "6", "1c", "&", "SF", "-", "Test", "&", "29.98", "&", "48.79", "&", "50.00", "&", "47.58", "1c2*Color", "-", "Based", "&", "LF", "-", "Test", "&", "8.33", "&", "15.81", "&", "27.50", "&", "4.12", "2", "-", "6", "1c", "&", "SF", "-", "Test", "&", "25.47", "&", "29.62", "&", "12.20", "&", "47.04", "tabular", "minipageResults", "for", "Cross", "-", "FaceResolution", "protocolresults", ":", "crossfaceresolutiontable"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "large faces"}, {"tokens": ["In", "phase", "1", ",", "each", "BAM", "model", "(", "MAM", ",", "RDM", "and", "ATCS", "-", "Table", "II", ")", "is", "used", "statically", "(", "no", "reconfiguration", ")", "for", "a", "24h", "simulation", "period", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "russian dolls model"}, {"tokens": ["ECS", "-", "DBN", "CreationEventually", ",", "the", "optimization", "process", "ends", "with", "the", "best", "individual", "which", "is", "used", "as", "misclassification", "costs", "to", "form", "an", "ECS", "-", "DBN", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["In", "our", "CSS", "scenario", ",", "multiple", "SUs", "sense", "the", "licensed", "sub", "-", "channels", "independently", ",", "and", "the", "PUs", "'", "activities", "can", "be", "predicted", "by", "the", "AP", "using", "the", "collected", "sensing", "results", "of", "SUs", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cooperative spectrum sensing"}, {"tokens": ["In", "GP", "is", "applied", "for", "pattern", "discovery", "and", "extrapolation", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Repetitive", "TransmissionThe", "incoming", "signals", "at", "from", "and", "may", "be", "combined", "using", "a", "time", "-", "diversity", "version", "of", "MRD", "and", "SD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "maximal ratio diversity"}, {"tokens": ["Unlike", "ID", ",", "CD", "does", "does", "spread", "secondary", "data", "over", "multiple", "disks", ",", "but", "CD", "can", "be", "extended", "by", "allowing", "the", "primary", "data", "to", "be", "distributed", "over", "the", "next", "disks", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["Specifically", ",", "we", "notice", "majority", "of", "the", "labels", "have", "BA", "score", "in", "range", "of", "-", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "balanced accuracy"}, {"tokens": ["Therefore", ",", "the", "average", "PL", "for", "air", "-", "to", "-", "ground", "link", "is", "given", "by", ":", "Base", "Stations", "Power", "ModelIn", "the", "active", "state", "and", "to", "serve", "its", "connected", "users", "during", "a", "time", "slot", ",", "the", "BS", "consumes", "power", "denoted", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["From", "simulation", "results", ",", "it", "follows", "that", "the", "PA", "has", "an", "obvious", "dramatic", "impact", "on", "the", "SR", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["Augmenting", "the", "model", "using", "a", "latent", "marked", "Poisson", "process", "and", "Polya", "-", "Gamma", "random", "variables", "we", "obtain", "a", "representation", "of", "the", "likelihood", "which", "is", "conjugate", "to", "the", "GP", "prior", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": [":", "We", "assess", "the", "FatSegNet", "reliability", "by", "comparing", "the", "difference", "of", "VAT", "-", "V", "and", "SAT", "-", "V", "across", "sessions", "for", "each", "subject", "of", "the", "test", "-", "retest", "and", "manually", "edited", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Similarly", ",", "for", "outdoor", "users", "modeled", "by", "Cox", "point", "process", "conditionally", "on", "the", "PLP", ",", "proposition", "remains", "valid", "with", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["The", "channel", "gain", "from", "BS", "to", "any", "-th", "relay", "node", "and", "from", "the", "-th", "relay", "to", "the", "-th", "user", "on", "the", "-th", "sub", "-", "carrier", "is", "denoted", "as", "and", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "generate", "suitable", "misclassification", "costs", "for", "DBN", "using", "the", "training", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "following", "processes", "summarize", "the", "SAR", "operations", "that", "use", "these", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["DSA", "-", "skills", "shows", "the", "selected", "DSA", "skills", ",", "i.e.", "the", "top", "150", "skills", "selected", "using", "the", "methodology", "described", "in", "sec", ":", "skills", "-", "similarity", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["For", "example", ",", "all", "models", "estimate", "a", "robust", "SSC", "for", "GDP", "for", "the", "UK", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gross domestic product"}, {"tokens": ["This", "observation", "motivates", "us", "to", "investigate", "the", "potential", "benefits", "of", "RS", "in", "the", "presence", "of", "the", "SI", ",", "since", "the", "SI", "has", "the", "effect", "of", "altering", "the", "CSI", "between", "the", "estimation", "stage", "and", "the", "transmission", "stage", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["Similar", "TS", "and", "PS", "methods", "could", "then", "be", "applied", "to", "separate", "the", "DC", "current", "to", "perform", "EH", "and", "ID", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["If", "there", "is", "more", "than", "one", "PS", ",", "each", "one", "should", "maintain", "a", "portion", "of", "global", "shared", "parameters", "and", "communicates", "with", "each", "other", "to", "replicate", "and", "to", "migrate", "parameters", "for", "reliability", "and", "scaling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["MAXDistanceMultiHop", "-", "Maximum", "distance", "threshold", "for", "a", "UE", "from", "the", "nearest", "D2D", "Relay", "in", "order", "to", "act", "ad", "D2D", "Multi", "-", "hop", "Relay", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["used", "a", "stochastic", "compartmental", "model", "to", "investigate", "the", "effects", "of", "control", "measures", "on", "ASFV", "and", "found", "that", "early", "intervention", "can", "help", "in", "managing", "the", "ASF", "epidemics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "african swine fever"}, {"tokens": ["ConclusionIn", "this", "paper", ",", "we", "implemented", "a", "GMM", "based", "classification", "with", "DeepVAE", "for", "star", "cluster", "detection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "impact", "of", "allocated", "power", "of", "OAM", "beam", "over", "the", "SC", "is", "analyzed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["Notably", ",", "the", "theoretical", "framework", "as", "well", "as", "the", "convergence", "properties", "of", "GPS", "methods", "have", "been", "extended", "in", "cases", "with", "linear", "constrains", ",", "boundary", "constrains", "and", "general", "Lagrangian", "formulation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["We", "introduce", "AML", ",", "an", "actor", "-", "based", "language", "for", "modeling", "communicating", "components", "in", "concurrent", "systems", ",", "to", "study", "various", "aspects", "of", "actor", "systems", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["TTP", "decrypts"], "acronym_pos": [1, 0], "long_form": "trusted third party"}, {"tokens": ["First", "column", "are", "the", "exemplars", ",", "second", "and", "third", "are", "computed", "with", "OT", ",", "BS", "respectively", "with", "a", "patch", "size", "of", "4", "and", "fourth", "column", "is", "synthesis", "with", "a", "random", "filter", "gram", "loss", "with", "256", "filters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bidirectional similarity"}, {"tokens": ["sup", "-", "ske-", "'", "sleep", "'", "MP", "xwafs-", "NP", "xusp(idan)Other", "West", "Iranian", "languages", "vary", "as", "to", "whether", "they", "show", "metathesis", "in", "the", "same", "words", ";", "this", "variation", "is", "often", "language", "internal:[noitemsep]PIr"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["The", "existence", "conditions", "of", "the", "RSSD", "static", "output", "feedback", "controller", "are", "developed", "by", "exploiting", "the", "properties", "of", "-gap", "metric", "of", "SCP", "central", "plant", ",", "the", "sufficiency", "condition", "of", "SCP", "central", "plant", "for", "simultaneous", "stabilization", ",", "and", "the", "eigenstructure", "assignment", "algorithm", "for", "output", "feedback", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["Some", "promising", "directions", "for", "future", "work", "include", ":", "variants", "and", "extensions", "of", "CNet", "-", "NIC", ",", "including", "those", "that", "substantially", "improve", "the", "quality", "of", "captions", ",", "provide", "justifications", "for", "the", "captions", "that", "they", "produce", ",", "tailor", "captions", "for", "visual", "question", "answering", ",", "tailoring", "captions", "to", "different", "audiences", "and", "contexts", ",", "etc", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural image caption"}, {"tokens": ["The", "key", "principle", "of", "our", "continual", "learning", "method", "is", "that", "we", "are", "able", "to", "reconstruct", "implicit", "GP", "priors", "over", "the", "space", "-", "of", "-", "functions", "conditioned", "to", "past", "posterior", "distributions", "via", "the", "predictive", "GP", "formulation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "digital", "ZF", "precoder", "at", "the", "BS", "is", "given", "by", "where", "the", "equivalent", "channel", "matrix", "can", "be", "expressed", "as", "where", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["This", "experiment", "substantiates", "the", "efficiency", "of", "the", "proposed", "SFM", "for", "large", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "structural factorization machine"}, {"tokens": ["Location", "of", "the", "state", "and", "its", "transition", "from", "its", "previous", "state", "are", "updated", "in", "the", "corresponding", "MGM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "markov geographic model"}, {"tokens": ["True", "positive", ",", "TN", "defines", "True", "negative", ",", "FP", "and", "FN"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "true negative"}, {"tokens": ["The", "minimum", "PI", "allocation", "is", "a", "/48", "or", "a", "/56", "depending", "on", "the", "RIR", "and", "they", "can", "be", "larger", "if", "justified", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["Both", "LMEM", "and", "RF", "produced", "significantly", "higher", "than", "the", "ANN", "model", "at", "all", "evaluated", "locations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["In", "this", "paper", ",", "we", "propose", "FatSegNet", ",", "a", "novel", "fully", "automated", "deep", "learning", "pipeline", "based", "on", "our", "CDFNet", "architecture", "to", "localize", "and", "segment", "VAT", "and", "SAT", "on", "abdominal", "Dixon", "MR", "images", "from", "the", "Rhineland", "Study", ",", "an", "ongoing", "large", "population", "-", "based", "cohort", "study", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["In", "all", "examples", "observed", "thus", "far", ",", "the", "RB", "converges", "to", "the", "final", "load", "amplitude", "in", "a", "single", "increment", ",", "requiring", "7", "-", "13", "Quasi", "-", "Newton", "iterations", ",", "with", "only", "2", "-", "4", "assemblies", "of", "the", "Jacobi", "matrix", "and", "a", "runtime", "of", "10", "-", "50", "seconds", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["Given", "a", "expected", "partitionpayload", ",", "BSP", "recursively", "creates", "subpartitions", "if", "the", "number", "of", "objectsinside", "a", "partition", "exceeds", "the", "specified", "payload", "(", "Algorithm", "algo", ":", "binarysplit", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["The", "second", "term", "is", "the", "product", "of", "the", "maximum", "of", "the", "back", "-", "pressure", "of", "own", "queue", "and", "relay", "queue", "with", "respect", "to", "BS", "and", "the", "link", "connecting", "MS", "with", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Combined", "Requirements", "for", "Crop", "Yield", "and", "Crop", "Area", "EstimatorsIt", "has", "already", "been", "mentioned", "that", "it", "was", "very", "unlikely", "to", "get", "accurate", "estimations", "of", "yield", "before", "the", "end", "of", "the", "growing", "season", "(", "based", "on", "EO", "data", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "earth observation"}, {"tokens": ["Right", "ventricle", "(", "RV", ")", "imaging", "is", "particularly", "difficult", "because", "of", "its", "anatomy", "and", "the", "motion", "of", "the", "heart", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["Furthermore", ",", "the", "combined", "signal", "is", "also", "seriously", "corrupted", "by", "AN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "artificial noise"}, {"tokens": ["This", "first", "version", "of", "the", "GCP", "consists", "in", "finding", "an", "interesting", "vertex", "partition", "to", "compress", "the", "graph", ",", "thus", "inducing", "a", "partition", "of", "its", "edges", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph compression problem"}, {"tokens": ["The", "Mean", "Average", "Conceptual", "Similarity", "(", "MACS", ")", "score", "is", "=", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "mean average conceptual similarity"}, {"tokens": ["Motivated", "by", "this", "observation", ",", "we", "proposed", "the", "RS", "strategy", "to", "tackle", "the", "saturation", "occured", "in", "multi", "-", "pair", "MIMO", "relay", "systems", "with", "imperfect", "CSIT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["However", ",", "she", "can", "delayer", "each", "layer", ",", "image", "those", "layers", "with", "SEM", "and", "extract", "the", "gate", "-", "level", "netlist", "using", "reverse", "engineering", "software", "like", "Pix2Net", "or", "Chipwork", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["The", "maximum", "DI", "score", "is", "then", "added", "to", "the", "UniqT", "parameter", "to", "get", "the", "final", "IPI", "for", "each", "person", "entity", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "document index"}, {"tokens": ["Then", ",", "we", "obtain", "the", "unique", "models", "of", "delay", "and", "energy", "consumption", "for", "FL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "federated learning"}, {"tokens": ["LAP", "is", "a", "quasi", "-", "stationary", "aerial", "communications", "platform", "that", "operates", "at", "an", "altitude", "of", "less", "than", "km", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low altitude platform"}, {"tokens": ["Guidelines", "for", "selecting", "a", "proper", "function", "in", "the", "Convex", "IB", "LagrangianWhen", "chossing", "the", "right", "function", ",", "it", "is", "important", "to", "find", "the", "right", "balance", "between", "avoiding", "value", "convergence", "and", "aiming", "for", "strong", "convexity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["For", "example", ",", "with", "20", "selected", "features", ",", "our", "two", "methods", "outperform", "the", "best", "baseline", "by", "20\u2013-40", "relatively", "in", "terms", "of", "ACC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "accuracy"}, {"tokens": ["Two", "separate", "U", "-", "Nets", "were", "trained", "on", "patches", "comprising", "the", "four", "MR", "channels", "plus", "the", "WT", "ground", "truth", "labelmap", "as", "a", "fifth", "channel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "whole tumor"}, {"tokens": ["This", "is", "a", "considerable", "enhancement", "over", "non", "-", "adaptive", "FEC", "mechanisms", "and", "also", "reinforces", "the", "importance", "of", "using", "adaptive", "FEC", "-", "based", "scheme", "which", "takes", "into", "account", "motion", "intensity", "when", "protecting", "a", "video", "stream", "with", "varying", "characteristics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Figure_1.pngAbsolute", "error", "in", "ACE", "estimation", "for", "Twins", "task", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "average causal effect"}, {"tokens": ["Conditioned", "on", ",", "the", "FA", "and", "MD", "probabilities", "are", "given", "bywhere", "is", "a", "random", "variable", "with", "chi", "-", "squared", "distribution", "with", "degrees", "of", "freedom", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "missed detection"}, {"tokens": ["itemizeGenerally", ",", "QA", "systems", "allow", "the", "users", "to", "search", "for", "information", "using", "a", "natural", "language", "interface", ",", "and", "return", "short", "answers", "to", "the", "users", "questionVoorhees2006", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "goal", "of", "multi", "-", "language", "adaptation", "is", "to", "develop", "and", "evaluate", "a", "language", "-", "invariant", "ARS", "model", "for", "multiple", "target", "languages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "addressee and response selection"}, {"tokens": ["The", "simulation", "results", "show", "that", "CLT", "and", "MP", "still", "identify", "the", "abnormal", "random", "variables", "with", "fewer", "observations", "than", "SLT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "message passing"}, {"tokens": ["User", "5", "and", "User", "6", "are", "associated", "with", "the", "rogue", "AP", "to", "access", "the", "Internet", "and", "their", "data", "confidentiality", "is", "compromised", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Compared", "with", "the", "ANN", "model", ",", "the", "RF", "model", "'s", "performance", "exhibited", "a", "more", "significant", "performance", "improvement", "when", "supplied", "with", "more", "training", "data", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["trades", "off", "the", "impact", "of", "AN", "and", "FN", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["In", "a", "second", "step", "we", "make", "sure", "that", "all", "superlinear", "SCCs", "are", "purely", "superlinear", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "strongly connected components"}, {"tokens": ["ABEP", ",", ",", "of", "square", "-QAM", "versus", "the", "number", "of", "relay", "nodes", ",", ",", "for", "average", "transmit", "SNR", "dB", "and", "dB", "over", "IID", "Nakagami-", "fading", "channels", "with", "different", "values", "of", ":", "(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["This", "paper", "attempts", "to", "improve", "the", "RTF", "of", "the", "TPIB", "system", "using", "an", "incremental", "transfer", "learning", "approach", "where", "the", "parameters", "learned", "by", "the", "ANN", "from", "other", "conversations", "are", "updated", "using", "current", "conversation", "rather", "than", "learning", "parameters", "from", "scratch", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["For", "TFN", ",", "LMF", ",", "and", "MFM", ",", "we", "re", "-", "did", "experiments", "with", "using", "our", "features", "for", "a", "fair", "comparison", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low - rank multimodal fusion"}, {"tokens": ["Moreover", ",", "EE", "can", "be", "derived", "as", "below", "for", "the", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "[", "35", "-", "36],So", "the", "above", "equation", "shows", "that", "EE", "is", "related", "to", "the", ",", "and", "as", "before", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Time", "slot", "(", ")", "is", "allocated", "by", "the", "BS", "to", "only", "one", "node", "'s", "transmission", "for", "the", "purpose", "of", "avoiding", "collisions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Given", "the", "beamforming", "vector", "of", "confidential", "messages", "and", "AN", "projection", "matrix", "and", "total", "power", "constraint", ",", "a", "PA", "strategy", "of", "maximizing", "secrecy", "rate", "(", "Max", "-", "SR", ")", "is", "proposed", "for", "secure", "DM", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["Background", ":", "Memory", "NetworksHere", ",", "we", "give", "a", "brief", "description", "of", "memory", "networks", "which", "have", "shown", "promising", "results", "on", "QA", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["Because", "of", "this", "battery", "specific", "behavior", ",", "we", "explore", "and", "validate", "two", "different", "options", ";", "1", ")", "we", "select", "the", "range", "of", "SOC", "values", "that", "cover", "the", "whole", "CC", "phase", "or", "2", ")", "we", "select", "the", "SOC", "range", "that", "yields", "the", "highest", "C", "-", "rate", "(", "we", "call", "this", "max", "C", "-", "rate", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["But", "the", "realizations", "sampled", "from", "a", "GP", "with", "this", "covariance", "function", "(", "Figure", "f.samples_kernel_expcosqua", ")", "show", "a", "smooth", "variation", "in", "the", "amplitude", "envelope", ",", "and", "also", "maintain", "the", "properties", "described", "by", "the", "previous", "kernel", "e.kernel_expcos", ",", "i.e.", "a", "periodic", "structure", "with", "natural", "frequency", "and", "harmonics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Con", "-", "TS", "-", "RTP", "is", "more", "conservative", "with", "its", "exploration", "of", "untested", "price", "signals", "and", "avoids", "the", "constraint", "violations", "made", "by", "the", "unconstrained", "TS", "algorithm", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["In", "order", "to", "evaluate", "the", "method", "with", "limited", "target", "data", "and", "balance", "the", "training", "numbers", "of", "each", "category", ",", "we", "select", "the", "elaborated", "types", "of", "Cargo", ",", "Container", "Ship", "and", "Bulk", "Carrier", "of", "GRD", "mode", "(", "with", "resolution", "of", "10", "m", ")", "and", "VV", "polarization", "in", "our", "experiments", ",", "filtering", "those", "ship", "chips", "with", "the", "size", "larger", "than", "70", "70", "pixel", "to", "ensure", "the", "sufficient", "image", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ground range detected"}, {"tokens": ["Rebuild", "processing", "can", "be", "parallelized", "with", "the", "CD", ",", "ID", ",", "and", "GRD", "RAID1", "organizations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["ARToolKit", "is", "available", "as", "open", "source", "under", "the", "GPL", "license", "and", "is", "still", "very", "popular", "in", "the", "AR", "community", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["The", "PS", "protocol", "is", "employed", "at", "only", "one", "selected", "relay", "to", "support", "the", "source", "transmission", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Whenever", "it", "was", "not", "possible", "to", "learn", "from", "zero", "with", "a", "given", "algorithm", ",", "such", "as", "BP", "and", "DTP", ",", "we", "simply", "marked", "the", "appropriate", "slot", "with", "an", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "difference target propagation"}, {"tokens": ["Moreover", ",", "we", "compute", "AR", "and", "AP", "of", "different", "sizes", "of", "objects", "to", "further", "investigate", "on", "a", "specific", "scale", "of", "targets", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average recall"}, {"tokens": ["In", "addition", ",", "we", "found", "that", "even", "for", "the", "same", "learning", "algorithm", ",", "e.g.", ",", "DT", ",", "the", "incremental", "and", "retrained", "modeling", "can", "yield", "different", "positions", "on", "the", "trade", "-", "off", "surface", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["Then", ",", "and", "From", "this", "definition", "it", "follows", "that", "minimizing", "the", "dual", "IB", "Lagrangian", ",", ",", "for", "is", "equivalent", "to", "maximizing", "the", "IB", "Lagrangian", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Approximation", "of", "GP", "via", "sparse", "GP"], "acronym_pos": [0, 0, 1, 0, 0, 1], "long_form": "gaussian process"}, {"tokens": ["The", "quality", "of", "the", "upsampled", "images", "is", "evaluated", "in", "terms", "of", "SSIM", "metric", "between", "the", "clinical", "HR", "image", "data", "and", "reconstructed", "HR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], "long_form": "high - resolution"}, {"tokens": ["The", "convolution", "layers", "in", "MAD", "unit", "is", "trained", "from", "scratch", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["As", "will", "be", "explained", "in", "sec", ":", "subreg", ",", "SP", "languages", "are", "simple", "regular", "languages", "which", "encode", "only", "certain", "types", "of", "long", "-", "distance", "dependencies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["DiscussionFigure", "compares", "synthesis", "results", "of", "the", "non", "-", "parametric", "OT", "5", ",", "BS", "2", "methods", "and", "the", "statistical", "random", "convolution", "method", "in", "Algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bidirectional similarity"}, {"tokens": ["Given", "a", "QA", "benchmark", "(", "QALD7", ")", ",", "we", "evaluate", "a", "visual", "method", "which", "is", "based", "on", "iteratively", "creating", "diagrams", "until", "the", "answer", "is", "found", ",", "against", "four", "QA", "systems", "that", "have", "natural", "language", "queries", "as", "input", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Qualcomm", "announces", "the", "release", "of", "its", "AR", "platform", "SDK", "to", "the", "public", "in", "April", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Then", ",", "if", "we", "fix", "the", "functions", "and", "we", "can", "obtain", "the", "same", "point", "in", "the", "IB", "curve", "with", "both", "Lagrangians", "whenor", "equivalently", ",", "If", "we", "proceed", "like", "we", "did", "in", "the", "proof", "of", "Proposition", "we", "can", "find", "the", "mapping", "between", "and", "and", "between", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "above", "observations", "have", "promoted", "us", "to", "study", "an", "Evolutionary", "Cost", "-", "Sensitive", "Deep", "Belief", "Network", "(", "ECS", "-", "DBN", ")", "to", "deal", "with", "the", "imbalanced", "data", "problems", ",", "where", "we", "find", "ways", "to", "assign", "differential", "misclassification", "costs", "to", "the", "classes", ",", "that", "we", "also", "call", "class", "-", "dependent", "misclassification", "costs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "most", "interesting", "result", "is", "that", "random", "clustering", "results", "in", "spectral", "efficiency", "even", "worse", "than", "direct", "UE", "-", "BS", "communication", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "base station"}, {"tokens": ["[", "]", "An", "overview", "of", "deep", "learning", "-", "based", "approaches", "for", "FER", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "facial expression recognition"}, {"tokens": ["The", "discrimination", "learned", "by", "the", "ANN", "on", "one", "conversational", "recording", "can", "be", "useful", "for", "training", "an", "ANN", "on", "another", "recording", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "-values", "from", "Holm", "post", "-", "hoc", "test", "shown", "in", "Tables", "and", "indicates", "that", "the", "proposed", "ECS", "-", "DBN", "method", "statistically", "outperforms", "other", "methods", "with", "significant", "statistical", "differences", "based", "on", "the", "results", "of", "all", "58", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "set", "is", "linearly", "independent", "within", "the", "space", "and", "is", "called", "RB", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "reduced basis"}, {"tokens": ["The", "PA", "task", "seems", "generally", "more", "difficult", "and", "should", "thus", "be", "the", "primary", "focus", "of", "future", "work", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["Moreover", ",", "the", "PS", "based", "SWIPT", "provides", "higher", "EE", "than", "TS", "based", "SWIPT", "for", "CNOMA", "as", "well", "which", "is", "also", "shown", "in", "Figure", "8", "as", "well", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Our", "key", "contributions", "include", ":", "We", "study", "the", "performance", "of", "FL", "algorithm", "over", "wireless", "communication", "networks", "for", "a", "scenario", "in", "which", "each", "user", "locally", "computes", "its", "FL", "model", "parameters", "under", "a", "given", "learning", "accuracy", "and", "the", "BS", "broadcasts", "the", "aggregated", "FL", "model", "parameters", "to", "all", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["One", "of", "the", "major", "advantages", "of", "the", "CTC", "algorithm", "is", "that", "you", "do", "not", "need", "properly", "segmented", "labeled", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["In", "particular", "for", "all", ",", "SL", "SL", ",", "SP", "SP", ",", "LT", "LT", ",", "PT", "PT", "and", "LTT", "LTT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0], "long_form": "locally threshold testable"}, {"tokens": ["To", "overwhelmingly", "reduce", "the", "total", "number", "of", "parameters", "of", "the", "MD", "cascaded", "-", "ResBlock", "decoder", "networks", ",", "a", "symmetrical", "structure", "is", "designed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["211", "]", "introduced", "a", "PSO", "-", "Based", "virtual", "SDN", "customization", "for", "multi", "-", "tenant", "cloud", "services", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Compared", "with", "MF", ",", "SFM", "performs", "better", "with", "an", "average", "improvement", "of", "nearly", "50", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "structural factorization machine"}, {"tokens": ["[", "CC", ",", "1000", "runs", ",", "12", "clust", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "connected caveman"}, {"tokens": ["Training", ")", ",", "the", "adversarially", "trained", "Bayesian", "variant", "of", "it", "proposed", "in", "(", "Adv", "-", "BNN", ")", "and", "the", "Bayesian", "variant", "adversarially", "trained", "on", "A", "-", "PGD", "examples", "(", "Adv", "-", "BNN", "w/", "A", "-", "PGD", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "bayesian neural networks"}, {"tokens": ["hypercube", "(", "uniformly", ")", ",", "CMA", "-", "ES", ",", "CMA", "-", "ES", "-", "SB", ",", "CMA", "-", "ES", "-", "INV", "-", "SB", "and", "CMA", "-", "ES", "-", "SB", "-", "BF", "settings", ":", "we", "used", "suggested", "settings", "for", "enhanced", "global", "search", "abilities", ",", "mentioned", "in", "the", "C", "-", "code", "reference", "implementation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "brute force search"}, {"tokens": ["exp", "-", "time", "reports", "the", "running", "time", "of", "GPA", "and", "HARP", "that", "take", "as", "input", "the", "whole", "graph", "in", "each", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["To", "this", "end", ",", "we", "train", "MobileNets", "on", "images", "generated", "with", "different", "stages", "of", "the", "ISP", "selectively", "enabled", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Central", "Differential", "Privacy", "(", "CDP", ")"], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "centralized differential privacy"}, {"tokens": ["The", "energy", "predictor", "is", "also", "built", "atop", "GP", "regression", ",", "with", "energy", "consumption", "values", "directly", "measured", "from", "the", "hardware", "platform", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Answering", "SystemsAs", "argued", "earlier", ",", "one", "important", "use", "case", "of", "automatically", "generating", "questions", "from", "text", "/", "images", "is", "to", "eventually", "use", "these", "generated", "questions", "to", "train", "a", "QA", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "Video", "-", "aware", "FEC", "scheme", "is", "non", "-", "adaptive", "and", "due", "to", "that", ",", "it", "has", "a", "constant", "network", "overhead", ",", "as", "showed", "in", "Figure", "fig", ":"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Then", ",", "after", "30", "seconds", ",", "we", "start", "sending", "another", "flow", "using", "the", "scheme", "under", "investigation", "from", "another", "server", "to", "the", "same", "UE", "and", "will", "report", "the", "average", "throughput", "gained", "by", "both", "flows", "through", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "the", "PS", "protocol", ",", "before", "transforming", "the", "received", "signal", "from", "passband", "to", "baseband", ",", "the", "relay", "uses", "a", "fraction", "of", "it", "for", "EH", "while", "it", "uses", "the", "remaining", "part", "for", "information", "transmission", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["To", "get", "a", "more", "reliable", "estimate", "of", "the", ",", "we", "first", "train", "the", "regularized", "LR", "models", "on", "a", "training", "set", "locally", "for", "each", "node", "and", "then", "compute", "the", "objective", "function", "on", "a", "separated", "validation", "set", ",", "which", "is", "different", "from", "the", "training", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Therefore", ",", "in", "this", "paper", ",", "we", "propose", "ASARS", ",", "a", "novel", "framework", "that", "effectively", "imports", "the", "temporal", "dynamics", "methodology", "in", "CF", "into", "session", "-", "based", "RNN", "system", "in", "DL", ",", "such", "that", "the", "temporal", "info", "can", "act", "as", "scalable", "weights", "by", "a", "parallel", "attentional", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Problem", "FormulationOur", "idea", "is", "the", "BQ", "generation", "for", "MQ", "and", ",", "at", "the", "same", "time", ",", "we", "only", "want", "the", "minimum", "number", "of", "BQ", "to", "represent", "the", "MQ", ",", "so", "modeling", "our", "problem", "as", "optimization", "problem", "is", "an", "appropriate", "way", ":", ",", "where", "is", "the", "matrix", "of", "encoded", "BQ", ",", "is", "the", "encode", "MQ", "and", "is", "a", "parameter", "of", "the", "regularization", "term", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["Further", ",", "the", "x", "-", "coordinate", "of", "an", "ECC", "point", "requires", "60", "bits", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["The", "total", "transmit", "power", "of", "the", "BS", "is", ",", "and", "the", "direction", "angle", "between", "the", "BS", "and", "each", "destination", "user", "is", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["DE", "convergence", "is", "illustrated", "in", "figure", "and", "figure", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["EQPO", "algorithmThe", "dynamic", "framework", "introduced", "in", "Section", ",", "albeit", "optimal", "in", "terms", "of", "its", "capability", "of", "identifying", "the", "entire", "OPF", ",", "it", "may", "impose", "an", "excessive", "complexity", "quantified", "in", "terms", "of", "the", "number", "of", "dominance", "comparisons", "required", "for", "solving", "the", "optimization", "problem", "of", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal pareto front"}, {"tokens": ["In", "particular", ",", "even", "very", "mild", "smoothing", "(", ")", "increased", "the", "median", "ICC", "from", "0.63", "to", "0.76", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["In", "this", "case", ",", "the", "average", "running", "time", "for", "RK", "is", "always", "approximatively", "420", "seconds", ",", "while", "for", "IA", "it", "ranges", "from", "0.02", "seconds", "(", "for", "a", "single", "edge", "update", ")", "to", "6.2", "seconds", "(", "for", "a", "batch", "of", "1024", "edges", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "incremental approximation"}, {"tokens": ["During", "an", "ON", "period", ",", "the", "LTE", "-", "U", "BS", "transmits", "its", "data", "normally", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["A", "way", "to", "interpret", "the", "GMM", "residual", "probability", "distribution", "eq:3residue", "is", "that", "at", "each", "time", "the", "residual", "is", "drawn", "from", "the", "first", "GMM", "mode", "with", "probability", ",", "drawn", "from", "the", "second", "GMM", "mode", "with", "probability", ",", "and", "drawn", "from", "the", "third", "GMM", "mode", "with", "probability", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "same", "may", "be", "observed", "for", "the", "ICC", "CI", "width", ",", "which", "was", "increased", "for", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["the", "MVF", "of", "a", "sound", "is", "influenced", "by", "its", "voicing", "status", ",", "we", "take", "the", "U", "/", "V", "flag", "into", "consideration", "and", "revise", "the", "condition", "module", "of", "the", "base", "-", "h", "-", "NSF", "in", "order", "to", "predict", "from", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["MRC", "is", "considered", "at", "CEU", "to", "combine", "direct", "and", "relay", "link", "and", "perform", "ID", "effectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information decoding"}, {"tokens": ["Furthermore", ",", "we", "determine", "what", "functions", "of", "the", "ISP", "are", "most", "significant", "to", "achieve", "accurate", "predictions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["In", "our", "OT", "extension", "protocol", ",", "we", "need", "to", "verify", "whether", "a", "set", "strings", "are", "individually", "valid", "WH", "codewords", "or", "not", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Note", "that", "when", ",", "the", "CF", "side", "model", "does", "not", "learn", "but", "Joint", "still", "outperforms", "Disjoint", "and", "Base", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["[", "IB", "functional]Let", "and", "be", "statistically", "dependent", "variables", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["We", "analyze", "extensive", "longitudinal", "datasets", "with", "fine", "spatial", "granularity", "(", "AP", "level", ")", "covering", "16", "months", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["have", "introduced", "ICA", "as", "an", "optimization", "goal", "for", "modeling", "processes", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imperialist competitive algorithm"}, {"tokens": ["In", "this", "case", ",", "the", "ANN", "model", "may", "be", "a", "better", "prediction", "method", "to", "model", "the", "continuous", "magnetic", "fields", "generated", "by", "an", "eMNS", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Our", "experimental", "results", "demonstrated", "that", "PNN", "outperformed", "the", "other", "state", "-", "of", "-", "the", "-", "art", "models", "in", "4", "metrics", "on", "2", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["It", "was", "created", "by", "removing", "LScD", "words", "appearing", "in", "not", "greater", "than", "10", "texts", "in", "the", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["In", "LSC", ",", "the", "information", "is", "organised", "with", "one", "record", "on", "each", "line", "and", "parts", "of", "\u201c", "List", "of", "Authors", "\u2019", ","], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["With", "this", "the", "sum", "SR", "of", "the", "system", "can", "be", "expressed", "as;Joint", "Optimization", "Problem", "and", "Proposed", "SchemesThe", "focus", "of", "this", "work", "is", "to", "maximize", "SR", "with", "jointly", "optimizing", "the", "relay", "selection", ",", "sub", "-", "carrier", "assignment", "and", "BS", "'s", "transmit", "power", "loading", "over", "different", "sub", "-", "carriers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Furthermore", ",", "we", "found", "that", "rotating", "the", "SEM", "images", "does", "not", "introduce", "considerable", "new", "information", "and", "therefore", "the", "performance", "is", "not", "significantly", "improved", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["We", "figured", "out", "that", "the", "existing", "QA", "systems", "suffer", "from", "the", "following", "drawbacks", ":", "(", "1", ")", "potential", "of", "reusing", "its", "components", "is", "very", "weak", ",", "(", "2", ")", "extension", "of", "the", "components", "is", "problematic", ",", "and", "(", "3", ")", "interoperability", "between", "the", "employed", "components", "are", "not", "systematically", "defined", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Horovod", "also", "has", "less", "amount", "of", "code", "lines", "for", "distributed", "training", "and", "increased", "the", "scalability", "comparing", "to", "the", "well", "-", "known", "PS", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "parameter server"}, {"tokens": ["In", "our", "earlier", "work", ",", "we", "proposed", "a", "computationally", "feasible", "residual", "-", "based", "vocoder", ",", "using", "a", "continuous", "F0", "model", ",", "and", "MVF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "maximum voice frequency"}, {"tokens": ["Mirrored", "disks", "such", "as", "ID", ",", "GRD", ",", "and", "CD", "are", "referred", "to", "as", "semistructured", "and", "shown", "to", "outperform", "BM", "as", "far", "as", "seek", "distances", "are", "concerned", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["Five", "different", "cases", "were", "simulated", "as", "follows", ":", "(", "1", ")", "without", "any", "type", "of", "FEC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "forward error correction"}, {"tokens": ["Here", ",", "in", "order", "to", "spice", "up", "our", "analyses", ",", "we", "assume", "that", "while", "the", "BS", "-", "MS", "and", "BS", "-", "IO", "1-MS", "links", "are", "parallel", "to", "the", "ground", ",", "the", "reflected", "signal", "from", "IO", "2", "arrives", "to", "the", "MS", "with", "an", "angle", "of", "with", "respect", "to", "the", "MS", "route", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "flexibility", "of", "the", "EC", "/", "CC", "functional", "processing", "also", "depends", "on", "the", "placement", "of", "the", "requested", "files", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Orbit", "Selection", "for", "Descent", "InitiationFollowing", "the", "choice", "of", "an", "orbital", "descent", "strategy", "(", "no", "direct", "descent", "from", "LTT", ")", ",", "parameters", "of", "the", "descent", "orbit", "were", "studied", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lunar transfer trajectory"}, {"tokens": ["Consider", "momentarily", "the", "unconstrained", "and", "constrained", "models", "governed", "by", "eq", ":", "ssystem", "and", "eq", ":", "PVI", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "parabolic variational inequality"}, {"tokens": ["Deagggregation", "of", "address", "blocks", "due", "to", "secondary", "market", "transfersOne", "potential", "concern", "with", "the", "proposed", "fee", "structure", "is", "that", "it", "may", "incentivize", "the", "creation", "of", "a", "secondary", "address", "market", "that", "may", "extend", "the", "use", "of", "PI", "allocations", "by", "end", "sites", "as", "opposed", "to", "PA", "allocation", "from", "the", "LIRs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["A", "similar", "effect", "can", "be", "observed", "in", "PA", "allocations", "of", "different", "size", ",", "meaning", "that", "the", "fee", "for", "a", "/20", "is", "significantly", "less", "than", "times", "the", "fee", "for", "a", "/32", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider aggregatable"}, {"tokens": ["One", "way", "of", "doing", "so", "is", "by", "iteratively", "removing", "elements", "from", "the", "dataset", "up", "to", "a", "point", "where", "the", "CSG", "measure", "increases", "sharply", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["Over", "the", "past", "decades", ",", "there", "have", "been", "numerous", "works", "regarding", "standard", "-", "compliant", "MD", "coding", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "multiple description"}, {"tokens": ["As", "we", "can", "see", ",", "from", "the", "results", ",", "out", "of", "the", "4", "base", "classifiers", ",", "RF", "is", "the", "clear", "winner", "in", "most", "of", "the", "cases", "while", "LR", "did", "the", "worst", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Namely", ",", "the", "OT", "extension", "of", "requires", "seed", "OTs", "compared", "to", "of", "and", "thus", "improves", "the", "communication", "done", "via", "seed", "OTs", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["In", "contrast", ",", "we", "can", "see", "that", "the", "bpm", "representation", "achieves", "the", "worst", "results", "in", "the", "Arousal", "dataset", ",", "where", "both", "temporal", "dynamics", "and", "BPM", "are", "considered", "as", "important", "factors", "determining", "the", "intensity", "of", "emotion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "beat per minute"}, {"tokens": ["Both", "RF", "and", "ANN", "models", "predict", "rupture", "propagation", "with", "more", "than", "81", "accuracy", "and", "model", "parameters", "can", "be", "used", "to", "infer", "the", "underlying", "factors", "most", "important", "for", "rupture", "propagation", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "comparison", "among", "an", "SC", "-", "decoded", "MLPC", "system", ",", "an", "SC", "-", "decoded", "BIPCM", "system", ",", "both", "with", ",", "LTE", "turbo", "coded", "system", "with", ",", "WiMAX", "LDPC", "system", "with", ",", "an", "SCL", "-", "decoded", "MLPC", "system", ",", "and", "an", "SCL", "-", "decoded", "BIPCM", "system", ",", "both", "with", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "successive cancellation"}, {"tokens": ["Furthermore", ",", "the", "pipeline", "has", "a", "high", "test", "-", "retest", "reliability", "between", "the", "calculated", "volumes", "of", "VAT", "and", "SAT", "without", "the", "need", "of", "any", "image", "pre", "-", "processing", "(", "bias", "-", "correction", ",", "image", "registration", ",", "etc", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["With", "this", "approach", ",", "the", "final", "ranking", "list", "accounts", "for", "both", "pose", "information", "completeness", "and", "pose", "alignment", ",", "promoting", "progress", "in", "the", "ranking", "for", "those", "feature", "matchings", "that", "would", "get", "penalized", "by", "the", "single", "WF", "score", "calculation", "because", "of", "their", "frame", "-", "based", "pose", "misalignment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "weighted fusion"}, {"tokens": ["The", "MV", "-", "LV", "model", "is", "implemented", "using", "the", "open", "-", "source", "IBAMR", "software", "framework", "(", "https://github.com/IBAMR/IBAMR", ")", ",", "which", "provides", "an", "adaptive", "and", "distributed", "-", "memory", "parallel", "implementation", "of", "the", "IB", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "immersed boundary"}, {"tokens": ["Here", ",", "the", "adaptive", "constraint", "is", "fitness", "value", "of", "GA", "-", "SCP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["(", "3", ")", "We", "show", "that", "our", "MSC", "features", "are", "applicable", "for", "any", "CF", "-", "based", "tracking", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "correlation filter"}, {"tokens": ["[", "-", "]", "LE", "as", "a", "conventional", "pixel", "-", "based", "label", "equivalence", "solution", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "label equivalence"}, {"tokens": ["Furthermore", ",", "it", "is", "worth", "noting", "that", "in", "the", "case", "of", "selection", "from", "Open", "Images", ",", "GMM", "selection", "attains", "almost", "the", "same", "performance", "as", "scoring", "heuristics", ",", "but", "requires", "100", "times", "less", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["One", "possible", "direction", "is", "to", "combine", "the", "regularised", "SBM", "andadopt", "the", "framework", "of", "the", "weighted", "SBM", ",", "and", "have", "both", "versions", "of", "the", "SBM", "in", "an", "unifying", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["So", "in", "this", "work", "Words", ",", "POS", "tags", "and", "Position", "(", "relative", "distances", ")", "features", "are", "employed", "as", "input", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "IB", "based", "approach", "clusters", "the", "set", "of", "segments", "into", "a", "set", "of", "clusters", "such", "that", "most", "of", "the", "relevant", "information", "about", "is", "captured", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Average", "AP", "of", "the", "three", "layers", "on", "the", "dataset", "before", "feature", "selection", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["As", "GMM", "authors", "point", "out", ",", "GMM", "can", "be", "interpreted", "as", "an", "intermediary", "point", "between", "FMM", "(", ")", "and", "a", "purely", "iterative", "method", "(", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["For", "further", "details", ",", "the", "parameters", "of", "the", "performance", "model", "PS", ",", "P2P", ",", "and", "RA", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["However", ",", "our", "results", "also", "show", "that", "both", "MP", "and", "CF", "provide", "poor", "results", "for", "UC4", "being", "the", "most", "complex", "use", "case", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["BA", "can", "be", "interpreted", "as", "average", "accuracy", "achieved", "on", "either", "class", "(", "positive", "or", "negative", "regarding", "binary", "classification", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "balanced accuracy"}, {"tokens": ["DE", "of", "the", "Achievable", "Rate", "of", "the", "First", "Hop", "(", ")"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deterministic equivalent"}, {"tokens": ["A", "repair", "-", "by", "-", "transfer", "code", "at", "Exact", "-", "MBR", "case", "is", "proposed", "by", "Shah", "et", "al", ".", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["The", "3", "first", "lines", "basically", "confirm", "MAM", ",", "RDM", "and", "ATCS"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "russian dolls model"}, {"tokens": ["In", "a", "Capstone", "project", ",", "using", "UAVs", "in", "support", "of", "SAR", "operations", "in", "snow", "avalanche", "scenarios", "is", "explored", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["Nevertheless", ",", "interior", "-", "point", "methods", "can", "be", "considered", "standard", "baseline", "approaches", "to", "solve", "general", "OPF", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["We", "use", "alternating", "least", "squaresKoren:2009:MFT:1608565.1608614", ",", "a", "standard", "CF", "method", "based", "on", "matrix", "factorization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Colored", "values", "correspond", "to", "the", "GP", "prediction", "on", "the", "same", "test", "-", "samples", "at", "the", "-th", "iteration", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Reitmayr", "and", "Schmalstieg", "present", "a", "mobile", ",", "multi", "-", "user", "AR", "system", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Black", "colored", "curves", "correspond", "to", "the", "mean", "function", "and", "the", "95", "confidence", "interval", "of", "the", "predictive", "GP", "distribution", "all", "over", "the", "input", "-", "space", ",", "computed", "at", "each", "time", "iteration", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["FA", "aims", "to", "attract", "other", "objects", ",", "particularly", "their", "mates", "through", "their", "light", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "firefly algorithm"}, {"tokens": ["The", "residual", "network", "features", "achieve", "59.5", "mean", "AP", ",", "which", "outperforms", "hand", "-", "crafted", "features", "by", "8", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["During", "training", ",", "the", "real", "weights", "are", "no", "longer", "clipped", "as", "in", "BNN", "training", ",", "as", "the", "network", "can", "back", "-", "propagate", "through", "the", "activation", "and", "update", "the", "weights", "correspondingly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary neural networks"}, {"tokens": ["In", "the", "simulation", "part", ",", "we", "consider", "different", "noise", "by", "using", "our", "proposed", "signal", "model", "in", "Section", ",", "and", "in", "the", "real", "experimental", "setup", ",", "we", "use", "two", "SDR", "platforms", "to", "collect", "real", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "software defined radio"}, {"tokens": ["Although", "the", "ACFEC", "mechanism", "seems", "to", "be", "a", "good", "solution", "when", "the", "network", "is", "healthy", "and", "there", "is", "sporadic", "packet", "loss", ",", "when", "network", "congestion", "occurs", ",", "this", "mechanism", "will", "start", "to", "generate", "more", "and", "more", "FEC", "redundancy", "packets", ",", "which", "will", "increase", "the", "congestion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "detector", "built", "in", "this", "fashion", "gives", "the", "same", "AP", "regardless", "of", "the", "IOU", "threshold", ",", "since", "our", "detections", "are", "target", "boxes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Collaborative", "Filtering", "(", "CF", ")", "on", "the", "other", "hand", "is", "a", "technique", "for", "personalised", "recommendation", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "average", "number", "of", "users", "per", "SBS", "serves", "and", "the", "number", "of", "cooperative", "SBSs", "with", "respect", "to", "different", "received", "signal", "power", "threshold", "adopting", "SBS", "cooperation", "strategy", "with", "received", "signal", "power", "constraint", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["In", "this", "experiment", ",", "we", "train", "the", "network", "using", "generated", "LR", "images", ",", "in", "a", "supervised", "way", "using", "the", "loss", "function", "from", "Equation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["The", "\"", "VAT", "\"", "indicates", "that", "the", "model", "was", "trained", "with", "adversarial", "inputs", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["MINT", "-", "FEC"], "acronym_pos": [0, 0, 1], "long_form": "forward error correction"}, {"tokens": ["A", "dynamic", "Bayesian", "network", "(", "DBN", ")", "based", "model", "for", "dynamic", ",", "quantitative", ",", "and", "probabilistic", "trust", "estimates", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic bayesian network"}, {"tokens": ["SSIM", "drop", "from", "LR", "to", "HR", "light", "field", "image", "stems", "from", "the", "second", "residual", "addition", "which", "causes", "slight", "blur", "in", "the", "erroneous", "region", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Instead", "of", "sequentially", "solving", "each", "group", "with", "some", "inner", "iteration", "method", "and", "then", "using", "GS", "for", "outer", "iterations", "to", "converge", "the", "upscattering", ",", "the", "MG", "Krylov", "solver", "treats", "a", "block", "of", "groups", "(", "either", "all", "groups", "or", "just", "upscattering", "groups", ")", "at", "once", "such", "that", "the", "inner", "-", "outer", "iteration", "structure", "is", "removed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gauss seidel"}, {"tokens": ["Although", "PSO", "is", "a", "very", "efficient", "algorithm", "in", "solving", "ELD", "problems", ",", "however", ",", "it", "may", "suffer", "from", "trapping", "into", "local", "minimums", "during", "the", "search", "process", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["In", "LTE", ",", "the", "PDCCH", "is", "categorized", "into", "common", "and", "UE", "-", "specific", "PDCCHs", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["tabularccccccc", "-1.5exPacket", "loss", "&", "-1.5exQoE", "&", "-1.5exWithout", "&", "&", "-1.5exVideo", "-", "aware", "FEC", "&", "&", "-1.5exViewFEC", "1.0exrate", "&", "1.0exMetric", "&", "1.0exFEC", "&", "1.5exVideo", "-", "aware", "FEC", "&", "1.0exImprovement", "&", "1.5exViewFEC", "&", "1.0exImprovement", "2*Packet", "loss", "5", "&", "VQM", "&", "3.05", "&", "1.06", "&", "65.14", "&", "1.02", "&", "66.48", "&", "SSIM", "&", "0.76", "&", "0.91", "&", "19.74", "&", "0.92", "&", "21.05", "2*Packet"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "addition", ",", "to", "be", "able", "to", "include", "low", "-", "level", "linguistic", "information", "in", "our", "architecture", "designed", "for", "more", "complex", "sequence", "labeling", "tasks", ",", "we", "propose", "three", "new", "RNN", "variants", "to", "take", "into", "account", "external", "(", "POS", ")", "information", "for", "multilingual", "Super", "Sense", "Tagging", "(", "SST", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Our", "main", "data", "structure", "is", "a", "Playlist", "-", "Track", "matrix", "which", "is", "akin", "to", "a", "User", "-", "Item", "matrix", "in", "standard", "CF", "research", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["discussed", "random", "drift", "PSO", "(", "RDPSO", ")", "for", "solving", "various", "types", "of", "ELD", "problems", "of", "power", "systems", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["We", "adopt", "the", "GP", "-", "based", "solution", "to", "optimize", "the", "PS", "ratios", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "Vector", "Space", "Model", "(", "VSM", ")", "is", "a", "state", "-", "of", "-", "the", "-", "art", "IR", "model", "in", "which", "each", "document", "is", "represented", "as", "a", "vector", "of", "identifiers", "(", "here", "we", "describe", "each", "identifier", "as", "a", "term", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vector space model"}, {"tokens": ["Our", "experiments", "demonstrated", "that", "the", "new", "h", "-", "NSF", "can", "predict", "the", "MVF", "reasonably", "well", "on", "the", "basis", "of", "the", "voicing", "status", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["Both", "the", "concept", "of", "VO", "and", "CC", "were", "originally", "developed", "for", "holonomic", "robots", "moving", "along", "straight", "line", "trajectories", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collision cone"}, {"tokens": ["The", "central", "component", "in", "ANN", "language", "modelling", "is", "the", "use", "of", "an", "embedding", "layer", "which", "maps", "discrete", "symbols", "(", "words", ",", "characters", ")", "to", "continuous", "vectors", "in", "a", "relatively", "low", "-", "dimensional", "space", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["In", "addition", ",", "we", "also", "propose", "new", "state", "of", "the", "art", "landmark", "detector", "for", "HR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "high - resolution"}, {"tokens": ["DDSM", "combined", "Breast", "tissue", "vs", "Mass", "classification", "results", "(", "ROC", "plots", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "following", "discussion", "describes", "the", "features", "chosen", "for", "calculation", "of", "DI", "and", "IPI", "of", "a", "person", ",", "followed", "by", "the", "complete", "algorithm", "for", "detection", "of", "influential", "persons", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "document index"}, {"tokens": ["The", "idea", "behind", "the", "population", "manager", "is", "to", "adjust", "the", "total", "number", "of", "particles", "in", "PSO", "according", "to", "the", "solution", "-", "search", "status", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["CCU", "is", "assumed", "to", "be", "located", "much", "closer", "to", "the", "BS", "than", "CEU", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "base station"}, {"tokens": ["These", "methods", "have", "transferred", "some", "effective", "features", "such", "as", "word", "features", ",", "POS", "tags", ",", "Dependency", "Graphs", ",", "and", "Parse", "Trees", "from", "statistical", "methods", ",", "and", "use", "them", "as", "the", "input", "for", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["For", "this", "setup", ",", "we", "develop", "the", "algorithms", "named", "alg", ":", "CSMD_CTS", "(", "TS", "based", ")", "and", "alg", ":", "CSMD_ESCB", "(", "UCB", "based", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["By", "doing", "so", ",", "a", "(", "log-)likelihood", "ratio", "can", "be", "computed", ",", "denoted", "by", ",", "where", "and", "correspond", "to", "the", "parameters", "under", "the", "DC", "-", "SBM", "and", "the", "original", "version", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Therefore", ",", "the", "GP", "convex", "form", "can", "be", "formulated", "as", "follows", ":", "where", "the", "new", "variable", "is", "a", "vector", "that", "consists", "of", "(", "see", "for", "more", "details", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Instead", "of", "conditioning", "on", "a", "fixed", "number", "of", "inducing", "-", "points", ",", "we", "now", "make", "use", "of", "the", "continual", "GP", "prior", "in", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "the", "case", "of", "LTE", ",", "12", "bits", "DCI", "can", "be", "seen", "as", "a", "Format", "1C", "with", "5", "MHz", "of", "channel", "bandwidth", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["After", "running", "the", "experiments", "described", "in", "Section", ",", "we", "observe", "that", "jointly", "training", "our", "model", "for", "NER", "and", "MD", "results", "in", "an", "increase", "in", "the", "NER", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "morphological disambiguation"}, {"tokens": ["The", "last", "two", "characters", "'", "K", "'", "and", "'", "M", "'", "are", "not", "recognized", "because", "AN", "'s", "attention", "regions", "for", "these", "two", "characters", "are", "deviated", "a", "lot", "from", "them", "in", "the", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["All", "but", "the", "MGM", "GAN", "have", "to", "redistribute", "the", "oversampled", "density", "to", "other", "digits", ",", "preventing", "a", "one", "-", "to", "-", "one", "mapping", "of", "zeros", "-", "to", "-", "zeros", "and", "ones", "-", "to", "-", "ones", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["The", "distance", "between", "the", "eavesdropper", "and", "the", "AP", "is", "set", "as", "(", "m", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "BS", "calculates", "the", "transmission", "schedule", "at", "the", "end", "of", "RCAP", "by", "running", "the", "EHFS", "algorithm", "that", "we", "illustrate", "in", "Section", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["This", "section", "studies", "the", "complexity", "of", "checking", "whether", "an", "NCA", "is", "DBP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "determinisable by pruning"}, {"tokens": ["Following", "this", "methodology", ",", "the", "proposed", "method", "achieved", "a", "CCR", "of", "87.41", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["Meanwhile", ",", "the", "work", "in", "did", "not", "provide", "any", "convergence", "analysis", "for", "FL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "federated learning"}, {"tokens": ["With", "only", "500", "samples", ",", "CIFAR10", "gets", "a", "CSG", "score", "and", "a", "CNN", "accuracy", "similar", "but", "not", "identical", "to", "that", "of", "STL-10", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["So", ",", "the", "total", "channel", "capacity", "at", "for", "all", "the", "OAM", "wave", "from", "BS", "to", "is", "as", "below", ",", "Sum", "CapacitySo", ",", "the", "SC", "can", "be", "achieved", "by", "adding", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["As", "can", "be", "seen", "from", "Table", ",", "we", "are", "very", "close", "to", "the", "state", "of", "the", "art", "MD", "performance", "even", "if", "we", "only", "trained", "with", "a", "low", "number", "of", "parameters", "as", "stated", "in", "the", "beginning", "of", "this", "section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "morphological disambiguation"}, {"tokens": ["NP", "s(V)n-", ")", "word", "-", "initially", ",", "and", "-sn-", "word", "-", "medially", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["However", ",", "we", "observed", "a", "decrease", "in", "the", "number", "of", "longer", "length", "(", ")", "capillaries", "in", "older", "animals", "as", "compared", "to", "young", "in", "both", "WT", "and", "AD", "mice", "shown", "by", "a", "rightward", "shift", "in", "the", "cumulative", "distribution", "function", "curve", "(", "Fig", ".B", "and", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "wild type"}, {"tokens": ["TS", "maximizes", "the", "log", "-", "likelihood", "of", "the", "conditional", "distribution", "w.r.t", "the", "parameter", "T.", "stands", "for", "the", "logit", ",", "i.e.", "pre", "-", "softmax", "of", "the", "DNN", "model", "(", "same", "input", "as", "our", "approach", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature scaling"}, {"tokens": ["The", "number", "of", "the", "antennas", "at", "the", "BS", "is", ",", "the", "number", "of", "the", "users", "is", ",", "Rician", "K", "-", "factor", ",", "channel", "paths", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "a", "more", "supervised", "context", ",", "it", "may", "be", "appropriate", "to", "use", "other", "specializationsto", "guide", "the", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "stochastic block model"}, {"tokens": ["exp", ",", "the", "TI", "heuristic", "raises", "the", "initial", "threshold", "value", "substantially", ",", "restrict", "the", "unpromising", "candidates", "early", ",", "and", "therefore", ",", "reduces", "the", "search", "space", "and", "the", "running", "time", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "threshold initialization"}, {"tokens": ["In", ",", "the", "authors", "considered", "a", "hybrid", "model", "that", "combines", "TS", "and", "PS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["optimization_problem_intro", "for", "the", "DI", "case", "as", "We", "then", "introduce", "the", "following", "Lemma", "is", "a", "normalized", ",", "non", "-", "monotone", ",", "non", "-", "negative", "sub", "-", "modular", "functionof", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "direct inspection"}, {"tokens": ["Our", "contributions", "are", "listed", "below:[(1)]We", "design", "a", "general", "deep", "optimized", "MD", "coding", "framework", "based", "on", "artificial", "neural", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["\"", "666320647509921794", "\"", ",", "\"", "text", "\"", ":", "\"", "RT", "@ZeikBaard", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "retweets"}, {"tokens": ["We", "can", "also", "observe", "that", ",", "generally", ",", "SVM", "and", "LR", "perform", "better", "than", "RF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["In", "comparison", "to", "Brown", "news", "corpus", ",", "for", "Enron", "e", "-", "mail", "corpus", "A", "*", "algorithm", "has", "large", "MACS", "score", "for", "very", "few", "sentences", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "mean average conceptual similarity"}, {"tokens": ["This", "property", "is", "beneficial", "for", "our", "dynamic", "programming", "framework", ",", "since", "it", "eliminates", "the", "need", "for", "backwards", "propagation", ",", "thus", "only", "requiring", "the", "employment", "of", "a", "feed", "-", "forward", "method", "for", "the", "identification", "of", "the", "entire", "OPF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "optimal pareto front"}, {"tokens": ["For", "UEs", "configured", "with", "LWA", ",", "a", "split", "/", "switched", "LWA", "data", "bearer", ",", "as", "illustrated", "in", "Figure", "may", "be", "routed", "via", "both", "eNB", "and", "WT", "or", "WT", "alone", ",", "while", "the", "control", "plane", "connection", "remains", "on", "LTE", "eNB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "long term evolution"}, {"tokens": ["It", "is", "the", "first", "AR", "browser", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0], "long_form": "augmented reality"}, {"tokens": ["At", ",", "the", "average", "outbreak", "size", "is", "similar", "to", "that", "of", "RV", "strategy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random vaccination"}, {"tokens": ["The", "performance", "of", "the", "ECS", "-", "DBN", "suggests", "that", "it", "could", "provide", "quite", "good", "quality", "of", "diagnostic", "predictions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Another", "point", "of", "discussion", "concerns", "using", "the", "GMM", "to", "capture", "the", "representation", "manifold", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Note", ":", "the", "IS", "and", "FID", "values", "of", "our", "models", "are", "not", "necessarily", "directly", "comparable", "to", "the", "other", "models", ",", "since", "our", "model", "gets", "at", "test", "time", ",", "in", "addition", "to", "the", "image", "caption", ",", "up", "to", "three", "bounding", "boxes", "and", "their", "respective", "object", "labels", "as", "input", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["The", "Petal", "disk", "array", "utilizes", "striping", "(", "RAID0", ")", ",", "but", "also", "the", "CD", "organization", "as", "shown", "in", "Figure", "5", "in", ",", "which", "shows", "that", "alternate", "rows", "are", "dedicated", "to", "primary", "and", "secondary", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["6cStep", "3", "FR", "&", "&", "80k", "&", "5", "&", "4", "&", "12.5", "BS", "-", "87.5", "RS", "Datasets", "per", "Round"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "randomly sampled"}, {"tokens": ["The", "whole", "process", "of", "PSO", "usually", "initialize", "groups", "of", "random", "particles", "and", "computes", "fitness", "for", "each", "particle", "within", "iterations", "in", "order", "to", "converge", "into", "global", "optimum", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["Performance", "of", "TRADES", "WideResNet", "distilled", "onto", "MobileNetV2", "using", "ARD", "with", "different", "temperature", "terms", "on", "CIFAR-10", ",", "where", "robust", "accuracy", "is", "with", "respect", "to", "a", "-step", "PGD", "attack", "as", "in", "[", "15].[h", "!", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "study", "in", "showed", "that", "the", "PS", "protocol", "always", "achieves", "a", "system", "outage", "probability", "lower", "than", "that", "of", "the", "TS", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "time switching"}, {"tokens": ["The", "first", "step", "of", "DMD", "in", "eq", ":", "DMD", "is", "reminiscent", "of", "the", "proximal", "update", "in", "the", "usual", "mirror", "descent", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["The", "nodes", "in", "the", "innermost", "core", "have", "higher", "CC", "hence", ",", "they", "can", "rewire", "their", "connections", "to", "reduce", "congestion", "in", "the", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "closeness centrality"}, {"tokens": ["Different", "from", "the", "widely", "used", "MD", "by", "distilling", "knowledge", "from", "more", "complex", "models", ",", "we", "are", "utilizing", "the", "much", "less", "explored", "privileged", "information", "distillation", ",", "e.g.", ",", "by", "distilling", "from", "the", "privileged", "features", "described", "above", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "model distillation"}, {"tokens": ["Although", "the", "results", "based", "on", "the", "unsupervised", "submodular", "rank", "aggregation", "methods", "are", "all", "below", "the", "baseline", "result", ",", "the", "approach", "based", "on", "the", "nested", "structured", "LB", "divergence", "is", "close", "to", "the", "baseline", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["In", "the", "case", "of", "the", "SDD", ",", "participants", "were", "advised", "that", "they", "would", "be", "able", "to", "find", "most", "of", "the", "large", "targets", "without", "using", "the", "mouse", "to", "pan", "and", "zoom", ",", "but", "would", "need", "to", "use", "virtual", "navigation", "for", "the", "very", "small", "targets", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Table", "and", "show", "the", "SAD", "performance", "of", "these", "methods", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["In", "section", ",", "distance", "distribution", "of", "nearest", "LOS", "/", "NLOS", "BS", "to", "typical", "UE", ",", "association", "probability", "and", "SINR", "coverage", "probability", "of", "the", "network", "based", "on", "different", "approaches", "are", "derived", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["/puhl/", "NP"], "acronym_pos": [0, 1], "long_form": "new persian"}, {"tokens": ["It", "was", "demonstrated", "that", "the", "firing", "of", "MTL", "cells", "was", "sparse", "because", "most", "of", "them", "did", "not", "respond", "to", "the", "great", "majority", "of", "images", "used", "in", "the", "experiment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "medial temporal lobe"}, {"tokens": ["In", "this", "paper", ",", "we", "propose", "an", "initialization", "stage", "for", "the", "state", "-", "of", "-", "the", "-", "art", "algorithm", "presented", "at", "CVPR", "called", "Random", "Voting", "(", "RV", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random voting"}, {"tokens": ["[", "97.0", "]", "&", "&", "&", "&", "&", "&", "EO", "&", "&", "&", "&", "CRR", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "eyes open"}, {"tokens": ["In", "Section", "SECcollapse", "we", "will", "consider", "the", "issue", "of", "collapsing", ";", "this", "is", "straightforward", "for", "the", "SBM", ",", "but", "not", "for", "the", "SCF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Finally", ",", "RA", "systems", "also", "excel", "by", "virtue", "of", "overlapping", "computation", "time", "and", "communication", "time", ",", "which", "PS", "and", "P2P", "architectures", "fail", "to", "achieve", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["We", "note", "that", "the", "proposed", "approach", "provides", "the", "highest", "MP", "and", "the", "highest", "recall", "when", "all", "four", "aspects", "are", "considered", "during", "scoring", "rather", "than", "a", "single", "aspect", "such", "as", "content", "-", "relevance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean precision"}, {"tokens": ["From", "the", "results", ",", "our", "proposed", "method", "achieves", "the", "best", "overall", "scores", "for", "both", "SAD", "and", "RMSE", "metrics", "compared", "to", "other", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["In", "particular", ",", "our", "method", "seems", "to", "be", "close", "to", "the", "CF", "-", "based", "ceiling", "when", "it", "comes", "to", "not", "providing", "undesirable", "recommendations", ",", "as", "evidenced", "by", "the", "results", "of", "the", "uninterestedness", "question", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Derived", "from", "our", "prior", "work", "in", ",", "this", "work", "aims", "at", "revealing", "the", "potential", "of", "state", "-", "of", "-", "the", "-", "art", "PTM", "technologies", "previously", "defined", "in", "LTE", "Rel-14", "including", "the", "latest", "fully", "standardized", "eMBMS", ",", "to", "meet", "the", "requirements", "of", "the", "5", "G", "use", "cases", "and", "scenarios", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Comparing", "the", "proposed", "multi", "-", "linear", "filter", "with", "the", "low", "rank", "structure", "LR", ",", "all", "configurations", "of", "MLconv", "network", "significantly", "outperform", "their", "LR", "counterparts", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low rank"}, {"tokens": ["Therefore", ",", "each", "antenna", "can", "form", "independent", "beams", ",", "so", "that", "the", "multiple", "streams", "created", "by", "SVC", "-", "encoding", "are", "divided", "into", "parts", "and", "each", "part", "is", "assigned", "to", "a", "beam", "to", "be", "concurrently", "transmitted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scalable video coding"}, {"tokens": ["The", "CC", "and", "ECs", "are", "equipped", "with", "DUs", "which", "enable", "a", "virtualized", "functional", "processing", ",", "in", "which", "their", "computational", "resources", "can", "be", "virtualized", "and", "shared", "by", "connected", "RUs", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Interoperability", "ChallengeThe", "field", "of", "QA", "is", "so", "vast", "that", "the", "list", "of", "different", "QA", "systems", "can", "go", "long", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["To", "demonstrate", "the", "coding", "efficiency", "of", "our", "MDC", "framework", ",", "our", "method", "is", "compared", "with", "several", "state", "-", "of", "-", "the", "-", "art", "MDC", "approaches", ",", "including", "the", "multiple", "description", "coding", "approach", "with", "randomly", "offset", "quantizers", "and", "the", "newest", "convolutional", "neural", "network", "-", "based", "standard", "-", "compatible", "method", "in", "terms", "of", "image", "coding", "efficiency", "when", "testing", "on", "several", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["Specifically", ",", "if", "node", "acts", "as", "a", "CH", ",", ",", "otherwise", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "cluster head"}, {"tokens": ["NP", "giyan", "'", "tent", "'"], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["our", "CSG", "c", "-", "measure", "with", "the", "error", "rate", "(", "E.R.", ")", "of", "an", "AlexNet", "CNN", "(", "figure", "best", "viewed", "in", "color", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["These", "can", "be", "roughly", "grouped", "into", "two", "major", "categories", ":", "pixel", "-", "level", "and", "cell", "-", "level", "metric", ",", "where", "NPR", "belongs", "to", "cell", "-", "level", "measure", "and", "the", "others", "are", "pixel", "-", "level", "measures", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized probabilistic rand"}, {"tokens": ["Whereas", ",", "SC", "is", "the", "addition", "of", "capacity", "of", "CCU", "and", "CEU", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["One", "way", "is", "to", "develop", "a", "truly", "hierarchical", "model", ",", "potentially", "by", "incorporating", "a", "nested", "SBM", ",", "to", "infer", "the", "number", "of", "groups", "and", "the", "depth", "of", "the", "hierarchical", "structure", "simultaneously", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["To", "this", "end", ",", "we", "present", "a", "comprehensive", "technical", "overview", "of", "the", "LTE", "eMBMS", "system", ",", "and", "describe", "its", "evaluation", "methodology", "in", "detail", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["SAR", "operations", "using", "UAVs", "can", "be", "performed", "autonomously", ",", "accurately", "and", "without", "introducing", "additional", "risks", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["The", "EH", "-", "MEC", "system", "is", "equipped", "with", "solar", "panels", "for", "EH", "and", "an", "EB", "for", "energy", "storage", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "energy buffer"}, {"tokens": ["&", "20", "kg", "/", "LAP", "/", "1", "hour", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "low altitude platform"}, {"tokens": ["Available", ":", "http://www.researchandmarkets.com", "/", "reports/1945613/.", "A.", "Ra?cz", ",", "N.", "Reider", "and", "G.", "Fodor", ",", "\"", "On", "the", "Impact", "of", "Inter", "-", "Cell", "Interference", "in", "LTE"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "long term evolution"}, {"tokens": ["For", "example", ",", "although", "the", "macrocell", "BS", "can", "handle", "all", "the", "users", "during", "(", "i.e.", ",", ")", ",", "the", "optimization", "suggests", "to", "activate", "3", "MBSs", "and", "4", "drones", "for", "both", "zero", "and", "perfect", "knowledge", "cases", "in", "order", "to", "reduce", "the", "total", "transmit", "power", "of", "the", "macrocell", "BS", "and", "hence", ",", "the", "total", "energy", "consumption", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "second", "case", "is", "when", "we", "train", "and", "test", "with", "the", "Sleep", "Cassette", "subset", "of", "the", "dataset", "with", "a", "random", "patient", "independent", "split", ",", "from", "here", "on", "referred", "to", "as", "Sleep", "Cassette", "task", "(", "SC", "-", "task", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "sleep cassette"}, {"tokens": ["Training", "on", "CK+", "dataset", "and", "testing", "on", "SFEW", "dataset", ":", "in", "the", "second", "experiment", ",", "the", "test", "dataset", "is", "collected", "in", "the", "wild", "for", "unconstrained", "FER", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "facial expression recognition"}, {"tokens": ["We", "also", "compare", "TopKMintra", "with", "the", "state", "-", "of", "-", "the", "-", "art", "approach", "MintraBL", "which", "is", "an", "adapted", "version", "of", "the", "USpan", "algorithmyin2012uspan", "designed", "for", "mining", "top", "-", "k", "patterns", "from", "the", "activity", "-", "trajectory", "data", "and", "also", "analyze", "the", "effect", "of", "the", "above", "two", "mentioned", "heuristics", "by", "adopting", "it", "in", "the", "baseline", "algorithm", "as", "MintraBL+i", "(", "TI", "with", "baseline", ")", "and", "MintraBL+s", "(", "TU", "with", "baseline", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "threshold initialization"}, {"tokens": ["ECS", "-", "DBN", "can", "be", "further", "extended", "for", "online", "imbalanced", "classification", "problems", "with", "some", "online", "learning", "strategies", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Recall", "that", "the", "fBS", "knows", "downlink", "SINR", "via", "device", "feedback", ",", "in", "addition", ",", "the", "licensed", "and", "unlicensed", "bands", "use", "separate", "power", "budgets", "due", "to", "different", "government", "regulation", "requirements", ",", "so", "the", "unlicensed", "band", "data", "rate", "is", "a", "constant", "that", "is", "determined", "by", "WiFi", "rate", "function", "(", "for", "IFW", ")", ",", "LTE", "rate", "function", "(", "for", "DBF", ")", "and", "the", "instantaneous", "SINR", "in", "the", "unlicensed", "band", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "in", "-", "built", "GPS", "receiver", "in", "the", "smartphone", "is", "used", "to", "get", "the", "GPS", "coordinates", "of", "the", "users", "who", "reports", "to", "be", "likely", "infected", "with", "dengue", "fever", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["In", "this", "table", ",", "all", "the", "operations", "of", "convolutional", "neural", "networks", "for", "these", "MDC", "methods", "are", "run", "on", "an", "NVIDIA", "-", "GTX1080", "GPU", "device", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["At", "testing", "time", ",", "we", "evaluated", "our", "model", "with", "both", "LR", "-", "HR", "clinical", "image", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Previous", "works", "also", "show", "PS", "values", "ranging", "from", "0.5", "to", "1.5", "when", "shilling", "attacks", "are", "simulated", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "prediction shift"}, {"tokens": ["In", "the", "DC", "-", "SBM", ",", "the", "log", "-", "likelihood", "can", "be", "obtained", "by", "summing", "the", "logarithm", "of", "eqn.graph_ypq_kn11", "over", "all", "possible", "dyads", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "gap", "reduction", "is", "an", "measurement", "used", "to", "measure", "the", "effectiveness", "of", "the", "adaptation", "method", "which", "is", "defined", "as", ":", "We", "appreciate", "that", ",", "in", "general", ",", "the", "difference", "in", "CER", "between", "these", "two", "baselines", ",", "lower", "bound", "and", "upper", "bound", ",", "is", "about", "points", ",", "with", "the", "exception", "of", "the", "Esposalles", "dataset", ",", "which", "presents", "a", "much", "higher", "gap", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["Recent", "works", "have", "applied", "OT", "to", "non", "-", "parametric", "texture", "synthesis", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Prenorm", "layersIn", "the", "literature", "of", "GCNN"], "acronym_pos": [0, 0, 0, 0, 0, 1], "long_form": "graph convolutional neural network"}, {"tokens": ["In", "order", "to", "achieve", "improved", "location", "accuracy", ",", "the", "authors", "utilize", "an", "environmental", "fingerprinting", "approach", ",", "namely", ",", "using", "objects", "on", "the", "street", "to", "correct", "GPS", "errors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "global positioning system"}, {"tokens": ["We", "explore", "the", "design", "space", "and", "present", "two", "potential", "solutions", ":", "One", "uses", "body", "cues", "of", "a", "humanoid", "MR", "avatar", ",", "the", "other", "displays", "the", "direction", "change", "as", "a", "path", "on", "the", "ground", "(", "Figure", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mixed reality"}, {"tokens": ["Nevertheless", ",", "the", "proposed", "method", "obviously", "outperforms", "these", "DCNN", "based", "competitors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["As", "the", "number", "of", "GPU", "increases", ",", "the", "performance", "of", "parallel", "ring", "architecture", "is", "getting", "better", "and", "better", "than", "PS", "architecture", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "parameter server"}, {"tokens": ["Following", "this", "tractable", "method", ",", "the", "non", "-", "convex", "-", "non", "-", "smooth", "optimization", "problem", "given", "in", "is", "employed", "to", "obtain", "an", "SCP", "central", "plant", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["We", "observed", "different", "relative", "magnitudes", "for", "the", "importance", "of", "GDP", "in", "the", "US", "case", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gross domestic product"}, {"tokens": ["Alternatively", ",", "exploit", "the", "value", "convergence", "phenomenon", "with", ",", "for", "instance", ",", "the", "shifted", "exponential", "IB", "Lagrangian", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Embeddings", "composition", "as", "SRL", "modelsWe", "claim", "that", "several", "existing", "models", "boil", "down", "to", "SRL", "models", "where", "the", "sentence", "embeddings", "(", "act", "as", "entity", "embeddings", "(", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "statistical relational learning"}, {"tokens": ["The", "classification", "report", "(", "table", ")", "produced", "by", "the", "ANN", "model", "also", "shows", "nearly", "the", "same", "precision", ",", "recall", ",", "and", "F1", "scores", "as", "the", "RF", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Laptop", "computer", "runtimes", "of", "the", "RB", "model", "for", "the", "fibrous", "microstructure", "for", "various", "sizes", "of", "the", "basis", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["G", "-", "mean", "0.01[b]0.45]surf_plot_diff_costs_Precision.png", "Precision", "Illustration", "of", "the", "comparison", "between", "the", "performance", "of", "the", "proposed", "ECS", "-", "DBN", "and", "grid", "search", "of", "misclassification", "costs", "on", "DBN", "in", "terms", "of", "G", "-", "mean", "and", "Precision", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "DDE", "-", "MGM", "scheme", "is", "summarized", "in", "Algorithm", ",", "where", "the", "accumulators", ",", "i.e.", ",", "and", ",", "are", "simultaneously", "updated", "and", "queried", "by", "the", "modeling", "and", "classification", "threads", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Taking", "elevated", "mean", "scan", "(", "EMS", ")", "statistic", "for", "instance", ",", "it", "aims", "to", "decide", "between", "and", ":", "and", ",", "where", "for", "simplicity", "each", "node", "only", "has", "a", "univariate", "feature", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elevated mean scan statistic"}, {"tokens": ["Successful", "Uplink", "TransmissionsIn", "the", "uplink", ",", "a", "standard", "RTS", "is", "sent", "to", "the", "AP", "by", "the", "STA", "that", "won", "the", "-st", "round", "channel", "contention", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["During", "each", "iteration", ",", "which", "results", "in", "identifying", "a", "single", "Pareto", "-", "optimal", "route", ",", "the", "P", "-", "NDQIO", "algorithm", "first", "invokes", "the", "so", "-", "called", "Boyer", "-", "Brassard", "-", "Hoyer", "-", "Tapp", "Quantum", "Search", "Algorithm", "(", "BBHT", "-", "QSA", ")", "for", "the", "sake", "of", "identifying", "routes", "that", "are", "not", "dominated", "by", "any", "of", "the", "routes", "belonging", "to", "the", "hitherto", "identified", "OPF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "optimal pareto front"}, {"tokens": ["Greedy", "Algorithms", "in", "Hilbert", "SpacesWe", "present", "new", "greedy", "algorithms", "-", "inspired", "by", "MP", ",", "OMP", ",", "and", "FW", "-", "for", "the", "minimization", "of", "functions", "over", "a", "convex", "and", "bounded", "set", ",", "or", "over", "the", "linear", "span", "of", "a", "dictionary", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["The", "conceptual", "similarity", "between", "any", "two", "given", "terms", "and", "is", "computed", "by", "taking", "the", "average", "of", "number", "of", "edges", "in", "the", "shortest", "-", "path", "between", "and", "and", "the", "number", "of", "edges", "in", "the", "shortest", "-", "path", "between", "and", "(", "and", "hence", "the", "term", "average", "in", "MACS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mean average conceptual similarity"}, {"tokens": ["The", "only", "difference", "between", "Con", "-", "TS", "-", "RTP", "and", "the", "daily", "optimization", "in", "is", "the", "added", "constraints", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["We", "first", "perform", "IB", "based", "diarization", "followed", "by", "KL", "-", "HMM", "based", "realignment", "to", "get", "the", "relative", "speaker", "labels", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "RA", "process", "presented", "a", "mean", "time", "of", "2.5", "seconds", ",", "what", "is", "considered", "acceptable", "for", "our", "application", ",", "since", "it", "is", "commonly", "performed", "just", "one", "time", "for", "each", "new", "producer", "or", "consumer", ",", "to", "validate", "the", "system", "or", "the", "new", "member", ",", "respectively", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote attestation"}, {"tokens": ["B", "-", "OCC", "and", "B", "-", "OCC", "along", "with", "NG", "enable", "X", "and", "X", "energy", "reduction", "respectively", "compare", "to", "AE", "-", "OCC", "for", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "one class classifier"}, {"tokens": ["Using", "these", "methods", "together", ",", "RQI", "converged", "in", "fewer", "iterations", "and", "in", "less", "time", "than", "PI", "for", "a", "full", "pressurized", "water", "reactor", "core", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["DTP", "and", "FPL", "predict", "object", "centroids", "only", ",", "so", "IOU", "metrics", "are", "not", "applicable", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic trajectory predictor"}, {"tokens": ["Thus", ",", "inability", "of", "AR", "to", "lack", "dynamism", "is", "also", "a", "challenge", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["In", "OT", "Extension", "Phase", "II", ",", "communicates", "bits", "to", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "RA", "algorithm", "allows", "worker", "nodes", "to", "average", "gradients", "and", "send", "them", "to", "all", "nodes", "without", "the", "need", "for", "a", "PS", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["It", "can", "be", "compared", "with", "the", "model", "by", "for", "recommender", "systems", ",", "who", "also", "applied", "an", "SBM", "for", "seemingly", "non", "-", "relational", "data", "that", "can", "however", "be", "represented", "as", "graphs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "ASVspoof", "2019", "challenge", "combines", "both", "LA", "and", "PA"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "physical access"}, {"tokens": ["A", "known", "approach", "to", "supply", "this", "redundancy", "is", "using", "FEC", "techniques", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["For", "all", "approximate", "algorithms", "the", "log", "predictive", "test", "likelihood", "saturates", "already", "for", "few", "inducing", "points", "(", ")", "of", "the", "sparse", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["The", "lower", "accuracy", "may", ",", "at", "least", "partly", ",", "be", "due", "to", "a", "greater", "variety", "in", "texts", "than", "before", "and", "a", "larger", "proportion", "of", "unknown", "words", "in", "the", "MIM", "-", "GOLD", "test", "set", "compared", "to", "IFD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "icelandic frequency dictionary"}, {"tokens": ["This", "setting", "differs", "from", "the", "aforementioned", "task", "-", "oriented", "systems", "in", "following", "ways", ":", "itemizeTask", "-", "oriented", "systems", "are", "developed", "for", "a", "multitude", "of", "tasks", "(", "e.g.", "restaurant", "reservation", ",", "travel", "information", "system", ",", "virtual", "assistant", ",", "..", ")", ",", "whereas", "the", "QA", "systems", "are", "developed", "to", "find", "answers", "to", "a", "specific", "question", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["igo13", "showed", "that", "GMM", "is", "over", "-", "sensitive", "to", "the", "data", "and", "does", "not", "demonstrate", "robust", "clustering", "performance", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Each", "of", "the", "SL", "languages", "was", "defined", "with", "four", "banned", "substrings", "and", "each", "of", "the", "SP", "languages", "was", "defined", "with", "one", "banned", "subsequence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Two", "-", "pass", "IB", "based", "Diarization"], "acronym_pos": [0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Average", "GPR", "for", "each", "population", "of", "KBP", "plans", "compared", "to", "clinical", "plans", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gamma passing rate"}, {"tokens": ["The", "main", "distinction", "from", "ours", "toppyramid_feature_learn", "is", "the", "introduction", "of", "MAD", "unit", "to", "dynamically", "decide", "the", "attention", "weights", "of", "feature", "channels", "based", "on", "the", "context", "of", "the", "input", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["The", "LTE", "-", "U", "BS", "is", "connected", "to", "a", "computer", "with", "the", "hardware", "requirements", "of", "at", "least", "8", "GB", "RAM", "(", "Installed", "Memory", ")", ",", "64-bit", "operating", "system", ",", "x64-based", "processor", ",", "Intel(R", ")"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "same", "procedure", "adopted", "by", "uavFEC", "was", "applied", "to", "MINT", "-", "FEC", "however", ",", "different", "values", "were", "found", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["ConclusionAiming", "at", "industry", "4.0", ",", "we", "have", "proposed", "to", "use", "OPIUM", "-", "B", "OCC", "for", "predictive", "maintenance", "deployed", "in", "machine", "health", "monitoring", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "one class classifier"}, {"tokens": ["To", "demonstrate", "the", "effect", "of", "the", "more", "accurate", "contour", "estimation", "on", "the", "segmentation", "of", "partially", "overlapping", "objects", ",", "the", "performance", "of", "the", "GP", "-", "PF", "method", "was", "compared", "to", "the", "BS", "and", "the", "LESF", "methods", "on", "the", "nanoparticle", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Performance", "Comparison", "in", "Bike", "-", "sharing", "Demand", "DataWe", "find", "that", "HSMC", "can", "help", "diminish", "the", "performance", "gap", "between", "GP", "model", "and", "neural", "network", "model", ",", "even", "though", "GP", "has", "much", "less", "parameters", "than", "neural", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["*", "acru-", "'", "tear", "'", "Phl", "ars", ",", "MMP", "ars", ",", "asr", "NP", "ars", "(", "alongside", "ask", "*", "acru", "-"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["A", "joint", "time", "slot", "and", "FJ", "power", "allocation", "can", "be", "found", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["On", "the", "other", "hand", ",", "RV", "methods", "are", "usually", "more", "computationally", "efficient", "because", "the", "RV", "is", "a", "compact", "representation", "of", "the", "LiDAR", "data", "where", "the", "BEV", "is", "sparse", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "range view"}, {"tokens": ["It", "is", "important", "to", "note", "that", "the", "trained", "network", ",", "say", "HR", "-", "LD", "high", "resolution", "landmark", "detector", "(", "detailed", "in", "Section", ")", "achieves", "state", "of", "the", "art", "performance", "on", "AFLW", "and", "300W", "test", "sets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["The", "works", "on", "elliptic", "and", "parabolic", "variational", "inequalities", "(", "EVI", "and", "PVI", ")", ",", "such", "as", "on", "first", "order", "convergence", "of", "Galerkin", "FE", ",", "account", "for", "the", "lack", "of", "regularity", "of", "their", "solutions", "but", "handle", "only", "scalar", "linear", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parabolic variational inequality"}, {"tokens": ["T',alignscriptsizewhere", "is", "the", "coordinate", "of", "the", "typical", "femtocell", "UE", "(", "irrelevant", "to", "the", "result", ")", ",", ",", "and", "is", "the", "SIR", "threshold", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": [",", "we", "consider", "the", "performance", "of", "the", "proposed", "method", "in", "Section", "for", "the", "TTP", "minimization", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "total transmit power"}, {"tokens": ["The", "proposed", "solutions", "are", "centralized", "and", "the", "decision", "is", "made", "by", "the", "macrocell", "BS", "that", "is", "managing", "the", "rest", "of", "the", "BSs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["D7BT", ",", "UKEA", ",", "PGDP", ",", "PRDY", ",", "MGSX", ")", ",", "BIS", "(", "US", "private", "sector", "debt", ":", "Q", ":", "US", ":", "P", ":", "A", ":", "M", ":", "XDC", ":", "A", ",", "UK", ":", "ERI", ",", "GBP", "/", "USD", "(", "1955", "only", ")", ")", ",", "OECD", "(", "US", "CPI", ",", "US", "M3", ",", "US", "GDP", ",", "US", "Unemployment", ",", "US", "CA", ")", ",", "FRED", "(", "ID", ":", "RNUSBIS", ",", "FEDFUNDS", ",", "PRS85006163", ",", "A229RX0", ")", ",", "(", "UK", "private", "sector", "debt", ",", "M4", ",", "labour", "productivity)[h", "!", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gross domestic product"}, {"tokens": ["The", "EM", "is", "an", "entity", "responsible", "for", "selecting", "the", "appropriate", "energy", "source", "and", "for", "monitoring", "the", "energy", "level", "of", "the", "EB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "energy buffer"}, {"tokens": ["net_structure", "reports", "AR", "for", "different", "network", "design", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0], "long_form": "average recall"}, {"tokens": ["We", "define", "the", "CC", "property", "to", "ensure", "that", "most", "of", "the", "paths", "representing", "shortest", "distance", "between", "vertices", "pass", "through", "the", "innermost", "core", "(", "refer", "to", "section", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "core connected"}, {"tokens": ["However", "in", "the", "coBuchi", "setting", ",", "the", "GFG", "automaton", "is", "not", "necessarily", "DBP", ",", "and", "can", "actually", "be", "more", "succinct", "than", "any", "deterministic", "automaton", "for", "the", "language", "(", "Theorem", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["Although", "the", "motion", "primitives", "which", "will", "be", "discussed", "in", "the", "next", "section", "have", "already", "taken", "previous", "states", "of", "the", "path", "points", "into", "consideration", ",", "the", "time", "scale", "is", "limited", "in", "order", "to", "restrict", "the", "dimensions", "of", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["One", "solution", "is", "to", "employ", "a", "high", "-", "precision", "GPS", ",", "however", ",", "it", "may", "be", "difficult", "as", "the", "adjacent", "lanes", "are", "within", "just", "a", "few", "meters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["However", ",", "for", "the", "increasing", "distance", "between", "BS", "and", "CCU", "causes", "degradation", "of", "channel", "condition", "among", "them", "hence", "the", "ESC", "is", "decreased", "for", "all", "cases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["However", ",", "employing", "the", "FJ", "signal", "also", "decreases", "the", "quality", "of", "the", "legitimate", "channel", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["Set", "1", "&", "PiB", "Angular", "L", "/", "R", "&", "PiB", "Cingulum", "Ant", "L", "/", "R", "&", "PiB", "Cingulum", "Post", "L", "/", "R", "&", "PiB", "Frontal", "Med", "Orb", "L", "/", "R", "&", "PiB", "Precuneus", "L", "/", "R", "&", "PiB", "Temporal", "Sup", "L", "/", "R", "&", "PiB", "Temporal", "Mid", "L", "/", "R", "&", "PiB", "SupraMarginal", "L", "Set", "2", "&", "FA", "Cerebral", "peduncle", "R", "&", "FA", "Cerebral", "peduncle", "L", "&", "MD", "Corticospinal", "tract", "R", "&", "MD", "Corticospinal", "tract", "L", "&", "Trail", "-", "Making", "Test", "Part"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fractional anisotropy"}, {"tokens": ["Both", "the", "SP", "and", "TP", "were", "learning", "in", "an", "on", "-", "line", "fashion", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["More", "recently", ",", "other", "authors", "have", "proposed", "and", "studied", "sensing", "strategies", "that", "would", "reduce", "the", "required", "number", "of", "CSS", "measurements", "to", "the", "sparsity", "of", "the", "signal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "compressive spectrum sensing"}, {"tokens": ["NP", "sal", "'", "year'PIr"], "acronym_pos": [1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Two", "mechanisms", "assessed", "are", "non", "-", "adaptive", ",", "video", "-", "aware", "FEC", "and", "ViewFEC", ",", "and", "because", "of", "that", ",", "they", "have", "the", "same", "network", "overhead", "in", "all", "distances", ",", "which", "was", "65.10", "and", "38.90", ",", "respectively", ",", "as", "showed", "in", "Figure", "fig", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "performance", "are", "compared", "with", "the", "strategy", "of", "random", "neighbour", "selection", "(", "RV", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random vaccination"}, {"tokens": ["Additionally", ",", "we", "also", "implement", "the", "COLS", "in", "a", "class", "-", "wise", "manner", "(", "cdCOLS", ")", "as", "well", "as", "its", "kernel", "version", "KcdCOLS", "-", "these", "COLS", "based", "variants", "can", "be", "considered", "as", "upper", "bounds", "in", "performance", "of", "OLS", "based", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["The", "total", "transmit", "signals", "of", "the", "BS", "can", "be", "expressed", "aswhere", "is", "the", "AN", "signal", "sent", "by", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Part", "of", "speech", "(", "POS", ")", "tags", ":", "a", "vector", "where", "each", "feature", "represents", "the", "number", "of", "occurrences", "of", "a", "type", "of", "POS", "tag", "in", "the", "tweet", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["FA", ":", "feature", "alignment", ";", "HGP", ":", "hierarchical", "Gaussian", "process", ";", "GPA", ":"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feature alignment"}, {"tokens": ["shows", "the", "comparison", "results", "between", "the", "proposed", "method", "(", "TFGNSCS", ")", "and", "five", "state", "-", "of", "-", "arts", "(", "DVN", ",", "HM", ",", "VCL", ",", "TVN", "and", "FGN)for", "ZSL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "hybrid model"}, {"tokens": ["-0.5emSystem", "Model", "and", "Problem", "Formulation-0.5emConsider", "a", "cellular", "network", "that", "consists", "of", "one", "BS", "serving", "a", "set", "of", "users", ",", "as", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["This", "may", "render", "PI", "allocations", "more", "affordable", ",", "and", "parties", "that", "would", "not", "be", "willing", "to", "pay", "they", "yearly", "fee", "that", "the", "RIR", "or", "the", "InBlock", "charges", "for", "a", "/48", "allocations", ",", "may", "be", "willing", "to", "obtain", "a", "much", "cheaper", "/48", "from", "this", "secondary", "market", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["Both", "the", "PRR", "and", "SLT", "algorithms", "present", "stable", "speedup", "over", "the", "regular", "ring", "algorithm", ",", "proving", "good", "usability", "and", "high", "scalability", "for", "imbalanced", "PAPs", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pre - reduced ring"}, {"tokens": ["MU", "-", "RTS", "keeps", "the", "standard", "RTS", "frame", "structure", ",", "because", "the", "AP", "can", "utilize", "the", "Group", "-", "ID", "field", "of", "the", "PHY", "frame", "to", "notify", "targeted", "receivers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["*", "cccccccccc", "RAID5", "&", "BM", "&", "CD", "&", "GRD", "&", "ID", "&", "RAID6", "&", "LSI", "&", "RAID7", "&", "SSP", "&", "R8", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "MTTDLs", "as", "a", "ratio", "and", "a", "fraction", "of", "the", "MTTF", "(", ")", "and", "the", "first", "term", "in", "asymptotic", "reliability", "expression", "with", "denoting", "the", "unreliability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["The", "IS", "result", "of", "ALI", "is", "reported", "in", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["Phase", "change", "memory", "(", "PCM", ")", "can", "also", "be", "another", "alternative", "for", "secured", "NVM", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phase change memory"}, {"tokens": ["We", "show", "two", "versions", "of", "InterNet", "that", "incorporates", "both", "the", "feature", "intertwiner", "module", "and", "OT", "agreement", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Autonomous", "or", "computational", "personalization", "in", "SAR", "often", "seeks", "to", "maximize", "the", "participants", "'", "focus", "and", "performance", ",", "using", "rule-", ",", "model-", ",", "or", "goal", "-", "based", "approaches", "to", "personalization", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "actual", "element", "mesh", "sizes", "shown", "in", "Table", "for", "different", "parts", "of", "the", "FEM", "model", "were", "selected", "to", "meet", "both", "ECSS", "requirement", "and", "the", "geometrical", "compatibility", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["(", "ROC", ")", "curves", "for", "classification", "models", "for", "left", "ventricular", "hypertrophy", "(", "C", ")", "and", "diastolic", "dysfunction", "(", "D", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["More", "specifically", ",", "CF", "models", "analyze", "the", "relationships", "between", "users", "and", "interdependencies", "among", "items", "to", "identify", "preference", "similarity", "across", "individuals", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["We", "suggest", "using", "ECS", "-", "DBN", "to", "address", "the", "imbalanced", "data", "problem", "in", "fault", "diagnosis", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Link", "prediction", "performance", "is", "reported", "as", "the", "combined", "average", "of", "AUC", "and", "AP", "scores", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "average precision"}, {"tokens": ["table[h]tabular@lcc@Dataset", "&", "1ltabular[c]@c@W/", "Spammers(RMSE", ",", "PS)tabular", "&", "1ltabular[c]@c@", "W", "/", "o", "Spammers", "RMSEtabular", "Amazon", "-", "Beauty", "&", "(", "0.871", ",", "0.122", ")", "&", "0.901", "Amazon", "-", "Health", "&", "(", "1.056", ",", "0.047", ")", "&", "1.053Yelp!-Hotel", "&", "(", "1.124", ",", "0.150", ")", "&", "1.125Yelp!-Restaurant", "&", "(", "1.039", ",", "0.133", ")", "&", "1.034", "tabularRSME", "and", "PS", "on", "datasets", "with", "and", "without", "spam", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "prediction shift"}, {"tokens": ["Each", "non", "exemplar", "point", "is", "then", "assigned", "to", "the", "exemplar", "most", "similar", "to", "it", "Message", "passing", "between", "variable", "nodes", "and", "factor", "nodes", "in", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "affinity propagation"}, {"tokens": ["Taking", "target", "recognition", "as", "an", "example", ",", "recognizing", "targets", "in", "optical", "images", "and", "SAR", "images", ",", "or", "recognizing", "different", "kinds", "of", "SAR", "targets", "such", "as", "airplanes", "and", "ships", ",", "are", "usually", "looked", "upon", "as", "different", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["in", "propose", "a", "synchronized", "access", "scheme", "coordinated", "by", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access part"}, {"tokens": ["We", "are", "also", "interested", "in", "comparing", "the", "s", "-", "RNN", "performance", "between", "the", "SL", "and", "SP", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["In", "canonical", "PSO", ",", "the", "velocity", "update", "involves", "evaluation", "of", "the", "euclidean", "distance", "of", "the", "particle", "from", "its", "learning", "exemplars", ",", "referred", "to", "as", "learning", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["We", "observe", "that", ",", "while", "NCE", "approaches", "the", "exhaustive", "method", "in", "terms", "of", "matching", "the", "ground", "truth", "top-", "most", "similar", "nodes", ",", "NS", "fails", "to", "deliver", "the", "same", "quality", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "noise contrastive estimation"}, {"tokens": ["Using", "different", "settings", "on", "the", "DMD", ",", "we", "can", "sequentially", "acquire", "a", "set", "of", "measurements", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "digital micro - mirror device"}, {"tokens": ["GP", "-", "GAM", "denotes", "an", "additive", "GP", "model", "with", "only", "first", "-", "order", "interactions", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["From", "Left", "to", "Right", ":", "Ground", "Truth", "FS", "image", ",", "ZF", "image", ",", "GAN", "reconstructed", "image", ",", "Recon", "-", "GLGAN", "reconstructed", "image", ",", "ZF", "reconstruction", "error", ",", "GAN", "reconstruction", "error", "and", "Recon", "-", "GLGAN", "reconstruction", "error", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fully sampled"}, {"tokens": ["tabular", "l", "l", "Variable", "&", "Description", "&", "Length", "of", "the", "past", "&", "Length", "of", "the", "lookbehind", "part", "&", "(", "past", "+", "current", "step", ")", "&", "Length", "of", "the", "future", "&", "Length", "of", "the", "whole", "sequence", "&", "Index", "of", "a", "layer", "&", "Index", "of", "an", "Expert", "in", "the", "layer", "&", "Set", "of", "cluster", "centers", "(", "states", ")", "&", "of", "an", "Expert", "&", "Dimension", "of", ",", "number", "of", "&", "cluster", "centers", "&", "Sequence", "of", "complete", "observations", "&", "Sequence", "of", "observations", "of", "&", "Expert", "in", "layer", "&", "Hidden", "state", "of", "the", "Expert", "in", "layer", "&", "Output", "vector", "of", "the", "Expert", "in", "layer", "&", "Number", "of", "sequences", "considered", "in", "a", "TP", "&", "Set", "of", "all", "providers", "of", "context", "to", "&", "an", "Expert", "&", "Likelihoods", "of", "seeing", "each", "context", "&", "element", "from", "each", "provider", "in", "each", "&", "position", "of", "each", "sequence", "tabulart", ":", "notationSelected", "notation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["We", "leverage", "BNN", "as", "a", "powerful", "tool", "for", "uncertainty", "estimation", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian neural networks"}, {"tokens": ["Dashed", "linesin", "orange", "represent", "tight", "bounds", "confining", "the", "region", "(", "in", "light", "orange", ")", "of", "possible", "IB", "curves(delimited", "by", "the", "red", "line", ",", "also", "known", "as", "the", "Pareto", "frontier", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "time", "complexity", "for", "TS", "is", "also", "significantly", "reduced", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["LTE", "was", "designed", "based", "on", "the", "assumption", "of", "exclusive", "spectrum", "use", ",", "which", "is", "not", "true", "in", "the", "unlicensed", "band", "where", "devices", "withdifferent", "air", "interfaces", "coexist", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["System", "model", "of", "secure", "SM", "with", "TAS", "schemeReferring", "to", "the", "secure", "SM", "system", "model", "in", ",", "the", "transmit", "baseband", "signal", "with", "the", "aid", "of", "AN", "can", "be", "expressed", "aswhere"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["However", ",", "LOM", "has", "an", "inferior", "performance", "compared", "to", "SEM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["However", ",", "its", "performance", "is", "still", "worse", "than", "3D", "CNN", "MTL", ",", "which", "achieves", "a", "classification", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "multi - task learning"}, {"tokens": ["For", "20MHz", "bandwidth", ",", "the", "simulator", "assumes", "that", "LTE", "and", "WiFi", "physical", "layer", "rates", "are", "78Mbps", "and", "72Mbps", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "ODO", "system", "with", "a", "flat", "duration", "prior", "rather", "than", "the", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["There", "is", "an", "exact", "mapping", "between", "the", "values", "of", "BIC", "and", "the", "Bayes", "factor", "(", "BF", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "bayes factor"}, {"tokens": ["Unlike", "other", "evolutionary", "search", "paradigms", ",", "PSO", "has", "a", "single", "learning", "mechanism", ";", "known", "as", "velocity", "update", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["IR", "EnginesA", "QA", "framework", "was", "originally", "used", "to", "construct", "a", "QA", "system", "based", "on", "running", "a", "default", "Lucene", "installation", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["In", "particular", ",", "we", "will", "compare", "the", "non", "-", "linear", "DE", "capabilities", "of", "Isomap", "with", "our", "proposed", "autoencoder", "based", "algorithm", ",", "so", "in", "this", "section", "we", "provide", "a", "brief", "overview", "of", "Isomap", "and", "more", "in", "-", "depth", "derivation", "of", "autoencoders", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["A", "Gaussian", "process", "with", "this", "kernel", "function", "(", "an", "additive", "GP", ")", "constitutes", "a", "powerful", "model", "that", "allows", "one", "to", "automatically", "determine", "which", "orders", "of", "interaction", "are", "important", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["For", "the", "PA", "task", ",", "our", "CNN", "performs", "noticeably", "better", "when", "operating", "on", "the", "last", "4", "seconds", "of", "audio", "(", "model", "B", ")", "instead", "of", "the", "first", "4", "seconds", "(", "model", "A", ")", ",", "suggesting", "the", "presence", "of", "discriminative", "cues", "at", "the", "end", "of", "each", "audio", "signal", "which", "we", "confirm", "in", "Section", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["To", "this", "end", ",", "we", "first", "train", "the", "high", "to", "low", "resolution", "networks", ",", "and", "generate", "LR", "images", "of", "AFLW", "test", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["table[ht", "]", "tabularllll", "&", "Facebook", "&", "Google", "&", "Twitter", "Ads", "&", "All", "Candidates", ",", "&", "Federal", "&", "Federal", "Included", "&", "Issue", "ads", "&", "candidate", "&", "candidate", ",", "&", "&", "related", "&", "Issue", "ads", "Sponsor", "&", "Name", "&", "Name", ",", "&", "Name", ",", "Info", "&", "&", "FEC", "/", "EIN", "&", "billing", "info"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "federal election candidate"}, {"tokens": ["As", "opposed", "to", "the", "experimental", "results", "reported", "in", ",", "we", "observed", "inferior", "results", "of", "the", "LR", "structure", "compared", "to", "standard", "CNN", "when", "training", "from", "scratch", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low rank"}, {"tokens": ["By", "utilizing", "an", "ISP", ",", "even", "systems", "with", "low", "memory", "budgets", "benefit", "require", "fewer", "operations", "per", "inference", "(", "thus", ",", "lower", "latency", "and", "higher", "throughput", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Subsequently", ",", "perturbation", "ICCs", "were", "averaged", "over", "test", "and", "retest", "images", "to", "facilitate", "comparison", "with", "the", "test", "-", "retest", "ICC", ",", "as", "there", "was", "no", "consistent", "bias", "toward", "higher", "ICC", "values", "for", "one", "image", "set", "(", "see", "supplementary", "note", "6", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["SBM", "with", "longitudinal", "modelling", "The", "SBMs", "and", "related", "models", "introduced", "so", "far", "assume", "that", "the", "graph", "is", "observed", "at", "one", "instant", ",", "which", "can", "be", "regarded", "as", "a", "cross", "-", "section", "of", "a", "graph", "that", "is", "evolving", "over", "time", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["FEM", "Model", "known", "as", "Finite", "Element", "Methodgm97", ",", "is", "the", "most", "accurate", "physical", "model", "compared", "to", "other", "models", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element methodgm97"}, {"tokens": ["The", "IS", "is", "calculated", "through", "the", "inception", "object", "detection", "network", "and", "returns", "high", "scores", "when", "various", "and", "high", "-", "quality", "images", "are", "generated", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["Comparison", "of", "DMD", ",", "EMD", ",", "and", "iterative", "improvement", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "excessive mapping dissolution"}, {"tokens": ["In", "BA", "model", ",", "appearance", "of", "new", "connections", "totally", "depends", "on", "the", "addition", "of", "new", "nodes", "to", "the", "system", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "barabasi albert"}, {"tokens": ["Here", ",", "we", "project", "the", "AN", "lying", "in", "the", "null", "-", "space", "of", "desired", "channel", ",", "therefore", "the", "is", "given", "bywhere", "is", "the", "normalized", "factor", "of", "making", "the", "identity", "holds", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["In", "particular", "for", "predicting", "DTI", "FA", "in", "the", "parietal", "and", "temporal", "lobes", ",", "DKT", "has", "significantly", "better", "predictions", "that", "almost", "all", "methods", "tested", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fractional anisotropy"}, {"tokens": ["For", "learning", "our", "multilingual", "SST", "models", "based", "on", "RNN", "variants", "proposed", "in", "part", "(", "C", ")", "of", "section", "3.2.2", ",", "we", "also", "tag", "SemCor", "using", "TreeTagger", "(", "POS", "tagger", "proposed", "by", "Schmid95", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["For", "RAID1", "with", "disks", ",", "for", "BM", "and", "most", "RAID1", "organizations", ",", "and", "for", "the", "ID", "organization", ",", "since", "only", "one", "disk", "failure", "per", "cluster", "is", "allowed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["Each", "RS", "is", "located", "at", "a", "boundary", "of", "cells", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["There", "are", "different", "activation", "functions", "have", "been", "used", "such", "as", "sigmoid", ",", "hyperbolic", "tangent", ",", "softmax", ",", "and", "rectified", "linear", "in", "different", "implementations", "using", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["Experiment", "ResultsIn", "this", "section", ",", "all", "the", "parameters", "of", "DBN", "and"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["NP", "gu-:[noitemsep]PIr"], "acronym_pos": [1, 0], "long_form": "new persian"}, {"tokens": ["MINT", "-", "FEC", "Performance", "Evaluation", "and", "ResultsThe", "MINT", "-", "FEC", "goal", "is", "to", "improve", "on", "uavFEC", "(", "Section", ")", "to", "ensure", "an", "even", "higher", "perceived", "QoE", "for", "end", "-", "users", ",", "while", "avoiding", "unnecessary", "network", "overhead", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "proposed", "algorithm", "is", "a", "self", "-", "organizing", "hierarchical", "PSO", "with", "time", "-", "varying", "acceleration", "coefficients", "(", "SOHPSOTVAC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["The", "SP", "serves", "as", "a", "quantization", "of", "the", "input", "so", "that", "if", "the", "input", "does", "not", "change", "enough", ",", "the", "information", "will", "not", "be", "propagated", "further", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial pooler"}, {"tokens": ["Figure", "(", "b", ")", "shows", "the", "resultant", "GP", "by", "applying", "the", "proposed", "algorithm", "to", "real", "-", "world", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Furthermore", ",", "the", "above", "chance", "-", "level", "detection", "rates", "of", "NP", "models", "in", "ADHD", "and", "BIPL", "confirm", "a", "successful", "application", "of", "the", "proposed", "NP", "-", "based", "mixed", "-", "effect", "modeling", "in", "unsupervised", "diagnostic", "prediction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["This", "model", "not", "only", "ensures", "better", "recognition", "accuracy", "with", "fewer", "computational", "parameters", "against", "the", "state", "-", "of", "-", "the", "-", "art", "DCNN", "architectures", ",", "but", "also", "helps", "to", "improve", "the", "overall", "training", "process", "of", "the", "deep", "learning", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Thus", "there", "is", "no", "exact", "theoretical", "way", "to", "design", "ANN", "architecture", ",", "except", "by", "experiment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["LF", "-", "RCNNLate", "fusion", "encoder", "with", "concatenated", "history", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "late fusion"}, {"tokens": ["We", "again", "evaluate", "the", "performance", "on", "generated", "LR", "AFLW", "test", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["ExperimentsDataWe", "compared", "the", "proposed", "types", "of", "synthetic", "data", "by", "evaluating", "character", "and", "word", "error", "rates", "(", "CER", ",", "WER", ")", "of", "ASR", "systems", "trained", "on", "the", "Wall", "Street", "Journal", "corpus", "(", "LDC93S6B", "and", "LDC94S13B", ")", ",", "using", "the", "standard", "SI-284", "set", "containing", "37", "K", "utterances", "or", "80", "hours", "of", "speech", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["At", "the", "operating", "point", "0.01", "FAR", ",", "we", "then", "plot", "the", "improvement", "for", "each", "group", "of", "yaw", "angles", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "false acceptance rate"}, {"tokens": ["In", "the", "next", "experiment", "we", "implement", "Algorithm", "1", "on", "each", "node", "and", "measure", "the", "average", "number", "of", "acquaintances", "needed", "to", "reach", "the", "predefined", "TP", "lower", "-", "bound", "and", "the", "FP", "upper", "-", "bound", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["Theoretically", ",", "computer", "malware", "could", "also", "find", "new", "ways", "to", "exploit", "software", "or", "different", "OS", "APIs", "for", "spreading", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "operating system"}, {"tokens": ["Finally", ",", "we", "find", "the", "BQ", "of", "all", "142093", "testing", "questions", "from", "VQA", "dataset", "and", "collect", "them", "together", ",", "with", "the", "format", ",", "as", "the", "BQD", "in", "Section", "4", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["OCR", "System", ",", "Bengali", "printed", "OCR", ",", "BLSTM", "-", "CTC", ",", "Text", "Recognition", ",", "Printed", "text", "recognition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["In", "this", "section", ",", "the", "general", "results", "of", "the", "average", "achievable", "rate", "at", "UE", "with", "two", "common", "SBS", "cooperation", "strategies", ",", "namely", "the", "strategy", "with", "a", "distance", "constraint", "and", "the", "strategy", "with", "a", "received", "signal", "power", "constraint", ",", "are", "derived", "in", "the", "fractal", "small", "-", "cell", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["For", "the", "sensor", "node", ",", "is", "the", "energy", "charged", "at", "node", "with", "charge", "transmitted", "from", "ET", "within", "the", "time", "frame", "and", "is", "defined", "as", "followswhere", "is", "the", "transmit", "power", "of", "ET", ",", "is", "the", "path", "loss", "in", "terrestrial", "environment", ",", "is", "the", "power", "consumed", "by", "the", "sensor", "node", "for", "power", "reception", ",", "is", "the", "frame", "size", "(", "operation", "time+charging", "time", ")", ",", "is", "the", "charging", "time", "within", "T", "(", "thus", ",", "is", "the", "charging", "time", "for", "a", "sensor", "node", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy transmitters"}, {"tokens": ["The", "range", "of", "the", "Lagrange", "multipliers", "that", "allow", "the", "exploration", "of", "the", "IB", "curve", "is", "contained", "by", "which", "is", "also", "contained", "by", ",", "where", "is", "the", "derivative", "of", "w.r.t", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["OPF", "&", "Optimal", "power", "flow", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Quantitative", "Evaluation", "With", "Reinforcement", "LearningComparing", "the", "performance", "of", "RL", "algorithms", ",", "using", "the", "learned", "state", "representations", ",", "is", "the", "most", "relevant", "approach", "to", "evaluate", "the", "SRL", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "state representation learning"}, {"tokens": ["Corresponding", "SEM", "image", "which", "has", "already", "been", "registered", "with", "LOM", "image", "from", "the", "same", "area", "are", "masked", "using", "the", "mentioned", "binary", "mask", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Numerical", "Results", "and", "DiscussionsThe", "analytical", "expressions", "of", "the", "previous", "section", "have", "been", "used", "to", "evaluate", "the", "performance", "of", "ODF", "cooperative", "systems", "utilizing", "repetitive", "and", "RS", "-", "based", "transmission", "over", "INID", "Nakagami-", "fading", "channels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Given", "an", "ANN", "architecture", "and", "a", "dropout", "level", ",", "the", "dropout", "can", "be", "applied", "between", "any", "two", "consecutive", "layers", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Thus", ",", "the", "interference", "from", "RRH", "3", "to", "UE", "4", "will", "be", "carefully", "controlled", "when", "RRH", "3", "is", "serving", "UE", "5", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "user equipment"}, {"tokens": ["Table", "shows", "the", "global", "performance", "of", "AP", "and", "EAP", "as", "well", "the", "corresponding", "hyperparameters", "and", "number", "of", "clusters", "discovered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["Our", "base", "model", "that", "adapts", "CRNN", "for", "CDA", "recognition", "using", "BCE", "loss", "and", "sigmoid", "activation", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concurrent dialogue acts"}, {"tokens": ["Computational", "CostAverage", "computational", "time", "of", "ECS", "-", "DBN", ",", "DBN", ",", "ADASYN", "-", "DBN", ",", "SMOTE", "-", "DBN", ",", "SMOTE", "-", "borderline1-DBN", ",", "SMOTE", "-", "borderline2-DBN", "and", "SMOTE", "-", "SVM", "-", "DBN", "on", "the", "gun", "drilling", "imbalanced", "dataset", "are", "presented", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "(", ")", ",", "matrix", "is", "the", "AN", "projection", "matrix", ",", "is", "the", "random", "AN", "vector", ",", "is", "the", "total", "transmit", "power", ",", ",", "and", "are", "the", "power", "allocation", "factors", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Background", "overviews", "SAR", "in", "the", "relevant", "contexts", "of", "learning", ",", "ASD", ",", "and", "personalization", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Hereinafter", ",", "the", "FL", "model", "that", "is", "trained", "by", "each", "user", "'s", "dataset", "is", "called", "the", "local", "FL", "model", ",", "while", "the", "FL", "model", "that", "is", "generated", "by", "the", "BS", "using", "local", "FL", "model", "parameter", "inputs", "from", "all", "users", "is", "called", "the", "global", "FL", "model", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["Firstly", "by", "time", "duration", ",", "BS", "transmits", "with", "full", "power", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Hence", "FA", "fails", "in", "cases", "where", "we", "have", "instability", "or", "few", "gradients", "are", "acting", "on", "participating", "neurons", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["We", "trained", "our", "own", "HR", "landmark", "detector", "(", "HR", "-", "LD", ")", "on", "AFLW", "images", "for", "this", "purpose", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["Using", "88", "features", "including", "pitch", ",", "Mel", "-", "PLP", ",", "and", "TRAP", "-", "DCT", "input", "into", "a", "bottleneck", "DNN", ",", "they", "are", "able", "to", "improve", "the", "CER", "to", "40.2", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "perceptual linear prediction"}, {"tokens": ["DBN", "is", "known", "for", "its", "extraordinary", "end", "-", "to", "-", "end", "feature", "learning", "and", "classification", "characteristics", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["RT", ":", "Synonyms", "and", "HypernymsDescription", "of", "the", "Dataset", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ruthes"}, {"tokens": ["Lastly", ",", "the", "OT", "extensions", "presented", "in", "all", "the", "works", "in", "the", "table", "except", "inherently", "produce", "-out", "-", "of-", "OTs", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Given", "the", "feasible", "set", "of", "UEs", "from", "the", "UE", "selection", "algorithm", ",", "we", "provide", "a", "low", "-", "complexity", "single", "-", "layer", "iterative", "algorithm", "(", "i.e.", ",", "Algorithm", "1", ")", "to", "solve", "the", "NPC", "minimization", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Figure", "depicts", "the", "results", "for", "different", "sizes", "of", "the", "RB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "reduced basis"}, {"tokens": ["Each", "element", "of", "is", "a", "binary", "latent", "variable", "without", "constraint", ",", "representing", "the", "absence", "or", "presence", "of", "a", "latent", "feature", ",", "meaning", "that", "the", "sample", "space", "of", "is", "the", "combinations", "of", "0", "'s", "and", "1", "'s", "(", "note", "the", "similarity", "with", "the", "number", "of", "combinations", "in", "an", "overlapping", "SBM", "in", "Section", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["The", "GAN", "models", "trained", "using", "an", "adversarial", "loss", "generate", "more", "realistic", "synthetic", "MR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["Adaptive", "differential", "evolution", "(", "DE", ")", "algorithm", "will", "proceed", "to", "next", "generation", "and", "continuously", "iterate", "between", "mutation", "and", "selection", "to", "reach", "the", "maximum", "number", "of", "generations", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Yet", "both", "IS", "and", "CS", "require", "a", "common", "subset", "of", "technical", "knowledge", ",", "reflected", "also", "in", "the", "intersection", "of", "the", "respective", "study", "programs", "'", "curricula", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["Aiming", "for", "determinismIn", "cases", "where", "a", "GFG", "automaton", "is", "not", "enough", ",", "and", "we", "want", "instead", "to", "build", "a", "DCA", ",", "we", "can", "test", "whether", "the", "current", "automaton", "is", "DBP", "instead", "of", "GFG", "in", "the", "incremental", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["Note", "that", "the", "solid", "yellow", "circle", "represents", "the", "performance", "of", "ECS", "-", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "directed belief net"}, {"tokens": ["-", "7(r)8", "-", "10(r)11", "-", "1314", "-", "15Metric", "/", "Model", "&", "COR", "&", "QRFA", "&", "GS", "&", "COR", "&", "QRFA", "&", "GS", "&", "COR", "&", "QRFA", "&", "GS", "&", "COR", "&", "QRFA", "&", "GS", "&", "COR", "&", "QRFA", "Average", "/", "case", "&", "0.58", "&", "0.89", "&", "&", "0.74", "&", "1", "&", "&", "0.66", "&", "0.96", "&", "&", "0.7", "&", "0.99", "&", "&", "0.67", "&", "0.96", "Max", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gold standard"}, {"tokens": ["There", "are", "some", "approaches", "to", "circumvent", "this", "by", "either", "using", "TS", "or", "by", "using", "multiple", "DEM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "tessellation shader"}, {"tokens": ["In", "the", "proposed", "NP", "framework", ",", "these", "two", "sources", "of", "uncertainties", "are", "learned", "from", "data", "and", "are", "summarized", "in", "the", "distribution", "of", "the", "global", "latent", "variable", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["t", "]", "GPU", "RS", "Speedups", "over", "SRBP"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["In", "this", "subgame", "there", "exists", "an", "optimal", "MD", "strategy", "that", "maximizesthe", "reachability", "probability", "for", "every", "state", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["Therefore", ",", "each", "antenna", "can", "form", "independent", "beams", ",", "so", "that", "the", "multiple", "streams", "created", "by", "SVC", "-", "encoding", "are", "divided", "into", "parts", "and", "each", "part", "is", "assigned", "to", "a", "beam", "to", "be", "concurrently", "transmitted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scalable video coding"}, {"tokens": ["Further", ",", "increasing", "of", "shows", "that", "RV", "strategy", "reduces", "outbreak", "sizes", "to", "about", "1", "K", "infections", "at", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["Mutation", "is", "carried", "out", "with", "DE", "mutation", "strategy", "to", "create", "mutation", "individuals", "based", "on", "the", "current", "parent", "population", "as", "shown", "in", "Step", "2.1", "of", "Algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["For", "an", "ENF", "signal", ",", "CF", "is", "measured", "as", "the", "ratio", "of", "the", "peak", "value", "to", "the", "root", "mean", "square", "(", "rms", ")", "value", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "crest factor"}, {"tokens": ["MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["At", "the", "training", "stage", ",", "a", "PNN", "context", "encoder", "and", "an", "RNN", "session", "model", "are", "first", "pretrained", "separately", "to", "optimize", "the", "likelihood", "eqn", ":", "likelihood", ",", "where", "the", "negative", "items", "are", "defined", "using", "the", "items", "in", "the", "session", "-", "parallel", "mini", "-", "batches", "as", "in", "GRU4RECgru4rec", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["The", "queues", "will", "apply", "the", "conventional", "RA", "protocol", "but", "in", "the", "case", "of", "packet", "loss", "due", "to", "collision", "the", "two", "queues", "will", "exploit", "the", "feedback", "information", "to", "provide", "some", "level", "of", "coordination", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random access"}, {"tokens": ["We", "use", "an", "initial", "learning", "rate", "of", "0.1", "and", "we", "decrease", "the", "learning", "rate", "by", "a", "factor", "of", "10", "on", "epochs", "100", "and", "150", "(", "epochs", "and", "for", "Fast", "-", "ARD", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["It", "is", "evident", "from", "the", "figure", "that", "our", "network", "'s", "performance", "is", "closest", "to", "FS", "followed", "by", "GAN", "and", "ZF", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "fully sampled"}, {"tokens": ["Therefore", ",", "the", "complexity", "imposed", "by", "the", "exhaustive", "search", "aiming", "for", "identifying", "the", "entire", "set", "of", "routes", "belonging", "to", "the", "OPF", "is", "on", "the", "order", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "optimal pareto front"}, {"tokens": ["For", "the", "purpose", "of", "simplifying", "our", "analysis", "below", ",", "it", "is", "assumed", "that", "the", "above", "four", "critical", "points", "lie", "outside", "the", "PA", "interval", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power allocation"}, {"tokens": ["As", "shown", "in", "Figure", ",", "we", "compute", "the", "MACS", "score", "times", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "mean average conceptual similarity"}, {"tokens": ["Moreover", ",", "the", "alternative", "constellation", "points", "in", "TI", "technique", "have", "an", "increased", "energy", "and", "the", "implementation", "complexity", "increases", "due", "to", "the", "computation", "of", "theoptimal", "translation", "vector", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tone injection"}, {"tokens": ["In", "multipath", "channel", ",", "multipath", "effect", "will", "gather", "AN", "towards", "the", "desired", "receiver", "if", "the", "blocking", "object", "locates", "at", "the", "eavesdropper", "direction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["[", "5", "]", "We", "use", "the", "updated", "source", "code", "(", "IS", "of", ")", "as", "our", "baseline", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["Stage", "1", "Architecture", "of", "stage", "1", "of", "PIN", "is", "analogous", "to", "Faster", "RCNN", "and", "has", "two", "subnetworks", ":", "A", "proposal", "generator", "(", "RPN", ")", "and", "a", "proposal", "classifier", "(", "RCNN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["Comparing", "the", "UTI", "-", "to", "-", "MVF", "prediction", "results", "with", "text", "-", "to", "-", "MVF", "prediction", "(", "within", "HMM", "-", "based", "speech", "synthesis", ")", ",", "the", "latter", "seems", "to", "be", "a", "simpler", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["[", "]", "[", "]", "[", "]", "(", "a", ")", ":", "AR", "-", "Tennis", "by", "Henrysson", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["The", "proposed", "work", "is", "different", "from", "in", "many", "respects", "as", "it", "needs", "labeled", "data", "only", "in", "HR", "and", "learns", "to", "predict", "landmarks", "in", "LR", "images", "in", "an", "unsupervised", "way", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Remarkably", ",", "RS", "proved", "to", "be", "robust", "in", "both", "cases", "of", "HD", "and", "FD", "relaying", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["Furthermore", ",", "by", "exploiting", "the", "IB", "curve", "duality", "(", "Lemma", "10", "of", ")", "we", "were", "able", "to", "derive", "other", "families", "of", "Lagrangians", "which", "allow", "for", "the", "exploration", "of", "the", "IB", "curve", "(", "Appendix", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["We", "observe", "from", "columns", "(", "PF", "BS", ")", "and", "(", "PF", "Acc", ")", "that", "our", "model", "has", "the", "best", "accuracy", "and", "BS", "discrepancies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "brier score"}, {"tokens": ["We", "analyze", "the", "cumulative", "probability", "distribution(CPD", ")", "of", "the", "inter", "-", "event", "durations", "of", "TI", "1", ",", "TI", "2", "in", "Figure", "(", "b", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["ECDF", "of", "LSTM", "Prediction", "Accuracy", "for", "Flutes", "Cellos", "at", "AP", "and", "Building", "spatial", "levels"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Deagggregation", "of", "address", "blocks", "due", "to", "secondary", "market", "transfersOne", "potential", "concern", "with", "the", "proposed", "fee", "structure", "is", "that", "it", "may", "incentivize", "the", "creation", "of", "a", "secondary", "address", "market", "that", "may", "extend", "the", "use", "of", "PI", "allocations", "by", "end", "sites", "as", "opposed", "to", "PA", "allocation", "from", "the", "LIRs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "provider aggregatable"}, {"tokens": ["demonstrate", "that", "DTN", "has", "a", "clear", "advantage", "over", "the", "baseline", "method", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "domain transfer network"}, {"tokens": ["LTE", "DC", "Architecture", "[", "]", "0.235", "LTE", "DC", "Architecture", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["We", "use", "an", "intuitive", "example", "to", "illustrate", "the", "differences", "of", "OMP", ",", "OLS", "and", "COLS", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["Active", "Tracking", "in", "Real", "-", "world", "ScenariosTo", "evaluate", "how", "the", "active", "tracker", "performs", "in", "real", "-", "world", "scenarios", ",", "we", "take", "the", "network", "trained", "in", "a", "UE", "environment", "and", "test", "it", "on", "a", "few", "video", "clips", "from", "the", "VOT", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "unreal engine"}, {"tokens": ["DSA", "occupations", "and", "categoriesCompute", "the", "skill", "intensity", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["The", "UAP", "is", "71.2", "and", "the", "AP", "of", "the", "best", "model", "is", "59.7", "(", "FCOS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["FPMC", "is", "proposed", "to", "combine", "user", "-", "item", "matrix", "with", "Markov", "chains", "and", "it", "is", "still", "considered", "as", "one", "of", "the", "state", "-", "of", "-", "art", "sequential", "CF", "-", "based", "recommendation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["We", "propose", "a", "Von", "Mises", "distribution", "-", "Sum", "Secrecy", "Rate", "Maximization", "(", "VMD", "-", "SSRM", ")", "robust", "DM", "scheme", "which", "designs", "the", "robust", "signal", "beamforming", "matrix", "and", "AN", "beamforming", "matrix", "on", "the", "assumption", "that", "the", "estimation", "errors", "of", "direction", "angles", "toward", "the", "eavesdroppers", "follow", "the", "Von", "Mises", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["*", "argmax*argmin", "op", "-", "tical", "net", "-", "works", "semi", "-", "conduc", "-", "torPioneering", "Studies", "on", "LTE", "eMBMS", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Rule", "-", "based", "approaches", "to", "personalization", "have", "been", "successful", "in", "both", "short", "-", "term", "and", "long", "-", "term", "SAR", "interventions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "specified", "components", "of", "this", "system", "are", "modeled", "as", "actors", "of", "AML", "specified", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["The", "IB", "approach", "allows", "us", "to", "learn", "a", "low", "-", "dimensional", "interpretable", "compression", "of", "the", "relevant", "information", "during", "training", ",", "which", "we", "can", "use", "to", "make", "causal", "inferences", "where", "data", "is", "incomplete", "at", "test", "time", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["a", "BSP", "tree", "of", "depth", "is", "capable", "of", "recording", "solutions", ",", "only", "if", "the", "BSP", "tree", "is", "balanced", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["This", "new", "technique", "is", "completely", "different", "to", "ANN", "but", "encouraged", "through", "its", "different", "approaches", "that", "we", "will", "see", "very", "soon", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["is", "the", "bandwidth", "assigned", "to", "UE", ",", "and", "is", "the", "signal", "-", "to", "-", "interference", "-", "plus", "-", "noise", "ratio", "(", "SINR", ")", "at", "UE", "adopting", "SBS", "cooperation", "strategies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["This", "issue", "is", "resolve", "with", "fabric", "by", "execute", "the", "transaction", "first", "and", "then", "order", "the", "transaction", "over", "the", "BC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "blockchain"}, {"tokens": ["RBP", "and", "RS", "rely", "on", "greedily", "selecting", "updates", "based", "on", "message", "residuals", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["which", "works", "towards", "deciding", "the", "transmission", "mode", "of", "each", "UE", "and", "forms", "the", "best", "possible", "paths", "towards", "the", "base", "station", "using", "relays", "and", "clusters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Taking", "the", "source", "domain", "features", "as", "an", "example", ",", "the", "significance", "-", "aware", "IB", "loss", "can", "be", "obtained", "aswhere", "denotes", "the", "channel", "-", "wise", "product", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["&", "ECS", "-", "DBN", "&", "9977.39", "148.55", "&", "1280.28", "DBN", "&", "8697.11", "2308.22", "&", "-", "Results", "of", "Tool", "Wear", "EstimationTool", "wear", "estimation", "is", "the", "prognostic", "step", "in", "the", "MDP", "framework", "as", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["SSTL", "integrates", "the", "temporal", "modalities", "of", "STL", "with", "two", "spatial", "modalities", ";", "the", "somewhere", "operator", "and", "a", "novel", "bounded", "version", "of", "the", "topological", "surrounded", "operator", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "signal temporal logic"}, {"tokens": ["At", "full", "load", "and", "in", "all", "cache", "at", "CC", "scenario", ",", "half", "of", "users", "are", "served", ",", "while", "are", "served", "in", "EC", "scenario", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["The", "gain", "ratios", "are", "computed", "by", "(", "APAP)/AP", ",", "where", "AP", "and", "AP", "are", "AP", "of", "each", "class", "before", "and", "after", "progressive", "instance", "-", "switching", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["shows", "the", "recognition", "performance", "of", "DBN", ",", "CNN", ",", "CNN", "with", "dropout", ",", "Gaussian", "filters", "and", "Gabor", "filters", "for", "30", "iterations", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["A", "/32", "PA", "allocation", "fee", "ranges", "between", "US", "1000", "and", "US", "2,500", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider aggregatable"}, {"tokens": ["The", "filterbank", "for", "LS", "and", "LM", "has", "a", "linear", "response", "(", "and", "lower", "resolution", ")", "for", "the", "lower", "frequencies", ",", "and", "a", "logarithmic", "response", "for", "the", "higher", "frequencies", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logarithmically spaced"}, {"tokens": ["In", "the", "canonical", "PSO", ",", "euclidean", "distance", "from", "the", "learning", "exemplar", "is", "used", "as", "a", "learning", ",", "as", "illustrated", "by", "the", "following", "velocity", "update", "rule", "for", "the", "dimension", "of", "the", "particle,*where", ",", "is", "inertia", "weight", ",", "are", "acceleration", "constants", "and", "are", "uniform", "random", "numbers", "which", "lie", "in", "[", "0,1]."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Bold", "values", "correspond", "to", "CCR", "when", "training", "angle", "is", "similar", "to", "testing", "angle", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["Section", "shows", "that", "the", "encoding", "matrix", "of", "the", "systematic", "Exact", "-", "MBR", "codes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Now", "let", "us", "look", "at", "the", "privacy", "guarantee", "of", "GDP", "(", "see", "Definition", "def", ":", "gdp", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["Our", "findings", "demonstrate", "that", "the", "fully", "autonomous", "SAR", "system", "was", "able", "to", "personalize", "its", "instruction", "and", "feedback", "over", "time", "to", "each", "child", "'s", "proficiency", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["From", "left", "to", "right", ",", "input", "low", "resolution", "MR", "image", ",", "baseline", "SR", "approach", "(", "no", "global", "loss", ")", ",", "the", "proposed", "anatomically", "constrained", "SR", "model", ",", "and", "the", "ground", "-", "truth", "high", "resolution", "acquisition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["In", "Figure", ",", "we", "present", "the", "distribution", "system", "constraint", "violations", "that", "were", "avoided", "by", "using", "Con", "-", "TS", "-", "RTP", "instead", "of", "an", "unconstrained", "TS", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Appendix", "C", ":", "ARD", "with", "naturally", "trained", "teacher", "modelsARD", "encourages", "a", "student", "to", "produce", ",", "for", "all", "images", "within", "an", "-ball", "of", "a", "data", "point", ",", "the", "teacher", "'s", "output", "at", "that", "data", "point", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["This", "FEC", "block", "can", "be", "adjusted", "in", "real", "-", "time", "depending", "on", "Markov", "models", "to", "estimate", "the", "PLR", "and", "the", "number", "of", "continuous", "losses", ",", "to", "boost", "video", "transmissions", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["On", "the", "other", "hand", ",", "EO", "data", "are", "still", "highly", "relevant", "as", "a", "source", "of", "qualitative", "information", "for", "early", "warning", "by", ",", "for", "instance", ",", "identifying", "strong", "anomalies", "in", "vegetation", "index", "or", "rainfall", "pattern", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "earth observation"}, {"tokens": ["In", "this", "experiment", ",", "we", "wish", "to", "examine", "if", "training", "networks", "and", "jointly", ",", "improves", "the", "performance", "on", "real", "LR", "images", "from", "Widerface", "dataset.(see", "Section", "for", "datasets", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["We", "compare", "the", "performance", "of", "the", "MGM", "GAN", "to", "both", "a", "traditional", "GAN", "and", "a", "cycle", "GAN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["As", "evaluation", "metrics", ",", "we", "use", "the", "three", "accuracies", "(", "ADR", "-", "RES", ",", "ADR", "and", "RES", ")", "used", "in", "ARS", "(", "Sec", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "addressee and response selection"}, {"tokens": ["Therefore", ",", "although", "features", "extracted", "by", "latter", "layers", "of", "the", "DCNN", "are", "consist", "of", "a", "large", "number", "of", "zero", "activations", ",", "highly", "discriminative", "features", "are", "still", "included", ",", "which", "contribute", "most", "to", "the", "final", "tracking", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Therefore", ",", "an", "adversary", "can", "deploy", "advanced", "FA", "tools", "to", "reverse", "engineer", "the", "memory", "and", "readout", "its", "contents", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["3", ",", "provides", "optimum", "SC", "for", "the", "proposed", "CNOMA", "-", "OAM", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["This", "is", "because", ",", "in", "RA", "the", "available", "network", "bandwidth", "is", "constant", "between", "worker", "nodes", "whereas", "for", "the", "PS", "or", "P2P", "systems", ",", "the", "bandwidth", "is", "a", "shared", "resources", "among", "all", "worker", "nodes", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["E", "means", "MAD", "extension", ";", "B", "means", "boosting", "and", "EB", "denotes", "the", "combination", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["t", "]", "[", "The", "LOF", "caption", "]", "Token", "-", "level", "POS", "tagging", "accuracy", "for", "Simple", "Projection", ",", "SRNN", "using", "MultiVec", "bilingual", "word", "embeddings", "as", "input", ",", "RNN", ",", "Projection+RNN", "and", "methods", "of", "Das", "Petrov", "(", "2011", ")", ",", "Duong", "et", "al", "(", "2013", ")", "and", "Gouws", "Sogaard", "(", "2015", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "accuracy", "scores", "for", "the", "best", "LR", "models", "are", "75.58", "forOCR", ",", "62.67", "for", "CAL", "and", "90.62", "for", "BMN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["In", "particular", "for", "all", ",", "SL", "SL", "and", "SP", "SP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0], "long_form": "strictly piecewise"}, {"tokens": ["The", "dataset", "(", "LR", "images", "HR", "labels", ")", "is", "randomly", "partitioned", "into", "three", "subsets", ":", "training", "(", ")", ",", "validation", "(", ")", ",", "and", "testing", "(", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["As", "Figure", "fig", ":", "mnistb", "shows", ",", "this", "allows", "the", "MGM", "GAN", "to", "preserve", "the", "identity", "of", "the", "digit", "through", "domain", "transfer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["the", "first", "environment", "participants", "were", "exposed", "to", "(", "SDD", "or", "TDW", "in", "brackets", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Secondly", ",", "we", "compare", "the", "performance", "of", "QA", "models", "with", "and", "without", "the", "proposed", "pingyin", "sequence", "embedding", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Then", ",", "the", "optimal", "EB", "design", "is", "formulated", "asThe", "optimal", "solution", "to", "(", ")", "is", "shown", "to", "be", ",", "where", "corresponds", "to", "the", "eigenvector", "associated", "with", "the", "largest", "eigenvalue", "of", ",", "denoted", "by", ",", "and", "the", "maximum", "harvested", "energy", "is", "thus", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy beam"}, {"tokens": ["The", "expression", "for", "for", "CD", "is", "derived", "in", "and", "also", "in", "the", "Appendix", "in", ":", "Let", "denote", "the", "number", "of", "visits", "to", "state", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["The", "cooperative", "DF", "relay", "transmission", "from", "to", "and", "additional", "symbol", "transmission", "directly", "by", "different", "OAM", "modes", "from", "BS", "are", "performed", "on", "the", "remaining", "duration", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Clustering", "results", "of", "the", "three", "path", "primitives", "based", "on", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["For", "classification", ",", "GBM", "was", "best", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["To", "further", "verify", "the", "effectiveness", "of", "our", "attention", "focusing", "mechanism", ",", "we", "compare", "FAN", "with", "AN", "in", "the", "context", "that", "both", "are", "based", "on", "the", "image", "-", "encoder", "released", "by", "Shi", "shi2016robust", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["Third", ",", "we", "divide", "the", "current", "value", "by", "an", "ideal", "cumulative", "entropy", "and", "generate", "the", "final", "metric", "score", "of", "NCE", ",", "which", "is", "in", "range", "between", "0", "and", "1", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["The", "RB", "protocol", "again", "can", "not", "find", "a", "good", "solution", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random beamforming"}, {"tokens": ["Due", "to", "mobility", ",", "an", "MS", "can", "have", "good", "channel", "to", "the", "BS", "in", "one", "slot", "and", "can", "has", "poor", "channel", "to", "the", "BS", "in", "another", "slot", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Figure", "fig_semantic_compare", "shows", "the", "averaged", "clustering", "results", "in", "terms", "of", "ACC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "accuracy"}, {"tokens": ["NP", "gul", "'", "flower", ",", "rose'PIr"], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["If", "we", "analyze", "the", "ER", "results", ",", "we", "can", "see", "that", "the", "performance", "is", "similar", "to", "the", "single", "-", "output", "GP", "regression", "case", ",", "where", "the", "precision", "remains", "constant", "in", "areas", "of", "the", "input", "space", "where", "training", "data", "is", "never", "revisited", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Finally", ",", "non", "-", "linear", "extensions", "of", "this", "work", ",", "particularly", "in", "the", "design", "and", "analysis", "of", "provably", "convergent", "DMD", "-", "based", "unmixing", "on", "non", "-", "linearly", "mixed", "ergodic", "time", "series", "are", "of", "interest", "and", "would", "complement", "related", "works", "on", "non", "-", "linear", "ICA", "and", "non", "-", "linear", "DMD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["Features", "with", "ICC", "were", "considered", "robust", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["Participants", "'", "responses", "about", "the", "adaptability", "of", "the", "SAR", "system", ",", "seen", "in", "Figure", ",", "correlate", "with", "the", "challenges", "encountered", "in", "adapting", "to", "the", "individual", "needs", "of", "each", "participant", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Mixed", "Decoding", "(", "MD", ")"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "mixed decoding"}, {"tokens": ["As", "can", "be", "seen", ",", "our", "CSG", "c", "-", "measure", "is", "heavily", "correlated", "to", "the", "complexity", "of", "the", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["System", "model", "of", "secure", "SM", "with", "TAS", "schemeReferring", "to", "the", "secure", "SM", "system", "model", "in", ",", "the", "transmit", "baseband", "signal", "with", "the", "aid", "of", "AN", "can", "be", "expressed", "aswhere"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["(", "e)-(h", ")", ":", "Lower", "neuron", "activation", "in", ";", "Higher", "neuron", "activation", "in", ";", "naive", "convolution", "output", "from", "and", ";", "attention", "map", "using", "MAD", "unit", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "map attention decision"}, {"tokens": ["As", "an", "alternative", "method", ",", "propose", "a", "visual", "method", "of", "QA", "using", "an", "iterative", "diagrammatic", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["For", "the", "latter", "we", "utilise", "sparse", "GP", "approximations", "to", "tackle", "the", "infinite", "dimensionalityof", "the", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "this", "scenario", ",", "we", "used", "CRF", "layer", "for", "the", "primary", "task", "(", "SRL", ")", "and", "softmax", "layer", "for", "the", "auxiliary", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["The", "prototype", "introduces", "a", "light", "-", "field", "-", "based", "approach", "to", "near", "-", "eye", "displays", "and", "can", "be", "seen", "as", "a", "next", "generation", "wearable", "display", "technology", "for", "AR", "as", "existing", "hardware", "ca", "n't", "provide", "accurate", "acommodation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Moreover", ",", "we", "present", "a", "novel", "loss", "function", "that", "is", "composed", "of", "a", "Kullback", "-", "Leibler", "divergence", "term", "with", "SAD", "similarity", "and", "additional", "penalty", "terms", "to", "improve", "the", "sparsity", "of", "the", "estimates", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["shows", "the", "sum", "-", "rate", "versus", "the", "bandwidth", "of", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Images", "generated", "by", "the", "capture", "model", "can", "be", "subsequently", "processed", "by", "any", "ISP", "configuration", "to", "generate", "an", "RGB", "image", "dataset", "(", "Figure", "fig", ":", "tiger", "-", "rgb", ")", "to", "use", "for", "training", "CNNs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["example_1_roc", "shows", "the", "ROC", "curves", "from", "using", "OGS", ",", "POGS", "and", "wavelet", "-", "based", "method", "respectively", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Experiments", "on", "Low", "Resolution", "imagesWe", "choose", "to", "perform", "direct", "comparison", "on", "a", "real", "LR", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["the", "users", "'", "CSI", "are", "utilized", "to", "select", "the", "near", "and", "far", "users", "with", "the", "shortest", "distance", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["This", "is", "because", ",", "in", "the", "NNNF", "strategy", ",", "the", "distance", "of", "the", "nearest", "user", "to", "the", "BS", ",", "i.e.", ",", ",", "approaches", "to", "zero", "and", "hence", "the", "term", "in", "is", "small", "which", "makes", "the", "difference", "of", "the", "bounds", "and", "the", "exact", "values", "insignificant", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Our", "experiments", "indicate", "that", "such", "additive", "structure", "is", "present", "in", "real", "datasets", ",", "allowing", "our", "model", "to", "perform", "better", "than", "standard", "GP", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Thus", ",", "if", "other", "strategies", "are", "correct", "TI", "neither", "generates", "false", "positive", "nor", "it", "generates", "false", "negative", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "threshold initialization"}, {"tokens": ["Our", "protocol", "when", "used", "to", "produce", "-out", "-", "of-", "OTs", "outperforms", "all", "the", "known", "actively", "secure", "OT", "extensions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["However", ",", "if", "the", "capacity", "reduces", "significantly", "so", "that", "the", "battery", "never", "experiences", "CC", "phase", ",", "our", "approach", "would", "underestimate", "the", "capacity", "loss", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant current"}, {"tokens": ["Therefore", ",", "in", "Chapter", "5", "we", "examine", "the", "current", "state", "of", "the", "art", "for", "question", "answering", "over", "knowledge", "graphs", "and", "contribute", "an", "original", "approach", "that", "alleviates", "the", "major", "bottle", "-", "neck", "of", "the", "existing", "systems", "for", "complex", "QA", ",", "namely", "query", "generation", "used", "for", "answer", "retrieval", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "FA", "tools", "required", "for", "such", "analysis", "(", "laser", "microscope", ")", "can", "be", "rented", "for", "a", "few", "hundred", "dollars", "per", "hours", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["vanilla.eps0.01[Simulated", "Raw]fig", ":", "tiger", "-", "rawtiger", "-", "raw.eps0.01[Simulated", "RGB]fig", ":", "tiger", "-", "rgbtiger", "-", "rgb.epsExample", "ImageNet", "sample", ":", "(", "a", ")", "original", "(", "RGB", ")", ",", "(", "b", ")", "processed", "by", "capture", "model", "to", "simulate", "raw", "HDR", "sensor", "data", "(", "colorized", ")", ",", "and", "(", "c", ")", "output", "of", "ISP", "software", "model", "operating", "on", "simulated", "raw", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["We", "also", "find", "that", "PNN", "*", ",", "which", "is", "the", "combination", "of", "IPNN", "and", "OPNN", ",", "has", "no", "obvious", "advantages", "over", "IPNN", "and", "OPNN", "on", "AUC", "performance", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Comparisons", "for", "systematic", "Exact", "-", "MBR", "codes*Comparisons", "for", "Exact", "-", "MBR", "codesover", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Some", "developers", "prefer", "to", "disable", "ECC", "to", "get", "more", "bandwidth", "from", "these", "devices", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["Second", ",", "the", "s", "-", "RNNs", "out", "-", "performed", "the", "LSTMs", "on", "the", "most", "complex", "SP", "experiment", "and", "performed", "comparably", "to", "them", "on", "the", "others", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Taguchi", "'s", "method", "is", "one", "of", "the", "DOE", "techniques", "that", "was", "developed", "in", "1979", "to", "improve", "the", "quality", "of", "goods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "design of experiment"}, {"tokens": ["l", "l", "l", "l", "l", "l", "6cHeadings", "of", "Sections", "Abstract", "&", "Aim(s", ")", "&", "Approach", "&", "Background", "&", "Conclusion(s", ")", "&", "Design", "Discussion", "&", "Finding(s", ")", "&", "Hypothesis", "&", "Introduction", "&", "Limitation(s", ")", "&", "Location", "Material(s", ")", "&", "Measure(s", ")", "&", "Measurement(s", ")", "&", "Method(s", ")", "&", "Methodology", "&", "Objective(s", ")", "Patient(s", ")", "&", "Population", "&", "Procedure(s", ")", "&", "Process", "&", "Purpose(s", ")", "&", "Rationale(s", ")", "Result(s", ")", "&", "Setting(s", ")", "&", "Subject(s", ")", "&", "Theoretical", "&", "&", "3cImplication(s", ")", "for", "health", "and", "nursing", "policy", "&", "&", "&", "An", "Example", "of", "Document", "Structure", "in", "the", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Modifications", "to", "BP", "Because", "of", "the", "relationship", "between", "alignment", "and", "performance", ",", "we", "investigated", "models", "that", "were", "trained", "with", "BP", "but", "with", "modifications", "that", "mimic", "features", "of", "FA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "feedback alignment"}, {"tokens": ["Penney", "penney_chilling_2016", "also", "starts", "with", "an", "ITS", "model", "to", "understand", "the", "impact", "of", "the", "Edward", "Snowden", "revelations", "on", "page", "views", "to", "\"", "terrorism", "-", "related", "\"", "Wikipedia", "articles", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interrupted time series"}, {"tokens": ["The", "real", "-", "world", "long", "-", "term", "SAR", "intervention", "for", "early", "childhood", "math", "learning", "used", "a", "meta", "-", "controller", "that", "sequentially", "executed", "each", "controller", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["htb]The", "comparison", "of", "running", "time(S", ")", "for", "different", "MDC", "methods", "when", "testing", "on", "an", "image", "with", "a", "size", "of", "512x512", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["There", "are", "41", ",", "8", ",", "6", ",", "16", "and", "17", "papers", "under", "SOELD", ",", "DELD", ",", "ELDNCS", ",", "MOELD", ",", "and", "ELDMG", "respectively", "whereas", "30", "publications", "are", "under", "general", "discussion", "about", "ELD", "problems", "and", "PSO", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power system operations"}, {"tokens": ["To", "tackle", "this", "issue", ",", "the", "MINT", "-", "FEC", "dynamically", "adapts", "itself", "by", "using", "fuzzy", "logic", ",", "to", "add", "a", "precise", "amount", "of", "redundancy", "to", "only", "the", "most", "QoE", "-", "sensitive", "data", ",", "while", "ensuring", "high", "-", "quality", "video", "and", "downsizing", "the", "usage", "of", "scarce", "wireless", "resources", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Tobias", "Hollerer", "develop", "a", "mobile", "AR", "system", "that", "allows", "the", "user", "to", "explore", "hypermedia", "news", "stories", "that", "are", "located", "at", "the", "places", "to", "which", "they", "refer", "and", "to", "receive", "a", "guided", "campus", "tour", "that", "overlays", "models", "of", "earlier", "buildings", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Finally", ",", "it", "is", "worth", "mentioning", "that", "integrating", "low", "level", "(", "POS", ")", "information", "lately", "(", "last", "hidden", "layer", ")", "seems", "to", "be", "the", "best", "option", "in", "our", "case", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "PatientEG", "schema", "based", "on", "SEM", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0], "long_form": "simple event model"}, {"tokens": ["However", ",", "adopting", "BC", "to", "IoT", "is", "not", "straightforward", "in", "most", "cases", ",", "due", "to", "overheads", "and", "delays", "caused", "by", "BC", "operations", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "blockchain"}, {"tokens": ["utilized", "Elliptic", "Curve", "Cryptography", "(", "ECC", ")", "to", "propose", "an", "identity", "-", "based", "key", "establishment", "protocol", "for", "SMIs", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["BPD", ":", "Baseband", "phase", "difference", "is", "another", "phase", "feature", "derived", "from", "IF", "and", "baseband", "STFT", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "baseband phase difference"}, {"tokens": ["By", "contrast", ",", "both", "the", "EQPO", "algorithm", "and", "the", "CDP", "method", "exhibit", "a", "complexity", "order", "similar", "to", "polynomial", "scaling", ",", "since", "its", "has", "been", "demonstrated", "in", "that", "the", "total", "number", "of", "Pareto", "-", "optimal", "routes", "increases", "at", "a", "significantly", "lower", "rate", "than", "that", "of", "the", "total", "number", "of", "routes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classical dynamic programming"}, {"tokens": ["Besides", ",", "PS", "is", "the", "only", "mechanism", "that", "simultaneously", "satisfies", ",", ",", "and", "bounded", "invariance", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["extended", "the", "microcanonical", "SBM", "by", "incorporating", "attributes", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["We", "showed", "that", "an", "effective", "initialization", "for", "RV", "based", "on", "affine", "transformation", "of", "atoms", "is", "more", "accurate", "and", "robust", "to", "noise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random voting"}, {"tokens": ["eqnarrayIn", "the", "NP", "framework", ",", "in", "order", "to", "learn", "such", "a", "distribution", "over", "random", "functions", "rather", "than", "a", "single", "function", "we", "need", "to", "create", "a", "context", "set", "of", "datasets", "each", "of", "which", "containing", "input", "-", "output", "context", "pairs", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["In", "particular", ",", "GPA", "achieves", "the", "performance", "gains", "of", "up", "to", "7.76", "and", "8.74", "on", "link", "prediction", "and", "node", "classification", "respectively", ",", "and", "reduces", "the", "running", "time", "by", "at", "least", "20", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["The", "decoding", "steps", "of", "the", "Reed", "-", "Solomon", "code", "involve", "the", "computation", "of", "the", "sub", "-", "matrix", "of", "the", "GM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "generator matrix"}, {"tokens": ["Data", "can", "be", "accessed", "from", "its", "primary", "or", "secondary", "areas", ",", "similarly", "to", "ID", "and", "GRD", "organizations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "group rotate declustering"}, {"tokens": ["In", "the", "proposed", "method", ",", "each", "individual", "chromosome", "is", "introduced", "into", "individual", "DBN", "as", "misclassification", "costs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["With", "features", "specific", "to", "natural", "images", "in", "higher", "layers", "of", "ImageNet", "pre", "-", "trained", "models", "and", "specific", "to", "reconstruction", "tasks", "of", "unlabeled", "SAR", "pre", "-", "trained", "models", ",", "we", "are", "going", "to", "explore", "the", "transitive", "transfer", "method", "with", "multi", "-", "source", "tasks", "related", "to", "SAR", "targets", "to", "enhance", "the", "generality", "of", "features", "in", "deep", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["presented", "an", "new", "approach", "aiming", "for", "AR", "browsers", "that", "also", "supported", "creation", "of", "digital", "information", "in", "-", "situ", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["[", "-", "]", "LE", "as", "a", "conventional", "pixel", "-", "based", "label", "equivalence", "solution", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "label equivalence"}, {"tokens": ["This", "uncertainty", "is", "reflected", "in", "the", "95", "confidence", "interval", "of", "each", "ICC", "value", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["Conversely", ",", "the", "convex", "IB", "Lagrangian", "allows", "finding", "the", "specific", "point", "that", "is", "obtained", "by", "a", "given", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["We", "can", "observe", "that", "the", "Color", "-", "based", "method", "on", "Cross", "-", "FaceResoultion", "-", "LF", "-", "Test", "is", "the", "only", "experiment", "within", "this", "protocol", "that", "seems", "to", "achieve", "good", "generalization", "capabilities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "large faces"}, {"tokens": ["(", "1", ")", "without", "any", "FEC", "mechanism", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["VLAD", "is", "another", "feature", "encoding", "and", "pooling", "method", "used", "to", "encode", "a", "set", "of", "local", "feature", "descriptors", "using", "a", "dictionary", "built", "using", "k", "-", "means", "clustering", ",", "unlike", "the", "FV", ",", "that", "used", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["In", "the", "literature", ",", "some", "studies", "deployed", "PSO", "as", "an", "effective", "tool", "for", "solving", "large", "-", "scale", "optimization", "problems", ",", "including", "optimal", "allocation", "of", "electric", "vehicle", "charging", "station", "and", "distributed", "renewable", "resource", "in", "power", "distribution", "networks", ",", "designing", "power", "system", "stabilizers", ",", "distribution", "state", "estimation", ",", "and", "reactive", "power", "control", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Therefore", ",", "proposed", "a", "nested", "SBM", ",", "also", "adopted", "by", ",", "which", "can", "be", "described", "using", "the", "aforementioned", "level", "-", "one", "graph", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["multi", "-", "objective", "net", "-", "works", "archi", "-", "tecture", "C", "-", "MAPSS", "different", "classification", "hyper", "-", "parameters", "pre", "-", "process", "pre", "-", "processing", "ECS", "-", "DBN", "DBNMSA", "Multi", "-", "State", "Diagnosis", "and", "Prognosis", "Framework", "with", "Feature", "Learning", "for", "Tool", "Condition", "MonitoringChong", "Zhang", ",", "Student", "Member", ",", "IEEE", ",", "Geok", "Soon", "Hong", ",", "Jun", "-", "Hong", "Zhou", ",", "Kay", "Chen", "Tan", ",", "Fellow", ",", "IEEE", ",", "Haizhou", "Li", ",", "Fellow", ",", "IEEE", ",", "Huan", "Xu", ",", "Jihoon", "Hong", ",", "Member", ",", "IEEE", ",", "and", "Hian", "-", "Leng", "ChanC."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "authors", "then", "utilize", "this", "model", "to", "demonstrate", "that", "URLLC", "reliability", "and", "latency", "requirements", "in", "its", "basic", "form", "can", "be", "met", "in", "LTE", "and", "5", "G", "NR", "systems", ",", "albeit", "at", "the", "cost", "of", "spectral", "efficiency", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["We", "used", "NDCG", "as", "the", "primary", "metric", "to", "measure", "relevance", ",", "and", "NCE", "as", "the", "secondary", "metric", "to", "measure", "diversity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["However", ",", "as", "in", "we", "assume", "that", "there", "is", "no", "direct", "link", "between", "the", "BS", "and", "the", "far", "user", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "wireless", "channel", "between", "each", "node", "and", "the", "BS", "is", "typically", "influenced", "by", "a", "variety", "of", "environmental", "factors", "and", "the", "transmission", "noise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["It", "is", "not", "yet", "fully", "disclosed", "whether", "disabling", "ECC", "(", "which", "is", "a", "hardware", "feature", "and", "requires", "reboot", "after", "modifications", ")", "has", "any", "direct", "impact", "besides", "available", "memory", "bandwidth", "(", "such", "as", "available", "registers", ",", "etc", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["We", "confirm", "that", "the", "parameter", "combinations", "found", "by", "the", "ANN", "approach", "are", "robust", "by", "repeating", "the", "fitting", "procedure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "QA", "model", "learns", "to", "maximize", "the", "objective", "by", "updating", "the", "parameters", "of", "private", "encoder", "which", "works", "adversarially", "towards", "the", "discriminator", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["app17", "Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs", "where", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["and", "Tab", ",", "which", "show", "that", "FAN", "still", "significantly", "outperforms", "AN", "in", "terms", "of", "accuracy", "and", "total", "NED", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["This", "is", "improved", "in", "where", "the", "checks", "are", "done", "per", "seed", "OT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "oblivious transfer"}, {"tokens": ["However", ",", "it", "is", "known", "that", "the", "IB", "Lagrangian", "can", "not", "be", "used", "to", "achieve", "varying", "levels", "of", "performance", "in", "deterministic", "scenarios", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "Figure", "6", ",", "the", "SC", "w.r.t", "is", "plotted", "for", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "first", "one", "is", "the", "cross", "-", "layer", "adaptive", "video", "-", "aware", "FEC", "mechanism", "(", "uavFEC", ")", ",", "in", "Section", "sec", ":", "uavFEC", ",", "and", "the", "second", "is", "the", "Motion", "INTensity", "and", "video", "-", "aware", "mechanism", "(", "MINT", "-", "FEC", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "forward error correction"}, {"tokens": ["[", ",", "STA", "Mbps", ",", "AP", "Mbps]Non", "-", "saturated", "throughput", "Average", "delayIt", "is", "also", "observed", "that", "the", "downlink", "throughput", ",", "as", "the", "network", "becomes", "saturated", ",", "is", "much", "lower", "than", "the", "uplink", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Submitting", "(", "17)and", "(", "18", ")", "into", "(", "8)", ",", "the", "average", "achievable", "rate", "of", "the", "SBS", "cooperation", "strategy", "with", "the", "received", "signal", "power", "constraint", "is", "expressed", "aswhere", "is", "the", "PDF", "of", "the", "path", "loss", "exponent", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["However", ",", "unlike", "VAE", "-", "GAN", "that", "uses", "different", "networks", "for", "discriminator", "and", "encoder", ",", "IAN", "combines", "the", "discriminator", "and", "encoder", "into", "a", "single", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "introspective adversarial network"}, {"tokens": ["The", "running", "sum", "(", "RS", ")", "is", "written", "to", "help", "illustrate", "the", "mechanics", "of", "the", "data", "set", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "running sum"}, {"tokens": ["NB", "is", "a", "generative", "model", ",", "whereas", "RF", "is", "an", "ensemble", "method", "using", "decision", "trees", ",", "and", "SVM", "and", "LR", "are", "discriminative", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["document", "QA", "(", "SQuAD)data_squad", ",", "knowledge", "-", "base", "QA", "(", "WikiMovies)data_kb_wikimovies", "and", "visual", "QA", "(", "VQA)VQA", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["While", "the", "high", "entropy", "of", "TI", "1", "(", ")", "means", "that", "the", "involved", "individuals", "randomly", "select", "their", "interactive", "locations", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["Their", "experimental", "results", "showed", "that", "the", "PSO", "algorithm", "can", "significantly", "improve", "utilization", "rate", "of", "the", "underlying", "network", "bandwidth", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "best", "AP", "here", "is", "44.3", "which", "is", "smaller", "than", "the", "best", "so", "far", "on", "COCO", "(", "46.9", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["VSM", "incurs", "fewer", "seeks", "than", "PCM", "in", "reading", "successive", "tracks", ",", "since", "the", "probability", "that", "there", "are", "interim", "arrivals", "and", "the", "R", "/", "W", "head", "moves", "after", "reading", "the", "current", "track", "is", "lower", "for", "VSM", "than", "PCM", ":", "and", ",", "where", "is", "track", "rotation", "time", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vacationing server model"}, {"tokens": ["The", "narrative", "would", "suggest", "that", "the", "s", "-", "RNNs", "and", "LSTMs", "may", "perform", "comparably", "on", "the", "SL", "experiments", ",", "but", "that", "s", "-", "RNN", "performance", "would", "be", "worse", "than", "LSTM", "performance", "on", "the", "SP", "experiments", "due", "to", "the", "presence", "of", "long", "-", "term", "dependencies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["The", "Linear", "Structured", "FrameworkThe", "first", "unsupervised", "learning", "framework", "based", "on", "the", "LB", "divergence", "is", "based", "on", "a", "linear", "structure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["We", "also", "compare", "between", "the", "performance", "of", "the", "proposed", "joint", "-", "optimization", "approach", "(", "GP", "with", "BPSO", ")", "with", "those", "of", "GP", "with", "BB", ",", "dual", "solution", "with", "BPSO", ",", "and", "dual", "-", "solution", "with", "BB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["As", "for", "-iterative", "improvement", ",", "a", "combination", "of", "suffices", "to", "recognize", "all", "those", "characters", "that", "can", "be", "recognized", "by", "DMD", "EMD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "excessive mapping dissolution"}, {"tokens": ["Once", "the", "dictionary", "is", "created", ",", "the", "FV", "encodes", "the", "gradients", "of", "the", "log", "-", "likelihood", "of", "the", "features", "under", "the", "GMM", ",", "with", "respect", "to", "the", "GMM", "parameters", "and", "compare", "descriptors", "to", "visual", "words", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Using", "a", "Joint", "GMM", "Method[J].", "IEEE", "Transactions", "on", "Image", "Processing", ",", "2016", ",", "25(9", ")", ":"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["We", "highlight", "the", "following", "a", "few", "observations", ":", "1", ")", "NMSRVI", "(", "1", ")", "achieves", "the", "best", "performances", ",", "and", "outperforms", "ANTs", "in", "terms", "of", "both", "MSE", "and", "mean", "CC", "on", "both", "tasks", ",", "likely", "due", "to", "the", "representation", "and", "optimization", "efficiency", "of", "deep", "neural", "nets", ";", "2", ")", "NMSRV", "yields", "consistently", "better", "results", "than", "VoxelMorph", ",", "demonstrating", "the", "efficacy", "of", "self", "-", "supervised", "optimization", "during", "the", "test", "phase", "for", "improving", "velocity", "field", "estimation", "and", "reducing", "the", "estimation", "gap", "between", "training", "and", "testing", ";"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cross - correlation"}, {"tokens": ["Fast", "-", "ARD", "models", "are", "trained", "for", "epochs", "so", "that", "they", "take", "the", "same", "amount", "of", "time", "as", "natural", "distillation", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["*", "where", "D", "and", "M", "are", "the", "set", "of", "pixels", "representing", "the", "particular", "class", "in", "the", "DCNN", "and", "manual", "segmentation", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Consequently", ",", "for", "any", "SL", "(", "SP", ")", "stringset", ",", "the", "smallest", "value", "for", "which", "it", "is", "SL", "(", "SP", ")", "is", "another", "measure", "of", "its", "complexity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "exhibits", "far", "better", "performance", "than", "other", "schemes", "in", "case", "of", "CCU", "capacity", "because", "of", "additional", "symbol", "transmission", "from", "BS", "to", "CCU", "by", "an", "OAM", "mode", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["However", ",", "our", "model", "differs", "from", "typical", "implementations", "of", "HG", "and", "OT", "in", "that", "the", "optimal", "structure", "does", "not", ",", "in", "general", ",", "decompose", "into", "a", "unique", "combination", "of", "the", "input", "constituents", "(", "entity", "and", "relation", "embeddings", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimality theory"}, {"tokens": ["Area", "Under", "the", "ROC", "Curve", "(", "AUC", ")", "is", "a", "useful", "metric", "for", "classifier", "performance", "as", "it", "is", "independent", "of", "the", "decision", "criterion", "selected", "and", "prior", "probabilities", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Variational", "Inference", "for", "GP", "-", "SSM", "with", "HSMCHere"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["(", "ICA", ")", "methods", "for", "this", "problem", "have", "similar", "statements", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["Otheradditional", "delay", "to", "detect", "the", "Wi", "-", "Fi", "AP", "due", "to", "the", "NI", "hardware", "ConclusionWe", "propose", "a", "ML", "based", "algorithm", "that", "can", "be", "used", "by", "a", "LTE", "-", "U", "BS", "to", "determine", "presence", "of", "one", "or", "two", "Wi", "-", "Fi", "APs", "on", "the", "channel", "so", "that", "the", "duty", "cycle", "can", "be", "adjusted", "accordingly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["From", "a", "local", "perspective", ",", "how", "do", "CF", "recommendation", "model", "work", "differently", "under", "user", "-", "item", "attacks", "by", "looking", "to", "user", "-", "classes", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Without", "using", "U", "/", "V", ",", "sinc2-h", "-", "NSF", "failed", "to", "predict", "MVF", "for", "some", "voiced", "regions", ",", "for", "example", ",", "from", "the", "400-th", "to", "500-th", "frames", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["The", "KITTI", "evaluation", "server", "computes", "the", "AP", "at", "a", "IoU", "across", "three", "difficulty", "levels", ":", "easy", ",", "moderate", ",", "and", "hard", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["If", "the", "English", "intent", "model", "is", "not", "confident", ",", "an", "English", "IA", "labels", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "intent analyst"}, {"tokens": ["Moreover", ",", "we", "show", "that", "almost", "-", "sure", "Buchi", "objectives(but", "not", "almost", "-", "sure", "co", "-", "Buchi", "objectives", ")", "are", "strongly", "MD", "determined", ",", "provided", "that", "the", "game", "is", "finitely", "branching", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["BC", "technology", "has", "the", "potential", "to", "overcome", "the", "scalability", "and", "security", "issues", "associated", "with", "IoT", "through", "decentralisation", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["Following", "their", "success", "with", "basic", "lexical", "features", ",", "AA", "as", "a", "subfield", "of", "research", "was", "dominated", "by", "efforts", "to", "define", "stylometric", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["However", ",", "thisproblem", "will", "be", "addressed", "in", "the", "future", ",", "based", "on", "the", "currentdevelopments", "in", "LTE", "-", "A."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "long term evolution"}, {"tokens": ["This", "research", "provides", "some", "extra", "security", "features", "by", "introducing", "BC", "technology", "in", "IoT", ",", "however", "it", "lacks", "the", "concept", "of", "consensus", "algorithm", "that", "every", "mainstream", "BC", "technology", "must", "have", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["On", "receiving", "an", "RTS", "from", "STA", ",", "the", "AP", "replies", "with", "a", "CTS", "that", "includes", "the", "MPR", "vacancy", "(", "the", "remaining", "space", "for", "parallel", "uplink", "transmissions", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["avg1", "shows", "that", "the", "mean", "function", "of", "the", "prior", "GP", "is", "given", "by", "the", "solution", "to", "the", "noise", "-", "free", "linear", "ODE", "obtained", "by", "removing", "the", "noisy", "term", "of", "the", "SDE"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Finally", ",", "we", "propose", "an", "extrinsic", "evaluation", "with", "the", "aim", "of", "assessing", "the", "end", "utility", "of", "these", "metrics", "in", "selecting", "good", "AQG", "systems", "for", "creating", "training", "data", "for", "QA", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["Augmented", "posterior", "over", "GP", "densityWith", "Eq", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Since", "for", "each", ",", "is", "finite", ",", "it", "is", "also", "possible", "to", "define", "SP", "stringsets", "with", "grammars", "of", "forbidden", "-subsequences", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Example", "of", "the", "output", "that", "is", "generated", "by", "our", "proposed", "TS", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "tree structures"}, {"tokens": ["After", "capturing", "all", "the", "LR", "images", ",", "the", "proposed", "algorithm", "was", "applied", "to", "realize", "fine", "correction", "in", "the", "image", "reconstruction", "process", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["By", "increasing", "the", "delay", "threshold", ",", "contents", "are", "likely", "to", "be", "stored", "at", "CC", "to", "benefit", "from", "the", "efficient", "computation", "capacity", "of", "DUs", "at", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "central cloud"}, {"tokens": ["Therefore", "the", "best", "improvements", "in", "the", "ACC", "and", "RMSE", "are", "slightly", "over", "60", "of", "the", "difference", "between", "the", "maximum", "possible", "skill", "and", "that", "of", "the", "No", "-", "ANN", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "anomaly correlation coefficient"}, {"tokens": ["Based", "on", "sys1eq5_1", "and", "sys1eq5_2", ",", "the", "completion", "time", "of", "user", "will", "be:-.5emLet", "be", "the", "completion", "time", "for", "training", "the", "entire", "FL", "algorithm", ",", "which", "must", "satisfy:-.5emAccording", "to", "sys1energy0", "and", "sys1time0", ",", "there", "is", "a", "tradeoff", "between", "completion", "time", "and", "total", "energy", "consumption", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["This", "section", "presents", "the", "verification", "of", "the", "accuracy", "of", "the", "derived", "DE", "expressions", "(", "analytical", "results", ")", "by", "means", "of", "comparison", "with", "the", "Monte", "Carlo", "simulation", "results", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deterministic equivalent"}, {"tokens": ["This", "is", "because", "FDMA", "enables", "users", "to", "simultaneously", "transmit", "data", "to", "the", "BS", "and", "the", "transmission", "time", "in", "FDMA", "is", "larger", "than", "that", "in", "TDMA", ",", "which", "results", "in", "energy", "saving", "compared", "to", "TDMA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Box", "plot", "summarizing", "mean", "predicted", "difficulty", "values", "of", "control", "algorithms", "(", "JC", ",", "SC", ",", "CC", "and", "CFB", ")", "in", "needle", "steering", "using", "physiological", "response", "(", "left", ")", "and", "kinematic", "features", "(", "right", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "steering control"}, {"tokens": ["At", "the", "first", "phase", ",", "energy", "harvesting", "is", "performed", "by", "TS", "at", "CCU", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["OT", "ExtensionsThe", "theoretical", "feasibility", "of", "OT", "extension", "was", "proved", "by", "Beaver", "."], "acronym_pos": [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["[", "]", "Three", "captions", "of", "the", "continual", "learning", "process", "of", "our", "single", "-", "output", "GP", "regressor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "present", "an", "effective", "cross", "-", "datacenter", "authentication", "and", "key", "-", "exchange", "scheme", "using", "blockchain", "and", "Elliptic", "curve", "cryptography", "(", "ECC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["In", "subsection", ",", "we", "discuss", "the", "LSTM", "neural", "network", "used", "to", "predict", "the", "short", "-", "term", "future", "server", "workloads", "and", "harvested", "energy", ",", "then", "in", "subsection", ",", "we", "solve", "P1", "by", "using", "LLC", "principles", ",", "GP", "theory", ",", "and", "heuristics", ",", "and", "lastly", ",", "in", "subsection", "we", "put", "forward", "the", "ARCES", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Local", "labeling", "with", "coarse", "-", "to", "-", "fine", "strategyThe", "first", "step", ",", "local", "labeling", "with", "a", "coarse", "-", "to", "-", "fine", "strategy", ",", "consists", "of", "four", "phases", ":", "initialization", ",", "coarse", "labeling", ",", "refinement", ",", "and", "ID", "conversion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "input data"}, {"tokens": ["Thus", ",", "in", "order", "to", "avoid", "the", "non", "-", "linear", "constraints", "from", "the", "IB", "functional", "the", "IB", "Lagrangian", "is", "defined", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Each", "circle", "represents", "a", "message", "(", "RBP", ")", "or", "vertex", "(", "RS", ")", ":", "Green", "indicates", "that", "message", "/", "vertex", "was", "updated", ";", "red", "indicates", "that", "message", "/", "vertex", "has", "been", "pruned", "for", "this", "round", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["In", "our", "case", ",", "each", "component", "of", "the", "obtained", "GMM", "constitutes", "a", "cluster", "that", "captures", "the", "distribution", "of", "valid", "requests", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "above", "effect", "is", "illustrated", "by", ",", "for", "example", ",", "the", "difference", "between", "the", "DC", "-", "SBM", "by", "and", "the", "original", "version", ",", "when", "applied", "to", "a", "real", "-", "world", "network", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Section", "reports", "on", "how", "the", "adaptive", "SAR", "system", "influenced", "cognitive", "skills", "gains", "across", "all", "participants", ",", "as", "measured", "by", "the", "pre", "-", "post", "intervention", "assessments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Experimental", "results", "showed", "that", "our", "model", "is", "robust", "towards", "noise", "perturbations", "which", "demonstrates", "relative", "improvement", "in", "epoch", "-", "wise", "average", "accuracy", "of", "on", "the", "SC", "-", "task", "and", "on", "the", "RS", "-", "task", "compared", "to", "Aboalayon", "et", "al", "..", "AcknowledgmentWe", "would", "like", "to", "thank", "the", "Department", "of", "EEE", "BME", ",", "BUET", "and", "Brain", "Station", "23", "(", "Dhaka", ",", "Bangladesh", ")", "for", "supporting", "this", "research", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random split"}, {"tokens": ["What", "'s", "more", ",", "the", "network", "energy", "efficiency", "of", "fractal", "small", "-", "cell", "networks", "adopting", "the", "SBS", "cooperation", "strategy", "with", "the", "received", "signal", "power", "constraint", "was", "analyzed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["The", "weighted", "combination", "of", "mean", "and", "variance", "is", "the", "conventional", "functional", "form", "in", "MAB", ",", "however", ",", "values", "proposed", "by", "the", "UCB", "algorithms", "as", "well", "as", "the", "GP", "-", "UCB", "algorithm", "can", "not", "directly", "be", "applied", "to", "our", "problem", "according", "to", "challenges", "explained", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Conversely", ",", "the", "UAVs", "using", "a", "FEC", "-", "based", "mechanism", "are", "able", "to", "sustain", "a", "better", "video", "quality", "longer", ",", "and", "it", "is", "only", "noticeable", "after", "500", "m", "for", "case", "2", ",", "and", "after", "700", "m", "for", "cases", "3", "to", "5", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "addition", "to", "these", "results", ",", "we", "also", "listed", "other", "metrics", "(", "label", "-", "based", ")", "of", "CC", "and", "LC", "methods", "which", "are", "reported", "in", "Appendix", "table", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classifier chain"}, {"tokens": ["Strikingly", ",", "distinctly", "increases", "the", "generality", "of", "features", "in", "mid", "and", "high", "layers", "which", "indicates", "although", "the", "distant", "source", "task", "of", "unlabeled", "SAR", "images", "reconstruction", ",", "the", "intermediate", "task", "of", "MSTAR", "classification", "has", "an", "impact", "on", "enhancing", "the", "transferability", "of", "features", "to", "other", "SAR", "target", "recognition", "tasks", ",", "on", "the", "condition", "that", "the", "pre", "-", "trained", "model", "on", "SAR", "images", "reconstruction", "provides", "a", "good", "basis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Similarly", ",", "the", "channel", "fading", "coefficients", "between", "BS", "and", "CEU", "is", "with", "zero", "mean", "and", "variance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["OT", "extension", "literature", "finds", "numerous", "attempts", "to", "achieve", "active", "security", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["is", "the", "bandwidth", "assigned", "to", "UE", ",", "and", "is", "the", "signal", "-", "to", "-", "interference", "-", "plus", "-", "noise", "ratio", "(", "SINR", ")", "at", "UE", "adopting", "SBS", "cooperation", "strategies", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Similar", "uses", "of", "the", "predictive", "formula", "within", "the", "posterior", "distribution", "were", "analyzed", "in", "before", "the", "appearance", "of", "variational", "methods", "in", "the", "GP", "literature", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Similarly", ",", "the", "latent", "vectors", "of", "CTR", "task", "are", "assumed", "to", "be", "generated", "from", "the", "counterparts", "of", "CF", "task", ":", "where", "is", "the", "index", "of", "a", "user", "or", "publisher", "feature", ";", "is", "defined", "similarly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Both", "BERT", "-", "Base", "and", "Large", "fine", "purely", "tuned", "on", "the", "TREC", "-", "QA", "corpus", "can", "surpass", "the", "previous", "state", "of", "the", "art", ",", "probably", "because", "the", "size", "of", "TREC", "-", "QA", "training", "corpus", "is", "larger", "than", "that", "of", "WikiQA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["As", "expected", ",", "for", "both", "RS", "-", "based", "schemes", ",", "improves", "with", "increasing", "and/or", "any", "of", "the", "fading", "parameters", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Shared", "Task", "Corpus", "(", "CMI", "=", "5.73", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "code - mixed index"}, {"tokens": ["Inspired", "by", "the", "squared", "IB", "Lagrangian", ",", ",", "we", "look", "at", "the", "conditions", "a", "function", "of", "requires", "in", "order", "to", "be", "able", "to", "explore", "the", "IB", "curve", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Our", "proposed", "NP", "-", "based", "normative", "modeling", "also", "employs", "the", "variational", "inference", "scheme", ",", "therefore", ",", "its", "computational", "complexity", "remains", "linear", "with", "respect", "to", "the", "number", "of", "samples", "in", "both", "training", "and", "inference"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["DSA", "skill", "shortages", "."], "acronym_pos": [1, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["Computational", "Time", "AnalysisAverage", "computational", "time", "of", "ECS", "-", "DBN", "and", "DBN", "are", "presented", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "practice", ",", "each", "user", "computes", "the", "local", "FL", "problem", ":", "by", "using", "the", "gradient", "method", "with", "a", "given", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["On", "receiving", "applying", "-", "RTSs", "(", "A", "-", "RTSs", ")", "from", "STAs", ",", "the", "AP", "responds", "with", "a", "pilot", "-", "requesting", "CTS", "(", "pR", "-", "CTS", ")", "to", "expect", "pilots", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["MINT", "-", "FEC", "Performance", "Evaluation", "and", "Resultssec", ":"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Without", "the", "importance", "sampling", "and", "manifold", "geometry", "terms", "of", "the", "MGM", "GAN", ",", "some", "of", "these", "cells", "in", "the", "source", "batch", "get", "mapped", "to", "other", "cell", "types", "in", "the", "target", "batch", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["How", "can", "the", "QA", "system", "correct", "an", "error", "?"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["the", "open", "issues", "aforementioned", "this", "section", "describes", "and", "evaluates", "the", "proposed", "cross", "-", "layer", "adaptive", "video", "-", "aware", "FEC", "mechanism", "(", "uavFEC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Therefore", ",", "it", "is", "expected", "that", "the", "classification", "performance", "can", "be", "significantly", "enhanced", "by", "replacing", "OMP", "with", "OLS", "under", "this", "framework", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["predicted", "by", "HMC", "simulations", "with", "different", "lengths", "of", "trajectories", ",", "time", "steps", "and", "integrating", "schemes", "(", "left", ")", "and", "by", "MD", "simulations", "using", "various", "time", "steps", "and", "integrators", "(", "right", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["It", "can", "be", "observed", ",", "in", "both", "HMC", "and", "MD", "cases", ",", "that", "AIA", "leads", "to", "broader", "sampling", "of", "the", "conformational", "space", "no", "matter", "the", "choice", "of", "time", "step", "or", "trajectory", "length", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["To", "this", "end", ",", "we", "first", "train", "a", "deep", "network", "which", "generates", "LR", "images", "from", "HR", "images", "and", "tries", "to", "model", "the", "distribution", "of", "real", "LR", "images", "in", "pixel", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["The", "model", "is", "kept", "relatively", "simple", "so", "that", "the", "comparisons", "against", "previous", "methods", "are", "directly", "comparable", "and", "that", "the", "performance", "comparison", "between", "the", "proposed", "SCP", "loss", "and", "KL", "divergence", "loss", "against", "MSE", "and", "MAE", "is", "controlled", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "squared cosine proximity"}, {"tokens": ["OT", "extension", "protocols", "are", "introduced", "to", "compute", "a", "very", "large", "number", "of", "OTs", "referred", "as", "extended", "OTs", "at", "the", "cost", "of", "a", "small", "number", "of", "OTs", "referred", "as", "seed", "OTs", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["In", "the", "next", "section", ",", "we", "discuss", "the", "distribution", "system", "reliability", "issues", "that", "could", "arise", "from", "Constraint", "Set", "A", "and", "a", "modification", "to", "the", "Con", "-", "TS", "-", "RTP", "algorithm", "to", "ensure", "the", "constraints", "are", "enforced", "on", "all", "days", "(", "i.e.", ",", "Constraint", "Set", "B", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Once", "the", "access", "to", "the", "unlicensedband", "is", "obtained", ",", "the", "fBS", "will", "follow", "the", "standard", "LTE", "air", "interface", "andassign", "radio", "resources", "to", "the", "sDevices", "through", "the", "licensed", "-", "band", "controlchannel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["h", "]", "Comparison", "of", "capillaries", "between", "young", "and", "old", "mice", "with", "WT", "and", "AD", "genotype", "(", "6", "mice", "in", "each", "group", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "wild type"}, {"tokens": ["This", "is", "part", "of", "the", "reason", "why", "BNN", "provides", "a", "better", "uncertainty", "estimation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "bayesian neural networks"}, {"tokens": ["Comparisons", "for", "partial", "downloading", "schemes", "on", "Exact", "-", "MBR", "codesThe", "partial", "downloading", "scheme", "is", "useful", "to", "reduce", "the", "requisite", "throughput", "to", "reconstruct", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Since", "these", "would", "indeed", "be", "PI", "allocations", "(", "as", "they", "are", "not", "provided", "by", "the", "ISP", ")", ",", "they", "are", "likely", "to", "be", "announced", "in", "the", "global", "routing", "table", "as", "separated", "routes", ",", "bloating", "the", "routing", "table", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["The", "total", "number", "of", "documents", "in", "LSC", "is", "1,673,824", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Therefore", ",", "we", "introduce", "the", "so", "-", "called", "glow", "parameter", "of", "the", "PS", "model", "and", "define", "an", "update", "rule", "as", "follows", ",", "Besides", "glow", ",", "the", "agent", "is", "also", "subject", "to", "a", "forgetting", "mechanism", ",", "which", "is", "presented", "by", "the", "parameter", "in", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "projective simulation"}, {"tokens": ["Figure", "shows", "the", "ROC", "curve", "of", "classification", "between", "normal", "and", "mass", "data", ",", "which", "is", "obtained", "by", "varying", "the", "threshold", "on", "the", "probabilities", "by", "classifier", "(", "SVM", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Basic", "block", "diagram", "of", "ACE", "processing", "strategy", "used", "in", "this", "study", "to", "simulate", "the", "CI", "-", "users", "signal", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "advanced combined encoder"}, {"tokens": ["In", "our", "deep", "MDC", "framework", ",", "each", "quantizer", "is", "accompanied", "by", "an", "importance", "-", "indicator", "map", "to", "generate", "the", "diversified", "multiple", "descriptions", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["where", "is", "the", "average", "distance", "between", "the", "ground", "BS", "and", "a", "served", "user", "located", "within", "its", "cell", ",", "is", "the", "carrier", "wavelength", ",", "and", "is", "the", "average", "additional", "loss", "due", "to", "the", "free", "space", "propagation", "loss", "for", "NLoS", "link", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["At", "last", ",", "after", "incorporating", "both", "the", "boosting", "and", "extension", "schemes", ",", "we", "have", "the", "final", "result", "on", "PASCAL", "to", "be", "79.8", "mAP", ";", "such", "an", "improvement", "bears", "from", "the", "zoom", "-", "in", "structure", ",", "the", "auto", "-", "selected", "MAD", "unit", "and", "the", "stronger", "classifier", "from", "boosting", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["Columbia", "'s", "Computer", "Graphics", "and", "User", "Interfaces", "Lab", "does", "an", "outdoor", "demonstration", "of", "their", "mobile", "AR", "restaurant", "guide", "at", "ISAR", "2001", ",", "running", "on", "their", "Touring", "Machine", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["An", "ET", "is", "capable", "of", "charging", "sensor", "nodes", "within", "a", "fixed", "radius", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy transmitters"}, {"tokens": ["SC", "are", "also", "relevant", "for", "more", "complex", "transactions", ",", "e.g.", "a", "farmer", "seeks", "insurance", "cover", "for", "temperature", "fluctuations", "outside", "an", "agreed", "range", "over", "an", "agreed", "time", "period", "Mainelli2017", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "smart contract"}, {"tokens": ["Average", "Precision", "(", "AP", ")", "(", "in", ")", "of", "object", "detection", "with", "different", "number", "of", "candidate", "proposals", "for", "Car", "on", "moderate", "difficulty", "level", "on", "the", "validation", "set", "of", "KITTI", "Object", "Detection", "dataset", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["rmargin=2cmSeismic", "Wave", "Scattering", "Through", "a", "Compressed", "Hybrid", "BEM", "/", "FEM", "Method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "finite element method"}, {"tokens": ["Learned", "weights", "of", "(", "a", ")", "layer", "1", "and", "(", "b", ")", "layer", "2", "in", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["respectively", ",", "we", "have", "the", "continuous", "form", "of", "OT", "divergence", ":", "where", "is", "a", "coupling", ";", "is", "the", "set", "of", "couplings", "that", "consists", "of", "joint", "distributions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["In", "the", "recent", "several", "years", ",", "the", "DOA", "measurement", "error", "is", "exploited", "and", "some", "robust", "beamforming", "methods", "of", "designing", "the", "beamforming", "vector", "of", "confidential", "messages", "and", "projection", "matrix", "of", "AN", "were", "proposed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["By", "using", "this", "approach", ",", "the", "number", "of", "data", "packets", "collected", "by", "the", "BS", "is", "maximised", ",", "meanwhile", ",", "the", "energy", "and", "fairness", "requirements", "are", "both", "achieved", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Section", "discussed", "different", "feature", "selection", "methods", "studied", "and", "applied", "in", "our", "paper", "followed", "by", "the", "results", "obtained", "from", "TS", "-", "RF", ",", "conclusion", "and", "future", "directions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["The", "circumstances", "under", "which", "NP", "sf", "came", "about", "remain", "unclear", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["h]input", "parameters", ":", "-", "number", "of", "elements", "(", "floats", ")", "in", "reduced", "data", "-", "number", "of", "iterations", "-", "mode", "of", "delay", ":", "one", "-", "late", "/", "rand", "-", "late", "-", "maximal", "delay", "of", "the", "process(es", ")", "-", "tested", "algorithm", ",", "one", "of", "ring", ",", "Rabenseifner", ",", "PRR", ",", "SLT", "-", "number", "of", "processes", "-", "process", "i", "d"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pre - reduced ring"}, {"tokens": ["Section", "presents", "a", "brief", "overview", "of", "existing", "literature", "on", "Wi", "-", "Fi", "LTE", "coexistence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "long term evolution"}, {"tokens": ["MMP", "wd", "/wad/", "NP", "bad", "'", "bad'PIr", "*", "uat", "-", "caka-", "MP", "waccag", "NP", "baccah", "'", "child'PIr"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["The", "dynamic", "opacity", "allows", "for", "the", "operator", "to", "use", "the", "image", "data", "undisturbed", "when", "making", "precise", ",", "slow", "motions", "where", "the", "kinematic", "inaccuracies", "would", "be", "apparent", "and", "naturally", "use", "the", "AR", "prediction", "when", "making", "larger", "motions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["In", "RB", "assignment", ",", "the", "channel", "state", "information", "plays", "a", "vital", "role", "and", "this", "information", "is", "acquired", "by", "an", "eNodeB", "from", "its", "connected", "users", "periodically", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resource blocks"}, {"tokens": ["In", "PSO", ",", "a", "swarm", "consists", "of", "N", "particles", ",", "which", "are", "stochastically", "generated", "in", "the", "search", "space", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["It", "presents", "the", "number", "of", "control", "signaling", "message", "exchanges", "between", "the", "network", "nodes", "in", "legacy", "LTE", "RAN", "and", "those", "between", "SRC", "and", "the", "data", "plane", "nodes", "in", "the", "proposed", "architecture", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "cross", "-", "validation", ",", "the", "U", "-", "Net", "reached", "average", "dice", "scores", "of", "(", "VAT", ")", "and", "(", "SAT", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["There", "have", "been", "many", "proposed", "SRL", "techniques", ",", "and", "the", "high", "performing", "models", "are", "mostly", "supervised", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["The", "SBS", "cooperation", "strategy", "with", "the", "distance", "constraint", "is", "configured", "that", "SBSs", "closest", "to", "UE", "cooperatively", "transmit", "the", "same", "data", "to", "UE", ",", "which", "is", "expressed", "aswhere", "denotes", "the", "set", "of", "cooperative", "SBSs", ",", "is", "the", "distance", "between", "and", "UE", ",", "satisfying", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["By", "taking", "into", "account", "previous", "insights", "from", "SRL", ",", "we", "proposed", "new", "composition", "functions", "and", "evaluated", "them", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "statistical relational learning"}, {"tokens": ["-", "We", "performed", "a", "similar", "analysis", "of", "grid", "properties", "for", "AC", "-", "OPF", "cases", "using", "k", "samples", "(", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["To", "improve", "student", "robustness", ",", "we", "introduce", "Adversarially", "Robust", "Distillation", "(", "ARD", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Furthermore", ",", "the", "MAD", "unit", "can", "actively", "attend", "important", "neuron", "activations", "and", "we", "verify", "its", "effectiveness", "via", "the", "last", "experiment", ":", "enhancing", "AR", "to", "76.51", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "average recall"}, {"tokens": ["We", "consider", "that", "a", "DBN", "with", "the", "unsupervised", "feature", "learning", "techniques", "allows", "us", "to", "automatically", "learn", "features", "that", "could", "be", "more", "suitable", "to", "establish", "a", "framework", "with", "better", "feature", "representation", "learning", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Interoperability", "of", "different", "QA", "tools", "and", "components", "is", "required", "to", "enhance", "QA", "process", "which", "is", "still", "missing", "at", "the", "conceptual", "level", "and", "currently", "more", "focused", "on", "implementation", "details", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Most", "existing", "Massive", "MIMO", "techniques", "rely", "on", "the", "availability", "of", "the", "full", "CSI", "of", "all", "users", "at", "the", "BS", ",", "which", "presents", "a", "major", "challenge", "of", "channel", "estimation", "in", "implementing", "Massive", "MIMO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Orbit", "Selection", "for", "Descent", "InitiationFollowing", "the", "choice", "of", "an", "orbital", "descent", "strategy", "(", "no", "direct", "descent", "from", "LTT", ")", ",", "parameters", "of", "the", "descent", "orbit", "were", "studied", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lunar transfer trajectory"}, {"tokens": ["The", "remaining", "frames", "were", "used", "to", "test", "the", "ANN", "as", "described", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Spectrum", "kernel", "as", "part", "of", "SK", "has", "been", "applied", "to", "many", "different", "applications", ",", "including", "text", ",", "DNA", ",", "and", "protein", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "string kernel"}, {"tokens": ["In", "training", ",", "however", ",", "LR", "images", "are", "synthetically", "generated", "from", "clinical", "HR", "data", "using", "the", "MR", "acquisition", "model", "discussed", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["The", "proposed", "optimal", "strategy", "was", "to", "fill", "the", "BS", "'s", "cache", "with", "the", "most", "popular", "files", "and", "then", "cache", "the", "remaining", "files", "of", "higher", "popularity", "in", "the", "mobile", "devices", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "Vector", "Space", "Model", "(", "VSM", ")", "is", "one", "of", "the", "overlap", "based", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vector space model"}, {"tokens": ["We", "made", "use", "of", "a", "constrained", "Thompson", "sampling", "heuristic", ",", "Con", "-", "TS", "-", "RTP", ",", "as", "a", "solution", "to", "the", "exploration", "/", "exploitation", "problem", "of", "an", "aggregator", "passively", "learning", "customers", "'", "price", "sensitivities", "while", "broadcasting", "price", "signals", "that", "influence", "customers", "to", "alter", "their", "demand", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Here", "the", "state", "transition", "is", "assumed", "to", "be", "governed", "by", "a", "nonparametric", "stochastic", "function", "following", "a", "GP", "prior", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["UAV", "efficient", "placement", "and", "the", "convergence", "speed", "of", "the", "PSO", "algorithm", "for", "different", "building", "heights", "is", "shown", "in", "Figure", "11", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["These", "outcomes", "demonstrate", "that", "computational", "personalization", "methods", "can", "be", "successfully", "incorporated", "in", "long", "-", "term", "personalized", "SAR", "deployments", "to", "support", "children", "with", "diverse", "learning", "needs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["In", "that", "way", ",", "we", "intend", "to", "overcome", "the", "conservatism", "exhibited", "by", "state", "-", "of", "-", "the", "-", "art", "structural", "TS", "approaches", ",", "which", "tend", "to", "retain", "the", "input", "rather", "than", "transforming", "it", ",", "and", "expect", "to", "improve", "the", "performance", "of", "a", "wide", "range", "of", "AI", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "target syntactic"}, {"tokens": ["However", ",", "instead", "of", "searching", "for", "a", "new", "path", "when", "the", "current", "one", "is", "blocked", ",", "agents", "in", "FAR", "simply", "wait", "at", "their", "current", "nodes", "until", "they", "can", "reserve", "their", "next", "set", "of", "moves", "in", "a", "reservation", "table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "flow annotation replanning"}, {"tokens": ["For", "example", ",", "the", "drop", "in", "performance", "is", "up", "to", "one", "order", "of", "magnitude", "lower", "with", ",", "i.e.", ",", "2.5", ",", "when", "we", "inject", "20", "of", "noise", "in", "the", "WikiQA", "and", "TREC", "-", "QA", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["paper_MIB_octG_density", "-", "eps", "-", "converted", "-", "to", "paper_MB_octG_density", "-", "eps", "-", "converted", "-", "to", "fig", ":", "orig", "Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs", "where", ",", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["Example", "1", ":", "ROC", "curves", "of", "faults", "detection", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["An", "IT2FS", "with", "trapezoidal", "UMF", ",", "and", "triangular", "LMF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "lower membership function"}, {"tokens": ["SL", "and", "SP", "classes", "encode", "local", "and", "long", "-", "distance", "dependencies", ",", "respectively", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Also", ",", "one", "could", "find", "a", "range", "of", "values", "for", "these", "Lagrangians", "to", "allow", "for", "the", "IB", "curve", "exploration", "and", "define", "a", "bijective", "mapping", "between", "their", "Lagrange", "multipliers", "and", "the", "IB", "curve", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["For", "simplicity", ",", "the", "total", "power", "consumption", "of", "an", "active", "BS", "during", "a", "time", "slot", "can", "be", "approximated", "by", "a", "linear", "model", "as", "follows", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Of", "the", "500", "stocks", "in", "the", "SP", "500", "available", ",", "385", "stocks", "were", "given", "to", "the", "neural", "network", ",", "which", "trained", "and", "tested", "itself", "over", "each", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standards poors"}, {"tokens": ["Because", "the", "task", "is", "extraction", "-", "based", "QA", ",", "the", "ground", "-", "truth", "answer", "must", "exist", "in", "the", "document", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Since", "many", "real", "-", "world", "data", "are", "naturally", "imbalanced", ",", "therefore", ",", "the", "misclassification", "costs", "of", "different", "classes", "are", "usually", "unknown", ",", "ECS", "-", "DBN", "offers", "an", "effective", "solution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["Once", "suitable", "SNs", "are", "selected", ",", "the", "MN", "instructs", "the", "SN", "to", "allocate", "the", "necessary", "resources", "for", "MC", ",", "and", "to", "facilitate", "connection", "establishment", "with", "the", "target", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["We", "train", "theses", "three", "methods", "using", "the", "similar", "hyperparameters", "as", "the", "3D", "CNN", "MTL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "multi - task learning"}, {"tokens": ["While", "the", "major", "advantages", "of", "ANN", "are", "the", "effective", "and", "efficient", "modeling", "of", "complex", "non", "-", "linear", "systems", ",", "one", "downside", "is", "that", ",", "training", "a", "model", "usually", "incurs", "high", "computational", "and", "storage", "costs", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["This", "LAP", "is", "given", "by", "taking", "to", "be", "the", "eigenvalues", "of", "and", "to", "be", "the", "eigenvalues", "of", ",", "with", "the", "cost", "of", "a", "pair", "(", "equivalently", ",", "one", "entry", "of", "the", "cost", "matrix", ")", "given", "by", "and", "are", "both", "real", "symmetric", "matrices", ",", "so", "they", "may", "be", "diagonalized", "as", ",", "where", "the", "are", "rotation", "matrices", ",", "and", "the", "are", "diagonal", "matrices", "with", "the", "eigenvalues", "along", "the", "diagonal", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear assignment problem"}, {"tokens": ["In", "sub", "-", "figure", "(", "b", ")", ",", "with", "the", "FN", "component", ",", "AN", "'s", "attention", "centers", "for", "the", "last", "two", "characters", "are", "rectified", "and", "positioned", "just", "on", "them", ",", "thus", "FAN", "outputs", "the", "correct", "text", "string", "\"", "83KM", "\"", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["For", "example", ",", "we", "plan", "to", "implement", "the", "RS", "strategy", "in", "millimeter", "wave", "systems", "with", "imperfect", "CSIT", "that", "consider", "hybrid", "precoding", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["Therefore", ",", "we", "extend", "the", "formulation", "of", "MAD", "to", ":", "equation^(m", ")", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["3cStrong", "Connectivity", "(", "SC", ")", "Directed", "graph", "&", "Edge", "insertions", "/", "deletions", "&", "Is", "the", "graph", "strongly", "connected", "?"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strongly connected"}, {"tokens": ["To", "quickly", "recover", "error", "on", "the", "decoder", "side", "without", "complicated", "motion", "searching", "for", "MD", "video", "coding", ",", "motion", "vectors", "are", "sampled", "according", "to", "each", "description", "'s", "redundancy", ",", "which", "could", "further", "strengthen", "error", "resilience", "when", "video", "streams", "are", "transmitted", "over", "error", "-", "prone", "wireless", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["AML", "is", "explained", "in", "details", "in", "Section", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["On", "a", "publicly", "available", "clinical", "fMRI", "dataset", ",", "we", "compare", "the", "novelty", "detection", "performance", "of", "multivariate", "normative", "models", "estimated", "by", "the", "proposed", "NP", "approach", "to", "a", "baseline", "multi", "-", "task", "Gaussian", "process", "regression", "approach", "and", "show", "substantial", "improvements", "for", "certain", "diagnostic", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["PSO", "is", "inspired", "from", "social", "\u2013", "psychological", "principles", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Hyper", "-", "ledger", "Fabric", "introduces", "a", "novel", "framework", "in", "BC", "that", "separate", "the", "execution", "phase", "from", "consensus", "and", "implement", "policy", "-", "based", "endorsements", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["[", "Two", "function", "realizations.]AMT2_demo_2_examplef.two_samplesExample", "of", "GP", "model", "with", "nonstationary", "kernel", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "Table", ",", "we", "provide", "our", "CSG", "c", "-", "measure", "with", "the", "test", "error", "rate", "of", "three", "CNN", "models", "as", "well", "as", "their", "Pearson", "correlation", "and", "p", "-", "value", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["We", "then", "transform", "to", "the", "same", "normalized", "space", "the", "polyhedral", "CM", "was", "trained", "on", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "centroid methods"}, {"tokens": ["The", "MAD", "vector", "could", "be", "spatially", "sized", "and", "proportional", "to", "each", "input", "image", "and", "level", "depth", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["Seed", "OT", "Phase", ":", "On", "behalf", "of", ",", "receives", ",", "the", "input", "of", "to", "the", "functionality", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["app8", "Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs", "where", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["These", "can", "be", "roughly", "grouped", "into", "two", "major", "categories", ":", "pixel", "-", "level", "and", "cell", "-", "level", "metric", ",", "where", "NPR", "belongs", "to", "cell", "-", "level", "measure", "and", "the", "others", "are", "pixel", "-", "level", "measures", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized probabilistic rand"}, {"tokens": ["Limited", "SAR", "annotated", "data", "in", "reality", ",", "it", "is", "not", "easy", "to", "find", "a", "source", "task", "which", "is", "both", "similar", "to", "SAR", "targets", "and", "with", "a", "large", "amount", "of", "related", "data", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Other", "important", "parameters", "that", "are", "missing", "in", "the", "AM", "-", "FEC", "protections", "are", "codec", "type", "and", "motion", "complexity", ",", "which", "have", "proved", "to", "be", "efficient", "in", "this", "kind", "of", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "fact", ",", "we", "can", "define", "more", "general", "or", "complicated", "product", "layers", ",", "gaining", "PNN", "better", "capability", "in", "exploration", "of", "feature", "interactions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["An", "Ordinary", "Least", "Square", "(", "OLS", ")", "regression", "test", "is", "used", "to", "investigate", "which", "of", "the", "three", "measures", "most", "accurately", "assesses", "the", "total", "number", "of", "interactions", "(", "i.e.", ",", "the", "total", "count", "of", "likes", "and", "comments", ")", "on", "posts", "based", "on", "the", "sample", "of", "160", "randomly", "sampled", "Facebook", "pages", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ordinary least square"}, {"tokens": ["Considered", "Publications", "for", "ELD", "problems", "using", "PSO", "yearly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power system operations"}, {"tokens": ["While", "training", "High", "to", "Low", "discriminator", ",", "the", "generated", "LR", "images", "are", "considered", "to", "be", "fake", "so", "that", "the", "generator", "tries", "to", "generate", "as", "realistic", "LR", "image", "as", "possible", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["theoremGiven", ",", "where", "is", "an", "formula", "and", "is", "a", "conjunction", "of", "the", "formulae", "of", "the", "form", "which", "contains", "only", "variables", "from", ",", "our", "aim", "is", "to", "construct", "a", "PA", "to", "accept", "models", "-", "as", "words", "-", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "presburger arithmetic"}, {"tokens": ["PAF", "is", "an", "extension", "of", "BF", ",", "with", "the", "expense", "of", "a", "higher", "control", "overhead", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider - aware forwarding"}, {"tokens": ["To", "evaluate", "the", "fairness", ",", "we", "send", "one", "Cubic", "flow", "from", "one", "server", "to", "an", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["Finally", ",", "with", "the", "recent", "publication", "of", "fast", "adversarial", "training", "methods", ",", "we", "hope", "to", "further", "accelerate", "ARD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["FAR", "is", "followed", "by", "BMAA", "*", "with", "a", "completion", "rate", "of", "and", "WHCA", "*", "with", "a", "completion", "rate", "of", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "flow annotation replanning"}, {"tokens": ["The", "analog", "beamforming", "matrix", "at", "the", "BS", "can", "be", "written", "as", "where", "stands", "for", "the", "-th", "element", "in", "the", "set", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Substitution", "of", "words", ":", "Some", "of", "words", "joined", "with", "\u201c", "-", "\u201d", "in", "the", "abstracts", "of", "the", "LSC", "require", "an", "additional", "process", "of", "substitution", "to", "avoid", "losing", "the", "meaning", "of", "the", "word", "before", "removing", "the", "character", "\u201c", "-", "\u201d", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["BenchmarkingWe", "evaluated", "the", "performance", "of", "our", "Open", "IE", "system", "Graphene", "using", "the", "benchmark", "framework", "proposed", "in", "Stanovsky2016EMNLP", ",", "which", "is", "based", "on", "a", "QA", "-", "Semantic", "Role", "Labeling", "corpus", "with", "more", "than", "10,000", "extractions", "over", "3,200", "sentences", "from", "Wikipedia", "and", "the", "Wall", "Street", "Journal(available", "under", "https://github.com/gabrielStanovsky/oie-benchmark", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Along", "-", "fiber", "GFA", "visualization", "and", "cosine", "similarity", "between", "pairs", "of", "fibers", "from", "three", "prominent", "bundles", ":", "a", ")", "CST", "(", "R", ")", ",", "b", ")", "CC", ",", "c", ")", "IFOF", "(", "R", ")", ",", "using", "framework", "of", "varifolds", "(", "Var", ")", "and", "functional", "varifolds", "(", "fVar", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "corpus callosum"}, {"tokens": ["To", "investigate", "whether", "our", "proposed", "structural", "TS", "approach", "is", "able", "to", "improve", "the", "performance", "of", "downstream", "NLP", "tasks", ",", "we", "compare", "the", "performance", "of", "a", "number", "of", "state", "-", "of", "-", "the", "-", "art", "Open", "IE", "systems", ",", "including", "ClausIE", ",", "OpenIE-4", ",", "ReVerb", ",", "Ollie", "and", "Stanford", "Open", "IE", ",", "when", "directly", "operating", "on", "the", "raw", "input", "data", "with", "their", "performance", "when", "our", "DisSim", "framework", "is", "applied", "as", "a", "preprocessing", "step", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["For", "large", "enough", "network", "(", "upward", ")", ",", "DE", "-", "based", "deployment", "shows", "a", "significant", "improved", "performance", "than", "its", "counterparts", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["As", "before", ",", "the", "characteristic", "function", "of", "the", "residual", "corresponds", "to", "a", "probability", "density", "function", "that", "is", "composed", "of", "the", "sum", "of", "multiple", "Gaussian", "modes", "-", "a", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Some", "examples", "of", "such", "cases", "in", "LSC", "for", "randomly", "selected", "rare", "words", "are", "presented", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["The", "message", "is", "the", "same", "as", "in", "AP", "as", "we", "have", "not", "modified", "the", "consistency", "constraint", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["ECS", "-", "DBN", "uses", "adaptive", "differential", "evolution", "to", "optimize", "the", "misclassification", "costs", "based", "on", "training", "data", ",", "that", "presents", "an", "effective", "approach", "to", "incorporating", "the", "evaluation", "measure", "(", "i.e.", "G", "-", "mean", ")", "into", "the", "objective", "function", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["AP", "involves", "two", "steps", ":", "message", "passing", "and", "decision", "mechanism", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["If", "we", "observe", "the", "architecture", "of", "recently", "developed", "DCNN", "models", ",", "most", "of", "them", "incorporate", "many", "components", "similar", "to", "that", "of", "the", "human", "visual", "information", "processing", "system", "for", "recognition", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Furthermore", ",", "we", "showed", "that", "in", "the", "case", "of", "a", "dense", "environment", "with", "increasing", "number", "of", "users", ",", "the", "ability", "of", "RS", "to", "tackle", "SI", "and", "multi", "-", "user", "saturation", "worsens", "because", "the", "common", "message", "has", "to", "be", "decoded", "by", "more", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["We", "demonstrate", "that", "the", "more", "a", "network", "conforms", "to", "the", "CC", "property", "across", "the", "time", "steps", ",", "the", "higher", "the", "accuracy", "of", "our", "predictions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "core connected"}, {"tokens": ["The", "most", "promising", "feature", "of", "BC", ",", "with", "regard", "to", "its", "application", "in", "IoT", ",", "is", "the", "possibility", "of", "maintaining", "a", "transaction", "record", "across", "all", "devices", ",", "thus", "and", "thus", "make", "a", "distributed", "and", "trustless", "ledger", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["However", ",", "DE", "-", "based", "deployment", "is", "superior", "to", "that", "of", "GSA", "-", "based", "heuristic", "as", "inferred", "from", "the", "p", "-", "values", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["the", "UE", "is", "moving", "away", "from", "and", "approaching", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "majority", "rule", "model", "(", "MR", ",", "see", "Krapivsky2003", ")", "is", "a", "special", "case", "of", "the", "TM", ",", "since", "all", "thresholds", "are", "one", "half", "(", "the", "randomly", "chosen", "individual", "tends", "to", "flip", "if", "the", "majority", "of", "its", "neighbors", "have", "opposite", "spin", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "majority rule"}, {"tokens": ["The", "maximum", "throughput", "is", "calculated", "by", "assuming", ":", "1", ")", "no", "collisions", "in", "both", "contention", "rounds", ";", "2", ")", "only", "one", "-", "way", "traffic", "is", "present", ";", "3", ")", "the", "number", "of", "STAs", "(", ")", "is", "always", "higher", "than", "the", "number", "of", "antennas", "at", "the", "AP", ",", "which", "enables", "all", "AP", "'s", "antennas", "to", "be", "fully", "utilized", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "open", "nature", "of", "CF", "models", ",", "which", "rely", "on", "user", "-", "specified", "judgments", "(", "e.g.", ",", "ratings", "or", "reviews", ")", "to", "build", "user", "profiles", "and", "compute", "recommendation", ",", "can", "be", "used", "in", "the", "hand", "of", "adversaries", "to", "manipulate", "the", "underlying", "data", "and", "affect", "the", "impact", "of", "recommendation", ",", "a", "phenomenon", "commonly", "referred", "to", "as", "shilling", "attacks", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Next", ",", "a", "random", "is", "used", "for", "th", "block", "of", "receiver", "'s", "input", "for", "where", "the", "random", "OT", "does", "the", "following", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["As", "the", "next", "section", "details", ",", "a", "goal", "-", "based", "RL", "approach", "was", "developed", "to", "personalize", "the", "instruction", "and", "feedback", "provided", "to", "each", "child", "by", "the", "SAR", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["htb", "]", "1", "1", "1", "1", "SEM", "and", "LOM", "example", "images", "for", "each", "microstructure", "class", "with", "ferrite", "as", "matrix", "and", "with", "diameter", "of", "up", "to", "100", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["DE", "of", "the", "Achievable", "Rate", "of", "the", "Second", "Hop", "with", "RS", "(", ")"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deterministic equivalent"}, {"tokens": ["QA", "is", "a", "rather", "simple", "neural", "network", "architecture", "compared", "to", "the", "previous", "introduced", "models", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "model", "trained", "on", "the", "full", "12.9", "billion", "tokens", "corpus", "with", "context", "window", "size", "outperforms", "other", "models", "according", "to", "HJ", ",", "RT", ",", "AE", "and", "precision", "at", "20", "metrics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ruthes"}, {"tokens": ["To", "access", "the", "LSC", "for", "research", "purposes", ",", "please", "email", "to", "ns433@le.ac.uk", "or", "suzenneslihan@hotmail.com", ".", ")"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["The", "microcanonical", "SBM", "is", "mentioned", "here", "because", "it", "can", "be", "derived", "from", "modifying", "the", "Poisson", "SBM", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "stochastic block model"}, {"tokens": ["Figure", "visualizes", "the", "post", "hoc", "analysis", "using", "the", "CD", "diagram", "for", "AW", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "critical difference"}, {"tokens": ["Although", "FID", "is", "relatively", "new", ",", "it", "has", "been", "shown", "to", "be", "better", "than", "IS", "heusel2017fidlucic2017gan", "-", "equal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["We", "approximate", "eq", ":", "PVI", "as", "follows", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "parabolic variational inequality"}, {"tokens": ["The", "CSG", "complexity", "measureAs", "mentioned", "before", ",", "a", "dataset", "with", "a", "low", "eigenvalue", "spectrum", "indicates", "a", "low", "inter", "-", "class", "overlap", "and", "thus", "easily", "separable", "classes", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["Energy", "consumption", "of", "the", "boundary", "-", "based", "OCC(B", "-", "OCC", ")", "is", "lower", "than", "autoencoder", "-", "based", "OCC", "(", "AE", "-", "OCC", ")", "since", "B", "-", "OCC", "requires", "less", "number", "of", "computation", "at", "the", "output", "layer", "than", "AE", "-", "OCC", "does", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "one class classifier"}, {"tokens": ["Nowadays", ",", "GPS", "is", "used", "in", "UAVs", "to", "locate", "the", "coordinates", "UAVs", "and", "target", "objects", "but", "GPS", "is", "known", "to", "have", "coverage", "and", "accuracy", "issues", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["As", "such", ",", "we", "view", "GP", "as", "a", "strong", "candidate", "for", "a", "future", "version", "of", "the", "PennAI", "Artificial", "Intelligence", "Engine", ",", "where", "the", "GP", "is", "seeded", "with", "the", "best", "known", "algorithm", "configurations", "and", "uses", "the", "core", "principles", "of", "GP", "(", "inheritance", ",", "mutation", ",", "and", "crossover)-distributed", "over", "a", "high", "-", "performance", "computing", "cluster", "-", "to", "improve", "the", "algorithm", "configurations", "from", "there", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["As", "expected", ",", "the", "number", "of", "grid", "parameters", "and", "number", "of", "constraints", "are", "significantly", "higher", "than", "those", "of", "the", "corresponding", "DC", "-", "OPF", "cases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["As", "clearly", "shown", ",", "improves", "with", "increasing", "for", "both", "RS", "-", "based", "transmission", "schemes", "whereas", "it", "degrades", "severely", "for", "both", "repetitive", "ones", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["The", "performance", "of", "pure", "and", "rate", "-", "selective", "RS", "is", "depicted", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["In", "Figure", ",", "we", "show", "three", "captures", "of", "the", "results", "for", "the", "predictive", "curves", "of", "the", "GP", "regression", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "terms", "of", "3D", "object", "detection", ",", "BEV", "methods", "have", "traditionally", "achieved", "higher", "performance", "than", "RV", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "range view"}, {"tokens": ["We", "find", "that", "network", "models", "converge", "more", "quickly", "than", "LR", "and", "FM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Moreover", ",", "Black", "-", "DROPS", "with", "GP", "-", "MI", "was", "able", "to", "find", "high", "-", "performing", "walking", "policies", "for", "a", "physical", "damaged", "hexapod", "robot", "(", "48D", "state", "and", "18D", "action", "space", ")", "in", "less", "than", "1", "minute", "of", "interaction", "time", "and", "outperformed", "ITE", "that", "excels", "in", "this", "setting", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Constraint", "(", ")", "ensures", "that", ",", "the", "total", "number", "of", "CP", "functions", "processed", "by", "a", "DU", "at", "CC", "must", "not", "exceed", "the", "maximum", "capacity", "of", "the", "number", "of", "CP", "functions", "that", "can", "be", "hosted", "by", "a", "DU", "at", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "central cloud"}, {"tokens": ["Hence", ",", "it", "is", "necessary", "to", "induce", "a", "classifier", "for", "each", "particle", "(", "PSO", "based", "algorithms", ")", "or", "parent", "(", "GA", ")", "and", "use", "the", "consequent", "classification", "performance", "as", "criterion", "function", ",", "in", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Far", "right", ":", "the", "additive", "GP", "model", "can", "weight", "each", "order", "of", "interaction", "seperately", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "population", "size", "for", "all", "DE", "-", "based", "methods", "is", ",", "and", "for", "all", "CMA", "-", "ES", "-", "based", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["NT2002", ",", "the", "first", "GSM", "phone", "with", "a", "built", "-", "in", "GPS", "sensor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "global positioning system"}, {"tokens": ["With", "limited", "training", "data", ",", "the", "DCNN", "was", "able", "to", "detect", "the", "scleral", "spur", "on", "unseen", "ASOCT", "images", "as", "accurately", "as", "an", "experienced", "ophthalmologist", ";", "and", "simultaneously", "isolated", "the", "anterior", "segment", "structures", "with", "a", "Dice", "coefficient", "of", "95.7", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Subject", "Reduction", "and", "ProgressThe", "subject", "reduction", "proof", "of", "essentially", "extends", "that", "of", "FJ", "(", "Solution", "19.5.1", ")", "taking", "into", "account", "intersection", "types", "and", "using", "theflexibility", "of", "the", "judgement", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "featherweight java"}, {"tokens": ["The", "SOC", "level", "that", "terminates", "the", "CC", "phase", "varies", "with", "the", "device", "and", "the", "corresponding", "SOC", "levels", "are", "74", ",", "85", ",", "and", "76", "for", "Galaxy", "S2", ",", "S3", ",", "and", "S4", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["To", "use", "the", "concentration", "matrix", "with", "GP", "-", "UCB", ",", "we", "do", "the", "mapping", "from", "image", "coordinates", "to", "real", "-", "world", "coordinates", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Thus", ",", "here", "in", "after", ",", "we", "focus", "on", "the", "design", "of", "regenerating", "codes", "at", "the", "MBR", "points", ",", "and", "the", "corresponding", "parameter", "configuration", "isIn", "the", "node", "-", "regenerating", "process", ",", "if", "the", "restored", "fragment", "is", "always", "the", "same", "with", "the", "fragment", "in", "the", "prior", "failed", "node", ",", "this", "property", "is", "called", "the", "exact", "regeneration", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": [")", "'", "hungry", "'", "MP", "gusnag", ",", "gursag", ";", "NP", "gusnah", ",", "gurusnah", ";", "Bakhtiyari", "gosne", ";", "Balochi", "(", "Marw", ")", "gusnag", ";", "Gaz", "vasse", ";", "Larestani", "gosna", ";", "Mazandarani", "vasna", ";", "Sivandi", "fese", "'", "qui", "a", "faim", "'", "(", "showing", "the", "Central", "Iranian", "development"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Considering", "the", "fact", "that", "these", "differences", "in", "performance", "are", "consistent", "across", "different", "model", "parameters", "and", "repetitions", ",", "it", "can", "be", "concluded", "that", "sMT", "-", "GPTR", "and", "NP", "are", "capturing", "different", "characteristics", "of", "the", "underlying", "biology", "of", "impulsivity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["In", "experimental", "study", ",", "we", "show", "that", "without", "increasing", "model", "complexity", ",", "HSMC", "can", "improve", "learning", "performance", "on", "GP", "-", "SSM", "with", "nonlinear", "emission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Flickr", ":", "ROC", "curves", "for", "edge", "perturbation", "[", "h", "!", "]"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Image", "to", "dataset", "visual", "similarityWe", "define", "a", "measure", "of", "similarity", "to", "the", "domain", "that", "is", "modeled", "by", "the", "GMM", ",", "Cityscapes", "Dense", ",", "so", "we", "can", "rank", "images", "from", "others", "datasets", ",", "as", "the", "maximum", "log", "probability", "under", "the", "model", "for", "all", "receptive", "fields", "of", "an", "image", ":", "and", "according", "to", "our", "hypothesis", "the", "larger", "is", ",", "the", "image", "is", "visually", "more", "similar", "to", "the", "modeled", "Cityscapes", "Dense", "image", "domain", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["the", "PS", "agent", "can", "add", ",", "one", "-", "by", "-", "one", ",", "qubits", "to", "the", "initial", "code", "(", "see", "Fig", ".", ")"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "projective simulation"}, {"tokens": ["The", "contribution", "of", "this", "paper", "is", "to", "answer", "the", "following", "three", "questions", "about", "transfer", "learning", "via", "CNNs", "for", "SAR", "target", "recognition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["NBC", "makes", "a", "strong", "assumption", "about", "the", "shape", "of", "the", "data", "distribution", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "naive bayes classifier"}, {"tokens": ["Authors", "want", "to", "gratefully", "acknowledge", "the", "contribution", "of", "Pablo", "Gely", "Munoz", "to", "the", "GMM", ",", "FIM", "and", "UFMM", "implementations", ",", "and", "to", "Adam", "Chacon", "for", "the", "interesting", "discussions", "and", "suggestions", "towards", "improving", "the", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["Therefore", ",", "we", "form", "an", "imbalanced", "gun", "drilling", "dataset", "and", "apply", "ECS", "-", "DBN", "on", "this", "dataset", "to", "investigate", "how", "well", "the", "ECS", "-", "DBN", "could", "handle", "with", "imbalanced", "data", "on", "fault", "diagnosis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["As", "mentioned", ",", "the", "MP", "approach", "is", "non", "-", "personalized", "and", "thus", ",", "each", "entity", "will", "receive", "the", "same", "recommendations", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "most popular"}, {"tokens": ["China", "Standard", "Time", "(", "CST", ")", "is", "UTC+08:00", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "china standard time"}, {"tokens": ["Making", "this", "claim", "rigorous", "or", "even", "just", "state", "a", "mathematical", "conjecture", "is", "quite", "challenging", "and", "would", "require", "an", "appropriate", "scaling", "of", "space", "and", "time", "similar", "to", "the", "diffusion", "scaling", "considered", "for", "a", "single", "server", "PS", "queue", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "processor sharing"}, {"tokens": ["Recall", "that", "when", "an", "MS", "sends", "data", "to", "the", "BS", ",", "i.e.", "on", "link", ",", "it", "can", "either", "transmit", "packets", "backlogged", "in", "the", "own", "queue", "or", "in", "the", "relay", "queue", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "trained", "by", "calculating", "the", "gradients", "of", "the", "loss", "for", "a", "batch", "of", "five", "sentences", "consisting", "of", "surface", "forms", "and", "its", "associated", "NER", "and/or", "MD", "labelsand", "updated", "the", "parameters", "with", "Adam", "for", "50", "epochs", "and", "reported", "the", "performance", "on", "test", "set", "of", "the", "model", "with", "the", "highest", "development", "set", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "morphological disambiguation"}, {"tokens": ["We", "presented", "how", "the", "observed", "path", "data", "can", "be", "incorporated", "into", "the", "GMM", "representation", "and", "what", "kind", "of", "typical", "features", "have", "been", "chosen", "to", "identify", "each", "path", "primitive", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["From", "eq", ":", "finalresidual", ",", "where", "is", "the", "difference", "between", "the", "individual", "GMM", "(", "mode", ")", "means", "and", "overall", "mean", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "results", "show", "that", "the", "nested", "structured", "LB", "divergence", "-", "based", "method", "is", "comparable", "to", "the", "learning", "to", "rank", "methods", "and", "even", "obtains", "better", "results", "when", "more", "potential", "candidates", "are", "considered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["The", "closer", "a", "RN", "is", "to", "BS", ",", "the", "more", "the", "likelihood", "of", "relaying", "more", "data", "and", "the", "faster", "it", "depletes", "its", "energy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["More", "precisely", ",", "the", "SCL", "-", "decoded", "BIPCM", "system", "performs", "better", "than", "the", "LTE", "turbo", "coded", "system", "by", "about", "0.8", "dB", ",", "in", "both", "fading", "scenarios", ",", "while", "the", "SC", "-", "decoded", "BIPCM", "system", "falls", "behind", "the", "LTE", "turbo", "coded", "system", "by", "about", "0.9", "dB", "in", "fast", "fading", "and", "about", "0.5", "dB", "in", "block", "fading", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "successive cancellation"}, {"tokens": ["Numerical", "ResultsIn", "this", "section", ",", "results", "for", "the", "user", "capacities", ",", "SC", "and", "EE", "of", "the", "proposed", "protocol", "and", "techniques", "are", "examined", "and", "explained", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["This", "included", "the", "largest", "maps", "from", "the", "game", "used", "to", "originally", "evaluate", "FAR", "and", "additional", "more", "small", "and", "mid", "sized", "maps", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "flow annotation replanning"}, {"tokens": ["The", "experimental", "LR", "images", "in", "the", "edge", "regions", "of", "the", "sample", "were", "chosen", "as", "the", "test", "data", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["In", "the", "following", "we", "restrict", "to", "well", "-", "formed", "AML", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["They", "also", "allow", "us", "to", "identify", "the", "specific", "that", "obtains", "a", "given", "point", ",", "provided", "we", "know", "the", "IB", "curve", "in", "the", "information", "plane", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Algorithms", "like", "Black", "-", "DROPS", "with", "GP", "-", "MI", "and", "VGMI", "effectively", "exploit", "parameterized", "simulators", "and", "should", "be", "able", "to", "learn", "in", "a", "handful", "of", "trials", "even", "for", "complex", "robots", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["FAST", "(", "red", ")", "and"], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "features from accelerated segment test"}, {"tokens": ["Moreover", ",", "the", "formulation", "of", "Lemma", "2", "demonstrates", "that", "it", "is", "effective", "to", "use", "GMM", "to", "develop", "the", "valid", "measurements", "for", "the", "activation", "functions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["In", "terms", "of", "rigorous", "continual", "learning", ",", "this", "is", "another", "way", "of", "revisiting", "past", "observed", "data", "and", "forces", "the", "GP", "model", "to", "concatenate", "old", "and", "new", "subsets", ",", "something", "that", "can", "be", "undesired", "for", "certain", "tasks", ",", "i.e.", "high", "-", "dimensional", "input", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["After", "having", "described", "the", "conventional", "multipair", "with", "relay", "transmission", "(", "NoRS", ")", "in", "Section", ",", "we", "focus", "on", "the", "application", "of", "the", "promising", "RS", "transmission", "method", "that", "is", "going", "to", "be", "applied", "in", "the", "second", "link", "between", "the", "relay", "station", "and", "the", "destination", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["Under", "assumptions", "-", ",", "with", "in", "equations", "prob1-prob3", "chosen", "such", "that", ",", "with", "probability", ",", "the", "Con", "-", "TS", "-", "RTP", "algorithm", "with", "Constraint", "Set", "B", "will", "uphold", "the", "probabilistic", "distribution", "system", "constraints", "as", "formulated", "in", "NOTclairvoyant_constraint", "for", "each", "day", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Or", "should", "we", "fit", "an", "SBM", "with", "different", "fixed", "'s", ",", "and", "view", "finding", "the", "optimal", "as", "a", "model", "selection", "problem", "?"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Suppose", "denotes", "the", "fading", "coefficient", "of", "a", "channel", "from", "BS", "to", "a", "user", "K", ",", "where", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["While", "communication", "is", "based", "on", "WLAN", ",", "accurate", "localization", "is", "performed", "using", "GPS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "global positioning system"}, {"tokens": ["MCC", "can", "be", "calculated", "as", "follows", ":"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["Specifically", ",", "the", "communication", "per", "extended", "OT", "is", "brought", "down", "to", "one", "hash", "value", "for", "a", "special", "case", "where", "the", "extended", "OTs", "are", "needed", "for", "random", "inputs", "of", "the", "sender", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "main", "focus", "in", "this", "paper", "is", "investigating", "polyglot", "decoding", ",", "and", "in", "particular", "the", "effect", "of", "training", "models", "on", "multiple", "datasets", "when", "translating", "to", "individuals", "APIs", "or", "SP", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "semantic parsing"}, {"tokens": ["MP", "gul", "NP", "gul", "'", "flower'PIr", "*", "carda-", "MP", "sal", "(", "MMP", "sar", ")"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["The", "second", "step", "of", "DMD", "in", "eq", ":", "DMD", "uses", "the", "shift", "model", "to", "anticipate", "the", "optimal", "decision", "for", "the", "next", "round", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["However", ",", "this", "flexibility", "comes", "at", "the", "price", "of", "slightly", "lower", "BA", "but", "makes", "a", "model", "capable", "of", "operation", "in", "the", "face", "of", "unavailable", "sensors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "balanced accuracy"}, {"tokens": ["Then", "she", "derives", "a", "new", "DH", "output", "for", "the", "next", "root", "KDF", "chain", "with", "her", "new", "ratchet", "private", "key", "to", "derive", "a", "new", "RK", "and", "a", "sending", "CK", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "root key"}, {"tokens": ["Let", "denote", "the", "signal", "vector", "formed", "by", "the", "independent", "data", "streams", "sent", "from", "the", "BS", "to", "the", "destination", "users", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["This", "meant", "that", "for", "example", "when", "using", "a", "CarvPath", "aware", "Sleuthkit", "MMLS", "module", ",", "storage", "of", "a", "partition", "in", "the", "OCFA", "CAS", "storage", "system", "required", "the", "full", "partition", "to", "be", "read", "for", "hashing", "purposes", "before", "it", "could", "be", "symlinked", "in", "the", "storage", "subsystem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "content addressed storage"}, {"tokens": ["Methods", "for", "Dealing", "with", "Long", "-", "Distance", "Dependencies", "in", "End", "-", "to", "-", "End", "ModelsIn", "SRL", "studies", ",", "Marcheggiani2017", "proposed", "a", "variant", "of", "deep", "bi", "-", "RNN", "models", "that", "connects", "the", "intermediate", "representations", "of", "the", "predictions", "for", "the", "words", "in", "syntactic", "dependency", "relations", "on", "top", "of", "the", "deep", "RNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["Moreover", ",", "as", "can", "be", "seen", "from", "the", "last", "row", "of", "Table", "GMM", "selection", "does", "not", "add", "much", "since", "visual", "similarity", "is", "already", "attained", "by", "using", "same", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Note", ",", "however", ",", "one", "needs", "to", "sample", "this", "GP", "only", "at", "the", "finite", "points", "in", "the", "random", "set", "and", "the", "fixed", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["It", "can", "overcome", "the", "key", "limitations", "of", "existing", "OR", "methodologies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "operations research"}, {"tokens": ["wafr", "NP"], "acronym_pos": [0, 1], "long_form": "new persian"}, {"tokens": ["Due", "to", "utilizing", "the", "separate", "time", "slot", "for", "each", "transmission", "except", "OAM", "based", "transmission", ",", "the", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "provides", "significantly", "lower", "EE", "than", "the", "proposed", "scheme", "w.r.t", "which", "is", "illustrated", "in", "Figure", "10", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["With", "no", "surprise", ",", "we", "observe", "that", "(", "from", "Table", ")", "training", "the", "heatmap", "prediction", "networks", "in", "a", "semi", "-", "supervised", "manner", ",", "and", "aligning", "the", "images", "directly", "in", "low", "resolution", ",", "improves", "the", "performance", "of", "any", "face", "recognition", "system", "trained", "with", "HR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "high - resolution"}, {"tokens": ["There", "is", "an", "additional", "vector", "of", "length", "which", "consists", "of", "the", "mixing", "weights", "for", "the", "Gaussian", "Mixture", "Model", "(", "GMM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["It", "should", "be", "noted", "that", "Algorithm", "3", "is", "done", "at", "the", "BS", "side", "before", "executing", "the", "FL", "scheme", "in", "Algorithm", "1", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Signal", "integrity", "(", "GPS", "spoofing)tabular", "&", "tabular[c]@l@1", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Typically", ",", "when", "using", "SVI", "for", "sparse", "GP", "models", ",", "one", "fixes", "the", "number", "of", "inducing", "-", "inputs", "and", "applies", "any", "stochastic", "gradient", "method", "computed", "from", "a", "smaller", "subset", "of", "samples", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "use", "the", "term", "global", "here", ",", "since", "in", "this", "analysis", "we", "would", "like", "to", "free", "our", "attention", "from", "the", "impact", "of", "attacks", "on", "CF", "models", ",", "attack", "quality", "(", "type", ")", "and/or", "quantity", "as", "they", "have", "been", "largely", "addressed", "in", "previous", "works", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["the", "range", "of", "for", "the", "PSRS", "codes", "is", ",", "so", "is", "the", "proposed", "Exact", "-", "MBR", "code", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["In", "this", "paper", ",", "we", "evaluated", "five", "different", "learning", "models", "for", "measuring", "predictive", "performance", "\u2013", "CNN", ",", "LSTM", ",", "RF", ",", "GBR", ",", "and", "LR", "-", "to", "predict", "the", "stream", "flow", "based", "on", "hydrological", "variables", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear regression"}, {"tokens": ["After", "this", "step", ",", "MVF", "is", "calculated", "from", "the", "speech", "signal", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["Overall", "the", "results", "show", "that", "the", "simple", "objective", "function", "features", ",", "can", "act", "as", "a", "predictor", "for", "selecting", "appropriate", "control", "parameters", "for", "DE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "differential evolution"}, {"tokens": ["A", "few", "days", "later", ",", "the", "acquisition", "of", "German", "AR", "company", "Metaio", "by", "Apple", "is", "announced", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["We", "analyze", "the", "generality", "and", "specificity", "of", "features", "in", "different", "layers", "with", "various", "source", "data", "when", "taking", "SAR", "target", "recognition", "as", "the", "target", "task", ",", "so", "as", "to", "decide", "which", "level", "of", "the", "features", "can", "be", "used", "as", "the", "off", "-", "the", "-", "shelf", "representation", "for", "the", "target", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["NP", "bisgar(d", ")"], "acronym_pos": [1, 0, 0], "long_form": "new persian"}, {"tokens": ["If", ",", "Eve", "will", "always", "declare", "that", "Alice", "is", "transmitting", "regardless", "of", "the", "observation", ",", "and", ",", "hence", ",", "not", "surprisingly", ",", "we", "note", "from", "MD", "-", "FA0", "that", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "missed detection"}, {"tokens": ["In", "particular", ",", "instead", "of", "designing", "a", "new", "deep", "convolutional", "neural", "network", "with", "the", "random", "initialization", ",", "we", "exploited", "existing", "trained", "DCNN", "on", "1000", "objects", "as", "a", "starting", "point", "to", "identify", "Devanagari", "alphabets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["tab", ":", "schooltabularllllllllModels", "&", "STL", "&", "ITL", "&", "SHAMO", "&", "MTFL", "&", "GO", "-", "MTL", "&", "BiFactor", "&", "TriFactor", "20", "&", "12.19", "(", "0.03", ")", "&", "12.00", "(", "0.04", ")", "&", "11.91", "(", "0.05", ")", "&", "11.25", "(", "0.05", ")", "&", "11.15", "(", "0.05", ")", "&", "10.68", "(", "0.08", ")", "&", "10.54"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "single task learning"}, {"tokens": ["Littermate", "WT", "mice", "(", "C57BL/6", ")", "served", "as", "controls", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "wild type"}, {"tokens": ["In", "Chapter", "chap", ":", "qa", "we", "describe", "our", "contribution", "as", "a", "novel", "approach", "to", "complex", "QA", "that", "pushes", "the", "state", "-", "of", "-", "the", "-", "art", "in", "this", "direction", "on", "a", "recent", "benchmark", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Shown", ",", "side", "by", "side", "are", "sample", "images", "from", "the", "CelebA", "dataset", ",", "the", "emoji", "images", "created", "manually", "using", "a", "web", "interface", "(", "for", "validation", "only", ")", ",", "and", "the", "result", "of", "the", "unsupervised", "DTN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "domain transfer network"}, {"tokens": ["FCOS", "model", "does", "the", "best", "here", "with", "AP", "of", "47.9", "(", "right", "panel", "in", "Fig", ".", ";"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["abFraction", "of", "robust", "features", "according", "to", "the", "test", "-", "retest", "intraclass", "correlation", "coefficient", "(", "ICC", "(", "1,1", ")", ")", "for", "a", "pre", "-", "interpolation", "Gaussian", "smoothing", "parameter", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["Notice", "that", "AP", "is", "a", "direct", "consequence", "of", "the", "classification", "accuracy", ",", "so", "if", "we", "can", "better", "classify", "objects", "we", "can", "obtain", "a", "better", "AP", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "average precision"}, {"tokens": ["The", "proposed", "ECS", "-", "DBN", "attained", "the", "best", "average", "AUC", "value", "over", "10", "trials", "of", "0.9946", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["He", "has", "been", "working", "on", "the", "systems", "design", "for", "LTE", "MAC", "/", "RLC", "/", "PDCP", "/", "RRC", "layer", "implementations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "radio link control"}, {"tokens": ["NP", "bah", "-", "PIr"], "acronym_pos": [1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["In", "Section", "we", "will", "discuss", "an", "effective", "means", "of", "reducing", "the", "number", "of", "GMM", "terms", "needed", "to", "represent", "the", "density", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Based", "on", "this", "technology", "he", "presents", "the", "famous", "AR", "-", "Tennis", "game", ",", "the", "first", "collaborative", "AR", "application", "running", "on", "a", "mobile", "phone", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Based", "on", "the", "simulation", "results", ",", "it", "is", "obvious", "that", "DBN", "outperforms", "other", "9", "conventional", "machine", "learning", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["By", "generalizing", "randomly", "generated", "quantizers", ",", "the", "theoretical", "performance", "of", "MDC", "with", "randomly", "offset", "quantizers", "is", "given", "in", "the", "closed", "-", "form", "expressions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["it", "can", "be", "seen", "that", "considerable", "time", "is", "consumed", "in", "the", "ANN", "model", "training", "stage", "which", "is", "reduced", "significantly", "by", "TPIB", "-", "ITL", "system", "on", "both", "NIST", "and", "AMI", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Among", "the", "phase", "-", "based", "features", ",", "IF", "and", "BPD", "outperform", "other", "features", "in", "terms", "of", "the", "average", "EERs", "over", "all", "the", "noise", "scenarios", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "baseband phase difference"}, {"tokens": ["At", "the", "high", "level", ",", "both", "client", "and", "server", "reside", "on", "the", "same", "machine", ",", "which", "allows", "replicas", "to", "send", "model", "updates", "to", "one", "-", "another", "instead", "of", "a", "central", "PS", ",", "as", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["Motion", "Primitive", "Model", "Training", "ProcessThe", "different", "training", "process", "or", "different", "types", "of", "motion", "primitive", "models", "can", "be", "concluded", "by", "four", "parameters", ":", "the", "number", "of", "different", "path", "primitive", ",", "the", "value", "of", "previous", "time", "scale", ",", "the", "value", "of", "prediction", "time", "scale", "and", "the", "number", "of", "GMM", "components", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "impact", "of", "the", "different", "parameters", "over", "capacities", "and", "EE", "for", "the", "proposed", "scheme", "is", "analyzed", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "as", "well", "to", "analyze", "the", "effectiveness", "of", "the", "proposed", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["Thus", ",", "is", "regarded", "as", "the", "average", "depth", "of", "the", "BSP", "tree", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["Also", ",", "joint", "optimization", "of", "DeepVAE", "with", "GMM", "can", "potentially", "improve", "the", "results", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Este", "trabalho", "utilizou", "MD", "para", "identificar", "perfis", "de", "estudantes", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "massa de dados"}, {"tokens": ["(", "VAT", ")", "and", "0.975", "(", "SAT", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["-a", "we", "observe", "that", "our", "model", "exhibits", "a", "drop", "in", "accuracy", "for", "recordings", "which", "are", "from", "the", "ST", "subset", "compared", "to", "the", "SC", "subset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "sleep cassette"}, {"tokens": ["=", "E[Y", "T=1", ",", "F_T=", "]", "-", "E[Y", "T=0", ",", "F_T=].alignIn", "general", ",", "the", "ACE", "and", "observational", "ACE", "are", "not", "equal", "as", "long", "as", "we", "assume", "ignorable", "treatment", "assignments.tdawid07", "show", "that", "the", "ACE", "and", "observational", "ACE", "are", "equivalent", "under", "the", "conditional", "independence", "assumption", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average causal effect"}, {"tokens": ["We", "use", "the", "recommended", "parameter", "values", "for", "OEC", "from", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["Results", "and", "organizations", "of", "the", "paperIn", "this", "paper", ",", "we", "developed", "two", "classes", "of", "Exact", "-", "MBR", "codes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Perpendicular", "Vegetation", "Index", "(", "PVI", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0], "long_form": "perpendicular vegetation index"}, {"tokens": ["In", "a", "similar", "way", ",", "we", "trained", "the", "same", "neural", "network", "by", "genetic", "algorithm", "with", "equivalent", "structure", "as", "we", "did", "for", "ICA", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "imperialist competitive algorithm"}, {"tokens": ["found", "that", "the", "second", "version", "is", "more", "predictive", "(", "than", "the", "usual", "single", "-", "layer", "SBM", ")", "when", "it", "comes", "to", "link", "prediction", "or", "network", "reconstruction", "(", "Section", ")", "for", "real", "-", "world", "networks", ",", "which", "may", "therefore", "be", "better", "described", "as", "an", "aggregation", "of", "multiple", "layers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Then", ",", "the", "following", "approximation", "of", "variational", "posterior", "distribution", "is", "used", "in", "order", "to", "perform", "the", "approximate", "inference", "in", "NP", ":", "eqnarray", "eq", ":", "NP_variationalq(Z", "X", ",", "Y", ")", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["On", "the", "other", "hand", ",", "once", "an", "ANN", "is", "trained", ",", "it", "requires", "little", "effort", "to", "process", "the", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["On", "the", "other", "hand", ",", "are", "respectively", "the", "change", "-", "windows", "or", "weight", "functions", "that", "allow", "a", "specific", "GP", "to", "appear", "or", "vanish", "in", "certain", "parts", "of", "the", "input", "space", "(", "time", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["That", "is", ",", "Our", "proposed", "network", "entails", "each", "MS", "to", "maintain", "two", "queues", ",", "own", "queue", "for", "storing", "packets", "arriving", "exogenously", "to", "the", "MS", "and", "relay", "queue", "to", "store", "the", "packets", "arriving", "from", "other", "MSs", "for", "relaying", "to", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["In", "SAR", "operations", ",", "image", "processing", "can", "be", "done", "either", "at", "the", "GCS", ",", "post", "target", "identification", ",", "or", "at", "the", "UAV", "itself", ",", "using", "on", "-", "board", "processors", "with", "real", "-", "time", "image", "processing", "capabilities", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["While", "for", "specific", "priors", ",", "this", "problem", "could", "be", "solved", "by", "PDE", "or", "ODE", "methods", ",", "we", "resort", "to", "a", "well", "known", "sparse", "GP", "approach", "with", "inducing", "points", "in", "this", "paper", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Only", "once", "did", "HOSVD", "achieve", "a", "higher", "CCR", "when", "training", "on", "a", "different", "sample", "to", "the", "one", "being", "tested", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["The", "GP", "mean", "predictive", "function", "(", "black", ")", "remains", "fitted", "all", "along", "the", "input", "domain", "as", "the", "model", "is", "re", "-", "trained", "with", "new", "data", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["ht]The", "area", "under", "the", "ROC", "curve", "metric", "of", "DSNet", "and", "the", "recent", "FrCN", "by", "for", "skin", "lesion", "class", "segmentation", "for", "ISIC-2017", "test", "and", "PH2", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Meanwhile", ",", "the", "controllability", "performance", "prediction", "on", "TBA", "and", "TDA", "is", "also", "slightly", "more", "difficult", "than", "that", "on", "RA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "random attack"}, {"tokens": ["A", "SC", "could", "be", "layered", "over", "a", "DL", "and", "conducts", "activity", "when", "certain", "conditions", "are", "met", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "smart contract"}, {"tokens": ["Now", "we", "shall", "prove", "that", "is", "DBP"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1], "long_form": "determinisable by pruning"}, {"tokens": ["Finally", ",", "BRNN", "-", "POS", "-", "H2-OOV", "achieves", "the", "best", "performance", ",", "which", "shows", "that", "the", "integration", "of", "POS", "information", "in", "RNN", "models", "and", "dealing", "with", "OOV", "words", "are", "useful", "to", "build", "efficient", "multilingual", "super", "senses", "taggers", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Position", "UpdateIn", "the", "majority", "of", "binary", "PSO", "variants", ",", "the", "position", "update", "process", "entails", "the", "decision", "to", "exclude", "or", "include", "each", "feature", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["A", "Score", "&", "MD", "Cerebral", "peduncle", "R", "&", "PET", "Cingulum", "Post", "R", "&", "tabular", "Group", "difference", "across", "Amyloid", "Load", "(", "PiB", "Positivity)tabletable", "[", "!", "]"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean diffusivity"}, {"tokens": ["CC", "-", "Phase", ":", "During", "the", "first", "phase", ",", "the", "batteries", "are", "charged", "to", "50", "-", "90", "of", "total", "capacity", ",", "depending", "on", "the", "models", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant charging"}, {"tokens": ["Section", "2", "summarizes", "the", "related", "work", "on", "image", "captioning", "that", "sets", "the", "stage", "for", "our", "work", "on", "CNet", "-", "NIC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "neural image caption"}, {"tokens": ["[", "t]Comparison", "of", "memory", "requirements", "for", "LR"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1], "long_form": "logistic regression"}, {"tokens": ["HT", "-", "MIMO", "works", "in", "the", "PCF", "mode", ",", "hence", "both", "uplink", "and", "downlink", "transmissions", "can", "only", "be", "initiated", "by", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access part"}, {"tokens": ["K40c", "(", "ECC", "off", ")", "]"], "acronym_pos": [0, 0, 1, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["(", "e.g.", "a", "D2D", "UE", "to", "D2DCH", "or", "D2DMHR", "request", "is", "always", "granted", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "rationale", "for", "switching", "from", "a", "BS", "to", "RS", "mode", "is", "to", "ensure", "those", "MS", "that", "would", "be", "served", "by", "the", "switched", "off", "cell", "and", "may", "suffer", "deep", "fading", ",", "are", "still", "be", "able", "to", "receive", "the", "same", "QoS.", "Furthermore", ",", "since", "the", "propagation", "distance", "has", "been", "shortened", "between", "the", "MS", "and", "serving", "BS", "via", "the", "back", "haul", "connection", ",", "the", "required", "MS", "transmit", "power", "is", "concomitantly", "reduced", "compared", "with", "the", "BS", "sleep", "and", "cell", "zooming", "technique"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["Knowing", "that", "Cityscapes", "Dense", "has", "2975", "training", "images", ",", "we", "observe", "that", ",", "if", "only", "1000", "weakly", "labeled", "images", "are", "available", ",", "then", "selecting", "similarity", "(", "GMM", ")", "over", "diversity", "(", "heuristics", ")", "works", "better", ",", "and", "the", "model", "does", "not", "overfit", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["By", "properly", "setting", "the", "aforementioned", "parameters", ",", "the", "results", "show", "that", "a", "WLAN", "implementing", "Uni", "-", "MUMAC", "is", "able", "to", "avoid", "the", "AP", "bottle", "-", "neck", "problem", "and", "performs", "very", "well", "in", "both", "the", "traditional", "downlink", "-", "dominant", "and", "emerging", "down", "/", "up", "-", "link", "balanced", "traffic", "scenarios", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["For", "the", "HNSCC", "cohort", ",", "the", "percentage", "of", "robust", "features", "increases", "with", "decreasing", ",", "which", "is", "also", "reflected", "in", "the", "ICC", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["Also", ",", "the", "interference", "from", "D2D", "users", "to", "the", "typical", "D2D", "receiver", "in", "the", "-th", "band", "is", "given", "bySimilarly", ",", "the", "received", "signal", "by", "the", "typical", "base", "station", "is", "given", "by", "The", "SINR", "of", "the", "typical", "BS", "in", "-th", "band", "is", "as", "follows", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["If", "is", "the", "vector", "of", "single", "pixel", "measurements", "from", "SPC", "and", "is", "the", "compressive", "sensing", "matrix", ",", "then", "we", "have", "the", "forward", "model", "as", ":", "LiSensIn", "Lisens", ",", "the", "2D", "image", "of", "the", "scene", "formed", "on", "the", "DMD", "plane", "is", "mapped", "onto", "a", "1D", "line", "-", "sensor", "which", "essentially", "captures", "the", "1D", "integral", "of", "the", "2D", "image", "(", "along", "rows", "or", "columns", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "digital micro - mirror device"}, {"tokens": ["Originally", "they", "illustrated", "the", "complementary", "nature", "of", "EMD", "and", "DMD", ",", "and", "here", "it", "is", "shown", "how", "iterative", "improvement", "succeeds", "in", "both", "cases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "excessive mapping dissolution"}, {"tokens": ["h", "]", "DE", "computational", "flowchart", "."], "acronym_pos": [0, 0, 1, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["After", "applying", "misclassification", "costs", "on", "the", "outputs", "of", "the", "DBN", ",", "we", "evaluate", "the", "training", "error", "based", "on", "the", "performance", "of", "the", "corresponding", "cost", "-", "sensitive", "hypothesized", "prediction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["we", "showed", "how", "each", "point", "of", "the", "IB", "curve", "can", "be", "found", "with", "a", "unique", "maximizing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "coordinated", "uplink", "access", "scheme", "implies", "the", "involvement", "of", "the", "AP", "(", "as", "a", "coordinator", ")", "and", "the", "employment", "of", "RTS", "/", "CTS", "exchanges", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["The", "convolutional", "autoencoder", "features", "achieve", "a", "mean", "AP", "of", "57", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["t", "]", "UAV", "efficient", "placement", "(", "upper", "part", ")", "and", "convergence", "speed", "of", "the", "PSO", "algorithm", "(", "lower", "part", ")", "for", "different", "building", "heights"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["To", "meet", "these", "requirements", ",", "inspired", "by", "how", "the", "ranking", "gain", "is", "accumulated", "and", "normalized", "in", "the", "definition", "of", "the", "ranking", "metric", "NDCG", ",", "we", "propose", "a", "new", "metric", ",", "which", "we", "term", "normalized", "cumulative", "entropy", "(", "NCE", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["cumu", "explicitly", "expressing", "the", "GMM", "modes", "leads", "to"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["They", "both", "achieve", "a", "similar", "balance", "of", "quality", "and", "diversity", "as", "TS", "with", ",", "with", "reranking", "leading", "to", "greater", "diversity", "than", "frame", "prediction", "and", "the", "latter", "showing", "higher", "ROUGE", "/", "BLEU", "scores", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature - based sampling"}, {"tokens": ["For", "the", "feature", "intertwiner", ",", "OT", "is", "capable", "of", "enforcing", "the", "less", "reliable", "set", "to", "be", "better", "aligned", "with", "the", "reliable", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Recommendation", "using", "collaborative", "filtering", "(", "with", "50", "latent", "dimensions", ",", "selected", "using", "a", "validation", "set", ")", "on", "the", "user", "-", "article", "editing", "matrix", ",", "which", "we", "call", "\"", "CF", "-", "based", "\"", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["An", "example", "of", "a", "PDP", "is", "shown", "in", "Figure", "fig", ":", "screenshot", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product display page"}, {"tokens": ["If", "the", "MG", "Krylov", "solver", "is", "preconditioned", "so", "that", "the", "eigenvector", "converges", ",", "RQI", "may", "be", "able", "to", "find", "the", "correct", "eigenvalue", "more", "efficiently", "than", "PI", "for", "cases", "of", "interest", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": [",", "agriculture", "'", "NP", "barz", "'", "a", "sown", "field", ",", "agriculture", "'", "(", "cf", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["In", "other", "words", ",", "the", "implicit", "CSI", "feedback", ",", "namely", ",", "the", "AP", "estimates", "the", "channel", "using", "the", "training", "sequence", "included", "in", "the", "MU", "-", "CTS", ",", "is", "adopted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["in", "our", "computer", "simulations", ",", "where", "the", "MS", "and", "the", "BS", "are", "located", "at", "and", "in", "terms", "of", "their", "-coordinates", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Geometric", "Programming", "MethodThe", "standard", "form", "of", "GP", "is", "defined", "as", "the", "minimization", "of", "a", "posynomial", "function", "subject", "to", "inequality", "posynomial", "constraints", "and", "equality", "monomial", "constraints", "as", "given", "below", ":", "where", ",", ",", "are", "posynomials", "and", ",", "are", "monomials", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Evaluation", "on", "each", "ModelFor", "problems", "of", "this", "type", ",", "there", "are", "many", "models", "suitable", "to", "handle", "such", "as", ":", "SVM", ",", "Bi", "-", "LTSM", ",", "LR", ",", "GRU", ",", "CNN", "and", "etc", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Different", "from", "the", "existing", "methods", ",", "FAN", "uses", "an", "innovative", "focusing", "network", "to", "rectify", "the", "drifted", "attention", "of", "the", "AN", "model", "in", "handling", "complicated", "and", "low", "-", "quality", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["The", "GP", "-", "UCB", "algorithm", "automatically", "adjusts", "and", "provides", "some", "theoretical", "guarantees", "on", "the", "regret", "bounds", "of", "the", "algorithm", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Based", "on", "the", "computational", "time", "without", "DBN", "training", "time", ",", "it", "can", "be", "observed", "that", "comparing", "with", "the", "training", "time", "of", "DBN", ",", "the", "average", "time", "of", "adjusting", "proper", "misclassification", "costs", "by", "evolutionary", "algorithm", "is", "very", "small", "that", "can", "be", "ignored", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Its", "functionality", "extends", "that", "of", "ANN", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0], "long_form": "artificial neural network"}, {"tokens": ["These", "updates", "have", "closed", "form", "solution", "as", "in", "the", "standard", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["To", "learn", "a", "better", "model", ",", "the", "identification", "and", "localization", "tasks", "are", "trained", "simultaneously", "through", "MTL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "multi - task learning"}, {"tokens": ["Seed", "OT", "Phase", ":", "On", "behalf", "of", ",", "receives", "the", "input", "of", "to", "the", "functionality", ",", "namely", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["In", ",", "a", "novel", "baseband", "signal", "synthesis", "method", "was", "proposed", "to", "construct", "the", "AN", "signal", "based", "on", "the", "null", "space", "of", "the", "channel", "vector", "in", "the", "desired", "direction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["In", "contrast", ",", "in", "finitely", "branching", "games", ",", "the", "almost", "-", "sure", "Buchi", "objective", "is", "strongly", "MD", "-", "determined", ",", "as", "the", "following", "theorem", "shows", ":", "theorem", "thm", ":", "BuchiLet", "be", "a", "finitely", "branching", "game", "with", "objective", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["For", "example", ",", "the", "AP", "can", "estimate", "the", "uplink", "channel", "coefficients", "from", "the", "same", "packets", "that", "carry", "the", "downlink", "channel", "coefficients", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Furthermore", ",", "in", "this", "case", ",", "the", "CF", "approach", ",", "which", "analyzes", "the", "18,593", "interactions", "between", "users", "and", "services", "in", "a", "personalized", "manner", ",", "provides", "better", "results", "than", "MP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "most popular"}, {"tokens": ["We", "also", "see", "that", "generating", "helpful", "suggestions", "is", "a", "difficult", "task", ":", "in", "many", "cases", "workers", "thought", "neither", "system", "was", "helpful", ",", "especially", "when", "given", "the", "outputs", "from", "BS", "/", "TS", "or", "TS", "/", "predicted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "beam search"}, {"tokens": ["It", "can", "be", "expressed", "as", "Then", ",", "the", "MSE", "of", "the", "LMMSE", "estimator", "is", "computed", "as", "which", "is", "always", "smaller", "than", "that", "of", "the", "LS", "estimator", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["In", "order", "to", "assess", "cyclists", "'", "risk", "based", "on", "different", "criteria", "one", "must", "define", "risk", "levels", "according", "to", "the", "specific", "criterion", "and", "design", "a", "distance", "matrix", "(", "used", "by", "the", "EMD", ")", "that", "properly", "captures", "the", "intended", "notion", "of", "nearness", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "earth mover 's distance"}, {"tokens": ["These", "SAR", "slices", "are", "randomly", "cropped", "from", "SAR", "scene", "images", "covering", "various", "landscapes", "from", "TerraSAR", "-", "X", ",", "a", "German", "Earth", "-", "observation", "satellite", "which", "provides", "high", "-", "quality", "and", "precise", "earth", "observation", "data", "of", "3", "m", "resolution", "with", "StripMap", "mode", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["The", "two", "very", "close", "sharp", "spikes", "followed", "by", "drops", "in", "both", "indices", "values", "corresponds", "the", "spike", "for", "the", "wind", "before", "the", "snow", "and", "the", "snow", "fall", "as", "identified", "by", "OEC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "online elliptical clustering"}, {"tokens": ["At", ":", "Campinas", "e", "de", "setembro", "de", "2016", ",", "SP", "-", "Brazi", ",", "available", "in", "https://www.fee.unicamp.br/sites/default/files/departamentos/dca/eadca/eadcaix/artigos/carvalho_et_al.pdf"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "sao paulo"}, {"tokens": ["buckler", "investigated", "the", "impact", "of", "ISP", "stages", "on", "different", "CV", "algorithms", ",", "and", "proposed", "a", "sensor", "design", "with", "adjustable", "precision", "and", "subsampling", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Difference", "between", "SC", "ST", "subsetsFrom", "Fig", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0], "long_form": "subset compared"}, {"tokens": ["All", "of", "the", "challenges", "of", "SAR", "for", "learning", "are", "significantly", "amplified", "in", "the", "ASD", "context", ",", "but", "ASD", "is", "also", "the", "context", "where", "the", "success", "of", "SAR", "in", "supporting", "learning", "is", "especially", "promising", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["As", "presented", "in", "tab", ":", "mscoco", ",", "our", "StackGAN", "with", "added", "object", "pathways", "outperforms", "the", "original", "StackGAN", "both", "on", "the", "IS", "and", "the", "FID", ",", "increasing", "the", "IS", "from", "to", "and", "decreasing", "the", "FID", "from", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["Next", ",", "we", "present", "a", "framework", "using", "DCNN", "that", "can", "be", "trained", "effectively", "and", "robustly", "with", "a", "small", "number", "of", "training", "examples", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Note", "that", "there", "is", "a", "dual", "adversarial", "process", "in", "DADA", ",", "which", "is", ",", "to", "the", "best", "of", "our", "knowledge", ",", "the", "first", "time", "to", "explore", "a", "dual", "adversarial", "strategy", "in", "domain", "adaptation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dual adversarial domain adaptation"}, {"tokens": ["[", "t", "]", "Comparison", "of", "both", "heuristic", "(", "denoted", "by", "H", ":", ")", "and", "ceiling", "(", "denoted", "by", "C", ":", ")", "performance", ",", "in", "terms", "of", "Acc", ",", "of", "AP", "and", "EAP", "on", "real", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["[", "c]0.49", "*", "DenseNet-121", "CIFAR100", "Comparison", "of", "ECE", "performance", "between", "TS", "and", "BNN", "in", "test", "and", "validation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature scaling"}, {"tokens": ["However", ",", "for", "a", "conventional", "DM", "network", ",", "there", "still", "exists", "a", "serious", "secure", "issue", ":", "the", "eavesdropper", "moves", "inside", "the", "main", "beam", "of", "the", "desired", "user", "and", "may", "intercept", "the", "confidential", "messages", "intended", "to", "the", "desired", "users", "because", "the", "beamforming", "vector", "of", "confidential", "messages", "and", "AN", "projection", "matrix", "are", "only", "angle", "-", "dependence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Therefore", ",", "we", "aim", "to", "select", "a", "TAS", "pattern", "of", "maximizing", "the", "minimum", "Euclidean", "distance", "over", "desired", "channel", "or", "minimizing", "the", "minimum", "Euclidean", "distance", "over", "eavesdropping", "channel", ",", "which", "are", "formulated", "as", "followsHere", ",", "we", "obtain", "two", "TAS", "patterns", "by", "(", ")", "and", "(", ")", ",", "then", "we", "select", "the", "one", "which", "results", "in", "higher", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["Neural", "processes", "(", "NP", ")", "garnelo2018conditional", ",", "garnelo2018neural", "are", "latent", "variable", "models", "that", "bring", "all", "the", "advantages", "of", "deep", "learning", "(", "e.g.", ",", "representation", "learning", "and", "computationally", "efficient", "training", "and", "prediction", ")", "to", "the", "stochastic", "process", "framework", "and", "can", "address", "the", "problems", "described", "above", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["One", "of", "the", "drawbacks", "of", "most", "current", "CF", "techniques", "is", "that", "they", "model", "users", "and", "items", "just", "based", "on", "the", "numeric", "ratings", "provided", "by", "users", "and", "ignore", "the", "abundant", "information", "existed", "in", "the", "review", "text", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["that", "obtained", "by", "the", "exhaustive", "UE", "search", "algorithm", "with", "an", "exponential", "computational", "complexity", "over", "the", "number", "of", "admitted", "UEs", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "this", "procedure", ",", "the", "solution", "of", "a", "reduced", "OPF", "problem", "is", "tested", "against", "all", "constraints", "of", "the", "full", "problem", ",", "the", "active", "set", "is", "extended", "by", "constraints", "that", "are", "violated", ",", "and", "a", "new", "reduced", "OPF", "problem", "is", "constructed", "and", "solved", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["proposed", "the", "PSO", "algorithm", "for", "solving", "energy", "management", "of", "a", "hybrid", "generation", "system", "(", "HGS", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["In", "early", "development", ",", "MD", "scalar", "quantizers", "constrained", "by", "the", "symmetric", "entropy", "are", "formed", "as", "an", "optimization", "problem", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["Ideally", ",", "we", "need", "more", "empirical", "evidence", "in", "the", "spirit", "of", "the", "Beseme", "project", "(", ")", "that", "such", "courses", "are", "useful", "for", "IS", "practitioners", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information systems"}, {"tokens": ["In", "Figure", "7", ",", "we", "see", "the", "ROC", "curve", "of", "the", "meta", "-", "learner", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "LR", "objective", "uses", "logistic", "loss", "to", "minimize", "the", "empirical", "risk", "and"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["GPS", "technology", "is", "also", "used", "to", "track", "the", "location", "of", "the", "dengue", "infected", "patients", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["However", ",", "when", "is", "not", "known", "beforehand", ",", "which", "is", "the", "entire", "point", "of", "DE", ",", "one", "can", "penalize", "the", "hidden", "layer", "entries", "so", "that", "they", "are", "encouraged", "to", "be", "small", ",", "or", "even", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["In", "the", "NP", "framework", ",", "a", "distribution", "over", "functions", "is", "modeled", "by", "learning", "an", "approximation", "to", "a", "stochastic", "process", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["Table", "shows", "the", "geometric", "dimensions", "of", "all", "parts", "in", "FEM", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "finite element method"}, {"tokens": ["A", "node", "is", "chosen", "randomly", "from", "the", "innermost", "core", "and", "its", "connection", "with", "a", "node", "is", "removed", "if", "the", "nodes", "and", "show", "assortativeness", "and", "the", "node", "also", "holds", "higher", "BC", "values", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["The", "ROC", "curves", "for", "the", "Cholec80", "dataset", "using", "GM", "-", "LoG", "features", "for", "smoke", "/", "non", "-", "smoke", "classification", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient magnitude"}, {"tokens": ["The", "following", "positive", "step", "size", "quantity", "relates", "the", "dual", "certificate", "value", "of", "the", "descent", "direction", "with", "the", "MP", "selected", "atom", ",", "for", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["QA", "is", "a", "kind", "of", "randomized", "algorithms", ",", "which", "prepares", "random", "parameters", "utilizing", "a", "quantum", "transition", ",", "and", "performs", "a", "local", "optimization", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "quantum annealing"}, {"tokens": ["Consequently", ",", "we", "will", "introduce", "some", "typical", "literatures", "on", "SAR", "target", "recognition", "with", "transfer", "learning", "methods", "in", "this", "section", "firstly", ",", "and", "then", "followed", "by", "several", "related", "literatures", "about", "transfer", "learning", "and", "domain", "adaptation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["[", ",", ",", "]", "&", "&", "&", "Linear", "regression", "models", "for", "the", "CNS", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["The", "future", "works", "cover", "the", "following", "topics", ":", "evaluation", "of", "the", "method", "for", "a", "wider", "range", "of", "interconnecting", "network", "speeds", "and", "larger", "number", "of", "nodes", "using", "a", "simulation", "tool", "e.g.", ",", "expansion", "of", "the", "method", "for", "other", "collective", "communication", "algorithms", ",", "e.g.", "all", "-", "gather", ",", "a", "framework", "for", "automatic", "PAP", "detection", "and", "proper", "algorithm", "selection", ",", "e.g.", "providing", "a", "regular", "ring", "for", "balanced", "PAPs", "and", "PRR", "for", "imbalanced", "ones", ",", "introduction", "of", "the", "presented", "PAT", "estimation", "method", "for", "other", "purposes", "e.g.", "asynchronous", "SDG", "training", "or", "deadlock", "and", "race", "detection", "in", "distributed", "programs", ",", "deployment", "of", "the", "solution", "in", "a", "production", "environment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival time"}, {"tokens": ["Comparative", "ApproachesFlat", "MethodsLogistic", "Regression", "(", "LR", ")"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0], "long_form": "logistic regression"}, {"tokens": ["Then", "it", "uses", "deep", "3D", "DPN", "to", "extract", "deep", "features", "from", "the", "detected", "and", "cropped", "nodules", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dual path network"}, {"tokens": ["We", "also", "provide", "an", "extensive", "analysis", "of", "the", "investigated", "grids", "as", "well", "as", "an", "empirical", "limit", "of", "performance", "of", "machine", "learning", "techniques", "providing", "optimal", "OPF", "solutions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Additionally", ",", "as", "the", "PA", "factor", "increases", "from", "0", "to", "1", ",", "the", "achievable", "SR", "increases", "accordingly", "in", "the", "low", "SNR", "region", "whereas", "it", "first", "increases", "and", "then", "decreases", "in", "the", "medium", "and", "high", "SNR", "regions", ",", "where", "the", "SR", "can", "be", "approximately", "viewed", "as", "a", "convex", "function", "of", "the", "PA", "factor", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power allocation"}, {"tokens": ["Another", "challenge", "is", "to", "allow", "autonomous", "UAVs", "that", "can", "maneuver", "an", "indoor", "environment", "with", "no", "access", "to", "GPS", "signals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Some", "approaches", "also", "combine", "CF", "with", "content", "features", "into", "hybrid", "recommender", "systems", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["This", "is", "probably", "because", "that", "the", "excitation", "vector", "derives", "from", "information", "directly", "in", "the", "preceding", "layer", "-", "an", "inherent", "design", "inpSENet", ";", "whilst", "our", "MAD", "comes", "from", "higher", "-", "level", "summation", ",", "leveraging", "the", "guidance", "of", "high", "-", "level", ",", "region", "-", "based", "semantics", "to", "merge", "local", "details", "in", "lower", "layers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["As", "can", "be", "observed", ",", "the", "GCNN", "model", "relies", "on", "less", "complicated", "features", "than", "the", "other", "methods", ",", "and", "therefore", "requires", "less", "computational", "time", "during", "feature", "extraction", ",", "at", "the", "cost", "of", "a", "higher", "prediction", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["First", ",", "we", "applied", "Deep", "Learning", "methods", "to", "classify", "each", "cropped", "steel", "object", "as", "illustrated", "in", "Figure", "from", "SEM", "or", "LOM", "images", "which", "we", "call", "object", "-", "based", "microstructural", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["In", "order", "to", "deploy", "an", "FL", "algorithm", ",", "it", "is", "necessary", "to", "train", "the", "underlying", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["On", "the", "other", "hand", ",", "regarding", "the", "correctly", "classified", "samples", ",", "the", "BNN", "not", "only", "adjusts", "the", "confidence", "better", ",", "but", "also", "classifies", "these", "samples", "with", "higher", "confidence", "than", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "temperature scaling"}, {"tokens": ["Using", "this", "information", ",", "the", "AP", "can", "identify", "the", "worst", "channel", "'s", "condition", "and", "then", "adjust", "the", "transmission", "rate", "and", "FEC", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "approach", "taken", "by", "Igarashi", ",", "Pierce", "and", "Wadler", "is", "instead", "to", "omit", "many", "features", "of", "Java", "obtaining", "an", "elegant", "and", "small", "calculus", ",", "i.e.", ",", "FJ", ",", "suitable", "for", "extensions", "and", "variations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "featherweight java"}, {"tokens": ["However", ",", "the", "results", "show", "that", "RQI", "was", "much", "faster", "and", "required", "far", "fewer", "Krylov", "and", "eigenvalue", "iterations", "than", "PI", "for", "this", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["Figure", "shows", "the", "distribution", "of", "lengths", "over", "documents", "of", "LSC", "before", "and", "after", "removing", "documents", "containing", "less", "than", "30", "and", "more", "than", "500", "words", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["demonstrates", "the", "average", "SR", "for", "the", "three", "TAS", "methods", "described", "in", "Section", "-", "III", "with", "and", ",", "where", "the", "random", "TAS", "method", "is", "used", "for", "performance", "reference", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["discussed", "fuzzy", "-", "adaptive", "PSO", "(", "FAPSO", ")", "algorithm", "for", "minimizing", "distribution", "network", "loss", "using", "optimum", "load", "response", "to", "the", "consumers", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Like", "the", "LSTMS", ",", "the", "s", "-", "RNNs", "generally", "performed", "worse", "in", "the", "SP", "4", "and", "8", "experiments", "than", "the", "SL", "4", "and", "8", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["In", "this", "case", ",", "we", "also", "trained", "High", "to", "low", "networks", "(", "and", ")", "using", "training", "images", "from", "Tinyface", "dataset", "as", "real", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["This", "meshes", "well", "with", "the", "idea", "that", "the", "AI", "of", "PennAI", "will", "aid", "non", "-", "machine", "-", "learning", "experts", "run", "complex", "algorithms", ",", "such", "as", "GP", ",", "without", "having", "to", "find", "or", "even", "understand", "every", "single", "parameter", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Bundle", "adjustment", "(", "BA", ")", ",", "is", "an", "indispensable", "procedure", "in", "the", "SFM", ",", "and", "use", "a", "basic", "cost", "function", "to", "evaluate", "the", "reprojection", "error", "from", "Undistorted", "to", "Distorted", "image", "domain", "with", "non", "-", "linear", "least", "square", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bundle adjustment"}, {"tokens": ["The", "MGM", "GAN", "architecture", "first", "extracts", "the", "latent", "representations", "of", "the", "data", "from", "an", "autoencoder", "to", "approximate", "the", "data", "manifold", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["In", "particular", ",", "PI", "was", "not", "able", "to", "converge", "before", "the", "wall", "time", "limit", "was", "reached", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["The", "number", "of", "documents", "(", "n", ")", "versus", "the", "number", "of", "LScD", "words", "contained", "in", "n", "or", "less", "documents", "in", "the", "LSC", "for", "those", "words", "appearing", "in", "at", "most", "20", "documents", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["The", "ZF", "precoder", "is", "utilized", ",", "and", "the", "CSI", "is", "obtained", "at", "the", "AP", "by", "receivers", "'", "feedback", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["MDC", "dataset", ":", "correlation", "between", "the", "four", "dimensions", "of", "social", "and", "spatial", "behaviour", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["These", "can", "be", "roughly", "grouped", "into", "two", "major", "categories", ":", "pixel", "-", "level", "and", "cell", "-", "level", "metric", ",", "where", "NPR", "belongs", "to", "cell", "-", "level", "measure", "and", "the", "others", "are", "pixel", "-", "level", "measures", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized probabilistic rand"}, {"tokens": ["We", "also", "display", "the", "results", "of", "ICA", ",", "which", "has", "a", "squared", "estimation", "errors", "for", "the", "unmixed", "signals", "of", ",", "and", "SOBI", ",", "which", "has", "an", "error", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["Furthermore", ",", "its", "detection", "accuracy", "is", "similar", "to", "SDR", "with", "nearly", "10-fold", "reduction", "of", "computational", "complexity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semidefine relaxation"}, {"tokens": ["The", "second", "and", "third", "column", "were", "synthesized", "with", "OT", "and", "patch", "size", "4", "and", "7", "respectively", ",", "the", "fourth", "image", "with", "and", "a", "patch", "size", "of", "4", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Caudell", "and", "Mizell", "coining", "AR", "in", "1992", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["(", "ECC", "on", ")", "&", "3cK40c"], "acronym_pos": [0, 1, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["The", "dataset", "contains", "registered", "images", "of", "steels", "taken", "by", "LOM", "and", "SEM", "and", "the", "corresponding", "binary", "LOM", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["The", "single", "condensation", "method", "is", "employed", "to", "convert", "these", "functions", "to", "posynomials", "as", "described", "below", ":", "The", "single", "condensation", "method", "for", "GP", "involves", "upper", "bounds", "on", "the", "ratio", "of", "a", "posynomial", "over", "a", "posynomial", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["We", "report", "both", "the", "DP", "rates", "at", "the", "conventional", "threshold", "of", "20", "pixels", "(", "DPR", ")", "and", "the", "OS", "rates", "at", "the", "threshold", "of", "0.5", "(", "OSR", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "overlap success"}, {"tokens": ["Therefore", ",", "the", "MDC", "is", "executed", "in", "a", "special", "Python", "interpreter", "that", "was", "generated", "with", "SCONE", "(", "as", "detailed", "in", "Sections", "sec", ":", "scone", "and", "sec", ":", "pythonSGX", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "metering data collector"}, {"tokens": ["Experimental", "results", "show", "that", ":", "(", "1", ")", "global", "normalization", "makes", "QA", "model", "more", "stable", "while", "pinpointing", "answers", "from", "large", "number", "of", "passages", ";", "(", "2", ")", "splitting", "articles", "into", "passages", "with", "the", "length", "of", "100", "words", "by", "sliding", "window", "brings", "4", "improvements;(3", ")", "leveraging", "a", "BERT", "-", "based", "passage", "ranker", "gives", "us", "extra", "2", "improvements;and", "(", "4", ")", "explicit", "inter", "-", "sentence", "matching", "is", "not", "helpful", "for", "BERT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["For", "HP", "scheduling", ",", "the", "nodes", "with", "high", "PRR", "occupy", "the", "SDTP", "for", "multiple", "super", "frames", "until", "they", "finish", "the", "transmissions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "packet reception rate"}, {"tokens": ["Overall", "resultsTo", "further", "understand", "the", "MINT", "-", "FEC", "achievements", ",", "a", "comparison", "against", "CLM", "-", "UEP", "and", "uavFEC", "is", "given", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["However", ",", "overall", "results", "from", "open", "set", "experiments", "confirm", "the", "need", "for", "a", "more", "systematic", "approach", "to", "open", "-", "set", "AA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "authorship attribution"}, {"tokens": ["Atomic", "predicates", ",", "Boolean", "operators", ",", "and", "the", "time", "bounded", "until", "operator", "are", "those", "of", "STL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "signal temporal logic"}, {"tokens": ["The", "Receiver", "Operating", "Characteristic", "(", "ROC", ")", "curves", "(", "Appendix", ")", "illustrate", "all", "trade", "-", "offs", "points", "between", "TP", "and", "FP", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["CO", ",", "PA", ",", "CG", "correspond", "to", "context", "-", "only", "attention", ",", "parallel", "attention", "and", "context", "-", "guided", "attention", "respectively", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parallel attention"}, {"tokens": ["In", "addition", ",", "inertia", "weight", "has", "positive", "affect", "convergence", "rate", "in", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "particle swarm optimization"}, {"tokens": ["For", "example", ",", "predicting", "entity", "recognition", "tag", "at", "lower", "layers", "or", "inserting", "predicate", "features", "at", "higher", "layers", "in", "an", "LSTM", ",", "because", "entity", "recognition", "does", "not", "need", "predicates", "as", "features", "and", "is", "considered", "as", "a", "lower", "-", "level", "task", "compared", "to", "SRL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "semantic role labeling"}, {"tokens": ["Well", ",", "IFT", "explains", "how", "people", "make", "decisions", "to", "move", "from", "one", "place", "to", "another", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information foraging theory"}, {"tokens": ["ECS", "-", "DBN", "shows", "a", "higher", "computational", "cost", "that", "is", "mainly", "due", "to", "the", "evolutionary", "algorithm", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["In", "Section", "particle_filter", ",", "we", "will", "consider", "a", "SIR", "PF", "with", "systematic", "resampling", "because", "it", "ranks", "higher", "in", "resampling", "quality", "and", "computational", "simplicity", "compared", "to", "other", "resampling", "methodsphol_resampling_2006", ",", "douc_comparison_2005", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential importance resampling"}, {"tokens": ["majorDTI17", "major", "DTI", "fiber", "bundles", "measured", "using", "Fractional", "Anisotropy", "(", "FA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "fractional anisotropy"}, {"tokens": ["In", "order", "to", "use", "the", "additional", "synthetic", "data", ",", "an", "IB", "approach", "must", "take", "more", "gradient", "steps", "with", "imaginary", "batches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imaginary batches"}, {"tokens": ["On", "the", "right", ",", "comparison", "of", "the", "speedups", "of", "GMB", "on", "BA", "and", "of", "IA", "on", "RK", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "incremental approximation"}, {"tokens": ["Using", "TS", "a", "grid", "mesh", "can", "be", "smoothed", ",", "making", "it", "easier", "to", "add", "details", ",", "thus", "we", "can", "also", "explore", "LOD", "and", "multi", "-", "resolution", "approaches", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tessellation shader"}, {"tokens": ["[", "HAP", "[", "Aircraft", "[", "Helios(NASA)Heliplat(Europe", ")", "]", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "high altitude platform"}, {"tokens": ["Past", "WorkThis", "section", "is", "a", "summary", "of", "results", "using", "RQI", "without", "preconditioning", "and", "the", "MGE", "preconditioner", "with", "fixed", "source", "problems", "or", "PI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "power iteration"}, {"tokens": ["There", "was", "a", "decrease", "in", "the", "number", "of", "long", "capillary", "segments", "in", "the", "aged", "animals", "compared", "to", "young", "in", "both", "the", "WT", "and", "AD", "groups", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "wild type"}, {"tokens": ["As", "traditionally", "done", "in", "SP", ",", "their", "approach", "involves", "learning", "individual", "models", "for", "each", "parallel", "dataset", "or", "language", "pair", ",", "e.g.", ",", "(", ",", "Java", ")", ",", "(", ",", "PHP", ")", ",", "and", "(", ",", "Haskell", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic parsing"}, {"tokens": ["Furthermore", ",", "it", "is", "assumed", "that", "the", "URLLC", "UE", "follows", "a", "high", "degree", "biased", "random", "walk", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "order", "to", "eliminate", "any", "potential", "presentation", "bias", ",", "the", "image", "sets", "were", "shown", "alternating", "for", "the", "environments", ",", "so", "that", "half", "the", "participants", "saw", "the", "set", "A", "images", "on", "the", "SDD", "and", "set", "B", "images", "on", "the", "TDW", ",", "and", "vice", "-", "versa", "for", "the", "rest", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["In", "the", "OEC", "clustering", "algorithm", ",", "the", "first", "points", "are", "used", "to", "calculate", "a", "single", "cluster", "prototype", "and", "the", "cluster", "evaluation", "starts", "from", "point", "with", "only", "one", "cluster", "in", "the", "system", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["In", "the", "case", "of", "augmentation", ",", "injecting", "noise", "in", "all", "instances", "of", "a", "single", "subset", "of", "attributes", "is", "not", "challenging", "for", "the", "network", "because", "the", "ANN", "will", "simply", "neglect", "these", "attributes", "during", "training", "by", "inhibiting", "the", "corresponding", "network", "nodes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "GP", "prior", "mean", "can", "be", "directly", "sampled", "from", "the", "conditional", "posterior", "given", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["As", "we", "have", "investigated", "using", "a", "USB3.0", "Yoshoo", "power", "monitor", "(", "see", "Figure", ")", "with", "USB2.0", ",", "AC", "wall", "chargers", "and", "an", "external", "battery", "pack", ",", "the", "maximum", "charging", "current", ",", "(", ")", "drawn", "by", "the", "charging", "controller", "can", "be", "defined", "as", "during", "the", "CC", "phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "charging current"}, {"tokens": ["Theoretically", ",", "computer", "malware", "could", "also", "find", "new", "ways", "to", "exploit", "software", "or", "different", "OS", "APIs", "for", "spreading", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "operating system"}, {"tokens": ["To", "compare", "the", "performance", "of", "the", "NPC", "minimization", "algorithm", ",", "the", "performance", "of", "the", "conventional", "transmit", "power", "minimization", "is", "also", "considered", ",", "where", "all", "the", "RRHs", "in", "each", "UE", "'s", "candidate", "set", "are", "assumed", "to", "be", "active", ".", "'"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["P.", "Mogensen", ",", "W.", "Na", ",", "I.", "Kovacs", ",", "F.", "Frederiksen", ",", "A.", "Pokhariyal", ",", "K.", "Pedersen", ",", "T.", "Kolding", ",", "K.", "Hugl", ",", "and", "M.", "Kuusela", ",", "\"", "LTE", "capacity", "compared", "to", "the", "shannon", "bound", ",", "\"", "in", "Proc", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["As", "for", "the", "AL", "query", "method", ",", "in", "the", "single", "-", "task", "SRL", ",", "we", "used", "random", "and", "uncertainty", "sampling", "query", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["Since", "is", "strongly", "connected", ",", "it", "still", "recognises", ",", "and", "since", "it", "is", "deterministic", "it", "is", "a", "witness", "that", "is", "DBP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "determinisable by pruning"}, {"tokens": ["We", "employ", "two", "recent", "deep", "learning", "based", "methods", ",", "SRGAN", "and", "ESRGAN", "to", "resolve", "given", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["Additionally", ",", "several", "enhancement", "techniques", "have", "been", "proposed", "for", "the", "ARQ", "methods", ",", "including", "some", "in", "combination", "with", "FEC", "-", "based", "schemes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Proposed", "General", "Power", "Allocation", "Strategy", "of", "Max", "-", "SRBefore", "investigating", "PA", ",", "let", "us", "consider", "the", "joint", "optimization", "problem", "of", "Max", "-", "SR", ",", "which", "is", "casted", "aswhere", "the", "three", "optimization", "variables", "are", "the", "PA", "factor", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["The", "third", "experiment", "compares", "our", "MSC", "-", "trackers", "with", "the", "top", "-", "performing", "CF", "-", "based", "trackers", "with", "deep", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "correlation filter"}, {"tokens": ["PRA", "has", "papers", "with", "small", "groups", ",", "shows", "minimal", "gradient", "in", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "collaboration coefficient"}, {"tokens": ["If", "the", "device", "is", "not", "utilized", ",", "the", "battery", "would", "receive", "the", "maximum", "constant", "charging", "current", "from", "the", "charger", "during", "CC", "period", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "constant charging"}, {"tokens": ["Results", "on", "the", "LA", "and", "PA", "development", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["Using", "the", "proposed", "approach", "we", "can", "perform", "full", "3D", "segmentation", "without", "explicit", "motion", "correction", "and", "do", "not", "have", "to", "rely", "on", "LR", "slice", "-", "by", "-", "slice", "2D", "segmentation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Indeed", ",", "weight", "initialization", "in", "standard", "CNNs", "relies", "on", "the", "number", "of", "input", "units", "to", "normalize", "the", "initial", "weights", ",", "which", "in", "a", "GCNN", "is", "unknown", "beforehand", "and", "depends", "on", "the", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["72", "tokens", "/", "utterance", ")", "breeds", "CDA"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1], "long_form": "concurrent dialogue acts"}, {"tokens": ["The", "AP", "then", "replies", "with", "an", "extended", "CTS", "that", "grants", "concurrent", "transmissions", "to", "the", "requesting", "STAs", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["QSM", "models", "from", "the", "TLS", "scans", "were", "made", "by", "and", "are", "the", "property", "of", "Pasi", "Raumonen", ",", "pasi.raumonen@tut.fi", ",", "Tampere", "University", "of", "Technology", ",", "Korkeakoulunkatu", "10", ",", "33720"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "terrestrial laser scanning"}, {"tokens": ["In", "most", "cases", "because", "of", "the", "larger", "number", "of", "clusters", "and", "lower", "accuracy", "of", "sk", "-", "means", "in", "finding", "the", "expected", "clusters", ",", "the", "scale", "of", "the", "iCVI", "values", "for", "the", "sk", "-", "means", "approach", "is", "much", "higher", "than", "the", "values", "corresponding", "to", "OEC", "clusters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["We", "have", "derived", "the", "time", "and", "energy", "consumption", "models", "for", "FL", "based", "on", "the", "convergence", "rate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["The", "comparison", "of", "the", "LS", ",", "LMMSE", ",", "and", "DL", "estimators", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["In", "a", "SISO", "AWGN", "channel", ",", "studies", "the", "R", "-", "E", "tradeoffs", "of", "both", "SepRx", "and", "IntRx", "using", "TS", "and", "PS", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "accuracy", "of", "recognizing", "spoken", "words", "has", "a", "vital", "influence", "on", "the", "success", "of", "the", "whole", "QA", "process", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["In", "contrast", ",", "QA", "systems", "must", "return", "an", "exact", "answer", "to", "the", "question", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["For", "each", "type", "of", "motion", "primitive", "GMM", "models", ",", "the", "input", "and", "output", "parameters", "are", "separated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["We", "chose", "random", "samples", "of", "and", "of", "the", "training", "data", ",", "generating", "867", "and", "1734", "noisy", "labels", ",", "on", "WikiQA", ",", "respectively", ",", "and", "5341", "and", "10683", "noisy", "labels", ",", "on", "TREC", "-", "QA", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["However", ",", "pseudo", "-", "labels", "can", "be", "quite", "noisy", "even", "if", "BNN", "is", "employed", "to", "estimated", "their", "reliability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian neural networks"}, {"tokens": ["The", "proposal", "seeks", "to", "reduce", "the", "end", "-", "to", "-", "end", "delay", "and", "FEC", "computational", "costs", "at", "the", "same", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "this", "way", ",", "the", "augmented", "likelihood", "becomes", "conjugate", "to", "a", "GP", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["All", "models", "consistently", "attribute", "importance", "to", "the", "same", "variables", ",", "mostly", "changes", "in", "GDP", "and", "prices", ",", "but", "also", "the", "policy", "rate", ",", "the", "money", "supply", "and", "private", "debt", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gross domestic product"}, {"tokens": ["We", "suggest", "the", "following", "(", "skeletal", ")", "protocol", "for", "signature", "verification", ":", "Step", "0", ":", "Alice", "verifies", "its", "identity", "and", "provides", "a", "set", "of", "reference", "signatures", "to", "TTP", "(", "such", "as", "the", "bank", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "trusted third party"}, {"tokens": ["We", "also", "use", "the", "extracted", "envelope", "from", "fast", "spectral", "kurtosis", "method", "to", "perform", "a", "similar", "ROC", "analysis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["[", ",", ",", "]", "Linear", "regression", "models", "for", "the", "MDC", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["Aside", "from", "the", "probabilistic", "CER", "correction", ",", "no", "CTC", "alignment", "or", "CCA", "post", "correction", "was", "applied", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["These", "parameters", "are", "forgetting", "factor", ",", "effective", "cluster", "boundary", "and", "outlier", "boundary", "threshold", "of", "0.99", "and", "0.999", "respectively", ",", "a", "stabilization", "period", "of", ",", "and", "and", "an", "OEC", "forgetting", "factor", "\ud835\udecc.The", "two", "clustering", "algorithms", "have", "slightly", "different", "initialization", "procedures", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["The", "production", "is", "estimated", "as", ":", "After", "September", ",", "the", "growing", "season", "is", "over", "and", "the", "crop", "yield", "can", "be", "estimated", "using", "EO", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "earth observation"}, {"tokens": ["On", "the", "left", ",", "speedups", "of", "IA", "on", "RK", "on", "the", "coPapersCiteseer", "network", ",", "run", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "incremental approximation"}, {"tokens": ["The", "source", "-", "destination", "pairs", "act", "as", "bidders", "which", "bid", "for", "the", "FJ", "power", "from", "the", "friendly", "jammer", "as", "the", "auctioneer", ",", "i.e.", ",", "the", "seller", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["As", "directly", "increasing", "the", "number", "of", "layers", "or", "the", "number", "of", "neurons", "for", "the", "neural", "network", "has", "no", "statically", "significant", "improvement", ",", "we", "do", "not", "conduct", "MD", "and", "UD", "here", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "model distillation"}, {"tokens": ["Although", "the", "situation", "since", "2011", "has", "improved", ",", "with", "the", "limited", "introduction", "of", "some", "new", "Log", "IS", ",", "many", "examples", "of", "manual", "reconciliation", "still", "exist", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["In", "SR", "application", ",", "AL", "enables", "the", "SR", "network", "to", "hallucinate", "fine", "texture", "detail", ",", "and", "the", "synthesized", "HR", "images", "appear", "qualitatively", "more", "realistic", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["Even", "it", "is", "possible", "that", "CF", "considers", "only", "a", "few", "rating", "for", "popular", "items", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Parallel", "to", "the", "Words", "-", "Sequence", ",", "POS", "tags", "Sequence", "is", "partitioned", "into", "three", "parts", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": [",", "Algorithm", ")", "and", "UE", "selection", "algorithm", "(", "i.e.", ",", "Algorithm", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Figure", "(", "a", ")", "and", "(", "b", ")", "show", "AP", "and", "gain", "ratios", "of", "each", "class", "before", "and", "after", "progressive", "instance", "-", "switching", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["shows", "the", "dispatch", "plan", "(", "in", "black", ")", ",", "the", "prosumption", "realization", "(", "dashed", "red", ")", "and", "the", "realization", "at", "the", "GCP", "(", "gray", "shaded", "area", ")", ":", "the", "prosumption", "realization", "differs", "from", "the", "dispatch", "plan", "due", "to", "forecasting", "errors", ",", "whereas", "the", "realization", "at", "the", "GCP", ",", "which", "is", "corrected", "by", "controlling", "the", "contribution", "of", "the", "battery", "and", "curtailable", "PV", "facility", ",", "achieves", "a", "good", "tracking", "of", "the", "dispatch", "plan", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "grid connection point"}, {"tokens": ["Similarly", ",", "we", "call", "the", "standard", "GP", "-", "UCB", "as", "GP", "-", "UCB", "with", "current", "variance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Among", "the", "non", "variational", "methods", ",", "the", "VCC", "theory", "constitutes", "a", "robust", "way", "to", "get", "precision", "out", "of", "small", "spaces", "with", "a", "computational", "cost", "sharply", "increasing", "with", "the", "level", "of", "excitations", "exponentially", "deployed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vibrational coupled cluster"}, {"tokens": ["The", "ViSTRA2", "coding", "framework", "has", "been", "integrated", "into", "the", "HEVC", "(", "HM", "16.20", ")", "and", "VVC", "(", "VTM", "4.01", ")", "reference", "software", ",", "and", "has", "been", "fully", "tested", "under", "JVET", "CTC", "using", "the", "Random", "Access", "configuration", "(", "Main10", "profile", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "common test conditions"}, {"tokens": ["Since", "the", "only", "difference", "between", "the", "proposed", "method", "and", "DCNN", "is", "the", "discrepancy", "between", "the", "convolutional", "block", "and", "the", "proposed", "FM", "block", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["It", "only", "reinforces", "the", "relevance", "of", "using", "adaptive", "FEC", "mechanisms", ",", "which", "take", "into", "consideration", "the", "motion", "intensity", "and", "packet", "loss", "prediction", "to", "protect", "a", "video", "streaming", "with", "fluctuating", "characteristics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Currently", "RIRs", "charge", "a", "fee", "for", "each", "PI", "allocation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "provider independent"}, {"tokens": ["The", "layers", "of", "first", "part", "are", "C(1", ",", "64", ",", "3)-C(64", ",", "64", ",", "3)-MP", "-", "C(64", ",", "128", ",", "3)-C(128", ",", "128", ",", "3)-MP", "-", "C(128", ",", "128", ",", "3", ")", "where", "C", "(", ",", ",", ")", "denotes", "the", "convolution", "layer", "with", "channels", "of", "input", ",", "channels", "of", "output", "and", "convolution", "kernel", "and", "MP", "denotes", "max", "pooling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "max pooling"}, {"tokens": ["The", "remarkable", "properties", "of", "PS", "has", "encouraged", "extensions", "to", "several", "settings", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["Then", ",", "the", "probability", "that", "a", "sensor", "outside", "the", "backbone", "network", "is", "not", "connected", "to", "the", "AP", "in", "its", "next", "move", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["However", ",", "for", "all", "three", "SNR", "values", ",", "the", "four", "TAS", "methods", "show", "the", "same", "SR", "performance", "trend", ":", "Max", "-", "SR", "leakage", "-", "based", "generalized", "EDAS", "random", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["So", "a", "DBN", "can", "be", "viewed", "as", "an", "RBM", "that", "defines", "a", "prior", "over", "the", "top", "layer", "of", "hidden", "variables", "in", "a", "directed", "belief", "net", ",", "combined", "with", "a", "set", "of", "\u201c", "recognition", "\u201d", "weights", "to", "perform", "fast", "approximate", "inference", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "BS", "broadcasts", "the", "global", "prediction", "model", "parameters", "to", "all", "users", "in", "the", "downlink", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["From", "the", "middle", "two", "rows", "of", "Table", ",", "our", "proposed", "lesion", "prior", "fusion", "method", "also", "improves", "the", "tumor", "segmentation", "performance", "of", "the", "ensemble", "of", "five", "3D", "U", "-", "Nets", ",", "particularly", "for", "the", "DSC", "of", "ET", "(", "2.1", ")", "and", "tumor", "core", "(", "1.7", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["Calculating", "the", "top", "-", "left", "corner", "of", "these", "rectangles", "(", "in", "their", "corresponding", "coordinate", "frames", ")", "and", "representing", "them", "in", "the", "coordinate", "frame", "of", "point", ",", "we", "arrive", "at", "the", "following", "four", "equations", "(", "note", "that", "these", "are", "not", "lines", ")", ":", "Results", "of", "our", "second", "strategy", "for", "estimating", "the", "upper", "bound", "AP", "(", "searching", "for", "the", "best", "bounding", "box", "or", "object", "label", "near", "a", "target", "box", ";", "among", "boxes", "with", "IOU", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["In", "this", "model", ",", "PUs", "are", "sellers", ",", "SUs", "are", "buyers", ",", "and", "the", "BS", "is", "the", "auctioneer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["This", "joint", "learning", "and", "communication", "problem", "is", "formulated", "as", "an", "optimization", "problem", "whose", "goal", "is", "to", "minimize", "a", "weighted", "sum", "of", "the", "completion", "time", "of", "FL", ",", "local", "computation", "energy", ",", "and", "transmission", "energy", "of", "all", "users", ",", "that", "captures", "the", "tradeoff", "of", "latency", "and", "energy", "consumption", "for", "FL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "federated learning"}, {"tokens": ["Unlike", "the", "voltage", "curve", ",", "the", "charging", "time", "curve", "is", "required", "to", "have", "charging", "time", "for", "all", "the", "SOCs", "within", "the", "CC", "phase", "boundary", ",", "which", "is", "equivalent", "to", "the", "first", "two", "segments", "of", "the", "voltage", "curve", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant current"}, {"tokens": ["Actually", ",", "GMM", "model", "is", "equivalent", "to", "the", "block", "sparse", "estimation", "with", "a", "block", "dictionary", "having", "blocks"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Besides", "popular", "scalable", "GP", "methods", "for", "dealing", "with", "non", "-", "Gaussian", "likelihoods", "in", "both", "single", "and", "multi", "-", "output", "scenarios", ",", "we", "focus", "in", "the", "open", "problem", "of", "heterogeneous", "likelihood", "models", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "particular", "for", "all", ",", "SL", "SL", ",", "SP", "SP", ",", "LT", "LT", ",", "PT", "PT", "and", "LTT", "LTT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["The", "intuition", "behind", "this", "is", "that", "having", "knowledge", "about", "the", "boundaries", "of", "the", "whole", "tumor", "will", "allow", "the", "CNN", "to", "become", "more", "confident", "in", "its", "predictions", "of", "ET", "and", "TC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["Mechanisms", "for", "with", "Partial", "PreferencesIn", "this", "section", ",", "we", "propose", "(", "Algorithm", "as", "extension", "of", "RP", ")", ",", "(", "Algorithm", ",", "as", "extension", "of", "PS", ")", ",", "and", "(", "Algorithm", ")", ",", "which", "can", "be", "seen", "as", "not", "only", "an", "eating", "algorithm", "but", "a", "special", "random", "priority", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["Figure", "5", "shows", "SC", "behavior", "w.r.t", "transmit", "SNR", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Technical", "Details", "of", "Deep", "Belief", "Network", "with", "Cost", "-", "sensitive", "LearningDeep", "Belief", "NetworkDeep", "Belief", "Network", "(", "DBN", ")", "is", "a", "probabilistic", "generative", "model", "stacked", "with", "several", "Restricted", "Boltzmann", "Machines", "(", "RBMs", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["As", "a", "result", ",", "the", "BS", "can", "identify", "the", "direction", "of", "the", "clusters", "which", "can", "be", "seen", "by", "the", "users", "in", "the", "cell", "area", ",", "and", "hence", "build", "up", "a", "map", "of", "the", "location", "of", "the", "scattering", "objects", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["ECS", "-", "DBN", "outperforms", "DBN", "and", "a", "group", "of", "resampling", "methods", "on", "51", "out", "of", "58", "benchmark", "datasets", "."], "acronym_pos": [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Wu", "studied", "the", "top", "-", "N", "recommendation", "problem", "and", "proposed", "a", "autoencoder", "based", "CF", "method", "wu2016collaborative", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Our", "goal", "is", "to", "perform", "GP", "regression", "once", "a", "year", "without", "forgetting", "the", "previously", "learned", "latent", "functions", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Partial", "dependence", "plots", "(", "PDP", ")", "simply", "plot", "the", "expectation", "of", "the", "marginal", "function", "on", "friedman2001greedy", ",", "which", "amounts", "to", "integrating", "out", "the", "values", "of", ":", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial dependence plots"}, {"tokens": ["(", ".south", "east", ")", "-", "(", ".south", "west", ")", ";", "[", "UAV", "classification", "based", "on", "communication", "platform", "[", "LAP", "[", "Balloon", "[", "Tethered", "Helikite", "]", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "low altitude platform"}, {"tokens": ["That", "is", "why", "CNOMA", "downlink", "transmission", "with", "PS", "based", "SWIPT", "protocol", "(", "CNOMA", "-", "SWIPT", "-", "PS", ")", "is", "a", "viable", "solution", "for", "simplicity", "and", "provides", "better", "capacities", "than", "TS", "as", "well", "[", "22]."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["Moreover", ",", "we", "further", "explored", "the", "association", "between", "age", "with", "SAT", "-", "V", "and", "VAT", "-", "V", "and", "found", "an", "obvious", "age", "effect", "on", "the", "accumulation", "of", "VAT", "-", "V", "in", "both", "men", "and", "women", ",", "and", "a", "weak", "age", "effect", "on", "SAT", "-", "V", "in", "women", "but", "not", "in", "men", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["[", "label=*)]UE", "-", "based", "GESTAGenerally", "path", "flow", "under", "the", "UE", "condition", "is", "not", "unique", "given", "O", "-", "D", "demand", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equilibrium"}, {"tokens": ["Assuming", "repetitive", "transmission", ",", "time", "slots", "are", "used", "to", "forward", "'s", "signal", "to", "in", "a", "predetermined", "order", ",", "whereas", "only", "two", "time", "slots", "are", "needed", "with", "RS", "-", "based", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["The", "first", "case", "is", "the", "comparison", "between", "CLM", "-", "UEP", "and", "MINT", "-", "FEC", ",", "and", "the", "second", "one", ",", "uavFEC", "against", "MINT", "-", "FEC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "forward error correction"}, {"tokens": ["Section", "describes", "experiments", "done", ":", "comparison", "of", "performance", "and", "an", "extensive", "evaluation", "of", "LAAV", "in", "conjunction", "with", "leading", "state", "-", "of", "-", "the", "-", "art", "RV", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "random voting"}, {"tokens": ["In", "FANET", ",", "DTN", "approach", "based", "on", "store", "-", "carry", "-", "forward", "model", "can", "be", "utilized", "to", "tackle", "the", "long", "delay", "for", "packets", "delivery", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "disruption tolerant networking"}, {"tokens": ["First", ",", "we", "solved", "the", "full", "OPF", "models", "and", "determined", "the", "binding", "constraints", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Graphs", "alignment", "and", "nodes", "matching", "for", "the", "generalised", "GM", "problem", "(", "right", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "graph matching"}, {"tokens": ["Algorithm", "for", "the", "SBMWe", "will", "first", "summarize", "the", "procedure", "used", "in", "our", "SBM", "algorithm", ",", "and", "then", "describethe", "change", "necessary", "to", "turn", "it", "into", "an", "SCF", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "highest", "accuracy", "was", "95", "and", "99", "for", "39", "speakers", "using", "GMM", "-", "UBM", "and", "i", "-", "Vector", "-", "PLDA", "based", "classifier", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["OverviewThe", "MINT", "-", "FEC", "mechanism", "aims", "to", "enhance", "the", "resilience", "of", "UAV", "real", "-", "time", "video", "transmissions", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "number", "of", "fair", "nodes", "of", "our", "algorithm", "is", "more", "than", "the", "ones", "of", "FCFS", ",", "LE", "and", "HP", "for", "200", ",", "180", ",", "155", "nodes", "when", "=", "50", "and", "N", "=", "300", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high prr"}, {"tokens": ["Such", "a", "design", "is", "denoted", "as", "'", "spatial", "MAD", "'", "in", "Table", "tab", ":", "design", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["SamplingThe", "existing", "machine", "learning", "framework", "of", "OTB", "includes", "sample", "selection", "and", "extraction", "applications", "suited", "for", "geospatial", "data", "like", "vector", "layers", "and", "RS", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "remote sensing"}, {"tokens": ["We", "discussed", "a", "regret", "guarantee", "for", "the", "proposed", "Con", "-", "TS", "-", "RTP", "algorithm", "which", "bounds", "the", "total", "number", "of", "suboptimal", "price", "signals", "broadcasted", "by", "the", "aggregator", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["demonstrate", "how", "GANs", "can", "be", "used", "for", "generation", "of", "a", "T2-weighted", "MR", "image", "from", "a", "T1-weighted", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["b", ")", "A", "straight", "-", "forward", "extension", "of", "-out", "-", "of-", "OT", "is", "-out", "-", "of-"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["A", "few", "approaches", "use", "simple", "analytic", "and", "fast", "simulators", "to", "create", "a", "GP", "prior", "of", "the", "dynamics", "(", "and", "assume", "the", "reward", "function", "to", "be", "known", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "the", "back", "-", "propagation", "phase", ",", "the", "pre", "-", "trained", "DBN", "was", "tuned", "with", "labeled", "samples", "in", "a", "supervised", "way", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["This", "mechanism", "protects", "I-", "and", "P", "-", "frames", "with", "a", "specific", "amount", "of", "redundancy", "according", "to", "the", "importance", "of", "each", "one", ";", "(", "4", ")", "the", "adaptive", "FEC", "-", "based", "mechanism", "(", "AdaptFEC", ")", ",", "which", "takes", "into", "consideration", "several", "video", "characteristics", "and", "the", "network", "state", "Immich2014", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Assume", "a", "DBN", "consists", "of", "hidden", "layer", "and", "the", "parameters", "of", "each", "layer", "by", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["For", "50", "of", "nodes", "information", ",", "the", "RV", "and", "AV", "strategy", "could", "not", "prevent", "disease", "spreading", "with", "vaccinating", "all", "nodes", "given", "their", "contact", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["A", "related", "functional", "ANOVA", "GP", "model", "decomposes", "the", "mean", "function", "into", "a", "weighted", "sum", "of", "GPs", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Green", "(", "blue", ")", "nodes", "play", "(", ")", "in", "the", "SSS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "stochastically stable states"}, {"tokens": ["This", "is", "only", "to", "serve", "as", "a", "baseline", "for", "comparison", "with", "the", "others", ";", "(", "2", ")", "a", "non", "-", "adaptive", "video", "-", "aware", "FEC", "(", "I-", "and", "P", "-", "Frames", "are", "equally", "protected", ")", "using", "a", "pre", "-", "set", "value", "of", "75", "of", "redundancy"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Then", ",", "the", "node", "will", "be", "connected", "with", "a", "node", "if", "it", "has", "higher", "-core", "value", "i.e.", ",", "and", "having", "less", "BC", ",", "i.e", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["GP", "regression", "is", "a", "Bayesian", "non", "-", "parametric", "which", "models", "a", "distribution", "over", "an", "infinite", "set", "of", "random", "variables", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Furthermore", ",", "we", "discussed", "an", "operational", "reliability", "guarantee", "that", "ensures", "the", "power", "distribution", "system", "constraints", "are", "upheld", "with", "high", "probability", "throughout", "the", "run", "of", "the", "Con", "-", "TS", "-", "RTP", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["eq5split", "ACE", ":", "="], "acronym_pos": [0, 1, 0, 0], "long_form": "average causal effect"}, {"tokens": ["So", ",", "the", "achievable", "capacity", "of", "is", "obtained", "as", "below", "by", "(", "4", ")", "and", "(", "11),Capacity", "of", "Using", "(", "5", ")", ",", "(", "6", ")", ",", "(", "8)", "and", "(", "12", ")", "the", "achievable", "capacity", "of", "for", "and", "can", "be", "achieved", "by", "following", "equation", ",", "Sum", "CapacitySo", ",", "the", "SC", "can", "be", "achieved", "by", "following", "equation", "[", "27]Whereas", ",", "and", "are", "the", "capacity", "of", "and", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "technique", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["@X", "rrrrr@", "&", "PC", "0", "&", "PC", "1", "&", "PC", "2", "&", "PC", "3", "&", "PC", "4", "CNS", "&", "0.53", "&", "0.21", "&", "0.13", "&", "0.10", "&", "0.04", "MDC", "&", "0.56", "&", "0.19", "&", "0.13", "&", "0.07", "&", "0.04", "Variance", "explained", "by", "principal", "components", "(", "only", "spatial", "data", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["This", "box", "plot", "presents", "the", "distribution", "of", "OLS", "Regression", "test", "assessing", "the", "number", "of", "interactions", "on", "a", "post", ",", "using", "the", "following", "three", "metadata", "metrics", ":", "post", "lifetime", "(", "blue", ")", ",", "number", "of", "comments", "(", "green", ")", ",", "and", "number", "of", "likes", "(", "red", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ordinary least square"}, {"tokens": ["The", "AP", "is", "chosen", "from", "the", "sixteen", "sensors", "randomly", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Training", "losses", "with", "embedded", "optimal", "transport", "divergence", "for", "EncapNet", "and", "ResNet", "(", "*", "OT", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Performance", "comparison", "of", "LR", "+", "-norm", "model", "with", "varying", "training", "size", "(", "instances", ")", "per", "class", "on", "NG", "dataset", "centering", "Table", "shows", "mean", "and", "(", "standard", "deviation", ")", "in", "bracket", "across", "five", "runs", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["=", "b.end", "(", ")", ";", "+", "+", "j", ")", "count++;The", "bitset", "and", "CRoaring", "implementations", "favor", "an", "approach", "that", "is", "reminiscent", "of", "the", "functional", "for", "-", "each", "construct", ",", "as", "implemented", "by", "STL", "'s", "std::for_each", "and", "Java", "'s", "forEach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard template library"}, {"tokens": ["[", "p", "]", "Wasserstein", "distance", "between", "GMM", "clusters", "of", "input", "gradient"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["However", ",", "the", "CER", "and", "WER", "results", "are", "computed", "on", "the", "official", "test", "set", "partitions", "in", "all", "datasets", ",", "so", "that", "those", "results", "are", "comparable", "with", "the", "literature", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["The", "system", "would", "have", "been", "solved", "with", "GS", ",", "which", "would", "have", "been", "restrictively", "slow", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gauss seidel"}, {"tokens": ["By", "automating", "transactions", ",", "SC", "promotes", "efficiency", "and", "could", "lead", "to", "structural", "changes", "in", "sectors", "that", "manage", "transactions", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "smart contract"}, {"tokens": ["Special", "attention", "is", "paid", "to", "the", "interpretation", "of", "an", "RUM", "model", "as", "the", "generator", "of", "a", "stochastic", "choice", "process", "leading", "to", "random", "demand", ",", "highlighting", "some", "implicit", "assumptions", "that", "may", "not", "be", "commonly", "acknowledged", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random utility maximization"}, {"tokens": ["Classification", "is", "used", "by", "PIN", "to", "categorize", "the", "region", "proposals", "in", "the", "Stage", "1", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "proposal indexing network"}, {"tokens": ["Simulated", "Raw", "Datasec", ":", "method", ":", "rawIn", "order", "to", "evaluate", "the", "impact", "of", "ISP", "design", "decisions", "on", "CNN", "model", "performance"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Visualized", "QA", ":", "answers", "texual", "questions", "from", "images", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["We", "focus", "on", "the", "case", "of", "a", "single", "user", "interacting", "with", "a", "RS", "model", "and", "leave", "the", "case", "of", "multi", "-", "user", "interactions", "for", "future", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["The", "UE", "device", "has", "two", "mobile", "interfaces", "or", "is", "using", "full", "duplex", "interface", "split", "equally", "between", "uplink", "and", "downlink", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "addition", ",", "the", "and", "the", "EIFS", "interval", "also", "have", "to", "be", "extended", "according", "to", "(", "as", "shown", "in", "Equation", "(", ")", ",", "where", "is", "the", "number", "of", "AP", "'s", "antennas", ")", "and", "Multi", "-", "User", "EIFS", "(", "MU", "-", "EIFS", ",", "as", "shown", "in", "Equation", "(", ")", ")", ",", "to", "take", "the", "scenario", "that", "the", "AP", "is", "involved", "in", "collisions", "into", "account", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["FJ", "power", "allocation", "in", "a", "multiuser", "two", "-", "way", "untrusted", "relay", "network", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["Average", "SSIM", "and", "network", "overhead", "of", "neuralFEC", "center", "tabularlccc", "&", "1lneuralFEC", "&", "1lVideo", "-", "aware", "FEC", "&", "1lWithout", "FEC", "SSIM", "&", "0,831", "&", "0,819", "&", "0,726", "Overhead", "&", "19,334", "&", "38,460", "&", "-", "tabular", "center", "tab", ":", "neuralFEC", ":", "summtableThe", "results", "showed", "that", "the", "neuralFEC", "mechanism", ",", "through", "an", "accurate", "motion", "intensity", "classification", "of", "video", "sequences", "with", "distinct", "characteristics", ",", "is", "able", "to", "add", "a", "precise", "amount", "of", "protection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["After", "receiving", "the", "de", "-", "quantized", "tensors", "and", ",", "we", "propose", "to", "use", "MD", "cascaded", "-", "ResBlock", "decoder", "networks", "to", "decompress", "these", "tensors", "since", "the", "learning", "of", "ResConv", "(", "denoted", "as", "Res", ")", "with", "a", "shortcut", "connection", "is", "a", "type", "of", "residual", "learning", ",", "whose", "gradients", "can", "be", "easily", "back", "-", "propagated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["This", "is", "mainly", "because", "the", "input", "could", "be", "under", "some", "random", "distribution", "over", ",", "yielding", "a", "random", "RV", "of", "random", "distribution", "over", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["The", "combining", "effect", "of", "execution", "time", "and", "a", "number", "of", "operation", "reduction", "results", "in", "X", "energy", "reduction", "for", "in", "B", "-", "OCC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "one class classifier"}, {"tokens": ["Then", "there", "is", "an", "MD", "strategy", "that", "is", "optimal", "minimizing", "in", "every", "state", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["Confusion", "matrix", "of", "DDE", "-", "MGM", "on", "the", "UCI", "character", "trajectory", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["In", "Table", ",", "we", "see", "that", "a", "MobileNetV2", "student", "model", "trained", "on", "CIFAR-100", "using", "ARD", "from", "an", "adversarially", "trained", "WideResNet", "is", "significantly", "more", "robust", "than", "an", "adversarially", "trained", "MobileNetV2", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["and", ",", "the", "error", "probability", "of", "MP", "based", "algorithm", "is", "worse", "than", "that", "of", "CLT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "message passing"}, {"tokens": ["Among", "the", "three", "weightings", ",", "using", "inverse", "ranks", "provides", "the", "top", "scores", "on", "the", "HJ", "and", "the", "AE", "datasets", "and", "the", "second", "best", "scores", "on", "the", "RT", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "ruthes"}, {"tokens": ["ht]Average", "gain", "of", "meta", "-", "optimization", "using", "conventional", "and", "weighted", "binary", "cross", "-", "entropy", "with", "k", "samples", "and", "DC", "-", "OPF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "optimal power flow"}, {"tokens": ["This", "is", "where", "TS", "come", "in", ",", "they", "provide", "ways", "to", "manage", "LOD"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tessellation shader"}, {"tokens": ["Animals", "were", "of", "both", "sexes", "and", "ranged", "in", "age", "from", "18", "to", "31", "weeks", "for", "young", "mice", "and", "from", "50", "to", "64", "weeks", "for", "the", "old", "mice", "(", "6", "WT", "and", "6", "AD", "at", "each", "age", ",", "for", "a", "total", "of", "24", "mice", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "wild type"}, {"tokens": ["We", "allow", "for", "approximate", "subroutines", "in", "all", "proposed", "MP", "and", "FW", "variants", ",", "that", "is", "the", "use", "of", "an", "approximate", "linear", "oracle", "(", "LMO", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["We", "observed", "that", ":", "For", "a", "fixed", "number", "of", "processors", ",", "when", "number", "of", "applications", "increase", ",", "the", "difference", "between", "LB", "and", "makespan", "time", "decreases", "i.e.", "efficiency", "in", "time", "increases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lower bound"}, {"tokens": ["The", "median", "ICC", "in", "each", "distribution", "is", "indicated", "by", "a", "horizontal", "line", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["A", "is", "the", "simplest", "NSP", "scheme", ",", "then", "the", "problem", "to", "compute", "the", "optimal", "PA", "factor", "can", "be", "significantly", "simplified", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["proofApplication", "of", "GDP", "tester", "to", "ensure", "privacy", "for", "the", "output", "of", "a", "given", "candidate", "algorithmsec", ":", "candIn", "this", "section"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["the", "meta", "-", "loss", "as", "optimized", "by", "meta", "-", "optimization", "outperformed", "that", "of", "the", "full", "OPF", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["cm", "R4", "cm", "Word", "&", "Number", "of", "documents", "containing", "the", "word", "&", "Word", "&", "Number", "of", "documents", "containing", "the", "word", "use", "&", "902,033", "&", "also", "&", "400,642", "result", "&", "812,154", "&", "present", "&", "389,735", "studi", "&", "723,827", "&", "increas", "&", "383,676", "show", "&", "498,705", "&", "two", "&", "375,586", "method", "&", "491,586", "&", "model", "&", "372,911", "effect", "&", "476,757", "&", "signific", "&", "370,435", "base", "&", "446,436", "&", "compar", "&", "355,381", "differ", "&", "445,739", "&", "paper", "&", "346,514", "can", "&", "441,512", "&", "time", "&", "344,817", "high", "&", "402,737", "&", "perform", "&", "341,547", "Processing", "the", "LSC", "and", "Building", "the", "LScD"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["When", "examining", "those", "image", "volumes", "that", "were", "segmented", "by", "both", "operators", ",", "there", "is", "similar", "disagreement", "in", "manual", "segmentation", "around", "the", "spine", "and", "hip", "bones", "in", "VAT", "and", "intramuscular", "tissue", "in", "SAT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["In", "comparison", "with", "other", "variants", "of", "EAs", ",", "DE", "has", "better", "exploration", "capability", "with", "fewer", "parameters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Results", "obtained", "via", "weighted", "least", "square", "regression", "(", "see", "Tables", "for", "the", "CNS", "dataset", "and", "S2", "in", "Supplementary", "Material", "for", "the", "MDC", "dataset", ")", "reveal", "that", "the", "social", "metrics", "are", "significant", "predictors", "for", "spatial", "metrics", "(", "p", "value", "in", "all", "cases", "except", "for", "M4", "in", "the", "MDC", "dataset", ")", ",", "and", "they", "typically", "have", "more", "importance", "than", "factors", "such", "as", "gender", ",", "time", ",", "coverage", "and", "age", "group", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["The", "additive", "GP", "recovered", "both", "of", "the", "original", "sine", "functions", "(", "shown", "in", "green", ")", ",", "and", "inferred", "correctly", "that", "most", "of", "the", "variance", "in", "the", "function", "comes", "from", "first", "-", "order", "interactions", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "addition", ",", "the", "transmitter", "added", "AN", "to", "interfere", "with", "other", "location", "of", "the", "eavesdropper", ",", "so", "that", "this", "scheme", "can", "significantly", "improve", "the", "ergodic", "safety", "capacity", "of", "information", "transmission", ",", "and", "improve", "the", "safety", "transmission", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Performance", "Analysis", "Simulation", "ResultsReduction", "in", "control", "signalingThe", "flow", "graphs", "for", "the", "various", "DC", "mobility", "events", "such", "as", "SeNB", "addition", ",", "SeNB", "change", ",", "and", "SeNB", "release", "in", "the", "legacy", "LTE", "architecture", "are", "presented", "in", "Section", "10.1.2.8", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Our", "approach", "outperforms", "the", "baseline", ",", "achieving", "state", "-", "of", "-", "the", "-", "art", "results", "on", "a", "complex", "QA", "benchmark", ",", "and", "demonstrates", "the", "limitations", "of", "the", "ground", "-", "truth", "sampling", "method", ",", "while", "improving", "recall", "even", "over", "the", "original", "answer", "sets", "provided", "by", "human", "annotators", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Convergence", "curves", "for", "regression", "by", "DE", "(", "left", ")", "and", "CMA", "-", "ES", "(", "right", ")", "using", "the", "autoenc", "-", "sphere", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["established", "a", "connection", "between", "modularity", "optimisation", "and", "the", "DC", "-", "SBM", "(", "Section", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["ELBO*softmax*categorical*KLLatent", "GP", "for", "disease", "stratificationSiddharth", "Ramchandran", ",", "Miika", "Koskinen", ",", "Harri", "Lahdesmaki[Latent", "Gaussian", "process", "with", "composite", "likelihoodsfor", "data", "-", "driven", "disease", "stratification"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "call", "this", "a", "Stereoscopic", "AR", "Predictive", "Display", "(", "SARPD", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["However", ",", "in", "order", "for", "DFA", "and", "FA", "to", "operate", "in", "this", "special", "setting", "certain", "restrictions", "are", "needed", ",", "e.g.", "the", "activation", "function", "must", "be", "specific", "like", "the", "hyperbolic", "tangent", "and", "non", "-", "zero", "initialization", "must", "be", "used", "for", "certain", "activations", "including", "the", "linear", "rectifier", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["Sources", "as", "buyers", ",", "i.e.", ",", "bidders", ",", "submit", "their", "bids", "to", "compete", "for", "the", "FJ", "power", "from", "the", "friendly", "jammer", ",", "i.e.", ",", "the", "seller", ",", "to", "increase", "their", "secrecy", "capacities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["Following", ",", "the", "RSSI", "of", "the", "-th", "UE", "can", "be", "written", "aswhere", "are", "serving", "cell", "(", ")", ",", "neighbour", "co", "-", "channel", "cells", ",", "and", "thermal", "noise", "powers", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["(", "ECC", "on", ")", "&", "2cTesla", "K40c", "(", "ECC", "off", ")", "&", "2cGeForce", "GTX", "1080", "6*turn90Key", "-", "onlyturn", "&", "3*BMS", "&", "Uniform", "&", "2.50", "&", "&", "2.48", "&", "&", "7.05", "&", "&", "&", "0.25-uniform", "&", "2.64", "&", "1.06x", "&", "2.61", "&", "1.05x", "&", "7.36", "&", "1.05x", "&", "&", "Binomial", "&", "2.89", "&", "1.15x", "&", "2.87", "&", "1.16x", "&", "7.89", "&", "1.11x", "2", "-", "9", "&", "3*RB", "-", "sort", "&", "Uniform", "&", "2.50", "&", "&", "3.69", "&", "&", "4.51", "&", "&", "&", "0.25-uniform", "&", "2.69", "&", "1.08x", "&", "3.71", "&", "1.00x", "&", "4.56", "&", "1.01x", "&", "&", "Binomial", "&", "2.80", "&", "1.12x", "&", "3.72", "&", "1.01x", "&", "4.95", "&", "1.10x", "1", "-", "91", "-", "96*turn90Key", "-", "valueturn", "&", "3*BMS", "&", "Uniform", "&", "1.82", "&", "&", "1.81", "&", "&", "5.85", "&", "&", "&", "0.25-uniform", "&", "1.99", "&", "1.10x", "&", "2.00", "&", "1.11x", "&", "6.71", "&", "1.15x", "&", "&", "Binomial", "&", "2.18", "&", "1.20x", "&", "2.16", "&", "1.20x", "&", "7.28", "&", "1.24x", "2", "-", "9", "&", "3*RB", "-", "sort", "&", "Uniform", "&", "1.29", "&", "&", "1.77", "&", "&", "2.31", "&", "&", "&", "0.25-uniform", "&", "1.45", "&", "1.13x", "&", "1.81", "&", "1.02x", "&", "2.33", "&", "1.01x", "&", "&", "Binomial", "&", "1.48", "&", "1.15x", "&", "1.93", "&", "1.9x", "&", "2.52", "&", "1.09x"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["*", "i", ",", "but", "is", "otherwise", "unchanged", "in", "Middle", "Persian", "(", "with", "a", "few", "stray", "exceptions", ";", "see", "below):[noitemsep]PIr", "*", "urtka-", "MP", "gurdag", "NP", "gurdah", "'", "kidney'PIr"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Each", "bidder", "is", "assigned", "with", "a", "subcarrier", ",", "and", "the", "problem", "is", "to", "allocate", "the", "FJ", "power", "to", "each", "subcarrier", "to", "maximize", "the", "secrecy", "rate", "of", "the", "information", "communication", "on", "the", "subcarrier", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["In", "the", "next", "section", ",", "we", "will", "present", "three", "TAS", "schemes", "for", "secure", "SM", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["DE", "is", "aimed", "at", "nonlinear", "non", "-", "differentiable", "continuous", "functions", "and", "has", "been", "designed", "to", "be", "a", "direct", "stochastic", "search", "method", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Algorithmic", "complexities", "of", "the", "well", "-", "established", "-based", "RB", "method", "and", "the", "novel", "-based", "RB", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "reduced basis"}, {"tokens": ["It", "should", "be", "noted", "that", "Algorithm", "3", "is", "done", "at", "the", "BS", "side", "before", "executing", "the", "FL", "scheme", "in", "Algorithm", "1", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["ROC", "curves", "(", "with", "AUROC", "indicated", ")", "for", "disease", "detection", "models", "for", "PAH", "(", "A", ")", ",", "HCM", "(", "C", ")", ",", "CA", "(", "E", ")", ",", "and", "MVP", "(", "F", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Furthermore", ",", "found", "that", "using", "the", "ICL", "criterion", "selected", "under", "the", "DC", "-", "SBM", ",", "meaning", "that", "any", "blocking", "leads", "to", "overfitting", ",", "while", "was", "selected", "under", "the", "original", "SBM", ",", "with", "different", "groups", "corresponding", "to", "different", "levels", "of", "node", "degrees", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Among", "all", "research", "studies", "had", "been", "done", ",", "according", "to", "the", "ABC", ",", "BA", ",", "BCO", "and", "HBMO", "are", "found", "the", "most", "useful", "application", ",", "from", "the", "highest", "number", "to", "the", "lowest", "number", ",", "in", "large", "scale", "engineering", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bee algorithm"}, {"tokens": ["In", "a", "-out", "-", "of-", "OT", "on", "bit", "strings", ",", "holds", "two", "inputs", ",", "each", "from", "and", "holds", "a", "choice", "bit", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "Shape", "Boltzmann", "Machine", "(", "SBM", ")", "for", "shape", "completion", "or", "missing", "region", "estimation", "was", "introduced", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "shape boltzmann machine"}, {"tokens": ["We", "show", "that", "states", "with", "are", "in", ",", "and", "states", "with", "are", "in", ",", "and", "in", "each", "case", "we", "give", "the", "claimed", "witnessing", "MD", "strategy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["We", "found", "that", "RQI", "got", "the", "correct", "answer", "and", "converged", "in", "fewer", "iterations", "than", "PI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "power iteration"}, {"tokens": ["The", "fundamental", "difference", "in", "the", "CSG", "proposed", "for", "each", "of", "the", "scenarios", "is", "the", "employed", "cost", "sharing", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cost sharing game"}, {"tokens": ["With", "the", "inner", "product", "operator", ",", "PNN", "is", "quite", "similar", "with", "FM", ":", "if", "there", "is", "no", "hidden", "layer", "and", "the", "output", "layer", "is", "simply", "summing", "up", "with", "uniform", "weight", ",", "PNN", "is", "identical", "to", "FM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["An", "ANN", "is", "called", "fully", "connected", "if", "each", "node", "in", "a", "layer", "is", "connected", "to", "all", "nodes", "in", "the", "subsequent", "layer", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Instead", "of", "points", ",", "the", "PLP", "is", "a", "random", "process", "of", "lines", "distributed", "in", "the", "plane", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["M.", "Rahman", ",", "A.", "Behravant", ",", "H.", "Koorapaty", ",", "J.", "Sachs", ",", "and", "K.", "Balachandran", ",", "\"", "License", "-", "exempt", "LTE", "systems", "for", "secondary", "spectrum", "usage", ":", "Scenarios", "and", "first", "assessment", ",", "\"", "in", "Proc", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "maximum", "skill", "differences", "between", "the", "models", "with", "the", "error", "-", "correcting", "ANNs", "and", "the", "No", "-", "ANN", "model", "are", "about", "0.04", "in", "the", "ACC", "and", "0.2", "in", "the", "RMSE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "anomaly correlation coefficient"}, {"tokens": ["Aging", "and", "Alzheimer", "'s", "disease", "have", "little", "effect", "on", "capillary", "characteristicsUsing", "a", "large", "database", "of", "vessel", "segments", "measured", "in", "three", "dimensions", ",", "we", "surprisingly", "found", "only", "very", "small", "differences", "between", "groups", "that", "were", "dwarfed", "by", "the", "variance", "in", "capillary", "diameter", "or", "tortuosity", "between", "young", "and", "old", "animals", "or", "between", "WT", "and", "AD", "mouse", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "wild type"}, {"tokens": ["Hence", ",", "the", "proposed", "Exact", "-", "MBR", "code", "is", "systematic", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["DBF", "cases", "have", "higher", "sum", "throughput", "than", "the", "other", "cases", ",", "because", "of", "the", "higher", "efficiency", "of", "LTE", "than", "WiFi", "at", "the", "MAC", "layer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["We", "also", "introduce", "qualitative", "and", "quantitative", "metrics", "along", "with", "visualization", "tools", "to", "facilitate", "the", "development", "and", "the", "comparison", "of", "SRL", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "state representation learning"}, {"tokens": ["As", "a", "result", ",", "the", "overall", "space", "complexity", "of", "the", "LR", "scenario", "is", "in", "order", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["While", "the", "importance", "of", "temporal", "logic", "in", "this", "context", "is", "perhaps", "the", "most", "obvious", "one", "due", "to", "its", "well", "-", "known", "applications", "in", "verification", ",", "also", "other", "non", "-", "classical", "logics", "have", "IS", "-", "relevant", "applications", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["MDR", "CCR", "is", "the", "correct", "classification", "rate", "and", "Rule", "Utility", "derives", "from", "the", "chi", "-", "square", "statistics", "of", "rule", "relevance", ",", "which", "measures", "the", "interaction", ":", "where", "We", "sum", "CCR", "and", "U", "as", "our", "reward", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["The", "DCNN", "is", "a", "variant", "of", "the", "proposed", "method", "that", "is", "implemented", "by", "replacing", "each", "FM", "block", "in", "the", "proposed", "method", "with", "a", "convolutional", "block", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["In", ",", "the", "authors", "corporate", "the", "GPS", "system", "with", "camera", "and", "image", "processing", "system", "to", "detect", "the", "charging", "station", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["The", "first", "one", "is", "the", "adaptive", "cross", "-", "layer", "VIdEo", "-", "aWare", "FEC", "-", "based", "Mechanism", "with", "Unequal", "Error", "Protection", "scheme", "(", "ViewFEC", ")", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["This", "work", "presented", "a", "formalized", "framework", "for", "human", "-", "robot", "learning", "as", "a", "hierarchical", "decision", "-", "making", "problem", "(", "hHRL", ")", "that", "decomposes", "a", "SAR", "intervention", "for", "tractable", "computational", "personalization", ",", "and", "utilized", "a", "reinforcement", "learning", "approach", "to", "personalize", "the", "level", "of", "challenge", "and", "feedback", "for", "each", "user", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Offline", "experiments", "on", "toy", "data", "show", "that", "only", "NCE", "could", "successfully", "measure", "both", "global", "and", "local", "diversity", "among", "several", "popular", "existing", "diversity", "metrics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["First", ",", "as", "another", "source", "of", "information", "for", "a", "TP", "when", "determining", "in", "which", "sequence", "it", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["The", "bold", "values", "indicate", "better", "performance", "in", "comparison", "with", "the", "ring", "algorithmThe", "mode", "of", "the", "introduced", "PAT", "delay", "influences", "slightly", "the", "measured", "values", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival time"}, {"tokens": ["Sum", "secrecy", "rate", "versus", "the", "transmit", "power", "of", "the", "BS", "for", ",", ",", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Figure", "shows", "performance", "as", "a", "function", "of", "ESS", "threshold", ",", "demonstrating", "that", "there", "is", "a", "fairly", "narrow", "range", "of", "thresholds", "for", "which", "performance", "is", "good", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "effective sample size"}, {"tokens": ["By", "proceeding", "this", "way", ",", "at", "most", "substituting", "operations", "suffice", "to", "make", "all", "superlinear", "SCCs", "purely", "superlinear", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "strongly connected components"}, {"tokens": ["Each", "evaluated", "solution", "is", "represented", "by", "a", "leaf", "node", "in", "the", "BSP", "tree", ",", "which", "occupies", "a", "sub", "-", "region", "in", "the", "partitioned", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["OT", "where", "holds", "inputs", "and", "holds", "a", "choice", "index", "of", "bits", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "increased", "number", "of", "membership", "choices", "(", "from", "to", ")", "naturally", "brings", "about", "the", "increased", "complexity", "of", "the", "overlapping", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "sequential monte carlo"}, {"tokens": ["We", "then", "calculated", "the", "IS", "and", "FID", "values", "on", "each", "of", "the", "nine", "samples", "of", "30,000", "generated", "images", "and", "report", "the", "averaged", "values", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["Since", "the", "ground", "truth", "segmentation", "masks", "are", "unavailable", "for", "the", "test", "set", "of", "the", "ACDC", "dataset", ",", "we", "instead", "use", "the", "outputs", "of", "the", "FS", "images", "in", "the", "test", "set", "as", "ground", "truth", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fully sampled"}, {"tokens": ["Specifically", ",", "we", "take", "questions", "from", "existing", "datasets", "for", "document", "QA", ",", "knowledge", "base", "QA", "and", "visual", "QA", "and", "add", "systematic", "noise", "to", "these", "questions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["TI", ",", "i.e."], "acronym_pos": [1, 0, 0], "long_form": "threshold initialization"}, {"tokens": ["Hence", ",", "by", "using", "proposition", ",", "the", "congestion", "probability", "conditionally", "on", "(", "PLP", ")", "can", "be", "expressed", "as", "where", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["But", "the", "average", "recognition", "time", "compared", "to", "the", "combination", "of", "DMD", "EMD", "is", "improved", "by", "-iterative", "improvement", "by", "more", "than", "one", "third", ",", "and", "for", "particular", "time", "intensive", "characters", "with", "a", "large", "number", "of", "strokes", ",", "the", "maximal", "recognition", "time", "is", "decreased", "by", "more", "than", "50", "percent", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deficient mapping dissolution"}, {"tokens": ["For", "the", "generative", "model", "of", "an", "NP", "we", "have", ":", "eqnarray", "eq", ":", "NPp(Z", ",", "Y", "X", ")", "=", "p(Z", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["In", "addition", "to", "this", ",", "it", "influences", "the", "mixing", "weights", "of", "GMM", "by", "acting", "as", "its", "inverse", "multiplier", "as", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "BS", "broadcasts", "the", "obtained", "solution", "to", "all", "users", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "the", "first", "case", "(", "without", "FEC", ")", ",", "a", "good", "video", "quality", "is", "noticed", "up", "to", "600", "m", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["[", "CC", ",", "1000", "runs", ",", "12", "clust", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "connected caveman"}, {"tokens": ["A", "larger", "enables", "DE", "of", "better", "exploration", "ability", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Since", "the", "RV", "is", "used", "for", "sketching", ",", "such", "correlation", "measurement", "implies", "the", "entropy", "loss", "from", "the", "input", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["DBN", "outperforms", "other", "competing", "methods", "in", "terms", "of", "all", "evaluation", "metrics", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["For", "one", "case", ",", "EMD", "succeeds", "to", "find", "the", "optimal", "mapping", "whereas", "DMD", "fails", ",", "and", "in", "the", "other", "case", ",", "the", "reverse", "is", "true", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "excessive mapping dissolution"}, {"tokens": ["In", "BC", "learning", ",", "two", "audio", "signals", "from", "different", "classes", "are", "mixed", "with", "each", "other", "with", "a", "random", "ratio", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "between class"}, {"tokens": ["Given", "the", "corrupted", "codeword", ",", "the", "RV", "and", ",", "the", "syndrome", "decoding", "algorithm", "computes", "*", "yields", "the", "syndrome", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["Sinkhorn", "used", "in", "this", "paper", "is", "two", "-", "folds", ":", "one", "is", "to", "indicate", "the", "computation", "of", "via", "a", "Sinkhorn", "iterates", ";", "another", "is", "to", "imply", "the", "revised", "OT", "divergence", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["sop", "-", "algorithmBackbone", "Architecturesec", ":", "network", "-", "architectureFigure", "fig", ":", "pipeline", "describes", "the", "overview", "of", "the", "proposed", "zoom", "out", "-", "and", "-", "in", "network", "with", "MAD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "map attention decision"}, {"tokens": ["Clearly", ",", "we", "can", "see", "how", "if", "is", "the", "identity", "function", "(", "i.e.", ",", ")", "then", "we", "end", "up", "with", "the", "normal", "IB", "Lagrangian", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Furthermore", ",", "there", "is", "a", "trade", "-", "off", "between", "(", "i", ")", "how", "much", "the", "selected", "function", "resembles", "a", "linear", "function", "in", "our", "region", "of", "interest", ";", "e.g.", ",", "with", "or", "close", "to", "zero", ",", "since", "it", "will", "suffer", "from", "similar", "problems", "as", "the", "original", "IB", "Lagrangian", ";", "and", "(", "ii", ")", "how", "fast", "it", "grows", "in", "our", "region", "of", "interest", ";", "e.g.", ",", "higher", "values", "of", "or", ",", "since", "it", "will", "suffer", "from", "value", "convergence", ";", "i.e.", ",", "optimizing", "for", "separate", "values", "of", "will", "achieve", "similar", "levels", "of", "performance", "(", "Figure", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Thus", ",", "the", "application", "of", "the", "RB", "model", "does", "not", "necessitate", "the", "computation", "of", "gradients", "of", "displacement", "fields", ",", "and", "even", "does", "not", "require", "the", "displacements", "to", "be", "available", "at", "all", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["By", "using", "the", "framework", "of", "BF", ",", "Logical", "Particle", "Filters", "satisfy", "sequential", ",", "update", "and", "prediction", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian filtering"}, {"tokens": ["dstcOverview", "of", "a", "DST", "module", "."], "acronym_pos": [0, 0, 0, 1, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["The", "previously", "encountered", "problems", "of", "the", "CCR", "for", "normal", "and", "carrying", "conditions", "are", "shown", "in", "Figure", "and", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct correction rate"}, {"tokens": ["Impose", "the", "intensity", "constraint", "with", "the", "captured", "images", "withwhere", "and", "are", "the", "complex", "field", "of", "the", "LR", "images", "with", "and", "without", "the", "intensity", "constraint", "respectively", ",", "and", "At", "this", "time", ",", "the", "updated", "Fourier", "spectrum", "of", "the", "LR", "image", "is", "Step", "4", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["While", "this", "works", "well", "for", "small", "APIs", ",", "it", "becomes", "less", "feasible", "when", "dealing", "with", "large", "sets", "of", "APIs", ",", "as", "in", "the", "polyglot", "case", ",", "or", "with", "more", "complex", "semantic", "languages", "typically", "used", "in", "SP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "semantic parsing"}, {"tokens": ["Partial", "downloading", "schemeThis", "subsection", "presents", "the", "partial", "downloading", "scheme", "on", "the", "proposed", "systematic", "Exact", "-", "MBR", "codes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["By", "considering", "the", "approximations", "of", "Pm_con_mod", ",", "we", "can", "formulate", "the", "GP", "approximated", "subproblem", "at", "the", "iteration", "of", "the", "SCA", "as", "follows", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Statistics", "of", "the", "M", "-", "ARS", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "addressee and response selection"}, {"tokens": ["Results", "comparing", "HerboldMethod", "and", "time", "-", "aware", "evaluation", "-", "HerboldMethod", "reports", "only", "one", "value", "of", "F", "-", "Score", ",", "AUC", "and", "MCC", "for", "each", "technique", "which", "is", "duplicated", "across", "all", "rows", "-2em"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["Finally", "it", "should", "be", "highlighted", ",", "that", "all", "single", "-", "view", "and", "the", "view", "-", "aggregation", "models", "achieve", "similarly", "excellent", "results", "on", "the", "SAT", "segmentation", "compared", "to", "inter", "-", "rater", "variability", "and", "outperform", "the", "manual", "raters", "for", "the", "more", "challenging", "VAT", "segmentation", "by", "a", "margin", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Dengue", ",", "Dengue", "virus", ",", "Dengue", "monitoring", ",", "Dengue", "tracking", ",", "GPS", ",", "Mobile", "applicationIntroductionHealth", "information", "technology", ",", "which", "includes", "computers", ",", "mobile", "devices", "and", "other", "devices", "used", "in", "the", "management", "of", "medical", "information", ",", "has", "great", "potential", "to", "promote", "health", "and", "support", "health", "care", "around", "the", "world", ",", ",", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["GS", "function", "scores", "an", "appearance", "of", "a", "word", "as", "the", "sum", "of", "the", "scores", "of", "all", "its", "following", "appearances", "as", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric sequence"}, {"tokens": ["Automating", "OARs", "segmentation", "has", "the", "benefit", "of", "both", "reducing", "the", "time", "and", "improving", "the", "quality", "of", "RT", "planning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "radiation therapy"}, {"tokens": ["These", "CF", "models", "stand", "for", "state", "-", "of", "-", "the", "-", "art", "models", "for", "the", "item", "recommendation", "task", ",", "each", "using", "a", "different", "prediction", "concept", ",", "allowing", "us", "to", "study", "the", "impact", "of", "different", "attack", "strategies", "from", "multiple", "viewpoints", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["A", "Surcharge", "Pricing", "Scheme", "(", "SPS", ")", "is", "also", "presented", ",", "such", "that", "the", "designed", "association", "bias", "values", "can", "be", "achieved", "in", "Nash", "equilibrium", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "surcharge pricing scheme"}, {"tokens": ["In", "our", "task", ",", "during", "testing", "stage", ",", "all", "the", "baseline", "QA", "models", "take", "into", "a", "machine", "-", "transcribed", "spoken", "document", "and", "a", "machine", "-", "transcribed", "spoken", "question", "as", "input", ",", "and", "the", "output", "is", "an", "extracted", "span", "from", "the", "ASR", "transcription", "of", "document", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Pure", "RSWith", "pure", "RS", "utilizes", "MRD", "to", "combine", "the", "signals", "from", "and", ",", "therefore", "the", "instantaneous", "SNR", "at", "'s", "output", "is", "given", "using", "Eq", ":", "g_best", "bySimilar", "to", "the", "derivation", "of", "Eq", ":"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal ratio diversity"}, {"tokens": ["Hybrid", "QA", ":", "requires", "federating", "knowledge", "from", "heterogeneous", "sources", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["A", "feature", "was", "deemed", "robust", "if", "the", "estimated", "ICC", "exceeded", "the", "threshold", "value", ",", "and", "non", "-", "robust", "otherwise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["Participants", "want", "to", "protect", "their", "data", "against", "any", "inference", "attack", "during", "the", "FL", "process", "and", "from", "the", "final", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Starting", "from", "the", "baseline", ",", "we", "add", "each", "training", "component", "individually", "and", "investigate", "their", "contribution", "to", "AR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "average recall"}, {"tokens": ["The", "performance", "gain", "percentage", "achieved", "by", "OPA", "parameter", "at", "SNR=30dB", "is", "remarkable", ",", "especially", "when", "the", "PA", "factor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power allocation"}, {"tokens": ["h", "]", "Summary", "of", "test", "G", "-", "mean", "results", "across", "7", "different", "algorithms", ",", "i.e.", "ECS", "-", "DBN", ",", "DBN", "and", "a", "group", "of", "resampling", "methods", "including", "ADASYN", "-", "DBN", ",", "SMOTE", "-", "DBN", ",", "SMOTE", "-", "borderline1-DBN", ",", "SMOTE", "-", "borderline2-DBN", ",", "SMOTE", "-", "SVM", "-", "DBN", ",", "on", "58", "KEEL", "benchmark", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["An", "incoming", "individual", "is", "converted", "to", "a", "POS", "skeleton", ",", "and", "the", "algorithm", "checks", "if", "the", "skeleton", "is", "contained", "in", "the", "skeleton", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["FN", "and", "AN", "are", "trained", "simultaneously", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["Since", "differs", "only", "slightly", "in", "the", "amplitude", "from", "the", "general", "pattern", ",", "these", "dictionaries", "seem", "insufficient", "to", "capture", "this", "fine", "dissimilarity", ":", "while", "Self", "and", "DI", "dictionaries", "simply", "do", "not", "contain", "enough", "elements", ",", "UI", "dictionary", "is", "to", "simple", "to", "capture", "this", "difference", "(", "it", "shares", "this", "feature", "with", "DI", "dictionary", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "dyadic indicator"}, {"tokens": ["In", "future", "work", ",", "we", "hope", "to", "naturally", "extend", "our", "model", "to", "handle", "arbitrary", "cross", "sections", "(", "same", "GP", "based", "model", ")", "and", "a", "much", "more", "structured", "hypothesis", "space", "to", "represent", "Gaussian", "Process", "based", "object", "parts", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["RQ1", "and", "RQ2", "about", "about", "IFT", ",", "so", "that", "guided", "our", "analysis", "of", "these", "two", "RQs", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information foraging theory"}, {"tokens": ["Feature", "Selection", "through", "PSO"], "acronym_pos": [0, 0, 0, 1], "long_form": "particle swarm optimization"}, {"tokens": ["At", "last", ",", "(", "5", ")", "adopts", "the", "proposed", "MINT", "-", "FEC", "mechanism", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "standard", "form", "of", "GP", "is", "defined", "as", "the", "minimization", "of", "a", "posynomial", "function", "subject", "to", "inequality", "posynomial", "constraints", "and", "equality", "monomial", "constraints", "as", "given", "below", ":", "where", ",", ",", "are", "posynomials", "and", ",", "are", "monomials", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["This", "is", "more", "appropriate", "for", "clinical", "usages", "where", "we", "are", "generally", "interested", "in", "interpreting", "the", "association", "between", "clinical", "covariates", "and", "biological", "measures", "marquand2016understanding", ";", "ii", ")", "using", "the", "fully", "probabilistic", "NP", "regime", ",", "we", "are", "also", "capable", "to", "evaluate", "aleatoric", "uncertainties", "resulting", "from", "individual", "differences", "and", "noise", "in", "addition", "to", "the", "epistemic", "parameter", "uncertainty", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["The", "derivation", "of", "the", "DE", "of", "the", "power", "of", "the", "multi", "-", "user", "interference", "follows", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deterministic equivalent"}, {"tokens": ["parallelism", "is", "possible", "with", "the", "ID", "organization", "for", "rebuilding", "primary", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["The", "binding", "status", "of", "generator", "output", "power", "lower", "-", "bound", "constraints", "was", "not", "predicted", "(", "but", "force", "-", "set", "to", "be", "always", "binding", ")", "as", "the", "reduced", "OPF", "problem", "may", "become", "unbounded", "with", "their", "removal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["The", "percentage", "of", "robust", "features", "according", "to", "the", "test", "-", "retest", "ICC", "is", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["AA", "smoothes", "the", "common", "neighbor", "method", "using", "neighbors", "'", "node", "degree", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adamic adar"}, {"tokens": ["It", "can", "be", "shown", "that", "GP", "requires", "a", "very", "small", "number", "of", "iterations", "to", "converge", "for", "a", "best", "approximation", "solution", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["To", "reduce", "the", "computational", "complexity", "of", "the", "large", "network", ",", "it", "is", "assumed", "that", "each", "UE", "can", "only", "be", "served", "by", "its", "nearby", "RRHs", "since", "only", "nearby", "RRHs", "contribute", "significantly", "to", "the", "UE", "'s", "signal", "quality", "due", "to", "the", "severe", "path", "loss", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Then", "the", "channel", "between", "the", "BS", "and", "the", "-th", "eavesdropper", "can", "be", "expressed", "aswhere", "is", "the", "estimated", "channel", "between", "the", "BS", "and", "the", "-th", "eavesdropper", ",", "is", "the", "channel", "estimation", "error", ",", "and", "is", "the", "bound", "of", "the", "norm", "of", "the", "channel", "estimation", "error", "of", "the", "-th", "eavesdropper", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Spectral", "Rolloff", "between", "SC", "and", "ST", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "subset compared"}, {"tokens": ["This", "restricted", "set", "-", "up", "is", "far", "from", "being", "realistic", "in", "dealing", "with", "highly", "entangled", "real", "-", "world", "AA", "tasks", "that", "involve", "a", "large", "number", "of", "candidate", "authors", "for", "attribution", "during", "test", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["*", "[", "htp]Performance", "of", "variants", "of", "CNet", "-", "NIC", "on", "MS", "COCO", "dataset", ",", "where", "B@", ",", "M", ",", "R", ",", "and", "C", "are", "short", "for", "BLEU@", ",", "METEOR", ",", "ROUGE", "-", "L", ",", "and", "CIDEr", "-", "D", "scores", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural image caption"}, {"tokens": ["Each", "token", "is", "tagged", "with", "POS", "and", "with", "the", "ID", "of", "the", "source", "article", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Explicitly", ",", "this", "check", ",", "which", "is", "referred", "to", "as", "the", "OPF", "Self", "-", "Repair", "(", "OPF", "-", "SR", ")", "process", "in", ",", "provides", "the", "EQPO", "algorithm", "with", "resilience", "against", "including", "sub", "-", "optimal", "routes", "in", "the", "early", "trellis", "stages", "due", "to", "the", "limited", "number", "of", "generated", "routes", ",", "hence", "preventing", "their", "propagation", "to", "the", "later", "stages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal pareto front"}, {"tokens": ["At", "ISMAR", "Lukas", "Gruber", "present", "the", "\"", "City", "of", "Sights", "\"", ",", "a", "collection", "of", "datasets", "and", "paperboard", "models(http://studierstube.icg.tugraz.at", "/", "handheld_ar", "/", "cityofsights.php", ")", "to", "evaluate", "the", "tracking", "and", "reconstruction", "performance", "of", "algorithms", "used", "in", "AR", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["c", ")", "shows", "the", "normalized", "mean", "value", "of", "each", "feature", "of", "TP", ",", "FP", ",", "TN", ",", "and", "FN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "true negative"}, {"tokens": ["We", "report", "this", "performance", "in", "Figure", ",", "where", "it", "can", "be", "seen", "that", "the", "GAT", "surrogate", "outperforms", "LS", "on", "7", "out", "of", "9", "datasets", ",", "although", "admittedly", "the", "difference", "is", "small", "and", "only", "statistically", "significant", "on", "3", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "least squares"}, {"tokens": ["adopted", "randomized", "benchmarking", "techniques", "to", "obtain", "a", "process", "tomography", "protocol", "that", "is", "robust", "towards", "state", "preparation", "and", "measurement", "errors", "(", "SPAM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "state preparation and measurement errors"}, {"tokens": ["Section", "reviews", "the", "previous", "works", ",", "such", "as", "repair", "-", "by", "-", "transfer", "codes", "and", "Exact", "-", "MBR", "codes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["run", "IB", "with", "an", "imaginary", "-", "to", "-", "real", "ratio", "of", "4", ",", "as", "used", "for", "2", "of", "3", "environments", "in", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imaginary batches"}, {"tokens": ["Hence", ",", "the", "RB", "model", "is", "equivalent", "to", "the", "FEM", ",", "but", "with", "basis", "functions", "that", "are", "globally", "supported", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["In", "light", "of", "these", "factors", ",", "we", "were", "expecting", "some", "of", "the", "students", "to", "claim", ",", "basically", ",", "that", "the", "course", "was", "too", "hard", "without", "being", "helpful", "for", "their", "future", "as", "IS", "practitioners", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information systems"}, {"tokens": ["Feature", "selection", "mainly", "provides", "three", "kinds", "of", "categories", ":", "filter", "-", "based", ",", "wrapper", "-", "based", "and", "embedded", "FS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "feature selection"}, {"tokens": ["For", "larger", "delays", "and", "message", "sizes", ",", "when", "only", "one", "process", "is", "delayed", "the", "PRR", "algorithm", "provides", "slightly", "smaller", "relative", "savings", "than", "in", "the", "case", "when", "the", "delays", "were", "introduced", "for", "all", "processes", ",", "with", "the", "uniform", "probabilistic", "distribution", ",", "it", "is", "especially", "visible", "for", "500", "-", "1000ms", "delays", "and", "message", "sizes", "of", "2", "-", "8", "M", "of", "floats", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pre - reduced ring"}, {"tokens": ["Thus", ",", "the", "expert", "list", "returned", "by", "GS", "*", "may", "include", "authors", "who", "are", "experts", "of", "less", "relevant", "fields", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "google scholar 's"}, {"tokens": ["RnBP", "converges", "with", "much", "higher", "parallelism", "than", "that", "required", "for", "RS", "and", "RBP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["Usually", ",", "the", "layers", "of", "an", "ANN", "model", "implement", "an", "affine", "transformation", "function", "or", "a", "(", "component", "-", "wise", ")", "non", "-", "linearity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["How", "ECS", "-", "DBN", "may", "impact", "on", "the", "majority", "class", "depends", "on", "the", "way", "we", "define", "the", "objective", "functions", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["table[ht]3pttabularllccccccccccccccccc", "Task", "type", "&", "Task", "&", "a", "&", "aE", "&", "DE", "&", "dM", "&", "d", "&", "EPD", "&", "e", "&", "eR", "&", "fM", "&", "i", "&", "R", "&", "SE", "&", "s", "&", "v", "&", "x", "4*Dataset", "&", "Variable", "types", "&", "&", "x", "&", "x", "&", "x", "&", "x", "&", "&", "x", "&", "&", "x", "&", "x", "&", "&", "x", "&", "x", "&", "x", "&", "&", "Dimensions", "&", "&", "x", "&", "x", "&", "x", "&", "x", "&", "x", "&", "&", "&", "x", "&", "x", "&", "&", "x", "&", "&", "x", "&", "&", "Other", "info", "&", "&", "&", "x", "&", "&", "&", "&", "&", "&", "&", "x", "&", "&", "&", "&", "x", "&", "&", "Compare", "datasets", "&", "x", "&", "&", "&", "&", "&", "&", "&", "&", "x", "&", "x", "&", "&", "&", "&", "x", "&", "5*Validity", "&", "Missing", "values", "&", "&", "x", "&", "x", "&", "x", "&", "x", "&", "x", "&", "x", "&", "&", "x", "&", "x", "&", "&", "x", "&", "x", "&", "x", "&", "x", "&", "Redundant", "col", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dataexplorer"}, {"tokens": ["Following", "model", "we", "show", "the", "joint", "distribution", "of", "GP", "-", "SSM", "for", "completeness", ",", "where", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Training", "times", "for", "adversarial", "training", ",", "clean", "distillation", ",", "ARD", ",", "and", "Fast", "-", "ARD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Therefore", ",", "for", "all", "points", "(", ")", "such", "that", "are", "solutions", "of", "optimizing", "the", "IB", "Lagrangian", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["From", "these", "results", ",", "we", "can", "observe", "that", "SFM", "consistently", "outperforms", "all", "the", "comparison", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "structural factorization machine"}, {"tokens": ["DE", "with", "symmetry", "breakingThe", "DE", "method", "comprises", "a", "population", "of", "solution", "candidates", ",", "which", "are", "iteratively", "updated", "and", "moved", "towards", "an", "optimal", "solution", "."], "acronym_pos": [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Further", ",", "the", "recombination", "operator", "cooperates", "with", "PSO", "by", "using", "the", "configurations", "which", "are", "discovered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["In", "Figure", ",", "for", "example", ",", "the", "word", "star", "heads", "the", "subject", "NP"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "noun phrase"}, {"tokens": ["al", "*", "Beese2016", "propose", "that", "IS", "complexity", "makes", "adaptive", "change", "more", "difficult", ";", "although", "as", "Xia", "and"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["However", ",", "the", "biggest", "difference", "lies", "in", "the", "source", "where", "MAD", ",", "called", "\"", "excitation", "recalibration", "vector", "\"", "inpSENet", ",", "comes", "from", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["Since", "differs", "only", "slightly", "in", "the", "amplitude", "from", "the", "general", "pattern", ",", "these", "dictionaries", "seem", "insufficient", "to", "capture", "this", "fine", "dissimilarity", ":", "while", "Self", "and", "DI", "dictionaries", "simply", "do", "not", "contain", "enough", "elements", ",", "UI", "dictionary", "is", "to", "simple", "to", "capture", "this", "difference", "(", "it", "shares", "this", "feature", "with", "DI", "dictionary", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "uniform indicator"}, {"tokens": ["Therefore", ",", "other", "than", "evaluating", "relevance", "by", "NDCG", "in", "our", "application", ",", "we", "also", "evaluate", "diversity", "by", "NCE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["The", "purpose", "of", "this", "top", "DSA", "skills", "list", "is", "to", "capture", "DSA", "labour", "trends", "rather", "than", "represent", "a", "complete", "taxonomy", "of", "DSA", "skills", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["Real", "DataWe", "use", "the", "SDR", "technology", "to", "build", "our", "testbeds", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "software defined radio"}, {"tokens": ["Random", "Voting", "(", "RV", ")", ",", "which", "is", "considered", "as", "the", "leading", "geometric", "method", "for", "motion", "segmentation", "partly", "because", "of", "its", "robustness", "to", "noise", ",", "has", "shown", "particularly", "successful", "results", "with", "a", "low", "computational", "cost", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random voting"}, {"tokens": ["By", "selecting", "the", "temporal", "level", "key", "pictures", ",", "hierarchical", "-", "B", "-", "pictures", "-", "based", "MD", "video", "coding", "framework", "adopts", "the", "simplest", "odd", "/", "even", "frame", "splitting", "method", "of", "generating", "redundancy", "descriptions", "as", "a", "special", "case", "of", "the", "framework", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["In", "order", "to", "design", "a", "tester", "for", "GDP", "property", ",", "we", "cast", "the", "problem", "of", "testing", "GDP", "property", "as", "a", "problem", "of", "testing", "Lipschitzness", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["Number", "of", "GMM", "componentsIn", "this", "ablation", "experiment", "we", "investigate", "the", "optimal", "number", "of", "GMM", "components", "for", "modeling", "the", "Open", "Images", "domain", ",", "having", "as", "a", "indirect", "metric", "the", "performance", "on", "Cityscapes", "validation", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Let", "RS", "saveall", "its", "historical", "and", "current", "(", "time", ")", "energy", ",", ",", "...", ",", "in", "a", "vector", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["ROC", "curves", "of", "cIBP", "-", "VAE", "in", "comparison", "to", "alternative", "models", "on", "the", "clinical", "ECG", "data", "set", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Perhaps", "one", "could", "use", "the", "recent", "method", "of", "SinkhornAutoDiff", "to", "provide", "a", "differentiable", "entropic", "OT", "loss", "between", "synthesis", "and", "exemplar", "representations", ",", "so", "that", "the", "optimization", "could", "be", "accomplished", "with", "SGD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["DE", "relies", "on", "genetic", "mutation", "and", "crossover", ",", "ABC", "uses", "the", "roles", "of", "three", "main", "groups", "within", "a", "bee", "colony", "and", "GSA", "is", "based", "on", "gravitational", "laws", "and", "mass", "interactions", "between", "particles", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["We", "also", "present", "the", "ROC", "analysis", "for", "all", "different", "datasets", "and", "the", "plots", "are", "given", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["In", "other", "words", ",", "we", "explain", "how", "learning", "manifests", "itself", "in", "the", "PS", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "projective simulation"}, {"tokens": ["Both", "are", "running", "asynchronously", ",", "and", "ROS", "is", "used", "to", "pass", "the", "data", "from", "the", "slave", "-", "tool", "tracking", "to", "the", "stereoscopic", "AR", "rendering", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "augmented reality"}, {"tokens": ["NP", "biyabanIn", "the", "following", "forms", ",", "PIr", "*"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["is", "calculated", "as", ":", "Naive", "Bayes", "Classifier", "for", "Unbalanced", "ClassesOne", "of", "the", "limitations", "of", "NBC", "is", "that", "the", "technique", "performs", "poorly", "on", "data", "sets", "with", "unbalanced", "classes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "naive bayes classifier"}, {"tokens": ["ANN", "guarantees", "us", "good", "learning", "through", "its", "different", "techniques", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["However", ",", "the", "UI", "was", "not", "actually", "used", "in", "the", "field", "and", "potential", "users", "emphasized", "the", "importance", "of", "privacy", "in", "a", "location", "-", "based", "approach", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user interface"}, {"tokens": ["Accuracy", "of", "minority", "class", "Illustration", "of", "the", "comparison", "between", "the", "accuracy", "of", "majority", "class", "and", "minority", "class", "respectively", "with", "the", "proposed", "ECS", "-", "DBN", "and", "grid", "search", "of", "misclassification", "costs", "on", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["The", "discrete", "trust", "state", "results", "in", "a", "standard", "DBN", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "dynamic bayesian network"}, {"tokens": ["In", "the", "SBM", ",", "where", "the", "desired", "stationary", "distribution", "is", "proportional", "to", ",", "we", "were", "able", "to", "use", "a", "standard", "Metropolis", "-", "HastingHastingsMetropolis", "algorithm", "with", "acceptance", "probabilityequation", "a_st", "="], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "final", "segmentations", "of", "all", "patients", "are", "used", "to", "train", "a", "fully", "supervised", "method", "for", "detecting", "and", "segmenting", "CD", "tissues", "(", "details", "are", "given", "in", "Section", "expt", ":", "eval", ")", "using", "fold", "cross", "validation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "crohn 's disease"}, {"tokens": ["Such", "a", "function", "solves", "SP", "in", ".For", "brevity", ",", "we", "set", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "splitting problem"}, {"tokens": ["When", "the", "non", "-", "adaptive", "Video", "-", "aware", "FEC", "and", "ViewFEC", "mechanisms", "were", "employed", ",", "the", "MOS", "average", "values", "were", "4.39", "and", "4.37", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["We", "hypothesize", "that", "images", "that", "are", "visually", "similar", "to", "Cityscapes", "Dense", ",", "depict", "street", "scenes", ",", "will", "have", "high", "probability", "density", "under", "the", "GMM", "and", "images", "from", "generic", "scenes", ",", "the", "majority", "of", "Open", "Images", "images", "not", "containing", "street", "scenes", ",", "will", "have", "low", "probability", "density", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Hence", "applying", "CDA", "help", "avoiding", "the", "overfitting", "phenomenon", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "canonical discriminant analysis"}, {"tokens": ["t]End", "-", "to", "-", "end", "OP", ",", ",", "of", "RS", "versus", "the", "average", "transmit", "SNR", "per", "bit", ",", ",", "for", "relay", "nodes", "over", "INID"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["PSO", "_", ":", "a->v", "="], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Assuming", "the", "data", "points", "arrive", "one", "-", "by", "-", "one", ",", "DDE", "-", "MGM", "incrementally", "models", "the", "stream", "without", "segmentation", "or", "any", "other", "preprocessing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Sparse", "approximations", "for", "sequential", "dataExact", "inference", "in", "GP", "models", "is", "widely", "known", "for", "its", "complexity", "for", "training", "and", "per", "test", "prediction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "friendly", "jammers", "as", "the", "bidders", "determine", "their", "optimal", "FJ", "powers", ",", "i.e.", ",", "bids", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["By", "TS", ",", "we", "denote", "the", "Triadic", "Simmelian", "Backbone", "and", "by", "QLS", "the", "Quadrilateral", "Simmelian", "Backbone", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "triadic simmelian"}, {"tokens": ["Similar", "to", "the", "systems", "generated", "for", "WikiMovies", "dataset", ",", "we", "generated", "variations", "of", "the", "dataset", "for", "this", "QA", "task", "also", ",", "i.e.", "removing", "stop", "-", "words", ",", "removing", "of", "named", "entities", ",", "removing", "relevant", "words", "and", "replacing", "the", "question", "words", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "roles", "of", "HN", ",", "VN", ",", "CN", "and", "FG", "in", "AON", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "filter gate"}, {"tokens": ["The", "AV", "and", "RV", "strategy", "requires", "information", "of", "at", "least", "75", "of", "nodes", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["From", "the", "figure", ",", "we", "conclude", "that", "a", "higher", "aggregation", "level", "generally", "gives", "more", "protection", "level", "to", "the", "codewords", ",", "which", "is", "reflected", "on", "the", "required", "CNR", "for", "both", "LTE", "-", "eMBMS", "and", "NR", "-", "PTP", "solutions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "ESS", "is", "calculated", "as", "follows", ":"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "effective sample size"}, {"tokens": ["benchmark_ranking_g_mean_acc_byalg_overall.eps", "The", "average", "rank", "of", "7", "different", "algorithms", ",", "i.e.", "ECS", "-", "DBN", ",", "DBN", ",", "ADASYN", "-", "DBN", ",", "SMOTE", "-", "DBN", ",", "SMOTE", "-", "borderline1-DBN", ",", "SMOTE", "-", "borderline2-DBN", "and", "SMOTE", "-", "SVM", "-", "DBN", ",", "in", "terms", "of", "G", "-", "mean", "and", "accuracy", "on", "58", "KEEL", "benchmark", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["However", ",", "in", "the", "case", "when", "the", "typical", "UE", "is", "associated", "with", "a", "LOS", "MBS", ",", "it", "is", "possible", "that", "some", "non", "-", "serving", "NLOS", "MBSs", "exist", "who", "are", "closer", "to", "the", "typical", "UE", ",", "hence", ",", "their", "holes", "are", "closer", "than", "serving", "hole", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Similar", "comparison", "results", "can", "be", "observed", "on", "SVHN", "dataset", ":", "using", "MLconv", "layers", "obtained", "lower", "classification", "errors", "as", "compared", "to", "LR", "layers", "at", "all", "complexity", "configurations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "low rank"}, {"tokens": ["PI", "uses", "the", "form", "of", "the", "problem", "seen", "in", "Eq", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["Let", "us", "now", "proceed", "by", "presenting", "the", "average", "parallel", "and", "the", "average", "sequential", "complexity", "imposed", "both", "by", "the", "EQPO", "algorithm", "and", "by", "the", "CDP", "method", ",", "which", "are", "shown", "in", "Figs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classical dynamic programming"}, {"tokens": ["Our", "view", "also", "includes", "weight", "-", "corrective", "variants", "of", "MP", "and", "FW", "which", "we", "are", "able", "to", "set", "in", "direct", "correspondence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["Further", ",", "grid", "operators", "must", "typically", "meet", "(", "at", "least", ")", "reliability", "requirements", "(", "e.g.", "North", "American", "Electric", "Reliability", "Cooperation", "requirement", "for", "the", "US", "grid", "operators", ")", ",", "resulting", "in", "additional", "constraints", "that", "significantly", "increase", "the", "computational", "complexity", "of", "OPF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "optimal power flow"}, {"tokens": ["In", "this", "section", ",", "we", "succinctly", "present", "basic", "FCA", "elements", "(", "thefundamental", "reference", "is", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "formal concept analysis"}, {"tokens": ["Task", "OverviewThe", "goal", "of", "single", "-", "language", "adaptation", "is", "to", "develop", "and", "evaluate", "a", "language", "-", "specific", "ARS", "model", "for", "a", "single", "target", "language", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "addressee and response selection"}, {"tokens": ["The", "number", "of", "documents", "(", "n", ")", "versus", "the", "number", "of", "LScDC", "words", "contained", "in", "n", "or", "less", "documents", "in", "the", "LSC", "after", "cleaning", "words", "appearing", "in", "not", "greater", "than", "10", "(", ")", "documents", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Extending", "it", "to", "multiple", "SCCs", "as", "above", ",", "we", "get", ":", "Let", "be", "a", "PSP", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strongly connected components"}, {"tokens": ["Accelerating", "ARD", "using", "fast", "adversarial", "training", "methodsThe", "ARD", "procedure", "described", "above", "takes", "approximately", "the", "same", "amount", "of", "time", "as", "adversarial", "training", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["The", "performance", "indices", "used", "for", "evaluation", "are", ":", "Arbitrage", "and", "self", "-", "sufficiency", "gains", "(", ")", ";", "Peak", "shaving", "gains", "(", "):", "difference", "between", "nominal", "PPC", "and", "the", "new", "PPC", "contract", "after", "adding", "storage", ";", "Total", "gains", "(", "):", "is", "the", "sum", "of", "and", ",", "Gains", "per", "cycle", "(", "):"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "peak power contract"}, {"tokens": ["DBN", "structure", "and", "parameters", "setup"], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Baumgartner", "MF", ",", "Fratantoni", "DM", ",", "Hurst", "TP", ",", "Brown", "MW", ",", "Cole", "TVN", ",", "Van", "Parijs", "SM", ",", "et", "al", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["First", ",", "as", "far", "as", "we", "know", ",", "the", "existing", "OR", "approaches", "introduced", "for", "biomanufacturing", "still", "focus", "on", "developing", "general", "methodologies", ",", "and", "they", "do", "not", "fully", "explore", "the", "pharmaceutical", "biotechnology", "domain", "knowledge", "(", "e.g.", ",", "the", "underlying", "physical", "mechanics", "causing", "the", "interdependence", "of", "raw", "material", "quality", ",", "production", "process", ",", "and", "bio", "-", "drug", "properties", "in", "safety", "and", "efficacy", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "operations research"}, {"tokens": ["Besides", ",", "developing", "threshold", "dependent", "camouflage", "cells", "involves", "dopant", "variation", "which", "can", "be", "identified", "from", "SEM", "imaging", "of", "the", "die", "at", "different", "beam", "voltages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Moreover", ",", "the", "alternative", "constellation", "points", "in", "TI", "technique", "have", "an", "increased", "energy", "and", "the", "implementation", "complexity", "increases", "due", "to", "the", "computation", "of", "theoptimal", "translation", "vector", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tone injection"}, {"tokens": ["On", "the", "other", "hand", ",", "some", "BPM", "languages", "focus", "on", "representing", ",", "in", "a", "lower", "-", "level", "of", "abstraction", ",", "the", "process", "execution", "details", ",", "e.g.", ",", "BPEL", "(", "process", "implementation", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "business process modelling"}, {"tokens": ["We", "used", "insights", "and", "data", "from", "our", "prior", "work", ",", "reported", "in", ",", "to", "inform", "the", "design", "of", "the", "controllers", "for", "SAR", "personalization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Generally", ",", "the", "problem", "in", "(", ")", "is", "an", "NP", "-", "hard", "combinatorial", "problem", ",", "but", "the", "LB", "divergence", "provides", "a", "close", "-", "form", "solution", ",", "where", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["Figure", "shows", "AP", "gap", "for", "all", "30", "attributes", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["With", "11", "neurons", "in", "the", "input", "layer", ",", "the", "implemented", "ANN", "contained", "three", "hidden", "layers", "with", "100", ",", "50", "and", "25", "neurons", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Experimental", "studies", "conducted", "on", "fixed", "topology", "feedforward", "neural", "networks", "indicate", "a", "significant", "improvement", "over", "standard", "DE", "and", "CMA", "-", "ES", "techniques", "in", "terms", "of", "global", "convergence", "speed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["But", ",", "the", "main", "focus", "of", "research", "effort", "so", "far", "has", "been", "spent", "on", "interfacing", "speech", "to", "IR", "-", "based", "QA", "systems", ",", "and", "much", "less", "on", "interfacing", "speech", "input", "to", "QA", "systems", "based", "on", "KGs", "(", "knowledge", "graphs", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["However", ",", "not", "only", "human", "readers", "may", "benefit", "from", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "tree structures"}, {"tokens": ["Convergence", "curves", "for", "regression", "by", "DE", "(", "left", ")", "and", "CMA", "-", "ES", "(", "right", ")", "using", "the", "sinc", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["In", ",", "two", "MD", "video", "coding", "coders", "employ", "a", "poly", "-", "phase", "downsampling", "technique", "to", "create", "multiple", "descriptions", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["As", "can", "be", "found", "in", "the", "experimental", "results", ",", "the", "improvement", "of", "SFM", "over", "the", "traditional", "collaborative", "filtering", "methods", "(", "e.g.", ",", "MF", ")", "is", "significant", "for", "datasets", "that", "are", "sparse", ",", "mainly", "because", "the", "number", "of", "samples", "is", "too", "scarce", "to", "model", "the", "items", "and", "users", "adequately", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "structural factorization machine"}, {"tokens": ["Regarding", "these", "matters", ",", "we", "propose", "a", "generic", "framework", "to", "enable", "DL", "for", "RS", "images", ",", "which", "(", "i", ")", "is", "open", "-", "source", "and", "cross", "-", "platform", ",", "(", "ii", ")", "enables", "users", "without", "programming", "knowledge", "to", "use", "deeps", "nets", "on", "RS", "images", ",", "(", "iii", ")", "is", "integrated", "in", "an", "existing", "rich", "machine", "learning", "framework", "for", "RS", "images", ",", "(", "iv", ")", "is", "computationally", "efficient", "and", "allows", "the", "processing", "of", "very", "large", "RS", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "remote sensing"}, {"tokens": ["Most", "of", "the", "recent", "research", "on", "PSO", "based", "feature", "selection", "are", "either", "application", "of", "BPSO", "or", "some", "extension", "of", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["We", "looked", "into", "the", "length", "of", "CC", "phases", "of", "user", "devices", "and", "found", "that", "around", "38", "devices", "among", "all", "the", "devices", "had", "CC", "phase", "length", "of", "zero", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["We", "note", "that", "the", "decision", "problem", "is", "in", "NP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "natural problem"}, {"tokens": ["The", "WER", "metric", "is", "computed", "similar", "to", "CER", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "character error rate"}, {"tokens": ["We", "evaluate", "the", "original", "DTP", "and", "FPL", "models", "for", "trajectory", "forecasting", ",", "as", "well", "as", "the", "versions", "modified", "for", "MOF", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic trajectory predictor"}, {"tokens": ["fig", ":", "internationalfigurefigure[tb", "]", "0.85", "tabularlrrrrrrrrr", "Ads", "&", "Non", "-", "ads", "&", "Accuracy", "&", "FP", "&", "FN", "&", "TP", "&", "TN", "&", "Precision", "&", "Recall", "354", "&", "1,830", "&", "92.0", "&", "68", "&", "106", "&", "248", "&", "1,762", "&", "0.784", "&", "0.7", "tabularOnline", "evaluation", "of", "Facebook", "ads", "and", "sponsored", "content", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true negative"}, {"tokens": ["Matching", "our", "intuition", ",", "we", "can", "see", "how", "the", "GT", "approach", "outperforms", "the", "DI", "only", "when", "is", "sufficiently", "high", ",", "and", "also", "that", "the", "gain", "in", "utility", "is", "larger", "for", "than", "for", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "direct inspection"}, {"tokens": ["Consensus", "segmentation", "results", "are", "also", "shown", "for", ",", "i.e.", ",", "without", "our", "SC", "score", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "self consistency"}, {"tokens": ["So", ",", "the", "SC", "can", "be", "achieved", "by", "adding", "Eq", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["So", ",", "we", "employed", "the", "NB", "and", "DT", "for", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["We", "trained", "LSTMs", "on", "both", "positive", "and", "negative", "examples", "of", "SL", "and", "SP", "languages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["LTE", "-", "U", "utilizes", "the", "unlicensed", "spectrum", "only", "for", "the", "downlink", "and", "all", "uplink", "transmissions", "use", "the", "licensed", "spectrum", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["A", "CNOMA", "-", "OAM", "is", "proposed", "to", "enhance", "the", "SC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "sum capacity"}, {"tokens": ["Epoch", "Vs", "CTC", "Loss", "for", "128", "units", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["The", "base", "station", "(", "BS", ")", "is", "assumed", "to", "have", "the", "imperfect", "knowledge", "of", "the", "direction", "angle", "towardeach", "eavesdropper", ",", "with", "the", "estimation", "error", "following", "the", "Von", "Mises", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Also", ",", "the", "extended", "version", "of", "R2U2", "provides", "detection", "of", "attack", "patterns", "(", "i.e.", ",", "ill", "-", "formatted", "and", "illegal", "commands", ",", "dangerous", "commands", ",", "nonsensical", "or", "repeated", "navigation", "commands", "and", "transients", "in", "GPS", "signals", ")", "rather", "than", "component", "failures", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["[", "2", "]", "When", "using", "the", "ground", "truth", "bounding", "boxes", "at", "test", "time", "(", "as", "we", "do", ")", "the", "IS", "increases", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["In", "CB", "-", "CSMA", "/", "CA", ",", "STAs", "are", "grouped", "in", "clusters", ",", "and", "the", "AP", "is", "assumed", "to", "have", "MPR", "capabilities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["The", "learned", "weights", "for", "the", "respective", "hidden", "layers", "of", "DBN", "are", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["&", "&", "UCSD", "to", "&", "Mall", "to", "Method", "&", "Mall", "&", "UCSD", "FA", "&", "7.47", "&", "4.44", "HGP", "&", "4.36", "&", "3.32", "GPA", "&", "4.18", "&", "2.79", "GPTL", "&", "3.55", "&", "2.91", "Bidirectional", "ConvLSTM", "&", "2.63", "&", "1.82", "-2em"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feature alignment"}, {"tokens": ["If", "then", "player", "wins", "with", "the", "MD", "strategy", "from", "Lemma", "lem", ":", "optmin", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["NP", "buzurgPIr"], "acronym_pos": [1, 0], "long_form": "new persian"}, {"tokens": ["BF", "affords", "more", "importance", "to", "the", "first", "appearance", "of", "a", "word", ",", "and", "the", "others", "an", "equally", "less", "importance", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary function"}, {"tokens": ["POS", "tagging", "results", "show", "that", "both", "models", "released", "in", "scispaCy", "are", "competitive", "with", "state", "of", "the", "art", "systems", ",", "and", "can", "be", "considered", "of", "equivalent", "practical", "value", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["hist.eps[Original", "RGB]fig", ":", "rgb", "-", "histrgb", "-", "hist.epsPixel", "value", "distributions", "(", "by", "color", "channel", ")", "at", "three", "points", "along", "the", "ISP", "pipeline", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "image signal processor"}, {"tokens": ["These", "results", "provide", "insights", "to", "Data", "Science", "researchers", ",", "educators", ",", "and", "policy", "-", "makers", "from", "other", "advanced", "economies", "about", "the", "types", "of", "skills", "that", "should", "be", "cultivated", "to", "meet", "growing", "DSA", "labour", "demands", "in", "the", "future", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["When", "the", "NSIM", "value", "changes", "because", "of", "change", "in", "number", "of", "topics", ",", "a", "different", "article", "with", "maximum", "DI", "score", "can", "get", "selected", "leading", "to", "change", "in", "the", "values", "of", "NDL", ",", "NPNF", ",", "UniqT", "and", "the", "final", "IPI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "document index"}, {"tokens": ["Using", "real", "-", "time", "SRL", "tools", ",", "we", "note", "discontinuities", "in", "the", "state", "space", "learned", "by", "AE", ",", "even", "if", "reconstruction", "error", "is", "low", ",", "and", "that", "hinders", "RL", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["Overlapping", "SBM", "When", "applying", "MMSBMs", ",", "while", "some", "nodes", "might", "have", "genuine", "mixed", "memberships", ",", "some", "other", "nodes", "might", "have", "single", "memberships", ",", "that", "is", ",", "being", "a", "vector", "with", "all", "0", "'s", "but", "one", "1", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["In", "the", "course", "of", "two", "years", ",", "PLOS", "One", "articles", "went", "from", "virtually", "no", "articles", "with", "a", "DAS", "(", "2013", ")", "to", "more", "than", "half", "of", "articles", "(", "2015", ")", "having", "a", "DAS", "of", "category", "2", "or", "3", ",", "(", "those", "are", "\"", "data", "within", "the", "article", "\"", "and", "\"", "data", "in", "a", "repository", "\"", "respectively", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data availability statement"}, {"tokens": ["Performance", "on", "BraTS2017", "training", "and", "validation", "setsEvaluation", "of", "the", "results", "is", "performed", "merging", "the", "predicted", "labels", "into", "three", "classes", ":", "enhancing", "tumor", "ET", "(", "label", "1", ")", ",", "whole", "tumor", "WT", "(", "labels", "1", ",", "2", ",", "4", ")", ",", "and", "tumor", "core", "TC", "(", "labels", "1", ",", "4", ")", ",", "using", "Dice", "score", ",", "Hausdorff", "distance", ",", "Sensitivity", "and", "Specificity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["It", "can", "also", "be", "concluded", "that", "subsampled", "images", "are", "unable", "to", "capture", "the", "distribution", "of", "real", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["Checking", "whether", "an", "NCA", "is", "DBP", "is", "NP", "-", "hard", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["welfare", "in", "addition", "to", "modifying", "the", "SSS", "by", "restricting", "the", "action", "set", "and", "influencing", "the", "decisions", "of", "their", "non", "-", "fixed", "neighbors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastically stable states"}, {"tokens": ["As", "in", "the", "SBM", "introduced", "in", "Section", ",", "the", "groups", "of", "nodes", "and", "arise", "from", "a", "multinomial", "distribution", ",", "and", "the", "edge", "variable", "follows", "a", "Bernoulli", "distribution", "with", "parameter", ",", "where", "and", "represent", "the", "memberships", "in", "the", "groups", ",", "not", "the", "topics", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "best", "performers", "are", "identified", "using", "the", "ROC", "and", "accuracy", "values", "shown", "in", "Tables", "I", "and", "II", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["By", "adding", "a", "tailored", "amount", "of", "redundancy", "to", "each", "FEC", "block", ",", "it", "is", "possible", "to", "better", "protect", "the", "most", "QoE", "-", "sensitive", "data", ",", "maximising", "the", "video", "quality", "and", ",", "at", "the", "same", "time", ",", "minimising", "the", "network", "overhead", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "aim", "of", "this", "paper", "is", "to", "describe", "all", "researching", "work", "made", "for", "selecting", "and", "computing", "attribute", "sets", "related", "to", "soccer", "results", ",", "into", "a", "specific", "framework", ":", "FCA", ",", "and", "starting", "from", "soccer", "match", "results", ",", "with", "no", "previous", "analysis", "of", "any", "other", "specific", "attributes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "formal concept analysis"}, {"tokens": ["GPS", "formulationThe", "unconstrained", "problem", "of", "minimizing", "a", "continuously", "differentiable", "function", "is", "formally", "described", "as", "Next", "we", "present", "a", "short", "description", "of", "iterative", "GPS", "minimization", "of", "Eq", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["Section", "briefly", "explains", "the", "IB", "and", "TPIB", "systems", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["As", "can", "be", "seen", ",", "DMD", "itself", "performs", "quite", "well", "but", "fails", "in", "some", "examples", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deficient mapping dissolution"}, {"tokens": ["Figure", "shows", "an", "example", "of", "a", "feed", "-", "forward", "ANN", "with", "two", "hidden", "layers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Of", "importance", "is", "the", "reason", "behind", "the", "DC", "-", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "stochastic block model"}, {"tokens": ["This", "effect", "is", "called", "the", "effect", "of", "gathering", "AN", "due", "to", "multipath", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["[", "Bijective", "mapping", "between", "IB", "curve", "point", "and", "convex", "IB", "Lagrange", "multiplier", "]"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["A", "third", "solution", "strategy", "that", "has", "been", "popular", "during", "many", "years", ",", "is", "a", "combination", "that", "approximates", "radiation", "damping", "via", "the", "BEM", "technique", ",", "while", "the", "scatterer", ",", "(", "including", "heterogeneities", "and/or", "nonlinearities", ")", ",", "is", "treated", "with", "an", "FEM", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "finite element method"}, {"tokens": ["This", "is", "not", "required", "for", "symmetry", "breaking", "approaches", "which", "map", "each", "solution", "cadidate", "exactly", "to", "the", "selected", "partition", ",", "such", "as", "DE", "-", "INV", "-", "SB", "or", "DE", "-", "SB", "-", "BF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "brute force search"}, {"tokens": ["As", "a", "result", ",", "excluding", "the", "QA", "has", "the", "largest", "difference", "between", "the", "min", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "quantum annealing"}, {"tokens": ["To", "show", "the", "effect", "of", "dilated", "convolutions", ",", "we", "replace", "the", "backbone", "of", "EncNet", "with", "that", "of", "the", "original", "FCN", "(", "the", "same", "as", "our", "method", ")", ",", "resulting", "in", "the", "OS", "to", "be", "32", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "output stride"}, {"tokens": ["The", "attention", "centers", "are", "marked", "as", "''", "of", "yellow", "(", "for", "AN", ")", "and", "green", "(", "for", "FAN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["The", "poor", "results", "for", "UC4", "indicate", "that", "we", "need", "more", "sophisticated", "algorithms", "than", "MP", "and", "CF", "in", "this", "setting", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "most popular"}, {"tokens": ["The", "ACK", "-", "delay", "problem", "refers", "to", "that", ",", "due", "to", "different", "transmission", "durations", "of", "asynchronous", "uplink", "transmissions", ",", "the", "delayed", "ACKs", "sent", "by", "the", "AP", "to", "those", "earlier", "-", "finished", "STAs", "can", "trigger", "STAs", "'", "ACK", "time", "-", "out", "counters", ",", "which", "could", "interrupt", "the", "ACK", "'s", "transmission", "and", "degrade", "the", "network", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["GP", "-", "UCB", "GP", "-", "UCB", "we", "use", "is", "originated", "from", "Srinivas", "but", "extended", "to", "take", "into", "account", "our", "problem", "setting", "."], "acronym_pos": [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Our", "motivation", "to", "use", "a", "multi", "-", "task", "method", "is", "in", "the", "same", "spirit", "as", "where", "they", "employed", "related", "syntactic", "tasks", "to", "improve", "SRL", "in", "low", "-", "resource", "languages", "as", "multi", "-", "task", "learning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["CUB", "has", "particular", "architecture", "-", "based", "fine", "-", "grained", "optimizations", ",", "and", "we", "suspect", "it", "is", "originally", "optimized", "for", "when", "ECC", "is", "disabled", "to", "use", "all", "hardware", "resources", "to", "exploit", "all", "available", "bandwidth", "as", "much", "as", "possible", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["Referring", "to", "Figure", ",", "we", "use", "for", "input", "high", "resolution", "images", "of", "size", ",", "for", "generated", "LR", "images", "of", "size", "and", "for", "real", "LR", "images", "of", "the", "same", "size", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["The", "proposed", "method", "converges", "to", "the", "optimal", "EB", "solution", "as", "the", "iterations", "proceed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "energy beam"}, {"tokens": ["If", "QA", "is", "biased", "(", "bad", "QA", ")", ",", "it", "will", "come", "up", "with", "discriminating", "information", "which", "is", "biased", "based", "on", "race", ",", "gender", ",", "age", ",", "ethnicity", ",", "religion", ",", "social", "or", "political", "rank", "of", "publisher", "and", "targeted", "user", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["tab", ":", "evaluation", "tabularlllll", "&", "2cXING", "&", "2cTMALL", "1", "-", "5", "&", "Recall@20", "&", "MRR@20", "&", "Recall@20", "&", "MRR@20", "1", "-", "5", "ItemKNN", "&", "0.2235", "&", "0.0932", "&", "0.1541", "&", "0.0614", "GRU4REC", "&", "0.2597", "&", "0.1169", "&", "0.3789", "&", "0.1886", "PNN", "&", "0.1439", "&", "0.0507", "&", "0.1755", "&", "0.0694", "ARNN", "&", "0.3106", "&", "0.1252", "&", "0.3812", "&", "0.1953", "tabular", "tableEvaluation", "of", "our", "model", "on", "XING", "provided", "us", "with", "a", "clear", "evidence", "that", "capturing", "user", "-", "contextual", "preference", "using", "a", "PNN", "is", "indeed", "helpful", "for", "RNN", "session", "models", "when", "rich", "user", "-", "side", "context", "is", "available", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["In", "general", ",", "the", "results", "suggest", "that", "PA", "task", "is", "harder", "than", "LA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["The", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "enhances", "the", "spectral", "efficiency", "and", "energy", "efficiency", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "ANN", "model", "was", "implemented", "using", "the", "Keras", "library", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["As", "part", "of", "our", "algorithm", "IA", ",", "we", "also", "propose", "a", "new", "algorithm", "with", "lower", "time", "complexity", "for", "updating", "single", "-", "source", "shortest", "paths", "in", "unweighted", "graphs", "after", "a", "batch", "of", "edge", "insertions", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "incremental approximation"}, {"tokens": ["The", "purpose", "of", "deploying", "these", "FPRNs", "is", "to", "initiate", "connections", "among", "CHs", "and", "BS", "whose", "positions", "are", "fixed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Due", "to", "utilizing", "the", "separate", "time", "slot", "for", "each", "transmission", "except", "OAM", "based", "transmission", ",", "the", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "provides", "comparatively", "lower", "SC", "w.r.t", "than", "the", "proposed", "scheme", "which", "is", "illustrated", "in", "Figure", "7", "as", "before", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["However", ",", "sampling", "of", "SciCorp", "differs", "from", "the", "LSC", "as", "being", "restricted", "to", "two", "disciplines", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Tumor", "core", "(", "TC", ")", "is", "the", "union", "of", "necrosis", "non", "-", "enhancing", "tumor", "and", "enhancing", "tumor", "(", "ET", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["In", "summary", ",", "our", "results", "show", "that", "autonomous", ",", "personalized", "SAR", "interventions", "are", "both", "feasible", "and", "effective", "in", "providing", "long", "-", "term", "in", "-", "home", "developmental", "support", "for", "children", "with", "diverse", "learning", "needs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["An", "example", "of", "a", "PDP", "is", "shown", "in", "Figure", "fig", ":", "screenshot", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product display page"}, {"tokens": ["The", "model", "is", "kept", "relatively", "simple", "so", "that", "the", "comparisons", "against", "previous", "methods", "are", "directly", "comparable", "and", "that", "the", "performance", "comparison", "between", "the", "proposed", "SCP", "loss", "and", "KL", "divergence", "loss", "against", "MSE", "and", "MAE", "is", "controlled", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "squared cosine proximity"}, {"tokens": ["BPP", "deployed", "at", "a", "particular", "height", "above", "the", "ground", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binomial point process"}, {"tokens": ["Therefore", ",", "the", "power", "allocation", "Problem", "is", "a", "standard", "GP", "(", "convex", "problem", ")", ",", "where", "the", "objective", "function", "and", "constraints", "are", "monomial", "and", "polynomials", ",", "which", "completes", "the", "proof", "of", "Proposition", "1", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["For", "distractor", "free", "training", ",", "is", "0.2", "is", "0.1", ",", "the", "VAT", "is", "18", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["The", "TP", "runs", "only", "if", "the", "winning", "cluster", "in", "the", "SP", "changes", "which", "results", "in", "an", "event", "-", "driven", "architecture", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial pooler"}, {"tokens": ["Lastly", ",", "we", "find", "a", "concrete", "vulnerability", "for", "the", "malicious", "corrupt", "receiver", "case", "in", "Lambaek", "'s", "PSI", "protocol", "when", "semi", "-", "honest", "KK13", "OT", "protocol", "is", "used", "in", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["On", "the", "multi", "-", "center", "test", "data", ",", "the", "U", "-", "Net", "performs", "only", "slightly", "worse", ",", "with", "average", "dice", "scores", "of", "(", "VAT", ")", "and", "(", "SAT", ")", "and", "quantification", "errors", "of", "(", "VAT", ")", "and", "(", "SAT", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["That", "is", ",", "we", "suppose", "the", "Bregman", "divergence", "in", "eq", ":", "DMD", "has", "a", "quadratic", "form(This", "is", "generated", "by", "defining", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["Note", "that", "the", "macroscopic", "coordinate", "is", "not", "assumed", "to", "influence", "the", "RB", "approximation", ",", "i.e.", ",", "the", "same", "approximation", "is", "made", "throughout", "the", "macrostructure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["To", "demonstrate", "the", "effectiveness", "of", "DDE", "-", "MGM", "on", "modeling", "streaming", "time", "series", ",", "the", "PAMAP", "dataset", "is", "adopted", "because", "its", "samples", "last", "tens", "of", "minutes", "(", "comprising", "tens", "of", "thousands", "of", "points", ")", "that", "could", "be", "considered", "a", "streaming", "time", "series", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["A", "low", "ESS", "means", "that", "most", "of", "the", "weight", "is", "being", "placed", "on", "a", "small", "number", "of", "particles", ",", "and", "hence", "the", "approximation", "may", "be", "degenerate", "(", "although", "in", "some", "cases", "this", "may", "mean", "that", "the", "target", "distribution", "is", "peaky", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "effective sample size"}, {"tokens": ["we", "have", "and", ",", "where", "and", "stand", "for", "the", "initial", "distances", "between", "the", "BS", "and", "the", "MS", "and", "the", "MS", "and", "the", "IO", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "have", "to", "also", "note", "that", "in", "contrast", "with", "the", "NER", "task", ",", "the", "MD", "task", "did", "not", "enjoy", "a", "performance", "increase", "from", "joint", "learning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "morphological disambiguation"}, {"tokens": ["Following", "prior", "work", ",", "we", "primarily", "report", "CER", "results", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "character error rate"}, {"tokens": ["The", "transferability", "of", "features", "needs", "to", "be", "further", "explored", "and", "the", "discrepancy", "between", "source", "data", "and", "SAR", "targets", "should", "be", "fully", "taken", "into", "consideration", "to", "improve", "the", "performance", "of", "transfer", "learning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["BF", "affords", "more", "importance", "to", "the", "first", "appearance", "of", "a", "word", ",", "and", "the", "others", "an", "equally", "less", "importance", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary function"}, {"tokens": ["The", "reason", "for", "this", "is", "that", "even", "if", "the", "Temporal", "Pooler", "predicts", "a", "uniform", "distribution", "over", "the", "hidden", "states", "(", "i.e.", "the", "TP", "is", "not", "trained", "yet", ")", ",", "all", "the", "cluster", "centers", "are", "moving", "closer", "towards", "the", "real", "data", "and", "thus", "the", "average", "prediction", "improves", "no", "matter", "what", "cluster", "is", "predicted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["We", "also", "construct", "and", "share", "the", "list", "of", "top", "DSA", "skills", "generated", "from", "this", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["Additionally", ",", "SAR", "interventions", "target", "special", "populations", ",", "such", "as", "linguistic", "minorities", "(", "e.g.", ",", "American", "Sign", "Language", ")", "or", "personals", "with", "disabilities", "that", "involve", "speech", "and", "language", "difficulties", "or", "delays", "(", "e.g.", ",", "Dysarthria", "or", "autism", "spectrum", "disorder", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Metalearner", "PerformanceWhile", "the", "accuracy", "of", "prediction", "is", "not", "improved", "through", "the", "aggregation", "of", "high", "-", "performance", "models", "into", "a", "probability", "vote", "meta", "-", "learner", ",", "the", "Area", "under", "the", "ROC", "is", "the", "greatest", "of", "all", "that", "have", "been", "observed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Using", "the", "example", "of", "2", "layers", ",", "they", "assumed", "the", "adjacency", "matrix", "of", "layer", "is", "generated", "by", "a", "Bernoulli", "SBM", "according", "to", "block", "matrix", "independently", ",", "and", "then", "considered", "two", "versions", "of", "the", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["This", "new", "model", "parameterizes", "the", "FIR", "filters", "as", "windowed", "-", "sinc", "filters", "and", "predicts", "their", "MVF", "values", "from", "the", "input", "acoustic", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["Adaptive", "Video", "-", "aware", "Fuzzy", "Logic", "Mechanism", "(", "uavFEC)sec", ":", "uavFECConsidering", "the", "open", "issues", "aforementioned", "this", "section", "describes", "and", "evaluates", "the", "proposed", "cross", "-", "layer", "adaptive", "video", "-", "aware", "FEC", "mechanism", "(", "uavFEC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Moreover", ",", "the", "AlexNet", "proved", "the", "viability", "of", "DCNN", "approaches", "for", "object", "recognition", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["[", "The", "resultant", "GP", "learned", "by", "the", "UAV", "from", "real", "-", "world", "data", ".", "]"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["However", ",", "since", "the", "identity", "function", "is", "not", "strictly", "convex", ",", "it", "can", "not", "ensure", "the", "exploration", "of", "the", "IB", "curve", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["To", "sum", "up", ",", "we", "obtain", "the", "following", "conclusions", ":", "(", "i)By", "investigating", "feature", "interactions", ",", "PNN", "gains", "better", "capacity", "on", "multi", "-", "field", "categorical", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["In", "terms", "of", "scalability", "for", "single", "-", "output", "GP", "models", ",", "both", "and", "extended", "online", "learning", "methods", "and", "uncertainty", "propagation", "to", "the", "popular", "variational", "inference", "setup", "of", "sparse", "GP", "approximations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Then", "in", "Section", ",", "we", "present", "in", "detail", "the", "proposed", "derivative", "-", "free", "algorithm", ",", "a", "sketch", "of", "the", "reduction", "of", "the", "algorithm", "to", "the", "GPS", "formulation", "and", "the", "associated", "proof", "of", "fixed", "-", "point", "convergence", "guarantees", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["The", "experimental", "results", "showed", "that", "PSO", "achieves", "a", "better", "performance", "and", "a", "faster", "convergence", "in", "compared", "with", "GA", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["In", "this", "paper", ",", "we", "present", "a", "comprehensive", "analysis", "of", "IFT", "/", "formal", "Trojan", "detection", "techniques", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "information flow tracking"}, {"tokens": ["Now", "that", "we", "have", "formulated", "the", "problem", "and", "the", "variable", "in", "the", "appropriate", "format", "we", "can", "match", "each", "epoch", "of", "our", "initial", "algorithm", "with", "an", "iteration", "of", "a", "GPS", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "general pattern search"}, {"tokens": ["As", "seen", "from", "eq:11", ",", "the", "received", "signal", "has", "three", "Doppler", "components", ":", "Hz", ",", "Hz", ",", "and", "Hz", "due", "to", "the", "rays", "coming", "from", "the", "BS", ",", "IO", "1", ",", "and", "IO", "2", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["For", "the", "PSC", "problem", ",", "Feige", "showed", "that", "it", "can", "not", "be", "approximated", "within", "a", "factor", "of", "in", "polynomial", "time", "unless", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial set cover"}, {"tokens": ["Speech", "activity", "detector", "(", "SAD", ")", "is", "not", "employed", "as", "non", "-", "speech", "frames", "could", "be", "helpful", "for", "spoofing", "detection", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "speech activity detection"}, {"tokens": ["Considering", "the", "7", "FEC", "limit", "of", ",", "see", "dashed", "line", "in", "Fig", ".", ","], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["To", "avoid", "the", "wasted", "transmission", "resource", ",", "the", "develops", "a", "partial", "downloading", "scheme", "on", "the", "Exact", "-", "MBR", "code", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Interactive", "QA", "(", "IQA", ")", ":"], "acronym_pos": [0, 1, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["As", "proved", "in", ",", "the", "OT", "metric", "converges", "while", "other", "variants", "(", "KL", "or", "JS", "divergence", ")", "do", "not", "in", "some", "scenarios", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["The", "MP", "architecture", "improves", "performance", "especially", "when", "small", "metallic", "implants", "are", "dominated", "by", "the", "non", "-", "metal", "regions", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mask pyramid"}, {"tokens": ["[", "FEM", "result", "]", "[", "KIFMM", "result", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["We", "present", "a", "short", "survey", "of", "indexing", "platforms", "and", "data", "structures", "used", "in", "a", "wide", "range", "of", "QA", "systems", "in", "table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["NP", "narvan", "belong.(The", "elm", "appears", "to", "be", "the", "frequent", "target", "of", "folk", "etymology", "in", "Iranian", "languages", ";", "it", "is", "possible", "that", "Tati", "speakers", "have", "conflated", "the", "tree", "'s", "name", "with", "nal", "-", "band", "'", "smith", ",", "farrier", "'", "(", "Arabic", "na'l", "'", "horseshoe", "'", ")", ",", "on", "the", "basis", "of", "some", "perceived", "but", "non", "-", "obvious", "connection", "to", "horseshoes", ".", ")"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Hence", ",", "if", "the", "objective", "function", "in", "(", ")", "is", "reformulated", "into", "a", "posynomial", "function", ",", "problem", "(", ")", "is", "a", "standard", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "geometric programming"}, {"tokens": ["ht]Results", "of", "Posture", "Recognition", "&", "1l", "GMM", "&", "Skeleton", "&", "Angle", "&", "23", "&", "83.04", "SVM", "&", "RGB", "&", "HOG", "&", "23", "&", "97.95", "CNN", "&", "RGB", "&", "-", "&", "15", "&", "99.12"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "histogram of gradients"}, {"tokens": ["To", "improve", "the", "robustness", "to", "speech", "recognition", "errors", "of", "QA", "models", ",", "we", "augmented", "training", "data", "DRCD", "with", "DRCD", "-", "TTS", "and", "DRCD", "-", "backtrans", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Also", ",", "the", "learning", "system", "is", "limited", "to", "a", "maximum", "of", "100", "iterations", "per", "optimization", "run", "and", "importantly", ",", "the", "initial", "step", "of", "the", "model", "is", "trained", "using", "the", "standard", "variational", "bound", "of", "scalable", "sparse", "GP", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["For", "Mixed", "-", "Hero", ",", "the", "highest", "prediction", "accuracy", "is", "58.75", ",", "using", "a", "LR", "algorithm", "with", "features", "selected", "by", "the", "Wrapper", "feature", "selector", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Intuitively", ",", "is", "the", "probability", "that", "power", "vector", "is", "selected", "given", "that", "the", "network", "topology", "is", ",", "is", "the", "probability", "that", "MS", "opts", "to", "transmit", "the", "packets", "in", "the", "own", "queue", "to", "BS", "given", "that", "power", "vector", "is", "selected", "and", "the", "network", "topology", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["@X", "rrrrrrrrrr", "@", "&", "PC", "0", "&", "PC", "1", "&", "PC", "2", "&", "PC", "3", "&", "PC", "4", "&", "PC", "5", "&", "PC", "6", "&", "PC", "7", "&", "PC", "8", "&", "PC", "9", "CNS", "&", "0.39", "&", "0.17", "&", "0.12", "&", "0.08", "&", "0.07", "&", "0.06", "&", "0.04", "&", "0.03", "&", "0.03", "&", "0.01", "MDC", "&", "0.43", "&", "0.14", "&", "0.13", "&", "0.08", "&", "0.07", "&", "0.06", "&", "0.04", "&", "0.03", "&", "0.02", "&", "0.01", "Variance", "explained", "by", "principal", "components", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["The", "pre", "-", "training", "procedure", "of", "RBM", "of", "a", "DBN", "can", "be", "utilized", "to", "initialize", "the", "weight", "of", "DNNs", ",", "which", "can", "be", "discriminatively", "fine", "-", "tuned", "by", "BP", "error", "derivative", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Robustness", "of", "RS", "in", "FD", "systems?-ComparisonsThe", "metric", ",", "we", "employ", ",", "to", "shed", "light", "on", "this", "meaningful", "question", "is", "the", "theoretical", "DE", "sum", "-", "rate", "and", "the", "corresponding", "Monte", "Carlo", "simulation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deterministic equivalent"}, {"tokens": ["ROC", "AUC", "is", "the", "area", "under", "the", "receiver", "operating", "characteristic", "curve", "(", "Figure", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["corresponds", "to", "the", "desired", "energy", "buffer", "level", "and", "is", "the", "lowest", "EB", "level", "that", "the", "MEC", "server", "should", "ever", "reach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy buffer"}, {"tokens": ["Temperature", "distributions", "of", "the", "engine", "-", "block", "model", "computed", "by", "FEM", "and", "KIFMM", "BEM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["Major", "parts", "of", "the", "list", "were", "initially", "compiled", "by", "the", "member", "of", "the", "The", "list", "was", "compiled", "by", "the", "member", "of", "the", "Christian", "Doppler", "Laboratory", "for", "Handheld", "Augmented", "Reality(CDL", "on", "Handheld", "AR", ":", "http://studierstube.org/handheld_ar/", ")", "in", "2009", "(", "author", "list", "in", "alphabetical", "order", ")", "for", "the", "ISMAR", "society", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["For", "distractor", "free", "training", ",", "is", "3.5", ",", "the", "VAT", "is", "100", ",", "is", "0.4", "and", "is", "0.2", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["GP", "posterior"], "acronym_pos": [1, 0], "long_form": "gaussian process"}, {"tokens": ["Under", "this", "context", ",", "we", "considered", "the", "WST", "maximization", "problem", "and", "the", "TTP", "minimization", "problem", "through", "joint", "bandwidth", "unit", "and", "power", "allocation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "total transmit power"}, {"tokens": ["Importantly", ",", "it", "is", "shown", "that", "when", "the", "channel", "state", "information", "for", "RS", "is", "perfect", ",", "RS", "-", "based", "transmission", "schemes", "always", "outperform", "repetitive", "ones", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["images", "/", "dbpniterRecurrent", "DBPN", "with", "multiple", "pairs", "of", "projection", "units", "(", "DBPN", "-", "MR", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "middle resolution"}, {"tokens": ["The", "initial", "parameters", "of", "ICA", "algorithm", "are", "indicated", "in", "table", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "imperialist competitive algorithm"}, {"tokens": ["ABEP", ",", ",", "of", "DBPSK", "versus", "the", "number", "of", "relay", "nodes", ",", ",", "for", "different", "average", "transmit", "SNRs", "per", "bit", "and", "dB", ",", "over", "IID", "Rayleigh", "fading", "channels", ":", "(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["The", "idea", "of", "polyglot", "modeling", "has", "gained", "some", "traction", "in", "recent", "years", "for", "a", "variety", "of", "problems", "and", "has", "appeared", "within", "work", "in", "SP", "under", "the", "heading", "of", "multilingual", "SP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0], "long_form": "semantic parsing"}, {"tokens": ["Access", "is", "conditioned", "by", "several", "factors", "including", "staple", "prices", "and", "household", "income", "for", "which", "EO", "data", "can", "also", "provide", "interesting", "insight", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "earth observation"}, {"tokens": ["The", "second", "result", "is", "the", "systematic", "version", "of", "Exact", "-", "MBR", "code", "for", "all", "feasible", "values", "of", "based", "on", "the", "framework", "defined", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Although", "DDE", "-", "MGM", "takes", "longer", "time", "on", "the", "whole", "dataset", "(", "2858", "samples", ")", "in", "the", "online", "testing", ",", "it", "can", "still", "achieve", "real", "-", "time", "performance", "on", "any", "single", "sample", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["The", "CER", "is", "calculated", "using", "the", "disagreements", "(", "i.e.", ",", "one", "minus", "rand", "index", ")", "between", "the", "true", "and", "estimated", "block", "partitions", "in", "the", "three", "-", "way", "tensor", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "clustering error rate"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "RV", "strategy", "requires", "to", "up", "10", "K", "(", "about", "3", "of", "total", "nodes", ")", "nodes", "at", "and", "it", "is", "increased", "if", "is", "reduced", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["A", "cooperative", "jamming", "scheme", "was", "proposed", "in", "to", "enhance", "the", "PLS", ",", "and", "the", "authors", "analysed", "the", "impact", "of", "PA", "parameter", "between", "confidential", "information", "and", "AN", "by", "minimizing", "the", "secrecy", "outage", "probability", "subject", "to", "a", "minimum", "SR", "constraint", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["In", "particular", ",", "the", "number", "of", "test", "-", "retest", "images", "is", "usually", "just", "two", ",", "which", "may", "not", "suffice", "to", "determine", "the", "ICC", "with", "good", "precision", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["GHz", ",", "m", "/", "s", "with", "varying", "and", "values", "for", "a", "fixed", "BS", "-", "IO", "total", "distance", "of", "m."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "average", "achievable", "rates", "with", "SBS", "cooperation", "strategies", "are", "presented", "in", "Section", "III", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["Since", "the", "capture", "model", "can", "not", "perfectly", "reverse", "the", "ISP", "processing", ",", "it", "can", "not", "be", "validated", "by", "simply", "comparing", "a", "raw", "image", "to", "the", "result", "of", "running", "that", "image", "through", "our", "ISP", "model", "and", "then", "the", "capture", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["These", "works", "demonstrate", "that", "CNNs", "are", "capable", "of", "replicating", "ISP", "functions", ",", "and", "even", "exceeding", "them", "in", "terms", "of", "PSNR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Static", "routing", "of", "requests", "can", "be", "used", "to", "balance", "disk", "loads", "due", "to", "reads", "in", "CD", "as", "illustrated", "in", "Figure", "in", "Sectionsec", ":", "org", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["This", "network", "defined", "the", "default", "classification", "approach", ",", "where", "the", "DCNN", "first", "performs", "several", "convolutions", "and", "pooling", "operations", "in", "order", "to", "extract", "high", "-", "level", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["According", "to", "the", "main", "idea", ",", "the", "allocation", "of", "the", "fraction", "results", "by", "setting", "thetotal", "transmit", "power", "of", "the", "private", "messages", "of", "RS", ",", "in", "order", "to", "achieve", "approximately", "the", "same", "sum", "rate", "as", "the", "conventional", "multi", "-", "user", "BC", "with", "full", "power", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "broadcast channel"}, {"tokens": ["Definitions", "Centrality", "measuresBetweenness", "centrality", "(", "BC", ")", "is", "used", "to", "measure", "the", "extent", "to", "which", "a", "node", "lies", "on", "shortest", "paths", "between", "other", "node", "pairs", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["Betweenness", "Centrality", "(", "BC", ")", "plays", "a", "very", "important", "role", "in", "finding", "user", "'s", "shortest", "route", "hence", ",", "like", "DDC", ",", "BC", "-", "BC", "correlation", "may", "be", "used", "to", "assign", "a", "shortest", "as", "well", "as", "efficient", "route", "to", "each", "user", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["Our", "model", "exhibits", "a", "relative", "improvement", "of", "in", "epoch", "-", "wise", "accuracy", "on", "the", "SC", "-", "task", "and", "on", "the", "RS", "-", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "random split"}, {"tokens": ["In", "some", "cases", ",", "the", "goal", "of", "applying", "an", "SBM", "is", "not", "(", "only", ")", "the", "inference", "of", "the", "group", "memberships", ",", "but", "on", "dealing", "with", "partially", "or", "errorfully", "observed", "graphs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "model", "with", "this", "likelihood", "will", "be", "called", "the", "Bernoulli", "SBM", "hereafter", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["We", "also", "compared", "the", "results", "of", "our", "algorithm", "with", "other", "surrogate", "methods", "such", "as", "using", "a", "DT", "model", "trained", "over", "the", "same", "features", "and", "using", "as", "target", "variable", "the", "anomalous", "or", "non", "-", "anomalous", "labels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["The", "test", "-", "retest", "ICC", "was", "determined", "between", "both", "CT", "images", ",", "see", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["This", "is", "mainly", "driven", "by", "the", "strong", "intention", "both", "from", "3GPP", "and", "LTE", "-", "U", "forum", "to", "implement", "the", "technology", "as", "soon", "as", "possible", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Related", "worksWe", "mainly", "review", "four", "kinds", "of", "MDC", "methods", ":", "MD", "quantizers", ",", "correlating", "transform", "-", "based", "MDC", "methods", ",", "sampling", "-", "based", "MDC", "and", "standard", "-", "compliant", "MDC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["Case", "3", "(", "IFW", ")", ":", "Each", "small", "cell", "(", "IFW)operates", "in", "licensed", "and", "unlicensed", "bands", "with", "LTE", "and", "WiFi", "airinterfaces", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["We", "formulated", "two", "separate", "approaches", ",", "WF", "and", "WPR", ",", "that", "work", "also", "jointly", "and", "rely", "on", "the", "definition", "of", "canonical", "poses", ",", "weight", "-", "controlled", "fusion", ",", "generated", "canonical", "poses", "sequences", "and", "viewpoint", "-", "based", "sequences", "alignment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "weighted fusion"}, {"tokens": ["A", "similar", "concern", "is", "that", "of", "homophony", "between", "reconstructed", "etyma", ",", "namely", "formally", "identical", "items", "that", "can", "not", "be", "unified", "semantically", "(", "e.g.", ",", "*", "uarma-", "NP", "barm", "'", "pond", "'", "and"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["The", "top", "row", "shows", "the", "results", "for", "the", "normal", "IB", "Lagrangian", ",", "and", "the", "bottom", "row", "for", "the", "power", "IB", "Lagrangian", "with", ",", "both", "in", "the", "TREC-6", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Comparison", "between", "NSCLC", "and", "HNSCC", "cohortsTo", "validate", "the", "basic", "premise", "that", "feature", "robustness", "is", "dependent", "on", "the", "phenotype", ",", "we", "compared", "feature", "robustness", "based", "on", "the", "test", "-", "retest", "ICC", "in", "both", "cohorts", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["The", "achievable", "FH", "data", "rate", "of", "user", "served", "from", "a", "BS", ",", "where", ",", "over", "RB", "can", "be", "given", "as", ":", "where", "is", "the", "BS", "transmitted", "power", "allocated", "to", "RB", ",", "is", "the", "noise", "power", ",", "and", "is", "the", "inter", "-", "cell", "interference", "at", "the", "user", "caused", "by", "closest", "BS", "(", "no", "intra", "-", "cell", "interference", "on", "the", "downlink", "direction", "between", "different", "tiers", "is", "assumed", ")", "and", "expressed", "as", "follows", ":", "where", "is", "representing", "the", "exclusivity", "of", "the", "TBS", "and", "RB", "allocation", ":", ",", "if", "RB", "of", "nearby", "station", "is", "allocated", "to", "another", "user", "from", "TBS", ",", "and", ",", "otherwise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resource blocks"}, {"tokens": ["PAP", "therapy", "is", "applied", "through", "the", "use", "of", "a", "specialised", "medical", "device", "which", "delivers", "a", "highly", "controlled", "wave", "of", "pressurised", "air", "to", "the", "upper", "airway", ",", "acting", "as", "a", "pneumatic", "splint", "and", "preventing", "the", "blockage", "of", "the", "pharynx", "that", "characterises", "OSA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "obstructive sleep apnoea"}, {"tokens": ["Thus", ",", "SBSs", "closer", "to", "the", "UE", "offer", "a", "better", "channel", "fading", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Using", "PS", "is", "good", "when", "developers", "have", "less", "powerful", "and", "not", "reliable", "machines", "such", "as", "cluster", "of", "CPU", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["NP", "sar", "-", "dar", ",", "perhaps", "a", "later", "compound)PIr"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Following", "this", "line", "of", "work", ",", "we", "propose", "a", "method", "called", "Dual", "Adversarial", "Domain", "Adaptation", "(", "DADA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "dual adversarial domain adaptation"}, {"tokens": ["The", "continual", "lower", "-", "bound", "is", "obtained", "as", "followswhere", "is", "the", "new", "variational", "distribution", "that", "we", "want", "to", "update", ",", "and", "and", "are", "the", "past", "and", "current", "subsets", "of", "hyperparameters", "involved", "in", "the", "GP", "prior", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Both", "methods", "are", "based", "on", "a", "sparse", "GP", "approximation", "to", "make", "the", "infinite", "dimensional", "problem", "tractable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["BenchmarkAs", "a", "benchmark", ",", "we", "use", "the", "DNN", "speech", "synthesizer", "trained", "on", "CPS", "phonetic", "transcriptions", "of", "the", "speech", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "common phone set"}, {"tokens": ["r=0.85", ",", "p<0.001", ")", ",", "but", "only", "a", "moderate", "correlation", "with", "VAT", "-", "V", "(", "r=0.65", ",", "p<0.001", ")", "after", "adjusting", "for", "age", ",", "sex", ",", "and", "abdominal", "region", "height", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["With", "this", "manifold", ",", "we", "introduce", "two", "novel", "additions", "to", "the", "MGM", "GAN", "that", "facilitate", "manifold", "alignment", ":", "enumerate", "an", "importance", "sampling", "technique", "which", "calculates", "weights", "for", "each", "point", "based", "on", "a", "Voronoi", "partition", "of", "the", "manifold", "to", "offset", "differences", "in", "density", "between", "the", "domains", "in", "each", "partition", "a", "manifold", "geometry", "loss", "adapted", "from", "formal", "manifold", "alignment", "literatureenumerateBy", "explicitly", "minimizing", "the", "manifold", "geometry", "loss", ",", "the", "generators", "are", "encouraged", "to", "align", "the", "manifolds", "as", "best", "as", "they", "can", "without", "distorting", "the", "original", "points", "unnecessarily", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["SEM", "tags", "disambiguate", "POS", "tags", "in", "ways", "that", "are", "relevant", "to", "multilingual", "settings", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["We", "note", "that", "in", "some", "cases", "the", "charging", "current", "increases", "from", "an", "initial", "800", "mA", "to", "a", "stable", "925", "mA", "at", "the", "beginning", "of", "the", "CC", "phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "charging current"}, {"tokens": ["Suppose", "the", "TP", "lower", "-", "bound", "and", "FP", "upper", "-", "bound", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["The", "interval", "of", "each", "core", "depends", "on", "the", "difference", "of", "the", "maximum", "and", "minimum", "values", "of", "CC", "of", "nodes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "closeness centrality"}, {"tokens": ["We", "demonstrate", "this", "using", "UNet", "model", "for", "segmentation", ",", "pre", "-", "trained", "on", "FS", "images", "and", "the", "corresponding", "masks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "fully sampled"}, {"tokens": ["FAST", "(", "red", ")", "and"], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "features from accelerated segment test"}, {"tokens": ["In", "recent", "work", "we", "combined", "the", "regression", "approach", "with", "such", "an", "objective", "by", "minimizing", "the", "total", "number", "of", "the", "OPF", "solver", "iterations", "by", "predicting", "an", "appropriate", "warm", "-", "start", "for", "the", "interior", "-", "point", "primal", "variables", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["uar", "-", "ma-", "MP", "warm", "'", "pond", "'", "NP", "barmMP", "warm", "'", "memory", "'", "NP", "barmMP", "wardag", "'", "captive", ",", "prisoner", "'", "NP", "bardaPIr"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "new persian"}, {"tokens": ["N.", "B.", "Shah", ",", "\"", "Characterising", "exact", "repair", "-", "by", "-", "transfer", "for", "MBR", ",", "\"", "technical", "report", ",", "2012", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["While", "most", "of", "the", "tested", "web", "servers", "accept", "any", "permutation", "of", "CR", "and", "LF", ",", "Apache", "just", "ignores", "the", "CRLF", "sequence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "line feeds"}, {"tokens": ["The", "'", "spatial", "entropy", "'", "of", "TI", "1", "is", "2.48", "and", "the", "'", "spatial", "entropy", "'", "of", "TI", "2", "is", "0.25", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["Moreover", ",", "we", "assume", "a", "certain", "known", "UE", "trajectory", "at", "a", "velocity", "as", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Instead", "of", "replying", "a", "CTS", ",", "an", "Ant", "-", "CTS", "is", "broadcast", "by", "the", "AP", "with", "two", "functions", ":", "1", ")", "to", "notify", "the", "STA", "about", "the", "successful", "reception", "of", "the", "RTS", ",", "and", "2", ")", "to", "inform", "other", "STAs", "that", "the", "number", "of", "available", "antennas", "and", "the", "start", "of", "the", "-nd", "contention", "round", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["In", "order", "to", "accurately", "pinpoint", "the", "illegal", "paring", "vehicles", "or", "empty", "spaces", "on", "the", "map", ",", "the", "GPS", "coordinates", "obtained", "from", "the", "sensor", "need", "to", "be", "calibrated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["The", "usefulness", "is", "illustrated", "by", "an", "example", "of", "designing", "an", "equivalent", "control", "based", "sliding", "mode", "control", "(", "ECBC", "-", "SMC", ")", "with", "the", "proposed", "adaptive", "STA", "for", "a", "perturbed", "LTI", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["In", "den", "Dialogpassagen", "des", "Vergleichsessays", "reden", "RB", "und", "JB", "einander", "nicht", "an", ",", "das", "abwechselnde", "Sprechen", "ist", "nicht", "aufeinander", "gerichtet", "und", "doch", "geht", "es", "um", "Gemeinsames", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rosi braidotti"}, {"tokens": ["Although", "we", "can", "not", "completely", "eliminate", "mistakes", ",", "use", "of", "SC", "allows", "us", "to", "minimize", "them", "by", "assigning", "lower", "importance", "to", "erroneous", "annotations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "self consistency"}, {"tokens": ["RV", ",", "AV", ",", "IMV", ",", "DV", ",", "direct", ",", "indirect", "]", "solid", ",", "color", "=", "blue", "color", "=", "red", "color", "=", "green", "color", "=", "magenta", "color", "=", "black", "dashdotted", ",", "color", "=", "black", "customlegend", "tikzpicture", "pvan_a.pdfpvan_b.pdfpvan_c.pdfpvan_d.pdfAverage", "outbreak", "sizes", "at", "various", "vaccination", "rates", "(", "percentage", "of", "total", "nodes", ")", "of", "different", "strategies", ":"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["For", "complex", "biopharmaceutical", "production", "process", "which", "often", "has", "tight", "batch", "data", ",", "this", "limits", "OR", "methodology", "performance", "and", "interpretability", ",", "as", "well", "as", "its", "adoption", "in", "real", "applications", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "operations research"}, {"tokens": ["In", "SEM", ",", "the", "class", "sem", ":", "Actor", "holds", "entities", "that", "take", "part", "in", "an", "event", ",", "and", "the", "class", "sem", ":"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simple event model"}, {"tokens": ["Without", "having", "any", "prior", "knowledge", "involved", ",", "it", "is", "extremely", "hard", "to", "estimate", "the", "PAF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "plenacoustic function"}, {"tokens": ["Adaptive", "FEC", "-", "based", "techniques", "are", "known", "to", "be", "suitable", "to", "enhance", "the", "QoE", "of", "video", "transmitted", "over", "error", "-", "prone", "wireless", "networks", "with", "high", "mobility", ",", "which", "is", "an", "intrinsic", "characteristic", "of", "FANETs", "using", "UAV", "-", "to", "-", "Ground", "connection", "model", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Formally", ",", "a", "PAP", "is", "defined", "as", "the", "tuple", ",", "where", "is", "a", "measured", "PAT", "for", "process", ",", "while", "is", "the", "number", "of", "processes", "participating", "in", "the", "collective", "operation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival time"}, {"tokens": ["We", "ascribe", "it", "to", "the", "reason", "that", "a", "standard", "IB", "eliminates", "excessive", "information", "from", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["We", "reimplement", "the", "results", "of", "RFCN", "in", "the", "table", "using", "RPN", "proposals", ",", "which", "is", "to", "ensure", "that", "the", "AP", "performance", "difference", "descends", "from", "region", "proposals", "only", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Therefore", ",", "the", "unnaturally", "high", "ContF0", "values", "(", "e.g.", "between", "0", "-", "1", "and", "after", "6", "s", "in", "Fig", ")", ",", "which", "are", "the", "result", "of", "the", "interpolation", ",", "are", "compensated", "by", "the", "MVF", "parameter", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["TIR", "cameras", ",", "GPS", "."], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "global positioning system"}, {"tokens": ["Q", "refers", "to", "a", "SATB", "quartet", "with", "one", "singer", "per", "section", "and", "CM", "refers", "to", "a", "SATB", "choir", "mix", "with", "4", "singers", "per", "section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "choir mix"}, {"tokens": ["Let", "be", "a", "PLP", "defined", "as", "in", "section", "II.A", "with", "is", "the", "Poisson", "random", "variable", "that", "represents", "the", "number", "of", "roads", "that", "lie", "inside", "coverage", "area", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["SEM", "provides", "a", "skeleton", "for", "modeling", "event", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "simple event model"}, {"tokens": ["Most", "similar", "to", "this", "research", ",", "however", ",", "are", "two", "studies", "conducted", "using", "BGT", "data", "to", "assess", "DSA", "labour", "demands", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["For", "the", "CCC", "values", ",", "the", "differences", "are", "statistically", "significant", "for", "all", "the", "cases", ",", "except", "when", "the", "source", "domain", "is", "the", "MSP", "-", "IMPROV", "corpus", "and", "the", "DANN", "model", "is", "implemented", "with", "two", "layers", "(", "one", "-", "tailed", "t", "-", "test", "over", "the", "average", "across", "the", "twenty", "trails", ",", "asserting", "significance", "if", "-value", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["Transmission", "can", "be", "supported", "with", "4-", "and", "16-QAM", "with", "a", "7", "FEC", "code", "at", "11.3", "Mb", "/", "s", "and", "22.61", "Mb", "/", "s", ",", "respectively", ",", "and", "with", "a", "20", "FEC", "code", "for", "16-QAM", "at", "33.91", "Mb", "/", "s", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Experimental", "SetupIn", "DDE", "-", "MGM", ",", "there", "are", "four", "parameters", "in", "total-", ",", "and", "grid", "size", "for", "DDE", "(", "Eq", ".", ")", ","], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Then", ",", "we", "rank", "the", "all", "weights", "in", "and", "pick", "up", "the", "top", "3", "large", "weights", "with", "corresponding", "BQ", "to", "be", "the", "BQ", "of", "the", "query", "question", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["Average", "secrecy", "rate", "of", "four", "TAS", "methods", "for", ",", "CDF", "curves", "of", "secrecy", "rate", "for", "SNR=-5dB", ",", "0dB", ",", "5dB", "and", "Average", "BER", "curves", "of", "Bob", "for", "four", "TAS", "methodsFig", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["This", "condition", "imposes", "that", "the", "maximum", "time", "step", "is", "smaller", "than", "the", "travelling", "time", "duration", "of", "the", "fastest", "stress", "wave", "(", "dilatation", "wave", ")", "over", "the", "minimum", "element", "size", "inside", "the", "whole", "FEM", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "finite element method"}, {"tokens": ["Compared", "with", "the", "methods", "of", "MP", "or", "SP", ",", "the", "major", "challenge", "in", "the", "periodic", "decomposition", "is", "how", "to", "select", "the", "dominant", "periodic", "component", "in", "each", "iteration", ",", "due", "to", "the", "definition", "of", "the", "dominant", "periodic", "component", "in", "a", "signal", "is", "not", "clear", "yet", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["avg_plot_kv_k40_on.pdf[Key", "-", "value", ":", "K40c", "(", "ECC", "off", ")", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["To", "accomplish", "this", ",", "we", "compare", "the", "performance", "of", "models", "trained", "on", "raw", "images", "(", "no", "ISP", "processing", ")", "against", "those", "trained", "on", "RGB", "images", "(", "full", "ISP", "processing", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["If", "then", ",", "again", ",", "Lemma", "lem", ":", "pre", "-", "reach", "-", "unreach", "-", "geq", "-", "MD", "supplies", "either", "player", "or", "player", "with", "an", "MD", "winning", "strategy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["This", "paper", "discusses", "these", "issues", "for", "the", "target", "population", "of", "IS", "students", ",", "for", "whom", "the", "lack", "of", "direct", "relevance", "of", "the", "traditional", "logic", "courses", "seems", "to", "have", "led", "to", "their", "exclusion", "from", "the", "curriculum", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["Although", "Spoken", "-", "SQuAD", "is", "large", "enough", "to", "train", "state", "-", "of", "-", "the", "-", "art", "QA", "models", ",", "it", "is", "artificially", "generated", ",", "so", "it", "is", "still", "one", "step", "away", "from", "real", "SQA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Severe", "Sepsis", ",", "SK", "="], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "septic shock"}, {"tokens": ["Moreover", ",", "the", "MgNB", "RRC", "connection", "is", "established", "before", "MC", ",", "and", "is", "used", "to", "configure", "and", "control", "CSI", "feedback", "and", "channel", "measurements", "in", "the", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["Following", "a", "similar", "line", "of", "thought", "but", "implemented", "differently", ",", "a", "few", "recent", "works", "use", "a", "simulator", "to", "learn", "the", "kernel", "function", "of", "a", "GP", ",", "instead", "of", "utilizing", "it", "to", "create", "a", "mean", "function", "like", "in", "ITE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["But", ",", "the", "proposed", "routing", "strategy", "avoids", "larger", "BC", "nodes", "hence", ",", "we", "may", "get", "a", "higher", "value", "of", "and", "there", "will", "be", "less", "congestion", "on", "the", "nodes"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["As", "shown", "in", "table", ",", "PIN", "alone", "achieves", "1.13", "improvement", "while", "using", "a", "fraction", "of", "proposals", "compared", "to", "existing", "approaches", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["DI", "is", "an", "implementation", "of", "Inverse", "of", "Control", "(", "IoC", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dependency injection"}, {"tokens": ["In", "this", "work", ",", "SAR", "acts", "are", "formalized", "based", "on", "the", "directive", ",", "commissive", ",", "and", "representative", "illocutionary", "speech", "acts", ",", "or", "simply", "illocutions", ",", "originally", "defined", "in", "linguistic", "semantics", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Clearly", ",", "in", "the", "early", "learning", "stages", ",", "the", "unconstrained", "TS", "algorithm", "does", "not", "have", "accurate", "knowledge", "of", "the", "hidden", "parameters", "and", "violates", "the", "distribution", "system", "constraints", "often", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Block", "diagram", "of", "the", "PS", "protocol", "during", "time", "slots", "for", "one", "selected", "relay", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Assume", "that", "is", "-Lipschitz", "continuous", "and", "-strongly", "convex", ",", "i.e.,Under", "assumption", "flconrproofeq0", ",", "we", "provide", "the", "following", "theorem", "about", "convergence", "rate", "of", "Algorithm", "1", ",", "where", "each", "user", "solves", "its", "local", "FL", "problem", "with", "a", "given", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["For", "instance", ",", "can", "represent", "the", "classical", "UE", "where", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "user equilibrium"}, {"tokens": ["Its", "derivative", "with", "respect", "to", "the", "boundary", "condition", "isEffective", "Stress", "Effective", "StiffnessFor", ",", "we", "demand", "that", "the", "residual", "from", "eq", ":", "RB", ":", "residual", "is", "stable", "with", "respect", "to", "the", "boundary", "condition", "when", "converged", "to", ",", "It", "follows", "thatBasis", "for", "Symmetric", "Traceless", "Second", "Order", "TensorsReferences---[1]#1Rendek", ",", "M.", ";", "Lion", ",", "A.Amplitude", "dependence", "of", "filler", "-", "reinforced", "rubber", ":", "Experiments", ",", "constitutive", "modelling", "and", "FEM", "-", "Implementation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["for", "GP", "-", "UCB", "with", "current", "variance", "of", "increasing", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Furthermore", ",", "the", "proposed", "method", "was", "successfully", "deployed", "in", "a", "large", "population", "-", "based", "cohort", ",", "where", "it", "replicated", "well", "known", "SAT", "-", "V", "and", "VAT", "-", "V", "age", "and", "sex", "associations", "and", "demonstrated", "generalizability", "across", "a", "large", "range", "of", "anatomical", "differences", ",", "both", "with", "respect", "to", "body", "shape", "and", "fat", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Disk", "data", "placement", "may", "follow", "GRD", ",", "with", "half", "of", "disk", "capacity", "dedicated", "to", "primary", "data", "and", "the", "other", "half", "to", "secondary", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group rotate declustering"}, {"tokens": ["Intuitively", ",", "as", "we", "have", "more", "iterations", ",", "the", "sensors", "outside", "the", "backbone", "network", "will", "move", "randomly", "and", "eventually", "connect", "to", "the", "AP", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "CSG", "measure", "is", "derived", "from", "the", "probabilistic", "divergence", "between", "classes", "in", "a", "spectral", "clustering", "framework", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["BS", "transmits", "amount", "of", "power", "for", "direct", "transmissions", "for", "NOMA", "from", "BS", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["We", "perform", "experiments", "with", "PS", ",", "P2P", ",", "and", "RA", "architecture", "and", "compare", "it", "to", "our", "model", "results", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["Whether", "the", "number", "of", "PI", "allocations", "increases", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["We", "focus", "on", "a", "single", "RB", "scenario", "where", "only", "one", "CUE", "is", "considered", "in", "each", "cell", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resource blocks"}, {"tokens": ["The", "Joint", "Conditional", "LikelihoodIn", "our", "solution", ",", "the", "prediction", "models", "on", "CF", "task", "and", "CTR", "task", "are", "learned", "jointly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "accuracy", "of", "civilian", "GPS", "receivers", "is", "typically", "in", "the", "range", "of", "15", "meter", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["The", "sources", "determine", "their", "optimal", "FJ", "powers", ",", "and", "then", "the", "friendly", "jammers", "determine", "optimal", "power", "prices", "to", "maximize", "their", "own", "payments", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["InformationHere", "we", "provide", "the", "results", "of", "feature", "analysis", "techniques", "such", "as", "RDM", "and", "hierarchical", "clustering", "on", "ETH-80", "dataset", "for", "both", "HMAX", "and", "our", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "representational dissimilarity matrix"}, {"tokens": ["We", "show", "that", "over", "30fps", "for", "the", "stereoscopic", "AR", "rendering", "and", "24Hz", "for", "the", "slave", "-", "tool", "tracking", "from", "the", "EKF", "can", "be", "achieved", "while", "running", "simultaneously", "on", "a", "commodity", "GPU", "and", "using", "the", "robot", "operating", "system", "(", "ROS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["The", "dataset", "(", "LR", "images", "HR", "labels", ")", "is", "randomly", "partitioned", "into", "three", "subsets", ":", "training", "(", ")", ",", "validation", "(", ")", ",", "and", "testing", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["In", "this", "study", ",", "we", "also", "consider", "the", "reproducibility", "of", "dictionaries", "from", "the", "LSC", "and", "list", "of", "texts", "from", "other", "sources", "to", "be", "used", "by", "researchers", "in", "many", "other", "text", "mining", "applications", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Finally", ",", "the", "transparency", "of", "QA", "systems", "refers", "to", "the", "availability", "and", "accessibility", "to", "the", "reasons", "behind", "the", "decisions", "of", "the", "QA", "system", "in", "each", "step", "upon", "the", "request", "of", "involving", "individuals", "(", "e.g.", ",", "end", "user", ",", "developer", ",", "data", "publisher", ",", "policymakers", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Our", "contribution", "for", "RS", "images", "deep", "net", "training", "is", "a", "user", "-", "oriented", "OTB", "application", "dedicated", "for", "training", "existing", "models", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["Recently", ",", "proposed", "a", "conservative", "precoder", "design", "with", "the", "objective", "of", "maximizing", "the", "weighted", "sum", "-", "rate", "of", "UEs", "for", "arbitrary", "UE", "-", "centric", "clustering", "method", "with", "incomplete", "CSIs", ",", "where", "the", "long", "term", "channel", "statistic", "was", "incorporated", "into", "the", "optimization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["managed", "to", "integrate", "out", "the", "model", "parameters", "of", "the", "Poisson", "SBM", "in", "eqn.graph_ypq_poisson", ",", "to", "form", "a", "collapsed", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "sequential monte carlo"}, {"tokens": ["4", "(", "charts", ")", ",", "the", "GM", "accuracy", "is", "reported", "for", "the", "synthetic", "datasets", ",", "for", "each", "algorithm", "and", "for", "the", "simulated", "levels", "of", "deformation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph matching"}, {"tokens": ["In", "this", "paper", ",", "we", "provide", "a", "unified", "view", "on", "MP", "and", "FW", "algorithms", "from", "an", "optimization", "perspective", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["However", ",", "the", "simulation", "of", "SAR", "images", "requires", "high", "technology", "but", "the", "technique", "is", "not", "so", "mature", "to", "simulate", "enough", "reliable", "models", "and", "difficult", "to", "popularize", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["In", "all", "these", "RNN", "variants", ",", "the", "POS", "of", "the", "current", "word", "is", "also", "represented", "with", "a", "vector", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Therefore", ",", "a", "better", "unsupervised", "learning", "approach", "for", "training", "an", "LB", "divergence", "objective", "function", "with", "a", "deeper", "structure", "formulation", "is", "necessary", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["and", "AP", "(", "Sec", ".", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["The", "feasible", "values", "of", "these", "search", "variables", "are", "those", "satisfy", "all", "the", "constraints", "of", "the", "SCP", "central", "plant", "problem", "given", "in", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["For", "DC", "-", "OPF", "cases", "we", "carried", "out", "experiments", "using", "k", "and", "k", "samples", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["It", "is", "clear", "that", "ECS", "-", "DBN", "stands", "out", "from", "the", "rest", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["What", "Source", "Data", "/", "TasksIntuitively", ",", "we", "can", "imagine", "that", "the", "closer", "data", "or", "tasks", "are", "better", "to", "provide", "transferable", "features", "to", "SAR", "target", "recognition", ",", "such", "as", "other", "kind", "of", "SAR", "target", "recognition", ",", "SAR", "land", "cover", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["The", "previously", "encountered", "problems", "of", "the", "CCR", "for", "normal", "and", "carrying", "conditions", "are", "shown", "in", "Figure", "and", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct correction rate"}, {"tokens": ["However", ",", "considering", "the", "name", "of", "this", "workshop", "and", "book", "-", "Genetic", "Programming", "Theory", "and", "Practice", "-", "one", "may", "be", "left", "wondering", "how", "GP", "can", "be", "incorporated", "into", "PennAI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["It", "is", "also", "called", "a", "nonparametric", "SBM", ",", "not", "because", "of", "having", "no", "parameters", "but", "because", "that", "is", "being", "modelled", "(", "Section", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["But", "in", "this", "case", "what", "solution", "is", "Peck", "proposing", "for", "the", "enterprise", "-", "a", "non", "-", "Computer", "Based", "IS", "(", "e.g.", "a", "filing", "cabinet", ")", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["From", "r_train", ",", "we", "derive", "the", "LS", "estimate", "of", "as", "and", "the", "corresponding", "MSE", "is", "As", "shown", "in", "ls3", ",", "the", "performance", "of", "the", "LS", "estimator", "is", "inversely", "proportional", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "(", "SNR", ")", "defined", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["made", "the", "classifier", "learn", "the", "common", "knowledge", "among", "with", "different", "target", "-", "aspect", "angles", "of", "SAR", "targets", "via", "transfer", "learning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Then", "there", "exist", "a", "player", "MD", "strategy", "and", "a", "player", "MD", "strategy", "such", "that", "for", "all", "states", ",", "if", "or", ",", "then", "the", "following", "is", "true", ":"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["In", "doing", "that", ",", "it", "can", "offer", "less", "overhead", "during", "transmission", "in", "a", "wireless", "mesh", "network", "setting", "while", "providing", "as", "good", "video", "quality", "as", "non", "-", "adaptive", "FEC", "mechanisms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["IFT", "constructs", "have", "been", "used", "to", "explain", "and", "predict", "people", "'s", "information", "-", "seeking", "behavior", "in", "several", "domains", ",", "such", "as", "understanding", "navigations", "through", "web", "sites", "or", "programming", "and", "software", "engineering", "environments", "chi2001using", ",", "fleming2013information", ",", "fu2007snif", ",", "kuttal2013predator", ",", "niu2013departures", ",", "perez2014diagnosis", ",", "piorkowski2015fix", ",", "piorkowski2016foraging", ",", "srinivasa2016foraging", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information foraging theory"}, {"tokens": ["ITS", "America", ",", "2012", "."], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "intelligent transportation system"}, {"tokens": ["Lastly", ",", "GBM", "with", "deep", "features", ",", "detected", "nodule", "size", ",", "and", "raw", "pixels", "is", "employed", "for", "classification", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["Moreover", ",", "the", "function", "with", "and", "defined", "by", "symbols_moreno_new", "is", "a", "quadratic", ",", "strict", "and", "robust", "Lyapunov", "function", "for", "the", "perturbed", "system", "STA", "satisfying", "Rho", "with", "observable", "and", "variable", "gains", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["Besides", "the", "act", "of", "following", "cues", ",", "IFT", "has", "another", "foraging", "operation", ":", "enriching", "their", "information", "environment", "to", "make", "it", "more", "valuable", "or", "cost", "-", "efficient", "pirolli2007information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information foraging theory"}, {"tokens": ["Figure", "also", "shows", "a", "large", "standard", "deviation", "for", "the", "scenario", "without", "FEC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "forward error correction"}, {"tokens": ["This", "is", "because", "a", "large", "maximum", "transmit", "power", "can", "decrease", "the", "transmission", "time", "between", "users", "and", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["It", "is", "clear", "that", "DE", "-", "based", "deployment", "outperforms", "both", "ABC", "and", "GSA", "-", "based", "deployment", "in", "extending", "the", "useful", "network", "lifetime", "as", "vividly", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["As", "the", "MINT", "-", "FEC", "can", "handle", "arbitrary", "video", "resolution", ",", "several", "of", "them", "were", "used", "in", "the", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "architecture", "of", "PS", "is", "shown", "as", "Fig", ".", ","], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["In", "bigger", "networks", "with", "nodes", "on", "the", "periphery", "of", "the", "network", ",", "that", "is", ",", "they", "are", "only", "connected", "to", "one", "or", "a", "few", "nodes", "which", "are", "more", "central", "to", "the", "network", ",", "these", "peripheral", "nodes", "will", "be", "put", "together", "in", "a", "\"", "miscellaneous", "\"", "group", "with", "a", "low", "edge", "density", ",", "under", "the", "original", "SBM", ",", "instead", "of", "the", "same", "groups", "as", "the", "more", "central", "nodes", "they", "are", "connected", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["For", "large", ",", "loosely", "coupled", "systems", ",", "and", "PI", "will", "therefore", "converge", "slowly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["Batch", "size", "(", "BS", ")", "of", "up", "to", "40", "and", "learning", "rate", "of", "0.002", "was", "used", "for", "training", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "batch size"}, {"tokens": ["Ground", "Truth", "FS", "segmentation", "mask", ",", "Segmentation", "mask", "for", "ZF", ","], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fully sampled"}, {"tokens": ["In", "the", "experiments", ",", "there", "were", "six", "target", "languages", "to", "learn", ":", "three", "SL", "and", "three", "SP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "strictly piecewise"}, {"tokens": ["However", ",", "the", "use", "of", "combined", "metrics", "could", "be", "interesting", "for", "future", "work", ",", "as", "such", "metrics", "still", "show", "best", "performance", "in", "the", "OLS", "analysis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "ordinary least square"}, {"tokens": ["We", "achieve", "good", "performance", "on", "the", "PA", "and", "ranking", "on", "the", "LA", "tasks", "of", "the", "challenge", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["This", "is", "happening", "because", "due", "to", "increasing", "values", "of", ",", "the", "channel", "condition", "between", "BS", "and", "CCU", "is", "degraded", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["wechseln", "sich", "personliche", "Passagen", "von", "RB", "und"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0], "long_form": "rosi braidotti"}, {"tokens": ["In", "this", "section", ",", "a", "variable", "gain", "-", "selection", "algorithm", "for", "STA", "STA", "is", "introduced", "to", "give", "additional", "choices", "for", "updating", "and", "without", "damaging", "the", "robustness", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["receives", "from", "the", "OT", "the", "mask", "corresponding", "to", "its", "block", "which", "acts", "as", "its", "choice", "string", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["A", "simple", "version", "of", "the", "SBM", "is", "introduced", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["In", "the", "training", "phase", ",", "we", "calculate", "all", "the", "feature", "scores", "from", "BF1", "to", "BF5", "for", "the", "users", "as", "input", ",", "and", "train", "the", "BF", "multi", "-", "classifier", "with", "the", "role", "-", "related", "labels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic feature"}, {"tokens": ["The", "pairwise", "comparisons", "of", "the", "proposed", "ECS", "-", "DBN", "method", "against", "other", "kinds", "of", "methods", "in", "terms", "of", "accuracy", "and", "G", "-", "mean", "are", "shown", "in", "Tables", "and", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["(", "BQ", "+", "corresponding", "similarity", "score", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["Sharing", "of", "bandwidth", "between", "a", "UE", "and", "other", "UEs", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "ACA", "-", "A", "approach", "can", "also", "be", "found", "in", ",", "but", "the", "FJ", "power", "is", "employed", "from", "the", "untrusted", "relay", "itself", ",", "i.e.", ",", "the", "eavesdropper", ",", "to", "maximize", "the", "secrecy", "rate", "in", "a", "cooperative", "OFDMA", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["LR", "based", "attack", "."], "acronym_pos": [1, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Concrete", "cost", "of", "various", "OT", "extension", "protocols", "for", "producing", "-out", "-", "of-", "OTs", "with", "sender", "'s", "input", "length", "as", "and", "for", "achieving", "computational", "security", "of", "and", "statistical", "security", "of", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Similarly", ",", "in", "the", "work", "in", ",", "RN", "and", "MB", "are", "added", "to", "the", "synthetic", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "motion blurring"}, {"tokens": ["For", "operator", "gains", ",", "the", "center", "node", "plays", "in", "the", "SSS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "stochastically stable states"}, {"tokens": ["The", "main", "idea", "behind", "the", "training", "concept", "of", "a", "DBN", "is", "to", "train", "a", "sequence", "of", "RBMs", "with", "the", "model", "parameter", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["GMM", "and", "FIM", "have", "very", "similar", "results", "for", "3D", "and", "4D."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["In", "context", "of", "the", "average", "elapsed", "time", ",", "the", "PRR", "and", "SLT", "algorithms", "are", "faster", "for", "12.1", "and", "7.9", ",", "while", "for", "the", "training", "total", "time", "4.2", "and", "4.0", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pre - reduced ring"}, {"tokens": ["Interestingly", ",", "ARD", "students", "may", "exhibit", "even", "higher", "robust", "accuracy", "than", "their", "teacher", "(", "see", "Table", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["The", "RA", "process", "presented", "a", "mean", "time", "of", "2.5", "seconds", ",", "what", "is", "considered", "acceptable", "for", "our", "application", ",", "since", "it", "is", "commonly", "performed", "just", "one", "time", "for", "each", "new", "producer", "or", "consumer", ",", "to", "validate", "the", "system", "or", "the", "new", "member", ",", "respectively", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote attestation"}, {"tokens": ["From", "the", "first", "two", "rows", "of", "Table", ",", "our", "proposed", "lesion", "prior", "fusion", "method", "improves", "the", "performance", "of", "3D", "U", "-", "Net", ",", "particularly", "for", "the", "DSC", "of", "ET", "(", "3.5", ")", ",", "and", "H95", "of", "ET", "(", "2.56", ")", "and", "whole", "tumor", "(", "2.39", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["MovieLens", "is", "a", "well", "-", "known", "movie", "RS", "that", "has", "been", "in", "continuous", "use", "since", "1997", "with", "more", "than", "200,000", "users", "providing", "more", "than", "20", "million", "ratings", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["In", "such", "a", "case", ",", "the", "error", "(", "in", "term", "of", "probability", ")", "to", "recover", "from", "a", "sketch", "reduced", "to", "the", "error", "to", "look", "for", "a", "random", "variable", "over", "family", "of", "distributions", ",", "where", "the", "RV", "pair", "(", ")", "used", "for", "sketching", "and", "recovery", "is", "in", "distinct", ",", "(", "i.e.", ",", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["We", "got", "a", "Pearson", "correlation", "of", "0.956", "between", "our", "CSG", "dots", "and", "the", "error", "rate", "values", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["The", "RS", "could", "allow", "for", "the", "user", "to", "monitor", "and", "adjust", "the", "interaction", "thresholds", "according", "to", "their", "true", "preference", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["IAW", ",", "which", "uses", "UpdateSSSPW", ",", "and", "IA", ",", "which", "uses", "UpdateSSSP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "incremental approximation"}, {"tokens": ["Further", "CommentSL", ",", "SP", ",", "LT", ",", "PT", ",", "and", "LTT", "classes", "form", "infinite", "hierarchies", "of", "language", "classes", "based", "on", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Ultimately", ",", "generating", "questions", "to", "predicates", "and", "entity", "types", "unseen", "at", "training", "time", "will", "allow", "QA", "systems", "to", "cover", "predicates", "and", "entity", "types", "that", "would", "not", "have", "been", "used", "for", "QA", "otherwise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["In", "their", "approach", ",", "a", "two", "-", "step", "procedure", "and", "optional", "third", "step", "were", "utilized", "to", "optimize", "the", "network", "connectivity", "and", "throughput", "using", "PSO", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "researchers", "should", "also", "focus", "on", "the", "improvement", "of", "the", "autonomy", "and", "safety", "for", "UAVs", "to", "maneuver", "in", "the", "congested", "and", "indoor", "environment", "with", "no", "or", "weak", "GPS", "signals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Handling", "energy", "-", "block", "dense", "systems", "when", "there", "are", "more", "than", "a", "few", "energy", "groups", "is", "not", "tractable", "with", "GS", "as", "the", "multigroup", "solver", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gauss seidel"}, {"tokens": ["Using", "the", "map", "of", "the", "area", "and", "positions", "of", "users", ",", "the", "new", "user", "scheduling", "scheme", "works", "without", "CSI", "at", "the", "BS", ",", "as", "far", "as", "the", "location", "of", "multipath", "clusters", "is", "known", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["It", "is", "dominated", "by", "the", "social", "circle", "stability", "(", "CNS", ":", ",", "MDC", ":", ")", "and", "the", "activity", "space", "stability", "(", "CNS", ":", ",", "MDC", ":", ")", "for", "both", "datasets", "(", "see", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["t]ABEP", ",", ",", "of", "DBPSK", "versus", "the", "number", "of", "relay", "nodes", ",", ",", "for", "different", "average", "transmit", "SNRs", "per", "bit", "and", "dB", ",", "over", "IID", "Rayleigh", "fading", "channels", ":", "(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "maximal ratio diversity"}, {"tokens": ["For", "every", "GP", "function", ",", "we", "first", "introduce", "inducing", "GP", "targets", "at", "inducing", "GP", "inputs", ",", "which", "are", "jointly", "Gaussian", "with", "the", "transition", "function", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Moreover", ",", "combining", "ADEPOS", "algorithm", "with", "B", "-", "OCC", "helps", "us", "to", "achieve", "X", "less", "energy", "consumption", "than", "AE", "-", "OCC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "one class classifier"}, {"tokens": ["This", "problem", "arose", "in", "the", "context", "of", "list", "-", "decoding", "homomorphism", "codes", "but", "is", "also", "of", "independent", "interest", ",", "both", "as", "a", "problem", "in", "computational", "group", "theory", "and", "as", "a", "new", "and", "natural", "problem", "in", "NP", "of", "unsettled", "complexity", "status", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "natural problem"}, {"tokens": ["University", "of", "Memphis", ",", "TN", "2Alan", "Turing", "Institute", ",", "London", ",", "United", "Kingdom"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true negative"}, {"tokens": ["The", "meta", "-", "optimization", "has", "the", "following", "computational", "cost", ":", "with", "meta", "-", "training", "examples", ",", "particles", ",", "and", "meta", "-", "optimization", "steps", ",", "reduced", "OPF", "calculations", "are", "performed", ",", "where", ",", "and", "is", "the", "number", "of", "feasibility", "test", "iterations", "of", "the", "th", "reduced", "OPF", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Although", "Global", "Positioning", "System", "(", "GPS", ")", "has", "gained", "great", "success", "in", "many", "outdoor", "localization", "fields", ",", "such", "as", "commercial", ",", "personal", ",", "and", "military", "applications", ",", "it", "does", "not", "perform", "effectively", "in", "complex", "indoor", "environments", "owing", "to", "the", "disability", "of", "GPS", "signals", "to", "penetrate", "in", "-", "building", "materials", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["The", "users", "\u2019", "current", "location", "which", "is", "tracked", "through", "the", "GPS", "tracker", "and", "other", "important", "user", "information", "is", "stored", "in", "a", "database", "that", "can", "be", "further", "be", "integrated", "with", "existing", "electronic", "medical", "record", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["We", "leave", "open", "the", "question", "of", "finding", "an", "efficient", "actively", "secure", "transformation", "from", "-out", "-", "of-", "to", "-out", "-", "of-", "OT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "oblivious transfer"}, {"tokens": ["In", "this", "section", ",", "we", "briefly", "revisit", "the", "lineage", "of", "the", "SBM", ",", "discuss", "how", "it", "is", "extended", "for", "binary", "graphs", ",", "and", "introduce", "models", "for", "valued", "graphs", ",", "to", "answer", "question", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["In", "this", "paper", ",", "we", "seek", "to", "understand", "the", "impact", "of", "the", "ISP", "on", "CNN", "classification", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["and", "are", "considered", "for", "SC", "versus", "comparison", "for", "the", "proposed", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["Evaluation", "On", "Benchmark", "DatasetsIn", "this", "section", ",", "the", "proposed", "ECS", "-", "DBN", "approach", "is", "evaluated", "on", "58", "popular", "KEEL", "benchmark", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["MP", "gyan", "NP", "jan", "'", "life"], "acronym_pos": [0, 0, 1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Modifications", "to", "the", "FA", "algorithm", "We", "now", "describe", "modifications", "to", "FA", "that", "improve", "performance", "by", "reducing", "the", "possibility", "of", "vanishing", "or", "exploding", "gradients", "and", "encouraging", "angular", "alignment", "between", "the", "feedforward", "and", "feedback", "weights", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["Therefore", ",", "it", "is", "important", "to", "investigate", "the", "shortest", "path", "between", "the", "user", "pairs", "such", "that", "the", "overall", "BC", "-", "BC", "correlation", "of", "the", "nodes", "that", "appear", "in", "the", "path", "should", "be", "minimum", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["b]Association", "of", "BMI", "with", "SAT", "-", "Volume", "and", "VAT", "-", "Volume", "[", "!"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["BS", "utilizes", "full", "power", "(", ")", "to", "transmit", "to", "CEU", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Contributions", "of", "This", "WorkOur", "study", "on", "a", "new", "user", "selection", "algorithm", "considers", "high", "frequency", "stochastic", "geometry", "-", "based", "channels", "with", "large", "numbers", "of", "antennas", "at", "the", "BS", "receiver", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "base station"}, {"tokens": ["As", "we", "want", "to", "stick", "to", "RS", "images", "files", "formats", ",", "samples", "are", "concatenated", "in", "rows", "to", "form", "one", "unique", "big", "image", "of", "patches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["app9", "Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs", "where", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["Hence", ",", "Eve", "will", "select", "a", "such", "that", ",", "meaning", "that", "we", "can", "find", "the", "optimal", "using", "the", "first", "line", "in", "MD", "-", "FA0", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "missed detection"}, {"tokens": ["Since", "in", "expectloss", "is", "positive", ",", "the", "MSE", "of", "the", "DL", "estimator", "is", "lower", "than", "that", "of", "the", "LS", "estimator", "when", "is", "sufficiently", "large", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["The", "practical", "steps", "of", "ECS", "-", "DBN", "is", "summarized", "in", "Algorithm", ",", "and", "discussed", "next", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "a", "DM", "network", ",", "the", "beamforming", "vector", "and", "AN", "projection", "matrix", "depend", "heavily", "on", "the", "precision", "of", "DOA", "measurement", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["ROC", "curves", "for", "both", "schemes", "[", "h", "!", "]"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["In", "particular", ",", "we", "wanted", "to", "determine", "if", "there", "was", "indeed", "a", "definable", "performance", "improvement", "when", "using", "a", "TDW", "compared", "to", "a", "SDD", ",", "which", "corresponds", "to", "the", "popular", "expectation", "that", "big", "images", "need", "a", "big", "display", "to", "be", "seen", "\"", "properly", "\"", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["We", "optimized", "the", "parameters", "jointly", "by", "minimizing", "the", "sum", "loss", "of", ",", "where", "the", "first", "part", "of", "the", "equation", "is", "the", "SRL", "loss", "and", "the", "second", "part", "is", "the", "entity", "loss", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["Implementation", "DetailsIn", "this", "paper", ",", "five", "-", "layered", "ECS", "-", "DBN", "and", "DBN", "have", "been", "implemented", "on", "the", "gun", "drilling", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "particular", ",", "DM", "is", "a", "transmitter", "side", "technology", "that", "projects", "digitally", "modulated", "signals", "into", "a", "pre", "-", "specified", "safe", "direction", "and", "simultaneously", "distorts", "the", "constellation", "formats", "of", "the", "signals", "in", "other", "directions", "by", "AN", "projection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Employing", "PRN", "in", "addition", "to", "PIN", ",", "gives", "a", "10.25", "improvement", "over", "QRC", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["Since", "for", "each", ",", "is", "finite", ",", "SP", "stringsets", "can", "also", "be", "defined", "with", "grammars", "containing", "forbidden", "-subsequences", "as", "in", "sec", ":", "exp", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["In", "order", "for", "DBF", "to", "use", "the", "LTE", "air", "interface", "in", "the", "unlicensed", "band", ",", "we", "propose", "a", "channel", "access", "scheme", "that", "aligns", "with", "the", "LTE", "frame", "structure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Constraints", "(", "b", ")", "and", "(", "c", ")", "reflect", "that", "the", "minimal", "required", "payloads", "for", "MTCDs", "can", "be", "uploaded", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["The", "CC", "for", "lies", "between", "0.3", "to", "0.9", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaboration coefficient"}, {"tokens": ["Python", "-", "SGX", "is", "attested", "by", "SCONE", ",", "and", "afterwards", ",", "can", "attest", "the", "MDC", "component", "and", "guarantee", "that", "the", "SHA-256", "hash", "of", "the", "application", "code", "matches", "the", "hash", "provided", "during", "the", "SCONE", "attestation", "process", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "metering data collector"}, {"tokens": ["Batch", "Manhattan", "in", "particular", "was", "introduced", "to", "avoid", "vanishing", "/", "exploding", "gradients", "arising", "from", "the", "inherent", "weight", "asymmetry", "of", "FA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "feedback alignment"}, {"tokens": ["Increasing", "the", "delay", "threshold", "allows", "the", "users", "to", "access", "the", "content", "from", "the", "CC", ",", "thus", "allows", "the", "flexibility", "of", "processing", "the", "functions", "at", "CC", ",", "subsequently", "decreases", "the", "power", "consumption", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["LR", "refers", "to", "learning", "rate", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "learning rate"}, {"tokens": ["w.r.t", "transmit", "SNR", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["While", "comparing", "two", "classifiers", ",", "one", "may", "have", "a", "higher", "score", "using", "MCC", "and", "the", "other", "one", "has", "a", "higher", "score", "using", "and", "as", "a", "result", "one", "specific", "metric", "can", "not", "captures", "all", "the", "strengths", "and", "weaknesses", "of", "a", "classifier", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["Complex", "QA", ":", "deals", "with", "complex", "questions", "which", "are", "long", ",", "and", "ambiguous", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["[", "]", "[", "b", "]", "Training", "on", "CK+", "and", "testing", "on", "JAFFE", "[", "b", "]", "Training", "on", "CK+", "and", "testing", "on", "SFEW", "[", "b", "]", "Training", "on", "CK+", ",", "fine", "-", "tuning", "on", "80", "of", "SFEW", "and", "testing", "on", "20", "of", "SFEW", "Confusion", "matrices", "of", "the", "MFP", "-", "CNN", "trained", "the", "CK+", "database", "and", "tested", "on", "others", "FER", "databases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["Original", ",", "BP", ",", "AT", ",", "PAT", ",", "ANP", "]", "mark", "=", "square", ",", "solid", ",", "tomato", ",", "line", "width=2.4pt", "mark", "=", "square", ",", "solid", ",", "azure", ",", "line", "width=2.4pt", "mark", "=", "square", ",", "solid", ",", "uclagold", ",", "line", "width=2.4pt", "mark", "=", "square", ",", "solid", ",", "green(munsell),line", "width=2.4pt", "mark", "=", "square", ",", "solid", ",", "line", "legend", ",", "tractorred", ",", "line", "width=2.4pt", "customlegend", "tikzpicture", "0.31", "!"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "perform adversarial training"}, {"tokens": ["For", "performance", "comparison", ",", "simulation", "results", "for", "CCU", "capacity", "(", "capacity", ")", ",", "CEU", "capacity", "(", "capacity", ")", "and", "SC", "of", "NOMA", "-", "OAM", "-", "MDMA", ",", "conventional", "NOMA", "and", "OMA", "-", "OAM", "-", "MDMA", "are", "also", "provided", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["Lei2015", "proposed", "an", "SRL", "model", "based", "on", "the", "dimensionality", "reduction", "on", "a", "tensor", "representation", "to", "capture", "meaningful", "interactions", "between", "the", "argument", ",", "predicate", ",", "corresponding", "features", ",", "and", "role", "label", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["DatasetsThe", "HR", "SAR", "annotated", "land", "cover", "dataset", "exploited", "in", "this", "paper", "has", "been", "collected", "from", "the", "X", "-", "band", "TSX", "instrument", ";", "we", "used", "horizontally", "polarized", "(", "HH", ")", ",", "multi", "-", "look", "ground", "range", "detected", "(", "MGD", ")", "products", "which", "were", "radiometrically", "enhanced", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["We", "propose", "a", "non", "-", "parametric", "model", "MGM", "that", "could", "model", "the", "trajectories", "in", "an", "online", "manner", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["FA", "provides", "two", "important", "parameters", "alpha", "and", "gamma", ",", "which", "help", "FA", "to", "converge", "faster", "per", "each", "iteration", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "firefly algorithm"}, {"tokens": ["Particularly", ",", "the", "value", "convergence", "phenomenon", "can", "be", "exploited", "in", "order", "to", "approximately", "obtain", "a", "particular", "level", "of", "compression", ",", "both", "for", "known", "and", "unkown", "IB", "curves", "(", "see", "Appendix", "or", "the", "example", "in", "Figure", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["It", "should", "be", "noted", "that", "having", "both", "the", "temporal", "information", "in", "the", "data", "and", "a", "longitudinal", "/", "dynamic", "SBM", "does", "not", "guarantee", "that", "the", "actual", "groups", "will", "be", "discovered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Current", "RIRs", "fees", "are", "such", "that", "a", "/32", "costs", "in", "the", "range", "of", "US", "2,500", "to", "US", "1,000", ",", "and", "a", "/48", "(", "PI", ")", "costs", "in", "the", "range", "of", "US", "100", "and", "US", "800", "(", "plus", "an", "additional", "initial", "fee", "in", "the", "range", "of", "US", "250", "to", "US", "2,500", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["TrainingSix", "separate", "models", "are", "trained", ",", "one", "on", "each", "of", "the", "proposed", "augmented", "data", "sets", ":", "No", "augmentations", ",", "AWGN", ",", "APN", ",", "Small", "ET", ",", "large", "ET", "and", "all", "augmentations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0], "long_form": "elastic transformations"}, {"tokens": ["In", "the", "case", "of", "RSs", ",", "this", "would", "include", "the", "people", "creating", "and", "publishing", "the", "content", "being", "recommended", ",", "the", "people", "who", "are", "users", "of", "the", "platform", ",", "the", "people", "who", "are", "part", "of", "dynamic", "and", "likely", "ongoing", "data", "annotation", "process", ",", "the", "developers", "and", "maintainers", "of", "the", "RS", "itself", ",", "the", "RSs", "model", ",", "the", "people", "and", "organizations", "who", "are", "consuming", "the", "digital", "traces", "produced", "by", "the", "users", "of", "the", "system", "for", "other", "purposes", ",", "and", "others", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["An", "adversary", "can", "hire", "the", "FA", "tools", "at", "those", "labs", "can", "steal", "the", "IP", "or", "expose", "hardware", "based", "security", "functions", "in", "the", "chip", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["We", "have", "three", "setups", "of", "the", "PS", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "parameter server"}, {"tokens": ["In", "text", "-", "based", "QA", ",", "back", "-", "translation", "was", "used", "to", "paraphrase", "questions", "and", "paraphrase", "documents", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["We", "assume", "a", "network", "of", "aerial", "-", "BSs", "hovering", "at", "a", "height", "from", "the", "ground", "and", "uniformly", "distributed", "over", "a", "disc", "(", "i.e.", ",", "aerial", "-", "BSs", "follow", "a", "BPP", ")", "with", "a", "center", "and", "radius", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "binomial point process"}, {"tokens": ["is", "the", "up", "-", "sampling", "layer", ";", "we", "use", "option", "(", "d", ")", ",", "OT", "as", "the", "final", "candidate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["DMD", "correspond", "to", "the", "optimal", "solution", "to", "(", "i.e.", ",", "the", "solution", "of", "LQR", "/", "LEQR", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["Many", "typical", "RS", "problems", "have", "been", "successfully", "addressed", "with", "these", "architectures", ":", "synthetic", "aperture", "radar", "interpretation", "with", "target", "recognition", ",", "classification", "from", "time", "series", ",", "and", "parameter", "inversion", ",", "hyperspectral", "image", "analysis", "with", "classification", ",", "anomaly", "detection"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["This", "led", "to", "a", "situation", "where", "although", "CSIS", "might", "have", "one", "value", ",", "a", "DT", "could", "amend", "this", "data", "on", "a", "Base", "Inventory", "System", "otherwise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "delivery teams"}, {"tokens": ["For", "clarity", ",", "on", "the", "right", "of", "the", "tables", "we", "show", "the", "percentage", "improvement", "of", "the", "proposed", "SFM", "method", "over", "a", "variety", "of", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "structural factorization machine"}, {"tokens": ["Our", "work", "is", "more", "closely", "related", "with", "the", "stochastic", "optimization", "schemes", "that", "extend", "the", "framework", "in", ",", "and", "optimize", "a", "CSS", "action", "based", "on", "previous", "observations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "compressive spectrum sensing"}, {"tokens": ["Further", ",", "we", "look", "at", "correlations", "between", "the", "time", "series", "to", "different", "ASNs", "using", "the", "same", "ISP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "internet service providers"}, {"tokens": ["In", "the", "MINT", "-", "FEC", "mechanism", ",", "the", "motion", "intensity", "is", "now", "given", "by", "combining", "the", "spatial", "complexity", "and", "temporal", "intensity", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["There", "are", "two", "kinds", "of", "inputs", ":", "the", "arguments", "and", "the", "Region", "Templates", "(", "RT", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "region template"}, {"tokens": ["The", "procedure", "of", "training", "ECS", "-", "DBN", "is", "presented", "as", "follows", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["RDM", "(", "2nd", "line", ")", "shares", "bandwidth", "and", ",", "as", "such", ",", "preemption", "do", "occur", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "russian dolls model"}, {"tokens": ["The", "top", "panel", "examines", "the", "effect", "of", "enforcing", "fixed", "weight", "signs", "at", "various", "points", "in", "the", "initial", "stages", "of", "training", "on", "ImageNet", "test", "performance", "for", "models", "trained", "with", "FA", "-", "uSF", "and", "fixed", "weight", "norms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["In", "the", "following", "paragraphs", ",", "we", "will", "describe", "our", "plans", "for", "integrating", "GP", "into", "PennAI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Denoting", "the", "load", "in", "normal", "mode", "on", "primary", "and", "secondary", "disks", "in", "GRD", "by", "one", ",", "the", "load", "of", "secondary", "disks", "increases", "by", "when", "primary", "disks", "fail", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group rotate declustering"}, {"tokens": ["This", "is", "evident", "in", "the", "fact", "that", "CER", "is", "60.1", "for", "just", "the", "LDA", "MLLT", "alignments", ",", "and", "over", "doubles", "after", "the", "TDNN", "training", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["When", "are", "decisions", "hard", "for", "the", "GCNN", "policy", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["We", "observe", "that", "workers", "prefer", "the", "BS", "baseline", "over", "TS", ",", "although", "TS", "yields", "higher", "diversity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0], "long_form": "temperature - based sampling"}, {"tokens": ["These", "results", "show", "that", "the", "neuralFEC", "mechanism", "performs", "better", "than", "the", "non", "-", "adaptive", "Video", "-", "aware", "FEC", "mechanism", "in", "terms", "of", "overhead", ",", "by", "reducing", "in", "average", "a", "half", "of", "the", "redundancy", "needed", "to", "protect", "the", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["ResultsWe", "simulated", "the", "Con", "-", "TS", "-", "RTP", "algorithm", "for", "365", "days", "for", "an", "aggregator", "attempting", "to", "learn", "the", "sensitivities", "of", "the", "nodes", "in", "the", "system", "and", "shape", "their", "demands", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["tb", "]", "ccccc", "Figure", "&", "&", "&", "&", "SQUAB", "iterations", "&", "0.05", "&", "0.01", "&", "0.01", "&", "1,000,000", "&", "0.01", "&", "0.01", "&", "0.01", "&", "1,000,000", "&", "0.05", "&", "0.0006", "&", "0.001", "&", "1,000,000", "trials", "-", "&", "0.05", "&", "0.01", "&", "0.01", "&", "1,000,000", "trials", "-", "&", "0.05", "&", "0.0005", "&", "0.001", "&", "4,000,000", "&", "0.05", "&", "0.0006", "&", "0.001", "&", "1,000,000", "trials", "-", "&", "0.05", "&", "0.01", "&", "0.01", "&", "1,000,000", "trials", "-", "&", "0.05", "&", "0.0006", "&", "0.001", "&", "1,000,000", "Parameters", "of", "the", "PS", "agent", "(", "see", "Appendix", ")", "and", "SQUAB", "algorithm", "as", "used", "for", "the", "various", "tasks", "considered", "in", "Sec", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "projective simulation"}, {"tokens": ["Although", "the", "gap", "between", "FD", "and", "HD", "is", "kept", "constant", "at", "high", "SNR", "in", "the", "case", "of", "NoRS", ",", "RS", "appears", "to", "be", "even", "more", "preferable", "at", "the", "same", "SNR", "regime", ",", "as", "expected", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["Experimental", "results", "showed", "that", "our", "model", "is", "robust", "towards", "noise", "perturbations", "which", "demonstrates", "relative", "improvement", "in", "epoch", "-", "wise", "average", "accuracy", "of", "on", "the", "SC", "-", "task", "and", "on", "the", "RS", "-", "task", "compared", "to", "Aboalayon", "et", "al", "..", "AcknowledgmentWe", "would", "like", "to", "thank", "the", "Department", "of", "EEE", "BME", ",", "BUET", "and", "Brain", "Station", "23", "(", "Dhaka", ",", "Bangladesh", ")", "for", "supporting", "this", "research", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subset compared"}, {"tokens": ["We", "compare", "our", "automatic", "algorithm", "selection", "approach", "against", "each", "algorithm", "in", "our", "portfolio", "(", "i.e.", ",", "WHCA", "*", ",", "FAR", ",", "and", "BMAA", "*", ")", ",", ",", "which", "always", "selects", "the", "best", "algorithm", "in", "our", "portfolio", "for", "each", "problem", "instance", ",", "and", "a", "worst", "selector", ",", "which", "always", "selects", "the", "worst", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "flow annotation replanning"}, {"tokens": ["However", ",", "for", "a", "high", "number", "of", "dimensions", "this", "effect", "vanishes", "(", "its", "computation", "time", "is", "barely", "modified", "with", "the", "number", "of", "dimensions", ")", "and", "DDQM", "becomes", "the", "fastest", "algorithms", "together", "with", "FIM", "and", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "group marching method"}, {"tokens": ["We", "perform", "human", "evaluations", "to", "ascertain", "the", "importance", "of", "each", "of", "these", "components", "across", "different", "QA", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["From", "these", "fitted", "models", ",", "we", "extract", "DAC", "/", "PDP", "curves", "using", "the", "training", "data(PDP", "curves", "were", "calculated", "using", "the", "PDPbox", "library", "available", "at", "https://github.com/SauceCat/PDPbox", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial dependence plots"}, {"tokens": ["parametersThe", "used", "images", "are", "presented", "in", "Table", ":", "one", "VHRS", "Spot-7", "image", "acquired", "within", "the", "GEOSUD", "project(www.equipex", "-", "geosud.fr", ")", "and", "one", "S2", "TS", "provided", "by", "the", "THEIA", "Land", "Data", "Center(http://www.theia", "-", "land.fr", "/", "en", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time series"}, {"tokens": ["L", "Set", "2", "&", "FA", "Posterior", "thalamic", "radiation", "(", "include", "optic", "radiation", ")", "L", "&", "Set", "3", "&", "FA", "Corticospinal", "tract", "R", "&", "FA", "Superior", "fronto", "-", "occipital", "fasciculus", "R", "tabular", "Group", "difference", "in", "gendertabletable", "[", "!", "]"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fractional anisotropy"}, {"tokens": ["When", "learning", "from", "SRL", ",", "the", "states", "are", "normalized", "using", "a", "running", "mean", "/", "std", "average", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["NP", "for", "background", "information", "on", "NP", ")", ",", "we", "parametrize", "the", "integration", "over", "all", "on", "a", "lower", "dimensional", "(", ")", "Gaussian", "distributed", "global", "latent", "variable", "where", ",", "resulting", "the", "following", "generative", "model", ":"], "acronym_pos": [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["In", "order", "to", "address", "such", "limitations", ",", "Section", "sec", ":", "generalisation", "consists", "in", "a", "step", "-", "by", "-", "step", "generalisation", "of", "the", "GCP", "to", "make", "it", "suitable", "for", "the", "lossy", "compression", "of", "temporal", "graphs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph compression problem"}, {"tokens": ["Although", "GP", "regression", "for", "medical", "image", "registration", ",", "and", "variograms", ",", "were", "described", "in", ",", "neither", "quantitative", "results", ",", "nor", "estimation", "of", "the", "posterior", "uncertainty", "were", "provided", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["we", "show", "convergence", "of", "FE", "method", "for", "a", "scalar", "linear", "PVI", ";", "this", "should", "be", "compared", "with", "that", "for", "the", "coupled", "constrained", "system", "consider", "in", "Sec", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parabolic variational inequality"}, {"tokens": ["The", "context", "consists", "of", "three", "parts", ":", "1", ")", "the", "output", "of", "the", "SP", "(", "i.e.", "the", "cluster", "representation", ")", ",", "2", ")", "the", "next", "cluster", "probabilities", "from", "the", "TP", ",", "and", "3", ")", "the", "expected", "value", "of", "any", "rewards", "that", "the", "architecture", "will", "receive", "if", "in", "the", "next", "step", ",", "the", "input", "falls", "into", "a", "particular", "cluster", "(", "interpreted", "as", "goals)(In", "f", ":", "expert", ",", "the", "goals", "are", "shown", "as", "separate", "from", "the", "context", "for", "clarity", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial pooler"}, {"tokens": ["The", "EQ", "and", "ROM", "data", "were", "collected", "from", "each", "of", "the", "study", "participants", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "range of motion"}, {"tokens": ["(", "b", ")", "Sleep", "Cassette", "task", "(", "SC", "-", "task", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "sleep cassette"}, {"tokens": ["To", "compactly", "represent", "multiple", "description", "feature", "tensors", ",", "there", "should", "be", "an", "entropy", "regularization", "term", "for", "our", "deep", "MDC", "framework", "training", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["For", "more", "details", "on", "spectral", "clustering", "and", "its", "relation", "to", "SBM", ",", "please", "see", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["We", "trained", "both", "datasets", "(", "described", "in", "section", ")", "into", "a", "LR", "algorithm", "and", "both", "datasets", "into", "a", "RF", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["The", "AN", "is", "added", "to", "the", "transmit", "signals", "expecting", "that", "the", "AN", "would", "interfere", "with", "the", "eavesdroppers", "and", "not", "affect", "the", "legitimate", "receivers", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["In", "scene", "text", "recognition", ",", "the", "AN", "model", "has", "two", "major", "drawbacks", ":", "1)This", "model", "is", "easily", "impacted", "by", "complicated", "/", "low", "-", "quality", "scene", "data", ",", "and", "generates", "imprecise", "alignment", "factors", "because", "the", "model", "has", "no", "alignment", "constraint", "on", "the", "integration", "of", "glimpse", "vectors", ",", "which", "may", "result", "in", "mismatch", "between", "attention", "regions", "and", "ground", "-", "truth", "regions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["This", "kind", "of", "ANN", "where", "information", "flows", "in", "one", "direction", "from", "input", "layer", "to", "output", "layer", "through", "one", "or", "more", "hidden", "layers", "is", "called", "feed", "-", "forward", "ANN", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "artificial neural network"}, {"tokens": ["Comparing", "DE", "-", "SB", "with", "DE", "using", "ideal", "separation", "by", "brute", "force", "symmetry", "breaking", "(", "DE", "-", "SB", "-", "BF", ")", "on", "the", "syn5", ",", "sinc", "and", "inc", "-", "sinc", "datasets", "."], "acronym_pos": [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["MP", "balay", "NP", "bala", "'", "height'PIr"], "acronym_pos": [0, 0, 1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["While", "the", "KDE", "also", "recovers", "relatively", "well", "the", "data", "structure", "the", "GMM", "fails", "in", "this", "case", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "data", "(", "GPS", "coordinates", ")", "which", "is", "stored", "in", "the", "server", "will", "be", "featured", "in", "the", "website", "showing", "the", "location", "of", "users", "infected", "by", "Dengue", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["The", "results", "are", "compared", "with", "state", "-", "of", "-", "the", "-", "art", "methods", ",", "including", "MSSTBM", ",", "GMM", "-", "Zivkovic", ",", "CP3-Online", ",", "GMM", "-", "Stauffer", ",", "KDE", "-", "Elgammal", "and", "RMoG", "by", "using", "implementations", "of", "the", "original", "authors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["First", ",", "in", "a", "STL", "setup", "and", "then", "with", "each", "other", "dataset", "as", "auxiliary", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "single task learning"}, {"tokens": ["In", "the", "VCC", ",", "drivers", "can", "access", "cloud", "services", ",", "e.g.", ",", "processing", "services", ",", "from", "Service", "Providers", "(", "SPs", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vehicular cloud computing"}, {"tokens": ["Uplink", "TransmissionThe", "received", "signal", "at", "the", "BS", "when", "users", "have", "been", "selected", "from", "the", "pool", "of", "users", ",", "is", "given", "by", "where", "represents", "the", "symbol", "vector", "of", "users", ",", "and", "is", "constrained", "to", "have", "total", "expected", "power", "of", ",", "is", "the", "average", "uplink", "transmit", "power", "of", "the", "th", "user", "and", "denotes", "the", "aggregate", "channel", "of", "all", "selected", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "aim", "to", "exploit", "the", "collected", "energy", "level", "data", "by", "using", "the", "ML", "approach", "at", "the", "LTE", "-", "U", "BS", "to", "infer", "the", "presence", "of", "one", "or", "two", "Wi", "-", "Fi", "BSSs", "and", "make", "the", "decision", "to", "adapt", "the", "duty", "cycle", "appropriately", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["This", "will", "give", "NPR", "in", "MDFT", "FB", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0], "long_form": "near perfect reconstruction"}, {"tokens": ["not", "required", "ANN", "variants", "facilitate", "the", "use", "of", "any", "type", "of", "input", "data", "Computer", "software", "is", "available", "for", "modelling", "itemize", "&", "itemize", "Requires", "a", "significant", "amount", "of", "data", "for", "training", "data", "that", "needs", "to", "be", "representative", "of", "true", "data", "range", "and", "its", "variability", "Determining", "the", "most", "appropriate", "model", "is", "largely", "trial", "and", "error", "and", "therefore", "can", "be", "time", "consuming", "Most", "networks", "can", "not", "provide", "confidence", "limits", "on", "the", "output", "Pre", "-", "processing", "is", "required", "to", "limit", "the", "number", "of", "data", "inputs", "and", "reduce", "model", "complexity", "All", "published", "research", "is", "relatively", "recent", "Outputs", "need", "to", "mapped", "to", "a", "physical", "representation", "itemizeParameter", "Estimation", "with", "ANNs", "&", "itemize", "As", "for", "RUL", "Forecasting", "with", "ANNs", "Useful", "for", "incorporating", "with", "physics", "of", "failure", "models"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["After", "initialization", ",", "fine", "-", "tuning", "of", "the", "ANN", "is", "performed", "for", "a", "small", "number", "of", "epochs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Examples", "of", "contextual", "attributes", "are", ":", "BAM", "currently", "used", ",", "network", "manager", "tolerance", "for", "network", "problems", "(", "preemption", ",", "devolution", ",", "blocking", ",", "etc", ")", ",", "bandwidth", "defined", "for", "each", "BC", ",", "among", "others", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "bandwidth constraint"}, {"tokens": ["As", "we", "can", "see", ",", "source", "and", "target", "samples", "are", "better", "aligned", "for", "DADA", "than", "the", "source", "-", "only", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "dual adversarial domain adaptation"}, {"tokens": ["In", "order", "to", "evaluate", "the", "method", "with", "limited", "target", "data", "and", "balance", "the", "training", "numbers", "of", "each", "category", ",", "we", "select", "the", "elaborated", "types", "of", "Cargo", ",", "Container", "Ship", "and", "Bulk", "Carrier", "of", "GRD", "mode", "(", "with", "resolution", "of", "10", "m", ")", "and", "VV", "polarization", "in", "our", "experiments", ",", "filtering", "those", "ship", "chips", "with", "the", "size", "larger", "than", "70", "70", "pixel", "to", "ensure", "the", "sufficient", "image", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ground range detected"}, {"tokens": ["We", "have", "devised", "two", "test", "cases", ";", "the", "first", "is", "a", "multi", "-", "source", "task", "where", "a", "patient", "independent", "random", "split", "is", "performed", "on", "data", "from", "both", "SC", "and", "ST", ",", "from", "here", "on", "referred", "to", "as", "Random", "Split", "task", "(", "RS", "-", "task", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subset compared"}, {"tokens": ["In", "terms", "of", "ECC", ",", "the", "protocol", "leverages", "the", "concept", "of", "ECQV", ",", "ECDLP", ",", "and", "ECDHP", "to", "generate", "the", "intermediate", "tokens", "including", "authentication", "tokens", "and", "session", "keys", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["BarPlot", "-", "rank", "-", "comparison_78_5.pdf", "PSC", "Bridges", "fig", ":"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["By", "combining", "algorithms", "in", "this", "way", ",", "we", "can", "leverage", "the", "strengths", "of", "separate", "models", "to", "approximate", "a", "greater", "area", "under", "the", "ROC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["SWIPT", "in", "relay", "channels", "is", "studied", "in", ",", "where", "derives", "the", "achievable", "throughput", "when", "the", "relay", "adopts", "TS", "or", "PS", "receiving", "strategies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["In", "the", "VCC", ",", "drivers", "can", "access", "cloud", "services", ",", "e.g.", ",", "processing", "services", ",", "from", "Service", "Providers", "(", "SPs", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vehicular cloud computing"}, {"tokens": ["In", "contrast", ",", "non", "-", "browsing", "types", "(", "EL", ",", "LS", ",", "DU", ")", "tend", "to", "reach", "more", "distant", "nodes", "more", "frequently", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "local search"}, {"tokens": ["Hao", "et", "al", "introduced", "a", "new", "PSO", "with", "added", "crossover", "operator", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["To", "construct", "DBN", ",", "hidden", "layer", "of", "anterior", "RBM", "is", "regarded", "as", "the", "visible", "layer", "of", "its", "posterior", "RBM", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "particular", ",", "and", "most", "importantly", ",", "not", "only", "FD", "outperforms", "HD", ",", "but", "also", "RS", "enables", "increasing", "the", "range", "of", "SI", "over", "which", "FD", "outperforms", "HD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["So", "far", "we", "only", "looked", "at", "problems", "in", "the", "sk", "-", "means", "algorithm", "because", "OEC", "finds", "all", "the", "expected", "clusters", "in", "these", "three", "synthetic", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["LTE", "-", "U", "detects", "beacon", "(", "or", ")", "data", "packets", "time", "+"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Two", "variants", "of", "data", "placements", "for", "GRD", "are", "shown", "in", "Figure", "3", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "group rotate declustering"}, {"tokens": ["table*[htb]tabularlllllllllllView", "Rate", "&", "ID", "&", "II", "&", "SAGE", "&", "SWAG", "&", "SAGE", "(", "+", "ID", ")", "&", "SWAG", "(", "+", "ID", ")", "&", "SAGE", "(", "+", "II", ")", "&", "SWAG", "(", "+", "II", ")", "&", "SAGE", "(", "+", "II+ID", ")", "&", "SWAG", "(", "+"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "item description"}, {"tokens": ["Both", "the", "codes", "of", "the", "FEM", "and", "of", "the", "RB", "method", "are", "fairly", "efficient", "in", "-", "house", "C", "/", "C++", "developments", "and", "perform", "exact", "line", "searches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["He", "has", "been", "working", "on", "the", "systems", "design", "for", "LTE", "MAC", "/", "RLC", "/", "PDCP", "/", "RRC", "layer", "implementations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "radio link control"}, {"tokens": ["In", "the", "share", "auction", ",", "the", "FJ", "power", "is", "split", "among", "sources", ",", "and", "their", "payments", "depend", "solely", "on", "the", "bids", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["Ground", "-", "to", "-", "Ground", "Path", "Loss", "ModelThe", "average", "PL", "between", "a", "ground", "BS", "and", "a", "ground", "user", "is", "given", "by", "the", "average", "PL", "for", "the", "NLoS", "link", "and", "is", "expressed", "by", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["[", "]", "Performance", "of", "the", "continual", "GP", "learning", "approach", "under", "non", "-", "Gaussian", "data", "for", "binary", "classification", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Using", "these", "methods", ",", "RQI", "converged", "in", "fewer", "iterations", "and", "in", "less", "time", "than", "both", "PI", "and", "Arnoldi", "for", "large", "problems", "on", "large", "core", "counts", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["Secondly", ",", "a", "large", "number", "of", "pairs", "of", "constellation", "points", "at", "the", "MSED", "reduces", "the", "AIR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "achievable information rates"}, {"tokens": ["Identifying", "such", "grammatical", "complexities", "in", "a", "sentence", "and", "transforming", "them", "into", "simpler", "structures", ",", "using", "a", "set", "of", "text", "-", "to", "-", "text", "rewriting", "operations", ",", "is", "the", "goal", "of", "syntactic", "text", "simplification", "(", "TS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "target syntactic"}, {"tokens": ["Our", "goal", "is", "to", "develop", "a", "relatively", "simple", "dynamic", "strategy", "for", "choosing", "a", "sensing", "matrix", ",", "whose", "utility", "can", "be", "expressed", "in", "closed", "form", ",", "and", "can", "potentially", "outperform", "the", "DI", "alternative", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "direct inspection"}, {"tokens": ["introduces", "the", "GP", "density", "model", ",", "followed", "by", "an", "augmentation", "scheme", "that", "makes", "its", "likelihood", "conjugate", "to", "the", "GP", "prior", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "micro", "-", "controller", "modulates", "a", "given", "command", "(", "represented", "in", "binary", "code", ")", "from", "the", "CC", "server", "as", "a", "sequence", "of", "lights", "corresponding", "to", "the", "given", "command", "(", "the", "protocol", "used", "will", "be", "discussed", "later", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "covert channels"}, {"tokens": ["We", "proposed", "a", "concrete", "construction", "with", "included", "RV", "for", "sketching", "and", "recovery", "(", "secure", "sketch", ")", "in", "Section", "and", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["However", ",", "in", "some", "cases", ",", "we", "do", "not", "have", "enough", "labeled", "SAR", "data", "to", "pre", "-", "train", "a", "deeper", "network", "with", "strongly", "representative", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["While", "most", "of", "these", "are", "suited", "well", "to", "the", "LV", "geometry", ",", "they", "are", "insightful", "for", "successful", "RV", "segmentation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "right ventricle"}, {"tokens": ["We", "aim", "to", "exploit", "the", "benefits", "of", "multi", "-", "task", "GPs", "rather", "that", "using", "a", "single", "-", "output", "GP", "per", "sensor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Whole", "tumor", "(", "WT", ")", "is", "the", "union", "of", "edema", ",", "necrosis", "non", "-", "enhancing", "tumor", "and", "enhancing", "tumor", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "whole tumor"}, {"tokens": ["To", "sum", "up", ",", "in", "order", "to", "achieve", "a", "desired", "level", "of", "performance", "with", "the", "convex", "IB", "Lagrangian", "as", "an", "objective", "one", "should"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["It", "can", "be", "seen", "that", "these", "DCNN", "based", "comparison", "methods", "often", "produce", "more", "accurate", "results", "than", "the", "interpolation", "or", "the", "sparsity", "induced", "SSR", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["The", "PI", "=", "TRUE", "prints", "the", "prediction", "intervals", "used", "in", "nnar", "models", ",", "but", "may", "take", "long", "time", "processing", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "prediction intervals"}, {"tokens": ["The", "GPS", "module", "will", "help", "the", "UAV", "to", "navigate", "to", "the", "assigned", "station", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["In", "Section", "IV", ",", "we", "consider", "the", "maximum", "angle", "estimation", "error", "of", "the", "eavesdropper", "and", "design", "the", "information", "beamforming", "matrix", "and", "AN", "beamforming", "matrix", "to", "maximize", "the", "worst", "-", "case", "system", "sum", "secrecy", "rate", "with", "the", "MAEE", "-", "SSRM", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["by:-.5emwhere", "is", "the", "bandwidth", "allocated", "to", "user", ",", "is", "the", "transmit", "power", "of", "user", ",", "is", "the", "channel", "gain", "between", "user", "and", "the", "BS", ",", "and", "is", "the", "power", "spectral", "density", "of", "the", "Gaussian", "noise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["ACC", "the", "higher", "the", "better", ",", "ECE", "the", "lower", "the", "better", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "accuracy"}, {"tokens": ["Despite", "these", "considerations", ",", "our", "approach", "using", "GMM", "'s", "have", "shown", "improvements", ",", "so", "we", "expect", "even", "better", "improvements", "using", "more", "flexible", "density", "estimators", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["We", "refer", "to", "this", "objective", "as", "a", "meta", "-", "loss", "and", "its", "optimization", "as", "meta", "-", "optimization", "-", "expressing", "the", "fact", "that", "we", "tune", "the", "parameters", "of", "the", "OPF", "optimization", "via", "a", "predictor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["[", "17].", "Moreover", ",", "a", "suitable", "solution", "is", "required", "to", "improve", "the", "channel", "capacities", "of", "the", "users", "and", "SC", "of", "NOMA", "DL", "transmission", "without", "ICI", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["The", "results", "also", "show", "that", "XOR", "-", "based", "coding", "outperforms", "the", "RLC", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random linear coding"}, {"tokens": ["AP", "vs", "log", "size", "We", "finally", "compare", "our", "proposal", "with", "the", "state", "-", "of", "-", "the", "-", "art", "results", "in", "Table", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Geometry", "-", "based", "stochastic", "channel", "models", "(", "GSCMs", ")", "consider", "more", "physical", "reality", "of", "clusters", "such", "as", "their", "relative", "locations", "to", "the", "BS", "and", "users", "in", "the", "cell", "to", "investigate", "the", "performance", "of", "MIMO", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "this", "work", ",", "we", "implement", "A", "class", "-", "dependent", "version", "of", "OLS", "to", "perform", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["Finally", ",", "the", "model", "obtained", "with", "FT", "on", "just", "ASNQ", "produces", "the", "expected", "results", ":", "it", "performs", "much", "lower", "than", "any", "model", "and", "also", "lower", "than", "FT", "on", "just", "TREC", "-", "QA", "since", "the", "target", "domain", "of", "TREC", "questions", "is", "significantly", "different", "from", "that", "of", "ASNQ", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Note", "that", "topic", "and", "UDP", "POS", "both", "apply", "to", "the", "same", "en", "-", "wikipedia", "corpus", ",", "but", "PTB", "POS", "and", "SEM", "use", "two", "different", "unaligned", "sets", "from", "the", "GMB", "corpus", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["(", "on", "metathesis", "to", "-nz-", "in", "Median", "onomastic", "items", ",", "see", ")", ",", "e.g.", ",", "Parthian", "gazn", "'", "treasure", "'", "vs.", "NP", "gasn", "'", "abundance", "'"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["To", "handle", "such", "trapping", "into", "local", "minima", ",", "many", "modified", "and", "hybrid", "versions", "of", "PSO", "algorithm", "have", "been", "developed", "for", "solving", "ELD", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["In", "most", "cases", ",", "the", "proposed", "ECS", "-", "DBN", "method", "outperforms", "other", "state", "-", "of", "-", "the", "-", "art", "resampling", "methods", ",", "i.e.", "ADASYN", ",", "SMOTE", ",", "SMOTE", "-", "borderline1", ",", "SMOTE", "-", "borderline2", "and", "SMOTE", "-", "SVM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["shows", "the", "values", "of", "the", "two", "indices", "with", "and", "without", "forgetting", "for", "online", "clustering", "in", "with", "the", "OEC", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["Finally", ",", "the", "same", "marginalisation", "of", "(", "and", ")", "can", "be", "applied", "to", "eqn.graph_ypq_kn11", "to", "arrive", "at", "the", "microcanonical", "DC", "-", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "sequential monte carlo"}, {"tokens": ["The", "complexity", "of", "this", "natural", "problem", "within", "NP", "is", "unresolved", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "natural problem"}, {"tokens": ["Ablation", "studiesAs", "described", "above", ",", "the", "weights", "of", "MR", "-", "SSIM", "and", "MS", "-", "SSIM", "exert", "different", "effects", "on", "the", "MD", "coding", "efficiency", ",", "so", "the", "comparison", "between", "\"", "Ours", "-", "mr", "\"", "and", "\"", "Ours", "-", "ms", "\"", "is", "first", "given", "and", "discussed", "in", "the", "following", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["The", "base", "station", "collects", "the", "forwarded", "packets", "from", "the", "UAVs", ",", "verifies", "whether", "the", "relay", "node", "forwards", "a", "packet", "or", "not", "and", "computes", "the", "Message", "Dropping", "Rate", "(", "MDR", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "message dropping rate"}, {"tokens": ["These", "definitions", "lead", "to", "a", "well", "-", "known", "combinatorial", "problem", "that", "we", "call", "here", "the", "Lossless", "Graph", "Compression", "Problem", "(", "Lossless", "GCP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "graph compression problem"}, {"tokens": ["The", "network", "and", "source", "tasks", "should", "be", "both", "considered", "in", "transfer", "learning", "on", "SAR", "target", "recognition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["MB", ",", "MF", "and", "Dual", "comparison", ":", "Time", "taken", "to", "reach", "the", "goal", "state", "MB", ",", "MF", "and", "Dual", "comparison", ":", "Steps", "taken", "to", "reach", "the", "goal", "state", "MB", ",", "MF", "and", "Dual", "comparison", ":", "Transveral", "time", "with", "practice", "Response", "time", "decreases", "with", "practice"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "model - based"}, {"tokens": ["In", "Figure", "7", ",", "the", "influence", "of", "over", "SC", "is", "plotted", "for", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["It", "only", "underperformed", "on", "one", "dataset", ":", "EEG", "Eye", "state", "where", "GBM", "achieves", "55.8", "accuracy", "compared", "to", "79.5", "accuracy", "for", "k", "-", "NN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["Experiments", "and", "ResultsAblation", "ExperimentsWe", "experimentally", "demonstrated", "in", "Section", "(", "Figure", ")", "that", "networks", "trained", "on", "HR", "images", "perform", "poorly", "on", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["Dayal", "and", "Srivastava", "[", "213", "]", "proposed", "a", "model", "for", "DDoS", "detection", "based", "on", "RBF", "-", "based", "neural", "network", "with", "PSO", "optimization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": [",", "we", "are", "interested", "in", "transfer", "learning", "on", "SAR", "target", "recognition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["We", "describe", "state", "-", "of", "-", "the", "art", "word", "-", "by", "-", "word", "dialogue", "state", "tracker", "architectures", "and", "propose", "to", "use", "a", "new", "encoder", "-", "decoder", "architecture", "for", "the", "DST", "task", "(", "see", "Section", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["In", "the", "GP", "model", ",", "let", "be", "the", "displacement", "vector", "for", "the", "voxel", "at", "location", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["From", "Figure", ",", "for", "the", "first", "4", "time", "steps", "the", "device", "switched", "its", "associated", "AP", "without", "a", "real", "location", "change", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["In", "AWGN", ",", "both", "the", "NLI", "and", "ASE", "are", "modeled", "as", "additive", "Gaussian", "noise.(This", "assumption", "is", "well", "justified", "for", "dispersion", "uncompensated", "long", "-", "haul", "transmission", "systems", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "amplified spontaneous emission"}, {"tokens": ["Considering", "NOMA", ",", "investigated", "an", "M2", "M", "enabled", "cellular", "network", ",", "where", "multiple", "MTCDs", "simultaneously", "transmit", "data", "to", "the", "same", "MTCG", "and", "multiple", "MTCGs", "simultaneously", "transmit", "the", "gathered", "data", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["The", "impact", "of", "the", "different", "parameters", "over", "capacities", "and", "EE", "for", "the", "proposed", "scheme", "is", "analyzed", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "as", "well", "to", "analyze", "the", "effectiveness", "of", "the", "proposed", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "channel", "model", "consists", "of", "three", "parts", ":", "1", ")", "the", "channel", "path", "-", "loss", "modeled", "as", ",", "where", "(", "in", "km", ")", "is", "the", "distance", "between", "the", "th", "RRH", "to", "the", "th", "UE", ";", "2", ")", "the", "log", "-", "normal", "shadowing", "with", "zero", "mean", "and", "8", "dB", "standard", "derivation", ";", "3", ")", "small", "-", "scale", "Rayleigh", "fading", "with", "zero", "mean", "and", "unit", "variance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "proposed", "work", "is", "different", "from", "in", "many", "respects", "as", "it", "needs", "labeled", "data", "only", "in", "HR", "and", "learns", "to", "predict", "landmarks", "in", "LR", "images", "in", "an", "unsupervised", "way", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["It", "was", "demonstrated", "that", "the", "firing", "of", "MTL", "cells", "was", "sparse", "because", "most", "of", "them", "did", "not", "respond", "to", "the", "great", "majority", "of", "images", "used", "in", "the", "experiment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "medial temporal lobe"}, {"tokens": ["POS", "taggingFor", "syntactic", "categories", ",", "we", "use", "POS", "tags", ",", "as", "in", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["These", "turn", "out", "to", "perform", "worse", "than", "our", "CSG", "metric", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["The", "Video", "-", "aware", "Unequal", "Error", "Protection", "FEC", "(", "VaUEP", ")", "mechanism", "is", "the", "third", "scenario", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Often", ",", "the", "PS", "system", "uses", "parallelism", "technique", "called", "data", "parallelism", ",", "as", "described", "in", "where", "training", "dataset", "splits", "into", "small", "batches", "called", "mini", "-", "batches", "that", "are", "used", "to", "calculate", "model", "error", "and", "update", "model", "parameters", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["TS", ",", "QLS", "and", "LS", "keep", "mostly", "edges", "within", "dense", "regions", ",", "which", "results", "in", "increasing", "clustering", "coefficients", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "triadic simmelian"}, {"tokens": ["OT", "provides", "sensible", "cost", "functions", "when", "learning", "distributions", "supported", "by", "low", "-", "dim", "manifolds", "(", "in", "our", "case", ",", "and", ")", "while", "other", "alternatives", "do", "not", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Although", "CF", "techniques", "have", "shown", "good", "performance", "for", "many", "applications", ",", "the", "sparsity", "problem", "is", "considered", "as", "one", "of", "their", "significant", "challenges", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["In", "the", "following", ",", "we", "first", "explain", "our", "motivation", "for", "tackling", "M", "-", "ARS", "and", "then", "describe", "the", "formal", "task", "definitions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "addressee and response selection"}, {"tokens": ["The", "scheme", "without", "FEC", "averaged", "a", "value", "of", "5,277", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["MU", "-", "CTS", "and", "MU", "-", "ACK", "add", "a", "transmitter", "address", "field", "to", "the", "original", "CTS", "and", "ACK", "frames", "in", "order", "to", "facilitate", "the", "AP", "to", "differentiate", "multiple", "responding", "STAs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["One", "example", "is", "the", "Adaptive", "Multi", "-", "Hop", "FEC", "(", "AM", "-", "FEC", ")", "protection", "scheme", "to", "improve", "the", "quality", "of", "video", "streaming", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Consequently", ",", "simplifying", "clausal", "components", "is", "the", "main", "focus", "of", "the", "proposed", "TS", "systems", "of", "this", "category", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["CO", ",", "PA", ",", "CG", "correspond", "to", "context", "-", "only", "attention", ",", "parallel", "attention", "and", "context", "-", "guided", "attention", ",", "respectively", ";", "and", "the", "-CVAE", "suffix", "indicates", "their", "CVAE", "variant", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parallel attention"}, {"tokens": ["The", "combination", "of", "Rank", "1-BA", "generates", "more", "robust", "depth", "-", "map", "and", "is", "significantly", "faster", "than", "using", "BA", "alone", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "bundle adjustment"}, {"tokens": ["Therefore", ",", "we", "hypothesize", "that", "any", "model", "(", "deep", "or", "shallow", ")", "trained", "on", "the", "PA", "dataset", "that", "does", "not", "specifically", "discard", "this", "information", "could", "exploit", "the", "duration", "of", "silence", "as", "a", "discriminative", "cue", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["Our", "SC", "score", "takes", "into", "account", "both", "global", "and", "local", "information", "and", "is", "able", "to", "accurately", "quantify", "a", "rater", "'s", "consistency", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "self consistency"}, {"tokens": ["LOD", "techniques", "were", "originally", "made", "for", "CPU", ",", "but", "as", "GPU", "became", "sophisticated", "those", "techniques", "were", "implemented", "with", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "tessellation shader"}, {"tokens": ["There", "is", "little", ",", "but", "a", "work", "towards", "interoperable", "architecture", ",", "e.g.", "QA", "archiecture", "developed", "by", "OKBQA(Open", "Knowledge", "base", "and", "Question", "Answering", "(", "http://okbqa.org", ")", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["In", "Figure", "(", "a", ")", ",", "the", "time", "series", "TI", "1", "shows", "a", "typical", "burst", "characteristics", ",", "while", "the", "time", "series", "TI", "2", "presents", "more", "regular", "intervals", "between", "two", "active", "events", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["This", "value", "was", "chosen", "because", "it", "showed", "a", "good", "tradeoff", "between", "QoE", "and", "network", "overhead", "in", "several", "PLR", ";", "(", "3", ")", "the", "adaptive", "FEC", "-", "based", "mechanism", "(", "uavFEC", ")", ",", "presented", "in", "Section", "sec", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["*", "personlich", "schreibt", ",", "und", "der", "Essay", "endet", "mit", "einem", "Beitrag", "von", "RB", ",", "also", "mit", "Rosi", "Braidotti", "als"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "rosi braidotti"}, {"tokens": ["All", "of", "the", "works", "mentioned", "above", "are", "trained", "on", "high", "quality", "images", "and", "their", "performance", "degrades", "on", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["On", "the", "Relationship", "Between", "Matching", "Pursuit", "and", "Frank", "-", "WolfeThe", "sub", "-", "linear", "convergence", "rates", "for", "MP", "and", "FW", "are", "related", "by", "the", "constant", "that", "essentially", "simulates", "a", "\"", "blown", "up", "\"", "set", "in", "which", "the", "analysis", "of", "FW", "can", "be", "applied", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["While", "the", "accuracy", "did", "not", "improve", "remarkably", "with", "the", "ensemble", "classifier", ",", "the", "area", "under", "the", "ROC", "curve", "is", "the", "largest", "of", "all", "classifiers", "that", "were", "produced", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Initial", "work", "demonstrated", "that", "FA", "was", "competitive", "with", "BP", "on", "the", "MNIST", "handwritten", "digit", "dataset", "and", "a", "random", "input", "-", "output", "task", "in", "multilayer", "fully", "-", "connected", "networks", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["The", "population", "size", "for", "all", "DE", "-", "based", "methods", "is", ",", "and", "for", "all", "CMA", "-", "ES", "-", "based", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Um", "dos", "pressupostos", "da", "MD", "\u00e9", "que", "existem", "informa\u00e7\u00f5es", "impl\u00edcitas", "dentro", "desta", "grande", "massa", "de", "dados", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "massa de dados"}, {"tokens": ["The", "additive", "GP", "performed", "best", "on", "datasets", "well", "-", "explained", "by", "low", "orders", "of", "interaction", ",", "and", "approximately", "as", "well", "as", "the", "SE", "-", "GP", "model", "on", "datasets", "which", "were", "well", "explained", "by", "high", "orders", "of", "interaction", "(", "see", "table", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "result", "shows", "that", "FA", "outperforms", "IFAB", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "firefly algorithm"}, {"tokens": ["At", "high", "current", "regions", ",", "especially", "between", "30", "and", "35", "A", ",", "the", "field", "-", "magnitude", "RMSE", "improvement", "of", "the", "ANN", "model", "over", "the", "LMEM", "was", "over", "35", "mT.", "This", "study", "demonstrates", "the", "feasibility", "of", "using", "machine", "learning", "methods", "to", "model", "an", "eMNS", "for", "medical", "applications", ",", "and", "its", "ability", "to", "account", "for", "complex", "nonlinear", "behavior", "at", "high", "currents", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["A", "Multi", "-", "Scale", "SBM", "was", "introduced", "in", "for", "shape", "modeling", "and", "representation", "that", "can", "learn", "the", "true", "binary", "distributions", "of", "the", "training", "shapes", "and", "generate", "more", "valid", "shapes", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "shape boltzmann machine"}, {"tokens": ["IPNN", ":", "PNN", "with", "inner", "product", "layer", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Furthermore", ",", "they", "showed", "that", "a", "RV", "detector", "can", "produce", "more", "accurate", "detections", "on", "small", "objects", ",", "such", "as", "pedestrians", "and", "bikes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "range view"}, {"tokens": ["The", "Ballroom", "dataset", "shows", "much", "smaller", "variability", "when", "BPM", "is", "included", "in", "the", "combination", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "beat per minute"}, {"tokens": ["RQI", "vs.", "PIWe", "first", "did", "a", "study", "on", "Jaguar", "to", "better", "characterize", "the", "performance", "of", "preconditioned", "RQI", "and", "compare", "it", "to", "preconditioned", "PI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "power iteration"}, {"tokens": ["DCNN", "subgraph", "."], "acronym_pos": [1, 0, 0], "long_form": "dynamic convolutional neural network"}, {"tokens": ["Despite", "the", "lower", "age", "of", "the", "subjects", ",", "the", "labeled", "volumes", "for", "SAT", "in", "the", "chosen", "scans", "are", "on", "average", "about", "75", "larger", ",", "while", "the", "VAT", "volumes", "are", "about", "50", "smaller", "than", "in", "the", "images", "of", "Tellus", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Simmelian", "Backbones", "(", "TS", ","], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "triadic simmelian"}, {"tokens": ["t]ABEP", ",", ",", "of", "DBPSK", "versus", "the", "number", "of", "relay", "nodes", ",", ",", "for", "different", "average", "transmit", "SNRs", "per", "bit", "and", "dB", ",", "over", "IID", "Rayleigh", "fading", "channels", ":", "(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["It", "is", "noteworthy", "to", "mention", "that", "in", "this", "case", "represents", "the", "groundtruth", "-", "heatmaps", "distribution", "on", "generated", "LR", "images", ",", "while", "represents", "the", "distribution", "on", "generated", "heatmaps", "of", "generated", "LR", "images", "and", "real", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["In", "this", "paper", ",", "we", "propose", "a", "new", "h", "-", "NSF", "model", "with", "trainable", "MVF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "maximum voice frequency"}, {"tokens": ["Due", "to", "the", "differences", "between", "the", "three", "competing", "structures", ",", "we", "observed", "that", "while", "the", "baseline", "CNN", "and", "LR", "networks", "work", "well", "with", "weight", "decay", ",", "applying", "weight", "decay", "to", "the", "proposed", "network", "structure", "tends", "to", "drive", "all", "the", "weight", "values", "close", "to", "zeros", "when", "is", "large", ",", "or", "the", "regularization", "effect", "is", "marginal", "when", "using", "a", "small", "value", "for", ",", "leading", "to", "the", "exhaustive", "search", "of", "suitable", "hyper", "-", "parameter", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low rank"}, {"tokens": ["OPF", "FrameworkSeveral", "synthetic", "grids", "from", "the", "Power", "Grid", "Library", "were", "used", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Table", "shows", "the", "efficiency", "of", "various", "OT", "extension", "protocols", "achieving", "computational", "security", "and", "statistical", "security", "for", "producing", "-out", "-", "of-", "OTs", "with", "-bit", "inputs", "of", "the", "sender", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Moreover", ",", "denote", "by", "the", "set", "of", "SCCs", "that", "satisfy", "the", "accepting", "conditions", "associated", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strongly connected components"}, {"tokens": ["With", "the", "widespread", "use", "of", "internet", "and", "social", "media", ",", "AA", "research", "has", "shifted", "gears", "in", "the", "last", "two", "decades", "towards", "texts", "written", "in", "everyday", "language", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["It", "can", "be", "seen", "that", "our", "models", "substantially", "outperform", "the", "baseline", "provided", "by", "the", "organizers", ",", "with", "the", "audio", "-", "text", "model", "[", "G1", "]", "achieving", "a", "CCC", "of", "with", "a", "standard", "deviation", "of", ".12", "(", "calculated", "across", "the", "videos", "in", "the", "Validation", "set", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["Given", "current", "state", ",", "Propose", "new", "state", ",", "Calculate", "SBM", "-", "acceptance", "propability", ",", "Draw", "a", "Bernoulli", "with", "probability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["MACS", "score", "between", "to", "shows", "the", "absence", "of", "path", "among", "concepts", "or", "a", "relatively", "much", "longer", "path", "in", "the", "knowledge", "-", "base", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean average conceptual similarity"}, {"tokens": ["The", "spatio", "-", "temporal", "compression", "caused", "by", "the", "clustering", "and", "event", "-", "driven", "nature", "of", "the", "TP", "results", "in", "a", "faster", "replay", "of", "the", "video", "as", "only", "significant", "changes", "in", "the", "position", "of", "the", "bird", "are", "clustered", "differently", "and", "thus", "remembered", "as", "events", "by", "the", "TP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "temporal pooler"}, {"tokens": ["elsarticle", "-", "numAppendixResults", "of", "CC", "method", "(", "example", "based", ")", "using", "top", "5", "single", "label", "classifers", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classifier chain"}, {"tokens": ["BS", "transmit", "signal", "to", "and", "signal", "to", "CEU", "for", "a", "duration", "of", "simultaneously", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Claims", "of", "DSA", "skill", "shortages", "are", "being", "made", "in", "labour", "markets", "around", "the", "world", ",", "including", "in", "Australia", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["We", "estimate", "the", "PRR", "as", "a", "function", "of", "empirically", "collected", "RSSI", "traces", "from", "a", "real", "testbed", "as", "outlined", "in", "Section", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "packet reception rate"}, {"tokens": ["We", "can", "use", "fc", ":", "KL", "divergence", "to", "define", "the", "Bregman", "divergence", "in", "eq", ":", "DMD", "to", "optimize", "a", "control", "distribution", "in", "the", "exponential", "family", ":", "if", "is", "an", "expectation", "parameter", ",", "we", "can", "set", ",", "orif", "is", "a", "natural", "parameter", ",", "we", "can", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["The", "ST", "provided", "boiler", "on", "-", "time", "(", "BO", ")", "and", "thermostat", "set", "point", "(", "SP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "set point"}, {"tokens": ["Though", "the", "OP", "is", "increased", "for", "at", "CCU", "because", "the", "distance", "between", "BS", "and", "CCU", "is", "increased", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Approaches", "for", "PAP", "detectionIn", "(", "dedicated", "for", "an", "all", "-", "to", "-", "all", "collective", "operation", ")", ",", "there", "is", "assumption", "about", "the", "call", "site", "(", "a", "place", "in", "the", "code", "where", "the", "MPI", "collective", "operation", "is", "called", ")", "paired", "with", "the", "message", "size", "that", "they", "have", "a", "similar", "PAPs", "for", "the", "whole", "program", "execution", ",", "or", "at", "least", "their", "behavior", "changes", "infrequently", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["On", "one", "hand", ",", "the", "models", "mostly", "agreed", "on", "the", "optimal", ",", "as", "found", "using", "their", "belief", "propagation", "algorithm", "and", "the", "observed", "data", "log", "-", "likelihood", "criterion", ",", "and", "found", "that", "the", "posterior", "in", "their", "DC", "-", "SBM", "is", "indeed", "maximised", "at", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Hashimoto14:Two", "shows", "that", "characterizes", "PS", "when", "we", "come", "to", "single", "-", "type", "resources", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["Both", "the", "SP", "and", "TP", "were", "learning", "in", "an", "on", "-", "line", "fashion", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial pooler"}, {"tokens": ["For", "supervised", "setting", ",", "PIN", "is", "trained", "using", "a", "RPN", "to", "predict", "the", "proposals", "close", "to", "the", "groundtruth", "bounding", "boxes", "for", "a", "phrase", "category", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "proposal indexing network"}, {"tokens": ["It", "is", "interesting", "to", "note", "that", "the", "collision", "probability", "of", "STAs", "is", "higher", "than", "that", "of", "the", "AP", "when", "the", "system", "is", "non", "-", "saturated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "outcome", "of", "the", "critic", "unit", "in", "OT", "module", "is", "denoted", "as", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["As", "the", "number", "of", "GPUs", "increases", ",", "in", "ring", "parallel", "architecture", "will", "be", "smaller", "than", "PS", "framework", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "parameter server"}, {"tokens": ["have", "developed", "a", "taxonomy", "of", "Collaborative", "Filtering", "RS", "evaluation", "metrics", "collapsed", "into", "three", "equivalence", "classes", "-", "predictive", "accuracy", "metrics", ",", "classification", "accuracy", "metrics", ",", "and", "rank", "accuracy", "metrics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["Though", "attention", "drift", "has", "been", "observed", "in", "attention", "training", "of", "speech", "recognition", ",", "where", "the", "authors", "proposed", "an", "MTL", "framework", "that", "combines", "CTC", "and", "AN", "to", "handle", "this", "issue", ",", "our", "paper", "is", "the", "first", "work", "that", "formally", "puts", "forward", "the", "concept", "of", "attention", "drift", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["The", "same", "energy", "SAD", "as", "used", "in", "the", "i", "-", "vector", "system", "filters", "out", "nonspeech", "frames", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "speech activity detection"}, {"tokens": ["As", "Table", "impactAMR", "shows", ",", "compared", "with", "SRL", "output", ",", "the", "fine", "-", "grained", "AMR", "semantic", "relations", "such", "as", ":", "location", ",", ":", "instrument", "appear", "to", "be", "more", "informative", "to", "infer", "the", "argument", "roles", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["However", ",", "we", "are", "presenting", "an", "improved", "version", "of", "the", "DCNN", "model", "inspired", "by", "the", "information", "processing", "mechanisms", "of", "the", "human", "visual", "cortex", ",", "and", "recently", "developed", "some", "promising", "DCNN", "architectures", "like", "Inception", "-", "v4", ",", "and", "RCNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Denoting", ",", "a", "random", "OT", "of", "above", "type", "generates", "random", "masks", "and", "delivers", "them", "to", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["So", "setting", "a", "priority", "to", "the", "first", "queue", "in", "the", "retransmission", "will", "also", "result", "in", "a", "service", "rate", "improvement", "for", "the", "second", "queue", ";", "this", "is", "because", "the", "RA", "with", "priority", "scheme", "has", "some", "form", "of", "coordination", "between", "the", "two", "queues", "in", "the", "retransmission", "stage", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random access"}, {"tokens": ["Related", "WorkEnd", "-", "to", "-", "End", "Models", "in", "SRLEnd", "-", "to", "-", "end", "approaches", "to", "SRL", "have", "been", "widely", "explored", "recently", ",", "and", "many", "state", "-", "of", "-", "the", "-", "art", "results", "have", "been", "achieved", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["The", "small", "problems", "showed", "that", "RQI", "can", "require", "fewer", "Krylov", "iterations", "than", "PI", ",", "and", "has", "the", "potential", "to", "be", "beneficial", "if", "the", "multigroup", "iterations", "are", "converged", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["We", "also", "prove", "that", "recursively", "reconstructing", "the", "continual", "GP", "prior", "avoids", "propagating", "the", "error", "of", "approximations", "forwards", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["reinterpreted", "PCA", "as", "a", "GP", "mapping", "from", "the", "latent", "space", "to", "the", "data", "space", "and", "proposed", "a", "generalisation", "by", "using", "a", "prior", "that", "allows", "for", "non", "-", "linear", "processes", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Our", "experiments", "demonstrated", "that", "the", "new", "model", "can", "predict", "a", "good", "trajectory", "of", "the", "MVF", "and", "produce", "high", "-", "quality", "speech", "for", "a", "text", "-", "to", "-", "speech", "synthesis", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["For", "long", "-", "axis", "4Ch", "view", "images", ",", "LV", ",", "myocardium", ",", "RV", ",", "LA", "and", "RA", "were", "manually", "annotated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "right atrium"}, {"tokens": ["Future", "implementation", "will", "be", "refactor", "these", "requirements", "on", "other", "BC", "platforms", ",", "i.e.", "Hyperledger", ",", "formal", "Verification", "of", "internal", "-", "consistency", "of", "a", "configuration", "file", "and", "a", "means", "of", "defining", "incremental", "adjustments", "to", "a", "test", "network", "by", "DSL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["Men", "tend", "to", "have", "lower", "SAT", "and", "higher", "VAT", "compared", "to", "women", "(", "p<0.001", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Then", ",", "the", "range", "of", "Lagrange", "multipliers", "that", "allow", "the", "exploration", "of", "the", "IB", "curve", "with", "the", "convex", "IB", "Lagrangian", "is", ",", "with", "where", "and", "are", "the", "derivatives", "of", "and", "w.r.t", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["However", ",", "it", "has", "not", "been", "investigated", "as", "to", "how", "cost", "-", "sensitive", "learning", "could", "enhance", "DBN", "to", "deal", "with", "imbalanced", "data", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Evaluation", "of", "Learned", "State", "RepresentationsThe", "most", "practical", "evaluation", "of", "SRL", "is", "assessing", "if", "the", "learned", "states", "can", "be", "used", "for", "solving", "the", "task", "in", "RL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["*", "caxra-", "'", "wheel", "'", "MP", "caxr", "NP", "carxPIr"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "new persian"}, {"tokens": ["While", "this", "tagging", "might", "raise", "a", "question", "whether", "there", "are", "overlapping", "tags", "with", "SRL", ",", "we", "argue", "that", "entity", "labels", "are", "less", "ambiguous", "compared", "to", "role", "arguments", "which", "are", "dependent", "on", "the", "predicate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["The", "desired", "received", "signal", "power", "at", "UE", "from", "the", "cooperative", "SBSs", "is", "given", "byThe", "interference", "power", "aggregated", "at", "UE", "is", "expressed", "asFurthermore", ",", "the", "average", "achievable", "rate", "with", "the", "anisotropic", "path", "loss", "model", "adopting", "the", "distance", "constraint", "is", "derived", "bywhere", "step", "(", "a", ")", "utilizes", "the", "transfer", "formula", "of", ",", "and", "are", "the", "Laplace", "transforms", "of", "the", "desired", "received", "signal", "power", "and", "the", "interference", "power", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Recently", ",", "similar", "stereo", "vision", "is", "adopted", "by", "some", "AR", "devices", "for", "enhancing", "MIS", "procedures", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["The", "ViewFEC", "mechanism", "imposes", ",", "on", "average", ",", "40", "less", "network", "overhead", "than", "the", "non", "-", "adaptive", "Video", "-", "aware", "FEC", ",", "with", "equal", "or", "slightly", "better", "video", "quality", ",", "as", "shown", "in", "Figure", "fig", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "NDCG", "results", "on", "the", "MQ", "and", "MQ", "datasets", "are", "shown", "in", "Figure", ",", "where", "Linear", "-", "LBD", "and", "Nested", "-", "LBD", "represent", "linear", "and", "nested", "structured", "LB", "divergence", "-", "based", "methods", "for", "unsupervised", "rank", "aggregation", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["Cross", "-", "lingual", "representation", "learning", "approaches", "have", "achieved", "good", "results", "in", "different", "NLP", "applications", "such", "as", "cross", "-", "language", "SST", "and", "POS", "tagging", ",", "cross", "-", "language", "named", "entity", "recognition", ",", "cross", "-", "lingual", "document", "classification", "and", "lexical", "translation", "task", ",", "cross", "language", "dependency", "parsing", "and", "cross", "-", "language", "semantic", "role", "labeling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["As", "mentioned", "earlier", ",", "the", "objective", "of", "this", "paper", "is", "to", "show", "that", "landmark", "prediction", "directly", "on", "LR", "image", "is", "feasible", "even", "in", "the", "absence", "of", "labeled", "LR", "data", ",", "and", "evaluate", "the", "performance", "of", "auxiliary", "tasks", "compared", "to", "commonly", "used", "practices", "of", "rescaling", "or", "super", "-", "resolution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Gaussian", "Mixture", "Model", "(", "GMM", ")", "is", "a", "well", "known", "technique", "for", "background", "modeling", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["This", "citation", ",", "like", "the", "citations", "of", "AP", ",", "seems", "to", "follow", "the", "producers", "content", "republishing", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "associated press"}, {"tokens": ["More", "importantly", ",", "it", "is", "shown", "that", ",", "as", "the", "fading", "conditions", "of", "the", "relay", "to", "destination", "channels", "become", "more", "favorable", "than", "those", "of", "the", "direct", "source", "to", "destination", "channel", ",", "RS", "-", "based", "transmission", "improves", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["This", "task", "has", "recordings", "from", "SC", "subjects", "in", "the", "training", "set", "and", "recordings", "from", "SC", "subjects", "in", "the", "test", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "subset compared"}, {"tokens": ["The", "average", "precision", "(", "AP", ")", "measures", "the", "mean", "precision", "for", "all", "recall", "values", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["We", "also", "ran", "the", "data", "through", "the", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "stochastic block model"}, {"tokens": ["Recent", "research", "and", "commercial", "products", "have", "begun", "exploring", "ISP", "specialization", "for", "vision", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["ApproachesSeveral", "aspects", "of", "SBMs", "and", "related", "models", "have", "been", "considered", "so", "far", ",", "namely", "the", "type", "of", "graph", ",", "whether", "the", "model", "is", "an", "SBM", "or", "not", ",", "the", "inference", "approach", ",", "the", "clustering", "approach", ",", "the", "number", "of", "groups", ",", "and", "whether", "there", "is", "longitudinal", "modelling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["In", "particular", ",", "they", "fit", "a", "nested", "SBM", ",", "thus", "constructing", "a", "hierarchical", "structure", "and", "allowing", "the", "number", "of", "groups", "to", "be", "inferred", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["From", "Left", "to", "Right", ":", "Ground", "Truth", "FS", "image", ",", "ZF", "image", "for", "4x", "undersampling", "factor", ",", "GAN", "with", "basic", "discriminator", "reconstructed", "image", ",", "GAN", "with", "context", "discriminator", "reconstructed", "image", ",", "ZF", "reconstruction", "error", ",", "GAN", "with", "basic", "discriminator", "reconstruction", "error", "and", "GAN", "with", "context", "discriminator", "reconstruction", "error", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fully sampled"}, {"tokens": ["B.", "ROC", "curve", "for", "a", "binary", "classification", "of", "left", "atrial", "enlargement", ",", "as", "defined", "by", "being", "in", "the", "upper", "90th", "percentile", "of", "indexed", "left", "atrial", "volume", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Our", "algorithm", "is", "guaranteed", "to", "satisfy", "this", "constraint", "because", "the", "DST", "transform", "expressed", "by", "Equation", "(", "11", ")", "generates", "and", "for", "the", "starting", "(", ")", "and", "the", "ending", "(", ")", "points", "of", "the", "warping", "functions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "discrete sine transform"}, {"tokens": ["Specifically", ",", "GPA", "considers", "the", "structure", "of", "the", "input", "graph", "by", "exploiting", "the", "graph", "partition", "algorithm", "to", "construct", "the", "sketch", "of", "a", "graph", "and", "minimize", "the", "size", "of", "edge", "cut", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["So", ",", "the", "expression", "becomes", ",", "(", "CV", "-", "LR", ")", "is", "the", "vector", "of", "the", "words", "in", "vocabulary", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["To", "compare", "the", "convergence", "behavior", "of", "the", "meta", "-", "model", "to", "the", "baseline", "(", "DE", ")", "across", "all", "problems", ",", "we", "performed", "Page", "'s", "trend", "test", "for", "ordered", "alternatives", "as", "proposed", "by", "Derrac", "et", "al", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["However", ",", "in", "our", "case", ",", "there", "is", "not", "a", "traditional", "PAP", ",", "because", "there", "is", "no", "central", "authority", "managing", "the", "policies", ",", "being", "each", "one", "of", "the", "document", "keepers", "managers", "of", "their", "own", "documents", ",", "working", "as", "a", "distributed", "PAP", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "policy administration point"}, {"tokens": ["Quick", "charging", "utilizes", "higher", "voltage", "and", "constant", "current", "during", "the", "CC", "phase", "of", "charging", ",", "whereas", "Samsung", "'s", "Fast", "charging", "employs", "pulse", "charging", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant charging"}, {"tokens": ["The", "first", "641", "subjects", "from", "the", "Rhineland", "Study", "with", "BMI", "and", "abdominal", "MR", "Dixon", "scans", "are", "included", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["NP", "varzidan", "'", "sow", "a", "field", "'", ",", "with", "v-)Elsewhere", ",", "PIr"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["NLM", "Dropout", "Variant", "(", "Validation", "/", "Test", ")"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural language modelling"}, {"tokens": ["AV", "strategy", "improves", "the", "efficiency", "of", "the", "RV", "strategy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random vaccination"}, {"tokens": ["The", "performances", "of", "BOA", "and", "WCA", "are", "better", "than", "GSP", "(", "with", "relative", "improvements", "of", "8.9", "and", "2.2", "respectively", ")", ",", "which", "indicates", "that", "both", "our", "proposed", "approach", "and", "the", "game", "-", "theoretic", "approach", "for", "revenue", "optimization", "are", "effective", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized second price"}, {"tokens": ["[", "Top", "]", "CSG", "c", "-", "measure", "alongside", "with", "test", "error", "rates", "for", "3", "CNN", "models", "on", "six", "datasets.[Bottom", "]"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["(", "MEM)The", "predictive", "mean", "of", "a", "GP", "in", "conditioned", "on", "data", "observed", "at", ",", "has", "the", "following", "structurewhere", "and", "stand", "for", "the", "covariance", "and", "the", "mean", "function", "of", "the", "prior", "GP", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["While", "per", "-", "class", "UAP", "is", "above", "the", "AP", "of", "the", "best", "model", "over", "all", "VOC", "classes", ",", "UAPs", "of", "5", "FASHION", "categories", "fall", "below", "the", "best", "model", "AP", "(", "messenger", "bags", ",", "tunics", ",", "long", "sleeve", "shirts", ",", "blouses", ",", "and", "rompers", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Some", "GPS", "algorithms", "are", ":", "the", "original", "Hooke", "and", "Jeeves", "pattern", "search", "algorithm", ",", "the", "evolutionary", "operation", "by", "utilizing", "factorial", "design", "and", "the", "multi", "-", "directional", "search", "algorithm", ",", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["We", "employ", "UnrealCV", ",", "which", "provides", "convenient", "APIs", ",", "along", "with", "a", "wrapper", "compatible", "with", "OpenAI", "Gym", ",", "for", "interactions", "between", "RL", "algorithms", "and", "the", "environments", "constructed", "based", "on", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "unreal engine"}, {"tokens": ["At", "the", "same", "time", ",", "video", "sequences", "that", "are", "using", "either", "type", "of", "FEC", "-", "based", "mechanisms", ",", "are", "able", "to", "maintain", "a", "good", "quality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["For", ",", "the", "welfare", "-", "minimizing", "SSS", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "stochastically stable states"}, {"tokens": ["This", "paper", "proposes", "an", "evolutionary", "cost", "-", "sensitive", "deep", "belief", "network", "(", "ECS", "-", "DBN", ")", "for", "imbalanced", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Based", "on", "Nakagami", "fading", "assumption", ",", "the", "channel", "gain", "between", "the", "UE", "and", "BSs", "are", "normalized", "Gamma", "random", "variables", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Bayesian", "Classifier", "Chains", "(", "BCC)Zaragoza2011It", "creates", "a", "maximum", "spanning", "tree", "based", "on", "marginal", "label", "dependences", "and", "then", "employs", "a", "classifier", "chain", "(", "CC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "classifier chain"}, {"tokens": ["IACFequil", "presents", "the", "IACF", "measured", "in", "HMC", "and", "MD", "with", "different", "integrating", "schemes", "for", "the", "same", "range", "of", "time", "steps", "and", "trajectory", "lengths", "described", "above", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["Here", ",", "we", "evaluate", "two", "unsupervised", "GAN", "models", "(", "CycleGAN", "and", "UNIT", ")", "for", "image", "-", "to", "-", "image", "translation", "of", "T1-", "and", "T2-weighted", "MR", "images", ",", "by", "comparing", "generated", "synthetic", "MR", "images", "to", "ground", "truth", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["WF", "Age", "Estimator", ";", "[", "-", ">", "]"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "white females"}, {"tokens": ["present", "a", "QA", "approach", "on", "the", "DBpedia", "dataset", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Observing", "this", "figure", ",", "we", "can", "find", "that", "the", "theoretical", "OPA", "parameter", "maintain", "1", "in", "the", "low", "SNR", "regime", "and", "begin", "to", "decrease", "in", "the", "medium", "and", "high", "SNR", "regimes", ",", "which", "represents", "that", "the", "AN", "has", "a", "little", "effect", "on", "SR", "performance", "in", "the", "low", "SNR", "regime", "and", "the", "impact", "of", "AN", "becomes", "larger", "in", "the", "medium", "and", "high", "SNR", "regimes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["DFA", "actually", "works", "fairly", "well", "compared", "to", "the", "other", "baselines", "if", "the", "activation", "function", "is", "the", "hyperbolic", "tangent", ",", "and", "does", "outperform", "FA", "when", "the", "logistic", "sigmoid", "is", "utilized", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["CSMD_TS", "fig", ":", "diabetesCMED", "-", "TS", "subfigure", "subfigure[b]0.2455", "results", "/", "cascade", "/", "regret_diabetes_CEMD", "-", "KL_10000_100.png", "alg", ":", "CSMD_KL"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Using", "RL", "notations", ",", "SRL", "corresponds", "to", "learning", "a", "transformation(In", "practice", ",", "the", "learned", "transformation", "is", "a", "neural", "network", ")", "from", "the", "observation", "space", "to", "the", "state", "space", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["The", "coverage", "is", "limited", "by", "the", "availability", "of", "cloud", "-", "free", ",", "high", "-", "resolution", "satellite", "imagery", "(", "see", "SI", ")", "and", "nosignificant", "differences", "in", "performance", "between", "countries", "is", "observed", ",", "unless", "the", "source", "imagery", "is", "of", "poor", "quality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "satellite imagery"}, {"tokens": ["Our", "approach", "is", "successfully", "applied", "to", "common", "RS", "images", "with", "two", "representative", "state", "of", "the", "art", "deep", "nets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["for", "both", "links", "aswhere", "is", "the", "DE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deterministic equivalent"}, {"tokens": ["This", "suggests", "that", "only", "the", "translations", "by", "NMT", "are", "not", "sufficient", "for", "building", "good", "multilingual", "ARS", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "addressee and response selection"}, {"tokens": ["We", "used", "wrapper", "based", "approach", "to", "calculate", "the", "fitness", "of", "each", "solution", "generated", "randomly", "in", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "tabu search"}, {"tokens": ["After", "removing", "too", "short", "and", "too", "long", "abstracts", "&", "1,673,824", "Organisation", "of", "the", "LSC"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "leicester scientific corpus"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "study", "in", "showed", "that", "the", "PS", "protocol", "always", "achieves", "a", "system", "outage", "probability", "lower", "than", "that", "of", "the", "TS", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "available", "modulation", "schemes", "for", "LTE", "eMBMS", "are", "QPSK", ",", "16QAM", ",", "64QAM", ",", "and", "256QAM", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Fortunately", ",", "the", "DMP", "co", "-", "processor", "of", "the", "MPU6050", "already", "implements", "these", "features", "very", "efficiently", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "digital motion processor"}, {"tokens": ["We", "also", "discussed", "solutions", "to", "reduce", "complexity", ",", "making", "PNN", "efficient", "and", "scalable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["At", "the", "BS", ",", "the", "number", "of", "RF", "chains", "is", ",", "which", "is", "equal", "to", "the", "number", "of", "users", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["M.", "Merhnoush", ",", "S.", "Roy", ",", "V.", "Sathya", ",", "and", "M.", "Ghosh", ",", "\"", "On", "the", "Fairness", "of", "Wi", "-", "Fi", "and", "LTE", "-", "LAA", "Coexistence", "\"", ",", "in", "IEEE", "Transactions", "on", "Cognitive", "Communications", "and", "Networking", ",", "Volume", "4", ",", "August", "2018", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Coref", ",", "WMD", "and", "FS", "denotes", "coreference", "system", ",", "word", "mover", "'s", "distance", "and", "frame", "semantics", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "frame semantic"}, {"tokens": ["Independent", "component", "analysis", "(", "fast", "ICA", ")", "was", "applied", "to", "remove", "ocular", "artifacts", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["This", "is", "because", "the", "PSO", "algorithm", "is", "designed", "for", "the", "case", "in", "which", "the", "locations", "of", "indoor", "users", "are", "uniformly", "distributed", "in", "each", "floor", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["This", "was", "caused", "by", "the", "fact", "that", "CDA", "'s", "name", "was", "presented", "unabbreviated", ":", "Christen", "Democratisch", "Appel", ",", "which", "was", "the", "only", "party", "with", "a", "special", "character", "(", "e", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "christen democratisch appel"}, {"tokens": ["Here", ",", "to", "plot", "the", "RDM", "of", "each", "view", "angle", ",", "first", ",", "the", "images", "of", "all", "input", "instances", "which", "are", "taken", "in", "that", "view", "are", "picked", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "representational dissimilarity matrix"}, {"tokens": ["The", "proposed", "method", "tunes", "the", "two", "gains", "of", "STA", "on", "line", "simultaneously", "such", "that", "a", "second", "ordersliding", "mode", "can", "take", "place", "with", "small", "rectifying", "gains", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["For", "example", ",", "the", "incremental", "DT", "reveals", "limited", "variance", "while", "the", "retrained", "DT", "is", "more", "variable", ",", "and", "the", "deviation", "is", "higher", "on", "the", "highly", "fluctuated", "S", "-", "RUBiS."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["Advantages", "Compared", "to", "General", "Displacement", "-", "Based", "SchemesThe", "proposed", "method", "is", "advantageous", "compared", "to", "both", "displacement", "-", "based", "POD", "methods", "and", "the", "classical", "FEM", "for", "the", "following", "reasons", ":", "No", "gradients", "need", "to", "be", "computed", "from", "displacement", "fields", ",", "which", "displacement", "-", "based", "schemes", "always", "require", "prior", "to", "the", "evaluation", "of", "the", "material", "law", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["This", "approach", "must", "cover", "all", "needs", "of", "current", "QA", "systems", "and", "be", "abstracted", "from", "implementation", "details", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["A", "first", "work", "is", "presented", "in", ",", "where", "the", "authors", "evaluate", "the", "impact", "of", "the", "finite", "buffer", "size", "with", "random", "arrivals", "at", "the", "AP", "in", "a", "donwlink", "MU", "-", "MIMO", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Online", "ModelingThis", "section", "elaborates", "on", "how", "the", "proposed", "DDE", "-", "MGM", "models", "and", "classifies", "the", "time", "series", "both", "in", "an", "online", "manner", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["DiscussionThe", "results", "of", "the", "long", "-", "term", "in", "-", "home", "deployment", "provide", "several", "insights", "for", "personalization", "in", "SAR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "line", "of", "work", "on", "Open", "IE", "begins", "with", "TextRunner", ",", "a", "self", "-", "supervised", "learning", "approach", "which", "uses", "a", "Naive", "Bayes", "classifier", "to", "train", "a", "model", "of", "relations", "over", "examples", "of", "extraction", "tuples", "that", "are", "heuristically", "generated", "from", "sentences", "in", "the", "Penn", "Treebank", "using", "unlexicalized", "POS", "and", "NP", "chunk", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "noun phrase"}, {"tokens": ["CSMD_TS", "fig", ":", "heartCMED", "-", "TS", "subfigure", "subfigure[b]0.2455", "results", "/", "cascade", "/"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Inc", "&", "&", "&", "&", "&", "&", "OMv", "&", "Theorem", "Thm", ":", "SensitivityD", "(", "reachability", ",", "&", "&", "&", "&", "&", "&", "&", "&", "4", "-", "9", "BPMatch", ",", "SC", ")", "&", "&", "&", "&", "&", "&", "&", "3SUM", "&", "kopelowitz2016higher", "-sh", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strongly connected"}, {"tokens": ["We", "compare", "the", "performance", "of", "MP", "and", "LASSO", "based", "hypothesis", "testing", "algorithms", "on", "large", "values", "of", "and", "which", "is", "the", "computational", "challenging", "case", "for", "LT", "in", "Figs", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "message passing"}, {"tokens": ["To", "address", "the", "impact", "of", "the", "removed", "images", "the", "same", "evaluation", "procedure", "was", "carried", "for", "the", "whole", "Vysis", "subset", ",", "in", "this", "test", "the", "network", "achieved", "a", "CCR", "of", "83.91", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["Specifically", ",", "the", "joint", "density", "of", "and", "iswhere", "is", "given", "by", "eqn.graph_y_micro", ",", "and", "the", "model", "is", "termed", "the", "nonparametric", "weighted", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Moreover", ",", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "provides", "higher", "EE", "than", "other", "schemes", "due", "to", "higher", "SC", "can", "be", "achieved", "by", "different", "OAM", "mode", "based", "transmission", "from", "BS", "to", "the", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["To", "compromise", "the", "confidentiality", "of", "data", ",", "a", "malicious", "user", "can", "set", "up", "a", "rogue", "base", "-", "station", "or", "AP", "(", "e.g.", ",", "an", "AP", "installed", "without", "the", "authorization", "of", "the", "system", "administrators", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "TI", "strategy", "basically", "pre", "-", "inserts", "some", "patterns", "as", "candidates", "to", "raise", "the", "initial", "threshold", "before", "starting", "the", "mining", "process", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "threshold initialization"}, {"tokens": [",", "\"", "Study", "on", "LTE", "Device", "to", "Device", "Proximity", "Services", "(", "Release", "12", ")", ",", "\"", "v.1.2.0", ",", "February", "2014", ",", "available", "at", "http://www.3gpp.org", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "channel", "is", "assumed", "to", "be", "error", "-", "free", "and", "independently", "fade", "from", "frame", "to", "frame", ",", "which", "creates", "independent", "channels", "from", "the", "AP", "to", "STAs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "access part"}, {"tokens": ["The", "UE", "device", "has", "one", "WiFi", "interfaces", "(", "like", "all", "mobiles", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "this", "paper", ",", "we", "propose", "an", "Evolutionary", "Cost", "-", "Sensitive", "Deep", "Belief", "Network", "(", "ECS", "-", "DBN", ")", "by", "incorporating", "cost", "-", "sensitive", "function", "directly", "into", "its", "classification", "paradigm", "with", "the", "misclassification", "costs", "being", "optimized", "through", "adaptive", "differential", "evolution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["These", "results", "confirm", "our", "earlier", "observations", "from", "synthetic", "and", "CD", "patient", "datasets", "about", ":", "1", ")", "the", "superior", "performance", "of", ";", "2", ")", "effectiveness", "of", "SSL", "in", "predicting", "missing", "annotation", "information", ";", "3", ")", "inferior", "performance", "of", "LMStaple", "due", "to", "predicting", "sensitivity", "and", "specificity", "parameters", "from", "annotations", "without", "considering", "their", "overall", "consistency", ",", "and", "using", "EM", ";", "and", "4", ")", "contribution", "of", "our", "SC", "score", "and", "graph", "cuts", "in", "obtaining", "better", "consensus", "annotations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "crohn 's disease"}, {"tokens": ["In", "this", "case", ",", "the", "distribution", "corresponds", "to", "a", "component", "of", "the", "GMM", "(", ")", ",", "so", "the", "distance", "is", "defined", "as", ":", "equation", "(", "x_i,_k", ")", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Objectives", "and", "ContributionsThe", "main", "goals", "of", "this", "thesis", "are", "to", "define", "a", "method", "which", "enables", "the", "characterization", "of", "the", "motion", "intensity", "in", "arbitrary", "video", "sequences", "and", "also", "to", "design", ",", "implement", ",", "and", "assess", "several", "FEC", "-", "based", "mechanisms", "with", "content", "-", "awareness", "to", "enhance", "the", "quality", "of", "video", "delivery", "from", "the", "point", "-", "of", "-", "view", "of", "end", "-", "users", "over", "diverse", "types", "of", "wireless", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Below", "we", "recall", "the", "KK13", "OT", "extension", "protocol", "prior", "to", "presenting", "our", "attack", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Adopted", "Nomenclature", "for", "Relay", "Selection", "Schemes", "under", "StudyWhile", "the", "literature", "on", "PHY", "layer", "security", "is", "abundant", ",", "the", "study", "of", "security", "issue", "for", "cooperative", "IR", "networks", "affected", "by", "eavesdropper", "generated", "AN", "has", "not", "been", "previously", "addressed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["[", "CC", ",", "1000", "runs", ",", "24", "clust", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "connected caveman"}, {"tokens": ["Simulation", "results", "showed", "that", "the", "proposed", "UE", "selection", "can", "achieve", "near", "-", "optimal", "performance", "compared", "to", "the", "optimal", "exhaustive", "UE", "search", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["BA", "provides", "improvements", "to", "the", "HS", "framework", "by", "introducing", "robust", "quadratic", "error", "formulation", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "black and anandan"}, {"tokens": ["This", "application", "provides", "a", "generic", "support", "for", "the", "operational", "deployment", "of", "trained", "deep", "nets", "on", "RS", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "remote sensing"}, {"tokens": ["The", "resulting", "AIR", "is", "approximately", "bit/4D", "-", "sym", ",", "i.e.", ",", "we", "are", "targeting", "a", "FEC", "rate", "of", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "achievable information rates"}, {"tokens": ["Our", "baseline", "model", ",", "pre", "-", "trained", "just", "using", "a", "synthetically", "produced", "data", ",", "already", "achieves", "a", "26.05", "CER", "on", "the", "GW", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["For", "example", ",", "if", "one", "SEM", "image", "contains", "martensitic", "and", "ferritic", "constituents", ",", "a", "group", "of", "material", "science", "experts", "have", "assigned", "martensite", "and", "ferrite", "labels", "to", "the", "\"", "objects", "\"", "or", "rather", "grains", "which", "the", "mentioned", "sample", "contains", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["The", "core", "of", "idea", "of", "PSO", "is", "the", "search", "directed", "on", "the", "basis", "of", "information", "gained", "through", "'", "self", "-", "learning", "'", "and", "'", "social", "-", "learning", "'", "from", "peers", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Moreover", ",", "compared", "to", "standalone", "B", "-", "OCC", ",", "NG", "reduces", "program", "memory", "footprint", "for", "the", "EEG", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "one class classifier"}, {"tokens": ["the", "superimposed", "AN", "is", "unnecessary", "in", "the", "low", "SNR", "regime", "because", "the", "channel", "noise", "is", "large", "enough", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["We", "conclude", "that", "the", "RB", "is", "a", "collection", "of", "orthonormal", "-like", "quantities", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["For", "DBP", "checking", ",", "the", "same", "proof", "as", "Theorem", "shows", "that", "it", "is", "NP", "-", "complete", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["Due", "to", "utilizing", "the", "separate", "time", "slot", "for", "each", "transmission", "except", "OAM", "based", "transmission", ",", "the", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "provides", "comparatively", "lower", "SC", "w.r.t", "than", "the", "proposed", "scheme", "which", "is", "illustrated", "in", "Figure", "7", "as", "before", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Without", "having", "any", "prior", "knowledge", "involved", ",", "it", "is", "extremely", "hard", "to", "estimate", "the", "PAF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "plenacoustic function"}, {"tokens": ["We", "design", "a", "new", "encoding", "matrix", "for", "systematic", "Exact", "-", "MBR", "code", ",", "and", "the", "partial", "downloading", "scheme", "are", "also", "proposed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["We", "build", "upon", "the", "OT", "extension", "code", "provided", "by", "the", "Encrypto", "group", "on", "github", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["We", "also", "note", "that", "the", "ground", "truth", "images", "from", "the", "DeepFashion", "dataset", "have", "an", "average", "IS", "of", "3.9", ",", "which", "indicates", "low", "degree", "of", "realism", "of", "this", "data", "according", "to", "the", "IS", "metric", "(", "for", "comparison", ",", "IS", "of", "CIFAR-10", "is", "11.2", "with", "best", "image", "generation", "methods", "achieving", "IS", "of", "8.8", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["Comparing", "to", "the", "conventional", "first", "oder", "sliding", "mode", "control", ",", "the", "adaptive", "STA", "can", "achieve", "a", "second", "order", "accuracy", ",", "i.e.", ",", ",", "with", "the", "chattering", "being", "greatly", "attenuated", "due", "to", "the", "absolute", "continuity", "of", "STA", "and", "adaptively", "attenuated", "gains", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["The", "adjacency", "matrices", "showing", "the", "clusterings", "found", "by", "the", "SCF", "(", "left", ")", "and", "SBM", "(", "middle", ")", "on", "the", "''", "network", "(", "Figure", "FIGlayout2x2", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "proposed", "mechanism", "enhances", "the", "work", "described", "in", "Sections", "sec", ":", "uavFEC", "and", "sec", ":", "MINT", "-", "FEC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "forward error correction"}, {"tokens": ["Still", ",", "whether", "the", "well", "-", "known", "natural", "images", "pre", "-", "trained", "models", "popular", "in", "transferring", "to", "other", "remote", "sensing", "tasks", "are", "transferable", "to", "SAR", "targets", "remains", "to", "be", "explored", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["It", "is", "expected", "from", "the", "information", "retrieval", "systems", "(", "either", "keyword", "-", "based", "search", "engines", "or", "QA", "systems", ")", "to", "identify", "mis-", ",", "dis-", ",", "mal-", "information", "from", "reliable", "and", "trustworthy", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["However", ",", "such", "measures", "are", "unsuitable", "for", "reduction", "by", "means", "of", "the", "proposed", "RB", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "reduced basis"}, {"tokens": ["We", "propose", "to", "combine", "multi", "-", "task", "and", "active", "learning", "methods", "into", "a", "single", "framework", "to", "achieve", "competitive", "SRL", "performance", "with", "less", "training", "data", ",", "and", "to", "leverage", "a", "semantically", "related", "task", "for", "SRL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "semantic role labeling"}, {"tokens": ["A", "consequence", "of", "this", "is", "that", "ICA", "will", "fail", "to", "unmix", "mixed", "independent", ",", "ergodic", "time", "series", "with", "Gaussian", "marginal", "distributions", ":", "each", "latent", "signal", "will", "have", "a", "kurtosis", "of", "zero", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["It", "is", "assumed", "that", "the", "BS", "and", "all", "users", "are", "equipped", "with", "one", "single", "antenna", "each", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "concluded", "that", "RS", "performs", "better", "than", "repetitive", "transmission", "when", "CSI", "for", "RS", "is", "perfect", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["CF", "-", "based", "RS", "."], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Black", "-", "DROPS", "and", "Black", "-", "DROPS", "with", "GP", "-", "MI", "(", "see", "Section", ")", "can", "greatly", "reduce", "the", "interaction", "time", "and", "take", "advantage", "of", "multi", "-", "core", "architectures", ",", "but", "they", "still", "require", "a", "considerable", "amount", "of", "computation", "time", "(", "e.g.", ",", "Black", "-", "DROPS", "with", "GP", "-", "MI", "required", "24", "hours", "on", "a", "modern", "16-core", "computer", "for", "26", "episodes", "of", "the", "pendubot", "task", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "underlying", "idea", "in", "GP", "regression", "is", "that", "the", "correlation", "function", "introduces", "dependences", "between", "function", "values", "at", "different", "inputs", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["To", "this", "purpose", "SSTL", "monitoring", "algorithms", "are", "combined", "with", "statistical", "model", "checking", "techniques", ",", "following", "up", "on", "earlier", "works", "on", "such", "combinations", "with", "STL", "TCS2015", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "signal temporal logic"}, {"tokens": ["[", "Depiction", "of", "the", "clusterization", "behavior", "of", "the", "bottleneck", "variable", "for", "the", "power", "IB", "Lagrangian", "with", ".]Depiction", "of", "the", "clusterization", "behaviorof", "the", "bottleneck", "variable", "for", "the", "power", "IB", "Lagrangian", "in", "the", "MNIST", "dataset", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["However", ",", "when", "we", "report", "the", "distortion", "or", "coverage", "area", "for", "the", "Lloyd", "algorithm", ",", "we", "report", "that", "of", "the", "largest", "connected", "subgraph", "which", "may", "not", "be", "connected", "to", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["This", "is", "because", "the", "changes", "in", "the", "SP", "representation", "degrade", "the", "sequences", "learned", "by", "the", "TP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "temporal pooler"}, {"tokens": ["Dec", "&", "&", "&", "&", "&", "&", "OMv", "&", "Theorem", "Thm", ":", "SensitivityD", "(", "reachability", ",", "&", "&", "&", "&", "&", "&", "&", "&", "4", "-", "9", "BPMatch", ",", "SC", ")", "&", "&", "&", "&", "&", "&", "&", "3SUM", "&", "kopelowitz2016higher", "-sh", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strongly connected"}, {"tokens": ["focused", "on", "the", "beamforming", "algorithm", "to", "maximize", "the", "sum", "-", "rate", "for", "arbitrary", "UE", "-", "centric", "clustering", "C", "-", "RAN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Figure", "shows", "that", "FP", "rate", "decreases", "and", "TP", "rate", "increases", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["The", "difference", "between", "OR", "and", "SC", "is", "that", "in", "OR", ",", "the", "best", "path", "is", "chosen", "prior", "to", "the", "sensor", "transmission", "and", "only", "the", "best", "path", "is", "activated", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "selection combining"}, {"tokens": ["ContributionsIn", "this", "paper", ",", "a", "drone", "-", "based", "communication", "problem", "is", "addressed", "from", "a", "new", "perspective", "by", "investigating", "the", "placement", "of", "multiple", "EH", "DBSs", "in", "order", "to", "support", "typical", "heterogeneous", "networks", "(", "HetNets", ")", "composed", "of", "a", "single", "macrocell", "BS", "and", "multiple", "ground", "micro", "cell", "BSs", "(", "MBSs", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "this", "step", ",", "user", "needs", "to", "upload", "the", "local", "FL", "parameters", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["First", "of", "all", ",", "all", "the", "reasons", "for", "including", "logic", "in", "the", "CS", "curricula", "still", "hold", "in", "the", "IS", "domain", ":", "it", "is", "widely", "acknowledged", "that", "studying", "logic", "directly", "contributes", "to", "software", "development", "skills", ",", "confirmed", "recently", "also", "by", "empirical", "studies", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["Character", "error", "rate", "(", "CER", ")", "has", "sometimes", "been", "suggested", "as", "a", "complement", "to", "address", "this", "issue", ",", "but", "I", "believe", "this", "is", "not", "very", "insightful", ":", "For", "any", "normalization", "system", "that", "achieves", "a", "reasonably", "high", "word", "accuracy", ",", "CER", "will", "highly", "correlate", "with", "accuracy", "simply", "because", "CER", "equals", "zero", "for", "any", "word", "that", "is", "accurately", "normalized.(When", "comparing", "word", "accuracy", "scores", "in", "Table", "with", "the", "same", "configurations", "evaluated", "using", "CER", ",", "they", "correlate", "with", "Pearson", "'s", ".", ")"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["Performance", "Curves", "for", "GA", ",", "DE", "and", "BOA]Optimal", "Objective", "Function", "vs.", "Number", "of", "Generations", "Performance", "Curves", "for", "GA", ",", "DE", "and", "BOA", "Comparing", "the", "results", "of", "BOA", "algorithm", "against", "GA", "and", "DE"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "differential evolution"}, {"tokens": ["To", "circumvent", "the", "problem", "that", "the", "likelihood", "is", "not", "conjugate", "to", "the", "GP", "prior", ",", "proposed", "a", "Metropolis", "-", "Hastings", "MCMC", "algorithm", "for", "this", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Equation", "describes", "probabilistic", "CER", "method", "."], "acronym_pos": [0, 0, 0, 1, 0, 0], "long_form": "character error rate"}, {"tokens": ["In", "Con", "-", "TS", "-", "RTP", "with", "Constraint", "Set", "A", ",", "the", "aggregator", "'s", "daily", "objective", "and", "constraints", "are", "dependent", "on", "the", "sampled", "parameter", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["They", "aim", "to", "optimize", "the", "TS", "and", "PS", "ratios", "in", "order", "to", "maximize", "the", "throughput", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["prc^ECwhere", "the", "first", "two", "terms", "denote", "the", "UP", "processing", "delay", "at", "CC", "and", "EC", "and", "the", "last", "two", "terms", "show", "that", "of", "CP", "at", "CC", "and", "EC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "central cloud"}, {"tokens": [",", "GBM", "outperformed", "all", "other", "algorithms", "across", "all", "datasets", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["In", "similar", "way", ",", "the", "most", "common", "100", "and", "1,000", "lemmas", "account", "for", "50", "and", "respectively", "75", "of", "all", "words", "used", "in", "OEC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "oxford english corpus"}, {"tokens": ["Since", "the", "ICAPC", "algorithm", "assumed", "perfect", "CSI", "and", "aimed", "to", "maximize", "the", "sum", "SE", "of", "DUs", "based", "on", "instantaneous", "CSI", ",", "the", "ICAPC", "algorithm", "outperforms", "the", "proposed", "scheme", "slightly", "in", "terms", "of", "system", "throughput", "when", "OT", "is", "adopted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "orthogonal training"}, {"tokens": ["Afterwards", ",", "the", "FEC", "codes", "are", "optimised", "with", "different", "parameters", "for", "different", "situations", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Again", ",", "our", "model", "has", "good", "results", "in", "the", "GBM", "simulation", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "geometric brownian motion"}, {"tokens": ["First", "row", "shows", "the", "HR", "images", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0], "long_form": "high - resolution"}, {"tokens": ["We", "parameterize", "the", "digital", "low-", "and", "high", "-", "pass", "filters", "as", "windowed", "-", "sinc", "filters", "and", "predict", "their", "cut", "-", "off", "frequency", "(", "i.e.", ",", "MVF", ")", "from", "the", "input", "acoustic", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["itemize", "We", "devise", "the", "GPA", "algorithm", "as", "an", "effective", "technique", "for", "the", "initialization", "of", "network", "embedding", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["As", "far", "as", "BC", "\u2019s", "applicability", "to", "IoT", "is", "concerned", ",", "it", "records", "the", "transaction", "histories", "of", "smart", "devices", "in", "an", "immutable", "manner", ",", "thus", "eliminating", "the", "need", "for", "a", "central", "authority", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["As", "the", "number", "of", "evaluated", "solutions", "increases", ",", "more", "nodes", "are", "inserted", "into", "the", "BSP", "tree", "as", "shown", "in", "Fig", ".", ";"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["In", "addition", ",", "the", "figures", "show", "that", "the", "macrocell", "UE", "density", "strongly", "influences", "the", "outage", "probability", "of", "both", "macrocell", "and", "femtocell", "UEs", ",", "while", "the", "femtocell", "density", "only", "has", "a", "slight", "influence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["However", ",", "if", "the", "sparse", "approximation", "requires", "a", "higher", "amount", "of", "inducing", "-", "inputs", "at", "some", "iteration", "of", "the", "learning", "process", "(", "e.g.", "the", "input", "domain", "increases", ")", ",", "the", "entire", "GP", "would", "have", "to", "be", "re", "-", "defined", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["On", "the", "other", "hand", ",", "SLNR", "method", "aims", "to", "minimize", "the", "confidential", "signal", "leakage", "to", "other", "users", "including", "all", "eavesdroppers", "and", "meanwhile", "to", "maximize", "AN", "power", "leakage", "to", "all", "eavesdroppers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Electric", "Vehicle", "Charging", "in", "Smart", "Grids", ":", "PSO", "can", "be", "applied", "to", "charging", "optimization", "of", "electric", "vehicle", "(", "charging", "plan", "of", "each", "vehicle", "while", "satisfying", "the", "requirements", "of", "the", "individual", "vehicle", "owners", "without", "distribution", "network", "congestion", ")", "and", "its", "coordination", "to", "minimize", "power", "losses", "and", "improve", "the", "voltage", "profile", "of", "the", "smart", "grid", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["The", "optimal", "variational", "form", "for", "the", "posterior", "is", "a", "GPgiven", "by", "where", "results", "in", "the", "Gaussian", "log", "-", "likelihoodwithFor", "general", "GP", "priors", ",", "this", "free", "form", "optimum", "is", "intractable", "by", "the", "fact", "that", "the", "likelihooddepends", "on", "at", "infinitely", "many", "points", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "results", "for", "the", "AA", "and", "physics", "group", "of", "journals", "differ", "considerably", "from", "the", "geosciences", "group", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "astronomy and astrophysics"}, {"tokens": ["indicates", "rank", "of", "AP", "of", "-th", "class", "sorted", "in", "a", "descending", "order", ",", "e.g", ",", "if", "-th", "class", "has", "the", "lowest", "AP", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "average precision"}, {"tokens": ["With", "the", "recent", "availability", "of", "consumer", "-", "grade", "4", "K", "UHD", "displays", ",", "it", "would", "be", "valuable", "to", "repeat", "the", "experiment", "in", "an", "environment", "that", "might", "represent", "an", "effective", "combination", "of", "the", "SDD", "and", "TDW", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Based", "on", "the", "fractal", "characteristics", "of", "cellular", "coverage", "and", "the", "anisotropic", "path", "loss", "model", "in", ",", "the", "average", "achievable", "rate", "and", "network", "energy", "efficiency", "adopting", "SBS", "cooperation", "strategies", "are", "derived", "to", "investigate", "the", "SBS", "cooperation", "performance", "in", "fractal", "small", "-", "cell", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["The", "average", "coverage", "error", "(", "ACE", ")", "is", "the", "coverage", "dependent", "component", "in", "C", "Wan", "'s", "cost", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average coverage error"}, {"tokens": ["[", "CC", ",", "100", "runs", ",", "12", "clust", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "connected caveman"}, {"tokens": ["The", "second", "result", "of", "this", "paper", "presents", "a", "new", "form", "of", "coding", "matrix", "for", "product", "-", "matrix", "Exact", "-", "MBR", "codes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["CF", "takes", "into", "account", "three", "factors-", "language", "(", "LF", ")", ",", "switching", "(", "SF", ")", "and", "mix", "(", "MF", ")", "factors", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "complexity factor"}, {"tokens": ["NP", "bun", "'", "tree'PIr"], "acronym_pos": [1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Then", "for", "every", "latent", "dimension", ",", "the", "true", "GP", "predictive", "distribution", "can", "be", "approximated", "by", "using", "the", "set", "inducing", "inputs", "and", "outputs", "as", "below", ",", "with", "notation", "omitted", ",", "where", "the", "covariance", "matrix", "with", "entries", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["ConclusionWe", "propose", "a", "multi", "-", "passage", "BERT", "model", "for", "open", "-", "domain", "QA", "to", "globally", "normalize", "answer", "scores", "across", "mutiple", "passages", "corresponding", "to", "the", "same", "question", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["&", "ECS", "-", "DBN", "&", "26.64", "1.50", "&", "18.23", "ADASYN", "-", "DBN", "&", "22.97", "3.95", "&", "14.56", "SMOTE", "-", "SVM", "-", "DBN", "&", "24.03", "2.33", "&", "15.62", "SMOTE", "-", "borderline2-DBN", "&", "24.53", "2.14", "&", "16.12", "SMOTE", "-", "borderline1-DBN", "&", "25.52", "2.59", "&", "17.11", "SMOTE", "-", "DBN", "&", "25.81", "3.10", "&", "17.40", "DBN", "&", "8.41", "1.28", "&", "-", "Statistical"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "coefficients", ",", "means", ",", "and", "covariances", "of", "the", "GMM", "modes", "(", ")", "of", "the", "measurement", "noise", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["In", "this", "section", ",", "we", "will", "look", "at", "models", "that", "do", "so", ",", "by", "incoporating", "a", "soft", "clustering", "approach", "in", "an", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "sequential monte carlo"}, {"tokens": ["From", "the", "representation", "it", "can", "be", "easily", "seen", "that", "the", "paddle", "moves", "just", "in", "one", "axis", "(", "linear", "structure", "discovered", "by", "the", "TP", ")", ",", "while", "the", "ball", "moves", "through", "the", "entire", "2D", "space", "(", "grid", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["In", "our", "adoption", "of", "MIFE", ",", "we", "add", "a", "public", "key", "distribution", "algorithm", "run", "by", "the", "TPA", "as", "a", "beneficial", "supplement", "of", "the", "original", "MIFE", "scheme", "proposed", "in", "to", "make", "it", "applicable", "to", "our", "FL", "framework", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["explored", "prior", "knowledge", "in", "the", "cost", "matrix", "and", "applied", "OT", "loss", "as", "a", "soft", "penalty", "for", "bridging", "the", "gap", "between", "target", "and", "source", "predictions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Vicrkey", "auctionTo", "maximize", "the", "secrecy", "capacity", "and", "to", "guarantee", "the", "truthfulness", "of", "the", "FJ", "power", "allocation", ",", "the", "Vickrey", "auction", "can", "be", "used", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["Looking", "at", "the", "networks", "in", "Figure", ",", "we", "see", "both", "AP", "and", "PBS", "as", "central", "nodes", "in", "the", "mainstream", "media", "communities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "associated press"}, {"tokens": ["Another", "noteworthy", "point", "is", ",", "due", "to", "the", "design", "of", "DCNN", "structure", ",", "features", "from", "deeper", "layers", "carry", "more", "semantics", "while", "the", "shallower", "layers", "include", "more", "spatial", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["CC", "-", "PEV", "and", "SPAM", "are", "used", "by", "DyFA", "that", "decreased", "the", "feature", "dimension", "properly", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subtractive pixel adjacency matrix"}, {"tokens": ["This", "paper", "is", "concluded", "in", "Section", "V.", "Related", "Works", "Different", "recent", "research", "has", "been", "done", "to", "improve", "the", "spectral", "efficiency", "of", "NOMA", "users", "and", "SC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "sum capacities"}, {"tokens": ["Table", "shows", "the", "average", "integrality", "gaps", "(", "given", "the", "best", "known", "upper", "bound", ",", "from", "PSPLIB", "and", "MISTA", "websites", ",", "and", "an", "obtained", "dual", "bound", ",", "the", "integrality", "gap", "is", "computed", "as", "follows", ":", ",", ")", "and", "the", "average", "computing", "times", "in", "seconds", "that", "have", "been", "obtained", "with", "the", "original", "LP", "relaxations", "and", "the", "strengthened", "LR", "for", "the", "instances", "from", "PSPLIB", "and", "MISTA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lp relaxation"}, {"tokens": ["System", "ModelWe", "consider", "a", "single", "cell", "having", "one", "BS", "and", "MSs", "equipped", "with", "full", "-", "duplex", "tranceivers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Select", "the", "top", "DSA", "occupations", "."], "acronym_pos": [0, 0, 0, 1, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["We", "also", "abbreviate", "the", "message", "passing", "and", "LASSO", "based", "hypothesis", "testing", "method", "to", "MP", "and", "LASSO", "in", "the", "figures", "below", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "message passing"}, {"tokens": ["The", "main", "idea", "behind", "GDP", "is", "that", "it", "allows", "us", "to", "incorporate", "the", "randomness", "over", "the", "data", "generating", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["The", "National", "Audit", "Office", "criticise", "the", "DSN", "for", "the", "antiquated", "nature", "of", "its", "logistic", "systems", ",", "noting", "that", "two", "of", "its", "main", "inventory", "IS", "began", "service", "in", "the", "1980s", "NationalAuditOffice2011", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["While", "a", "number", "of", "potential", "solutions", "had", "been", "proposed", "previously", ",", "the", "FA", "method", "generated", "substantial", "interest", "because", "it", "required", "no", "assumptions", "on", "the", "structure", "of", "the", "feedback", "weights", "used", "to", "convey", "error", "signals", ",", "instead", "taking", "them", "to", "be", "fixed", "and", "random", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["eq", ":", "c9equationLet", "us", "notice", "that", "in", "each", "output", "neuron", ",", "there", "is", "an", "error", "due", "to", "computation", ",", "i.e.during", "the", "computation", "of", "the", "ANN", "output", ",", "the", "neuron", "instead", "of", "performing", ",", "it", "performs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Figure", "plots", "the", "predicted", "MVF", "trajectory", "and", "the", "natural", "waveform", "spectrogram", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["The", "problems", "outlined", "above", "are", "well", "known", "in", "SRL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "statistical relational learning"}, {"tokens": ["Moreover", ",", "further", "knee", "extension", "is", "essential", "to", "enable", "forward", "propulsion", "in", "late", "MS", "and", "TS", ",", "which", "may", "be", "insufficient", "in", "case", "of", "a", "decreased", "range", "of", "motion", "in", "the", "knee", "joint", "and/or", "a", "lack", "of", "muscle", "strength", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "terminal stance"}, {"tokens": ["using", "FCA", "."], "acronym_pos": [0, 1, 0], "long_form": "formal concept analysis"}, {"tokens": ["In", "this", "work", ",", "we", "incorporate", "the", "OT", "unit", "between", "feature", "map", "and", ",", "which", "serve", "as", "inputs", "before", "the", "RoI", "-", "pooling", "operation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["BackgroundSocially", "Assistive", "Robotics", "(", "SAR", ")", "lies", "at", "the", "intersection", "of", "socially", "interactive", "robotics", "and", "assistive", "robotics", ",", "and", "focuses", "on", "developing", "intelligent", ",", "socially", "interactive", "robots", "that", "provide", "assistance", "through", "social", "interaction", ",", "with", "measurable", "outcomes", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Table", "shows", "our", "model", "obtained", "a", "CER", "of", "2.22", "using", "an", "ensemble", "of", "three", "models", ",", "each", "with", "dictionary", "correction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["Overall", ",", "we", "find", "that", "CNet", "-", "NIC", "which", "combines", "the", "background", "knowledge", "(", "ConceptNet", "derived", "terms", ")", "related", "to", "the", "detected", "objects", "and", "the", "scene", "in", "generating", "image", "captions", "outperforms", "all", "other", "methods", "that", "do", "not", "make", "use", "of", "such", "background", "knowledge", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural image caption"}, {"tokens": ["The", "SAR", "intervention", "was", "deployed", "in", "the", "home", "of", "each", "participating", "family", "for", "at", "least", "30", "days", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Advancement", "in", "FA", "tools", "and", "algorithm", "based", "attacks", "do", "not", "leave", "scope", "to", "consider", "any", "specific", "protection", "scheme", "as", "the", "ultimate", "preserver", "of", "the", "confidentiality", "and", "integrity", "of", "chip", "design", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["In", "what", "follows", ",", "we", "focus", "on", "the", "PA", "problem", "by", "assuming", "that", "the", "beamforming", "scheme", "is", "given", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["Execute", "-", "order", ":", "Previous", "BC", "technologies", "relies", "on", "order", "-", "execute", "architecture", "where", "mining", "of", "transactions", "degrade", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["Heatmaps", "predicted", "for", "unlabelled", "LR", "images", "are", "also", "included", "in", "the", "inputs", "of", "the", "discriminators", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["In", "this", "paper", ",", "a", "mobile", "based", "dengue", "fever", "monitoring", "and", "tracking", "application", "is", "proposed", "that", "monitors", "the", "spread", "of", "dengue", "via", "global", "positioning", "system", "(", "GPS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Taguchi", "'s", "method", "is", "one", "of", "the", "DOE", "techniques", "that", "was", "developed", "in", "1979", "to", "improve", "the", "quality", "of", "goods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "design of experiment"}, {"tokens": ["For", "DC", "-", "OPF", "classification", ",", "besides", "Ipopt", ",", "we", "also", "computed", "the", "maximal", "gain", "using", "two", "other", "(", "convex", ")", "solvers", ":", "ECOS", "and", "OSQP", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["The", "context", "consists", "of", "three", "parts", ":", "1", ")", "the", "output", "of", "the", "SP", "(", "i.e.", "the", "cluster", "representation", ")", ",", "2", ")", "the", "next", "cluster", "probabilities", "from", "the", "TP", ",", "and", "3", ")", "the", "expected", "value", "of", "any", "rewards", "that", "the", "architecture", "will", "receive", "if", "in", "the", "next", "step", ",", "the", "input", "falls", "into", "a", "particular", "cluster", "(", "interpreted", "as", "goals)(In", "f", ":", "expert", ",", "the", "goals", "are", "shown", "as", "separate", "from", "the", "context", "for", "clarity", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["The", "output", "from", "the", "GP", "becomes", "our", "temporal", "prediction", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "monitoring", "procedures", "spatially", "extend", "the", "property", "monitors", "introduced", "inMaler2004", "for", "the", "Boolean", "and", "in", "Donze2013", "for", "the", "quantitative", "semantics", "of", "STL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "signal temporal logic"}, {"tokens": ["To", "decode", "all", "messages", "from", "the", "received", "message", ",", "the", "BS", "will", "use", "SIC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["SEM", "and", "CEM", "methods", "captures", "similar", "ratio", "of", "changes", "in", "ECG", "peaks", "with", "different", "accuracies", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "squared entropy measurement"}, {"tokens": ["This", "meta", "-", "classifier", "has", "an", "accuracy", "of", "96.2", "with", "an", "area", "under", "the", "ROC", "curve", "of", "0.988", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Design", "choices", "in", "OT", "divergence", "."], "acronym_pos": [0, 0, 0, 1, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Among", "PSO", "variants", ",", "ErFS", "and", "PSO-42", "performed", "very", "poorly", ",", "which", "was", "expected", "as", "these", "variants", "are", "slightly", "updated", "version", "of", "the", "continuous", "PSO", "and", "does", "not", "include", "any", "meaningful", "learning", "mechanism", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Segmentation", "results", "on", "two", "different", "2D", "stack", "cardiac", "MR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["Since", "the", "MR", "images", "can", "naturally", "differ", "in", "intensity", ",", "each", "image", "is", "normalized", "before", "the", "calculations", "by", "division", "of", "the", "standard", "deviation", "and", "subtraction", "of", "the", "mean", "value", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["We", "use", "the", "first", "100", "days", "to", "estimate", "some", "basic", "parameters", "in", "our", "experiments", "(", "e.g.", ",", "the", "CTR", "and", "the", "valuation", "of", "each", "ad", ")", "and", "to", "construct", "the", "training", "data", "with", "the", "simulation", "-", "based", "method", "by", "assuming", "the", "auction", "mechanism", "to", "be", "standard", "GSP", "(", "in", "the", "quality", "score", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized second price"}, {"tokens": ["In", "other", "words", ",", "accumulating", "all", "best", "coordinate", "steps", "for", "each", "point", "and", "performing", "the", "movement", "at", "the", "end", "of", "the", "th", "iteration", "(", "as", "GPS", "method", "formulation", "requires", ")", "produces", "the", "same", "result", "as", "taking", "each", "coordinate", "step", "individually", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["QA", "systems", "can", "be", "broadly", "categorized", "into", "three", "categoriesbernardi10from", ":"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "coarse", "-", "grained", "semantics", "of", "an", "AML", "model", ",", "where", "and", "denotes", "the", "sequence", "of", "send", "statements", "of", "the", "main", "block", ",", "is", "given", "by", "a", "labeled", "transition", "system", "such", "that", ":", "is", "the", "set", "of", "global", "states", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["where", "MSTAR", "classification", "task", "can", "build", "a", "bridge", "between", "unlabeled", "SAR", "image", "reconstruction", "and", "OpenSARShip", "recognition", "to", "improve", "the", "generality", "of", "features", "in", "layers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Table", "shows", "the", "SAD", "and", "RMSE", "performance", "of", "the", "methods", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["In", "terms", "of", "accuracy", "and", "F1-score", ",", "ECS", "-", "DBN", "can", "also", "provide", "comparable", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["We", "introduce", "the", "BN", "-", "SV", "-", "MR", "based", "sensitivity", "analysis", "to", "provide", "the", "comprehensive", "study", "over", "the", "impact", "of", "model", "risk", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "model risk"}, {"tokens": ["For", "instance", ",", "the", "usedscanning", "-", "window", "templates", "trained", "with", "linear", "SVMs", "and", "HOG", "features", "are", "verysensitive", "to", "noise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "histogram of gradients"}, {"tokens": ["After", "that", ",", "the", "articles", "of", "the", "norms", "are", "represented", "as", "TF", "-", "IDF", "vectors", "in", "a", "Vector", "Space", "Model", "(", "VSM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "vector space model"}, {"tokens": ["Figure", "E", "depicts", "the", "CM", "for", "the", "TFL1", "gene", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "canalizing map"}, {"tokens": ["In", "this", "proposal", "we", "are", "discussing", "mainly", "both", "the", "Tessellation", "Shader", "-", "TS", ",", "which", "allows", "to", "refine", "simpler", "meshes", "into", "finer", "ones", ",", "and", "the", "Fragment", "Shader", "-", "FS", ",", "which", "is", "used", "to", "apply", "lighting", ",", "color", "blending", ",", "process", "and", "render", "a", "fragment", ",", "for", "example", "a", "pixel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tessellation shader"}, {"tokens": ["In", "this", "paper", ",", "we", "study", "AA", "in", "historical", "texts", "using", "a", "new", "data", "set", "compiled", "from", "the", "Victorian", "literature", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["Using", "FEC", ",", "the", "transmitter", "adds", "redundant", "information", "to", "transmitted", "data", "packets", "which", "allows", "the", "receivers", "to", "detect", "and", "correct", "some", "of", "corrupted", "bits", "of", "the", "received", "packets", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Therefore", ",", "Narayan2017", "gathered", "a", "new", "dataset", ",", "WebSplit", ",", "which", "is", "the", "first", "TS", "corpus", "that", "explicitly", "addresses", "the", "task", "of", "sentence", "splitting", ",", "while", "abstracting", "away", "from", "deletion", "-", "based", "and", "lexical", "simplification", "operations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "target syntactic"}, {"tokens": ["Phl", "wlz", "/warz/", "NP", "gurz", "'", "mace", "'", "(", "cf", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["This", "can", "be", "explained", "by", "the", "fact", "that", "LR", "structure", "was", "designed", "to", "approximate", "each", "individual", "2D", "convolution", "filter", "at", "every", "input", "feature", "map", "and", "the", "resulting", "structure", "comes", "with", "a", "closed", "-", "form", "solution", "for", "the", "approximation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low rank"}, {"tokens": ["Those", "targets", "chips", "acquired", "at", "depression", "angle", "of", "17", "are", "usually", "used", "as", "the", "training", "data", ",", "15", "as", "the", "testing", "data", "to", "evaluate", "the", "SAR", "target", "recognition", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["This", "can", "be", "seen", "by", "the", "rapid", "drop", "in", "the", "SDD", "success", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["The", "total", "transmit", "signals", "of", "the", "BS", "can", "be", "expressed", "aswhere", "is", "the", "AN", "signal", "sent", "by", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["The", "same", "applies", "for", "QA", "systems", ",", "developing", "an", "open", "-", "domain", "QA", "is", "a", "challenge", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["To", "design", "the", "robust", "signal", "beamforming", "matrix", "and", "AN", "beamforming", "matrix", ",", "first", "the", "upper", "and", "lower", "bounds", "of", "the", "estimated", "eavesdropping", "channel", "related", "coefficient", "are", "derived", ",", "then", "the", "system", "sum", "secrecy", "rate", "maximization", "problem", "based", "on", "the", "derived", "upper", "and", "lower", "bounds", "is", "constructed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Further", ",", "both", "methods", "work", "better", "with", "linear", "ML", "models", "(", "SVM", ",", "LDA", ",", "LR", ")", "as", "opposed", "as", "non", "-", "linear", "ones", "(", "DT", ",", "RF", ",", "KNN", ")", ",", "especially", "with", "the", "artificial", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Constraint", "(", "a", ")", "indicates", "that", "the", "execution", "time", "of", "the", "local", "tasks", "and", "transmission", "time", "for", "all", "users", "should", "not", "exceed", "the", "completion", "time", "for", "the", "whole", "FL", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["we", "show", "the", "performance", "of", "length", "2048", "SC", "-", "decoded", "and", "SCL", "-", "decoded", "BIPCM", "SCMA", "systems", "designed", "at", "dB", ",", "length", "2048", "SC", "-", "decoded", "and", "SCL", "-", "decoded", "MLPC", "systems", "designed", "at", "dB", ",", "a", "length", "2070", "LTE", "turbo", "coded", "system", ",", "and", "a", "length", "2016", "WiMAX", "LDPC", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "successive cancellation"}, {"tokens": ["The", "BS", "sends", "orthogonal", "-length", "pilot", "sequences", "to", "the", "users", "with", ",", "which", "is", "derived", "at", "the", "second", "stage", "but", "distorted", "by", "the", "imperfect", "phase", "shifters", ",", "as", "the", "analog", "precoding", "matrix", "and", "as", "the", "analog", "combining", "vector", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["By", "tuning", "in", "from", "to", ",", "the", "Sinkhorn", "divergence", "has", "the", "property", "of", "taking", "the", "best", "of", "both", "OT", "(", "non", "-", "flat", "geometry", ")", "and", "MMD", "(", "high", "-", "dimensional", "rigidity", ")", "loss", ",", "which", "we", "find", "in", "experiments", "improves", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Note", "that", "once", "a", "sensor", "node", "finds", "a", "path", "to", "the", "AP", ",", "our", "RL", "Algorithm", "will", "keep", "it", "in", "the", "backbone", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["To", "alleviate", "this", "difficulty", ",", "we", "conservatively", "replace", "the", "data", "rate", "of", "each", "UE", "with", "its", "lower", "-", "bound", "expression", "derived", "by", "using", "the", "Jensen", "'s", "inequality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["OP", "rasta-", "'", "right", "'", "MP", "rast", "NP", "rastPIr"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "new persian"}, {"tokens": ["Here", ",", "the", "PEP", "is", "the", "intermediate", "negotiator", "that", "intercepts", "the", "users", "'", "requests", "and", "enforces", "the", "PDP", "'s", "decision", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "policy decision point"}, {"tokens": ["Training", "is", "done", "in", "order", "to", "generate", "a", "unified", "FL", "model", "for", "all", "users", "without", "sharing", "any", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["The", "complete", "pipeline", "of", "ZIP", "and", "MAD", "algorithm", "for", "region", "proposal", "and", "object", "detection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["For", "the", "short", "-", "range", "contextual", "information", ",", "we", "train", "an", "MTL", "3D", "CNN", "that", "effectively", "extracts", "the", "features", "of", "vertebral", "samples", "by", "leveraging", "the", "domain", "information", "contained", "in", "both", "the", "vertebrae", "identification", "and", "localization", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multi - task learning"}, {"tokens": ["The", "objective", "of", "the", "RS", "model", "at", "time", "step", "is", "to", "provide", "items", "which", "the", "user", "is", "ultimately", "interested", "in", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["The", "best", "results", "report", "89.6", "-", "93.6", "accuracy", "for", "CC", "and", "89", "-", "93.5", "for", "LC", "method", "with", "low", "hamming", "loss", "0.079", "in", "most", "cases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classifier chain"}, {"tokens": ["In", "the", "frequency", "range", "higher", "than", "the", "actual", "value", "of", "MVF", ",", "white", "noise", "is", "used", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["(", "data", "-", "gNBs", ")", ",", "and", "d", "-", "WTs", "(", "data", "-", "WTs", ")", ";", "created", "out", "of", "LTE", "eNBs", ",", "5", "G", "gNBs", ",", "and", "WTs", ",", "respectively", "by", "removing", "their", "control", "functions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Later", "in", "ABC", "-", "Net", ",", "propose", "several", "strategies", "for", "improving", "the", "accuracy", "of", "BNN", "and", "adjusting", "the", "learning", "rate", "for", "larger", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary neural networks"}, {"tokens": ["0Some", "of", "our", "important", "contributions", "are", "as", "follows", ":", "(", "i", ")", "introducing", "the", "CC", "property", "and", "the", "analytical", "justification", "proving", "that", "the", "core", "periphery", "structure", "of", "a", "network", "can", "be", "used", "to", "identify", "top", "central", "nodes", ",", "(", "ii", ")", "an", "algorithm", "based", "on", "time", "series", "forecasting", "to", "predict", "the", "overlap", "of", "the", "top", "central", "nodes", "across", "time", "points", "(", "iii", ")", "an", "algorithm", "to", "exactly", "pinpoint", "the", "ids", "of", "the", "nodes", "that", "have", "high", "centrality", "when", "the", "network", "is", "available", "in", "time", "and", "(", "iv", ")", "a", "detailed", "validation", "scheme", "to", "show", "that", "the", "behavior", "of", "the", "high", "centrality", "nodes", "predicted", "by", "our", "algorithm", "indeed", "matches", "the", "behavior", "of", "the", "actual", "high", "centrality", "nodes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "core connected"}, {"tokens": ["Histogram", "AnalysisThe", "tone", "mapper", "we", "implement", "in", "our", "software", "ISP", "model", "performs", "localized", "histogram", "equalization(Our", "tone", "mapper", "compensates", "for", "gamma", "correction", "later", "in", "the", "ISP", "pipeline", ",", "resulting", "in", "a", "higher", "concentration", "of", "values", "toward", "zero", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Raw", "vs.", "RGB", "ExperimentWe", "first", "evaluate", "whether", "the", "ISP", "has", "any", "impact", "on", "CNN", "classification", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["However", ",", "this", "trend", "is", "reversed", "for", "WMHNs", "having", "more", "than", "7", "nodes", ",", "where", "the", "CDP", "method", "exhibits", "a", "complexity", "reduction", "compared", "to", "the", "BF", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classical dynamic programming"}, {"tokens": ["Aside", "from", "black", "-", "box", "analysis", ",", "a", "rough", "SoC", "integrator", "with", "access", "to", "reverse", "engineering", "and", "FA", "tools", "can", "also", "deploy", "physical", "attacks", "like", "optical", "probing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["Flowgraph", "for", "DE", "with", "symmetry", "breaking", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Note", "that", "for", ",", "the", "above", "results", "may", "not", "be", "true", "but", "in", "the", "context", "of", "HCN", ",", "it", "rarely", "happens", "that", "distance", "between", "typical", "UE", "and", "serving", "BS", "be", "less", "than", "meters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Zhiguo", "Wang", ",", "Patrick", "Ng", ",", "Xiaofei", "Ma", ",", "Ramesh", "Nallapati", ",", "Bing", "Xiang", "AWS", "AI", "Labs", "zhiguow", ",", "patricng", ",", "xiaofeim", ",", "rnallapa", ",", "bxiang@amazon.com", "BERT", "model", "has", "been", "successfully", "applied", "to", "open", "-", "domain", "QA", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["Another", "primitive", "used", "is", "the", "Binary", "Agreement", "(", "abbreviated", "BA", ")", "primitive", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "binary agreement"}, {"tokens": ["Similar", "to", ",", "the", "rate", "loss", "in", "the", "second", "link", "between", "the", "private", "messages", "of", "the", "NoRS", "and", "RS", "is", "proved", "to", "be", "upper", "bounded", "asSubstituted", "log1", "into", "DR", ",", "we", "obtain", "the", "desired", "result", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["When", "the", "transmit", "power", "of", "the", "BS", "increases", ",", "the", "destination", "user", "'s", "SINR", "increases", "more", "than", "the", "eavesdropper", "'s", "SINR", ",", "because", "these", "four", "methods", "all", "try", "to", "provide", "the", "eavesdroppers", "less", "confidential", "signal", "and", "more", "AN", "by", "designing", "the", "best", "signal", "beamforming", "matrix", "and", "AN", "beamforming", "matrix", ",", "thus", "limiting", "the", "eavesdropper", "'s", "SINR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["RB", ":", "coefficients", ",", "representing", "the", "weak", "form", "of", "eq", ":", "intro", ":", "micro", ":", "problem", "in", "the", "RB", "setting", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "reduced basis"}, {"tokens": ["We", "demonstrate", "the", "applicability", "of", "the", "proposed", "approach", "for", "cine", "stacks", "of", "2D", "MR", "and", "3D", "-", "US", "datasets", "composed", "of", "and", "cardiac", "image", "sequences", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["As", "we", "obtained", ",", "ICA", "was", "better", "than", "GA", "for", "training", "this", "network", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imperialist competitive algorithm"}, {"tokens": ["The", "Strictly", "Piecewise", "(", "SP", ")", "class", "was", "studied", "by", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Finally", ",", "GMM", "selection", ",", "has", "very", "high", "performance", "using", "as", "little", "as", "1000", "selected", "images", ",", "but", "the", "increase", "is", "marginal", ",", "when", "more", "images", "are", "selected", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["It", "supports", "both", "BSP", "and", "asynchronousexecution", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "bulk synchronous parallel"}, {"tokens": ["The", "direct", "transmission", "between", "an", "MS", "and", "the", "BS", "is", "a", "cellular", "link", "and", "that", "between", "any", "two", "MSs", "is", "a", "DD", "link", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["for", "-stage", "classification", "&", "&", "&", "&", "&", "IIR", "-", "MMD", "-", "DT", "&", "RS", "-", "task", "&", "15.6", "&", "58.2", "&", "95.6", "&", "83.8", "&", "80.3", "IIR", "-", "MMD", "-", "DT", "&", "SC", "-", "task", "&", "26.4", "&", "61.9", "&", "94.8", "&", "84.3", "&", "84.3", "Proposed", "Method", "&", "RS", "-", "task", "&", "43.8", "&", "66.5", "&", "97.9", "&", "88.8", "&", "85.5", "Proposed", "Method", "&", "SC", "-", "task", "&", "43.3", "&", "67.9", "&", "97.0", "&", "90.1", "&", "90.0"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subset compared"}, {"tokens": ["The", "Information", "Bottleneck", "in", "deterministic", "scenarioskolchinsky2018caveats", "showed", "that", "when", "is", "a", "deterministic", "function", "of", "(", "i.e.", ",", ")", ",", "the", "IB", "curve", "is", "piecewise", "linear", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "the", "SBM", "as", "investigated", "byMcDaidSBM", ",", "it", "is", "straightforward", "to", "use", "collapsingand", "integrate", "out", "the", "other", "variables", "that", "we", "are", "not", "directly", "interested", "in", "such", "as", "and", ",", "align", "*", "P_SBM(x", ",", "z", ",", "K", ")", "&", "=", "P_SBM(K", ")", "P_SBM(zK", ")", "P_SBM(xz", ",", "K", ")", "&", "=", "P_SBM(K", ")", "P_SBM(z", ",", "K", ")", "dP_SBM(x", ",", "z", ",", "K", ")"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["In", "RV", "all", "trials", "are", "independent", "and", "under", "the", "assumption", "that", "for", "enough", "trials", "the", "algorithm", "is", "bounded", "to", "converge", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random voting"}, {"tokens": ["However", ",", "it", "must", "be", "noted", "that", "our", "approach", "can", "only", "be", "applied", "to", "a", "subset", "of", "SC", "tasks", ":", "those", "that", "can", "be", "done", "on", "a", "street", "-", "view", "image", "of", "the", "space", ",", "and", "is", "limited", "by", "how", "up", "-", "to", "-", "date", "images", "are", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial crowdsourcing"}, {"tokens": ["Multi", "-", "output", "GP", "regression", "over", "three", "sequential", "channels", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["shows", "the", "performance", "results", "of", "our", "method", "and", "18", "existing", "methods", "as", "well", "as", "a", "baseline", "method", "that", "combines", "an", "AN", "and", "a", "ResNet", "-", "based", "feature", "extractor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["The", "gap", "between", "UAP", "and", "model", "AP", "over", "small", "objects", "is", "about", "35", "which", "is", "much", "higher", "than", "the", "gap", "over", "medium", "or", "large", "objects", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "number", "of", "steps", "in", "MD", "trajectories", "in", "HMC", "were", "exactly", "the", "same", "as", "in", "sec", ":", "Unconstrained", ",", "i.e.", "2000", "and", "4000", "in", "the", "tests", "with", "Verlet", ",", "and", "1000", "and", "2000", "for", "the", "two", "-", "stage", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["This", "is", "just", "somewhat", "more", "than", "percentage", "point", "higher", "than", "the", "median", "bootstrapped", "MAD", "for", "low", "peer", "review", "uncertainty", "and", "less", "than", "percentage", "point", "higher", "than", "the", "median", "bootstrapped", "MAD", "for", "high", "peer", "review", "uncertainty", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "median absolute difference"}, {"tokens": ["In", "the", "-th", "(", ")", "phase", ",", "MTCD", "transmits", "data", "to", "its", "serving", "MTCG", "with", "achievable", "throughputIn", "the", "-th", "phase", ",", "after", "having", "decoded", "all", "the", "messages", "of", "its", "served", "MTCDs", ",", "MTCG", "transmits", "the", "collected", "data", "to", "the", "BS", "with", "achievable", "throughputSimilar", "to", "(", ")", ",", "the", "total", "energy", "harvested", "of", "MTCD", "served", "by", "MTCG", "isAccording", "to", "(", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Then", ",", "we", "analyze", "the", "complexity", "for", "the", "three", "TAS", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["The", "initial", "goal", "in", "LTE", "was", "throughput", "enhancement", "via", "data", "split", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Let", "the", "IB", "curve", "be", "defined", "by", "the", "solutions", "of", "for", "varying", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": [",", "s2", "=", "0.82", "and", "s3", "=", "0.53", ",", "we", "can", "get", "the", "better", "utilization", "of", "BQ", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "basic question"}, {"tokens": ["CNOMA", "-", "OAM", "is", "proposed", "to", "enhance", "SC.The", "numerical", "result", "analysis", "showed", "that", "the", "proposed", "CNOMA", "-", "OAM", "provides", "a", "significantly", "higher", "SC", "than", "other", "schemes", "over", "the", "Rician", "fading", "channel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["This", "separation", "explains", "why", "the", "GMM", "can", "fit", "the", "representations", "from", "Cityscapes", "so", "well", "and", "single", "out", "representations", "from", "Open", "Images", "that", "are", "dissimilar", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["In", "eq", ":", "eff", ",", "represents", "the", "variance", "of", "the", "ASE", "noise", "and", "the", "variance", "of", "the", "NLI", "that", "includes", "both", "intra-", "and", "inter", "-", "channel", "distortions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "amplified spontaneous emission"}, {"tokens": ["The", "-nd", "contention", "round", "finishes", "as", ":", "1", ")", "all", "available", "antennas", "of", "the", "AP", "are", "occupied", "or", "2", ")", "a", "predefined", "duration", "of", "the", "-nd", "contention", "round", "elapses", "in", "case", "there", "are", "not", "enough", "contending", "STAs", "(", "the", "maximum", "duration", "of", "the", "-nd", "contention", "round", "is", "set", "to", "slots", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Tok", "delimited", "by", "three", "tags", ",", "[", "CLS", "]", ",", "[", "SEP", "]", "and", "[", "EOS", "]", "(", "beginning", ",", "SEP", "and", "end", "of", "sentence", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "separator"}, {"tokens": ["However", ",", "for", "CF", "systems", ",", "it", "is", "hard", "to", "identify", "the", "user", "latent", "interests", ",", "since", "the", "only", "information", "available", "is", "the", "user", "interaction", "information", "with", "the", "system", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["However", ",", "note", "that", "the", "ACC", "for", "the", "Truth", "model", "initialised", "with", "the", "same", "initial", "conditions", "perturbations", "is", "only", "0.52", "and", "its", "RMSE", "is", "5.59", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "anomaly correlation coefficient"}, {"tokens": ["It", "is", "evident", "from", "these", "experiments", "that", "networks", "trained", "with", "HR", "images", "or", "subsampled", "images", "are", "not", "effective", "for", "real", "life", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["The", "PAP", "framework", ",", "including", "estimation", "of", "computation", "time", "and", "warm", "-", "up", "was", "initiated", "only", "for", "the", "latter", "two", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["Adaptive", "Video", "-", "aware", "FEC", "-", "based", "Mechanism", "(", "ViewFEC)Motivated", "by", "the", "open", "issues", "afore", "-", "identified", ",", "this", "section", "proposes", "and", "validates", "the", "adaptive", "cross", "-", "layer", "VIdEo", "-", "aWare", "FEC", "-", "based", "Mechanism", "with", "Unequal", "Error", "Protection", "scheme", "(", "ViewFEC", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Training", "a", "DBN", "initially", "pre", "-", "train", "each", "RBM", "from", "the", "bottom", "to", "the", "top", "in", "layer", "-", "wise", "manner", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Computational", "Time", "AnalysisThe", "computing", "of", "ECS", "-", "DBN", "at", "run", "-", "time", "is", "closely", "related", "to", "the", "DBN", "network", "complexity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["XXX", "MD", "Properties", "&", "IACF", "equilibration", "&", "IACF", "production", "number", "of", "stages", "(", "fs", ")", "&", "2c25", "fs", "VV", "&", "124.21", "&", "122.49", "BCSS", "&", "324.56", "&", "FAILED", "AIA", "&", "112.75", "&", "110.98", "IACF", "for", "equilibration", "and", "prodcution", "with", "MD", "for", "the", "biggest", "simulated", "time", "step", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["Gaing", ",", "used", "a", "basic", "version", "of", "PSO", "algorithm", "with", "a", "new", "solution", "process", "for", "solving", "ELD", "problems", "considering", "generator", "constraints", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["The", "reduced", "method", "can", "be", "directly", "implemented", "by", "EGMM", "by", "marginalizing", "out", "the", "missing", "features", "prior", "to", "computing", "the", "surprise", ":", "This", "is", "easily", "done", "for", "each", "Gaussian", "component", "in", "the", "each", "GMM", "in", "EGMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Receiver", "operating", "characteristic", "(", "ROC", ")", "evaluation", "[", "!"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["For", "instance", ",", "given", "a", "WRFET", ",", "an", "ET", "node", ",", "two", "sensor", "node", "and", ",", "will", "harvest", "more", "energy", "than", ",", "if", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy transmitters"}, {"tokens": ["The", "maximum", "(", "over", ")", "of", "the", "K", "-", "S", "distance", "(", "left", "figure", ")", "and", "the", "average", "derivation", "(", "right", "figure", ")", "between", "proposed", "bounds", "and", "the", "CDF", "of", "CD", "and", "NND", "for", "different", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "contact distance"}, {"tokens": ["Specifically", ",", "JSC", "stands", "for", "Jaccard", "similarity", "coefficient", ",", "MCC", "stands", "for", "Matthews", "Correlation", "Coefficient", ",", "0", "-", "1", "stands", "for", "the", "0", "-", "1", "loss", ",", "EVS", "stands", "for", "explained", "variance", "score", ",", "and", "the", "number", "in", "the", "parenthesis", "indicates", "the", "thresholding", "value", "of", "continuous", "output", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["With", "regards", "to", "WF", ",", "we", "report", "in", "Figure", "the", "curve", "describing", "how", "the", "rank-1", "accuracy", "varies", "over", "the", "weighting", "parameter", "space", "of", "the", "linear", "combination", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "weighted fusion"}, {"tokens": ["In", "TensorFlow", ",", "PS", "architecture", "is", "well", "supported", "and", "developers", "will", "have", "a", "large", "community", "for", "help", "in", "debugging", "and", "suggestions", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["Note", "that", "this", "formulation", "is", "equivalent", "to", "applying", "the", "sum", "of", "the", "updates", "with", "two", "separate", "learning", "rates", ",", "as", "if", "the", "model", "learning", "rate", "is", ",", "then", "the", "effective", "learning", "rate", "for", "backpropagation", "is", "and", "the", "effective", "learning", "rate", "for", "FA", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["Treatment", "of", "constraints", "With", "the", "framework", "of", "ET", "and", "EAA", ",", "the", "power", "balance", "constraints", ",", "spinning", "reserve", "limitations", ",", "and", "network", "security", "constraints", "can", "be", "modified", "as", "the", "equations", "with", "DS", "structure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "evidence theory"}, {"tokens": ["We", "have", "that*Hence", ",", "eq", "holds", "if", "Simulation", "Results", "on", "23", "Real", "Datasets", "from", "ODDSTable", "gives", "the", "exact", "AUC", "and", "AP", "scores", "of", ",", ",", ",", ",", ",", "and", "on", "23", "real", "datasets", "from", "the", "ODDS", "library", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Problem", "and", "Model", "FormulationWe", "pose", "the", "problem", "formulations", "for", "CF", "and", "CTR", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["We", "compare", "the", "proposed", "FL", "scheme", "with", "the", "FL", "FDMA", "scheme", "with", "equal", "bandwidth", "(", "labelled", "as", "'", "EB", "-", "FDMA'),the", "FL", "FDMA", "scheme", "with", "fixed", "local", "accuracy", "(", "labelled", "as", "'", "FE", "-", "FDMA", "'", ")", ",", "and", "the", "FL", "TDMA", "scheme", "in", "(", "labelled", "as", "'", "TDMA", "'", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["b", ")", "and", "(", "d", ")", "are", "respectively", "more", "expressive", "than", "(", "a", ")", "and", "(", "c).Linking", "composition", "functions", "and", "SRL", "models"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "statistical relational learning"}, {"tokens": ["Combining", "WF", "and", "WPRDue", "to", "the", "conceptual", "complementarity", "of", "the", "two", "methods", ",", "we", "can", "combine", "them", "together", ",", "shown", "in", "Figure", ",", "to", "benefit", "from", "both", "additive", "contributions", "at", "the", "same", "time", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "weighted fusion"}, {"tokens": ["We", "use", "three", "different", "types", "of", "CNN", "(", "see", "figure", "2", ")", ":", "a", "classification", "model", "based", "on", "the", "SegNet", "architecture", "in", "order", "to", "perform", "binary", "classification", "(", "building", "/", "no", "-", "building", ")", ";", "a", "feedback", "neural", "network", "(", "FeedbackNet", ")", "performing", "weakly", "-", "supervised", "segmentation", "of", "the", "satellite", "images", "enabling", "us", "to", "obtain", "building", "footprints", ",", "and", "a", "denoising", "network", "which", "is", "capable", "of", "improving", "the", "quality", "of", "the", "source", "data", "by", "removing", "high", "-", "frequency", "noise", "from", "the", "satellite", "imagery", "(", "see", "SI", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "satellite imagery"}, {"tokens": ["However", ",", "the", "derived", "CDF", "for", "CD", "eq", ":", "FinalMCDN", "is", "significantly", "simpler", "than", "the", "one", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "contact distance"}, {"tokens": ["Mean", "Precision", "(", "MP", ")", "averages", "such", "measures", "for", "all", "requests", "from", "the", "dataset", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean precision"}, {"tokens": ["htb", "]", "QoE", "and", "Redundancy", "comparison", "In", "both", "cases", ",", "MINT", "-", "FEC", "presented", "a", "slightly", "better", "video", "quality", "until", "1200", "m", ",", "which", "was", "between", "0.59", "and", "2.01", ",", "and", "between", "0.69", "and", "1.63", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "this", "paper", ",", "we", "propose", "to", "solve", "the", "RV", "segmentation", "problem", "with", "a", "deep", "learning", "based", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["This", "is", "true", "both", "when", "transferring", "the", "samples", "of", "the", "set", "and", "when", "transferring", "the", "test", "set", "of", "SVHN", ",", "which", "is", "much", "smaller", "and", "was", "not", "seen", "during", "the", "training", "of", "the", "DTN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "domain transfer network"}, {"tokens": ["The", "application", "level", "FEC", "redundancy", "adaptation", "is", "done", "by", "multiple", "pre", "-", "encoded", "videos", "with", "different", "bit", "rates", "and", "FEC", "rate", ",", "so", ",", "in", "order", "to", "adapt", "theses", "parameters", ",", "the", "system", "has", "to", "switch", "to", "a", "different", "bit", "stream", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "proposed", "approach", "is", "in", "essence", "a", "new", "learning", "strategy", "for", "PSO", "hence", "it", "would", "be", "interesting", "to", "benchmark", "its", "performance", "using", "existing", "PSO", "based", "feature", "selection", "approaches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Initially", ",", "all", "nodes", "are", "in", "AD", "state", "and", "the", "BS", "schedules", "the", "node", "(", ")", "which", "has", "maximum", "to", "transmit", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "present", "a", "complete", "system", ",", "and", "show", "through", "a", "user", "study", "that", "the", "result", "is", "an", "efficient", "AR", "rendering", "architecture", "for", "streaming", "stereoscopic", "displays", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["The", "steps", "in", "Line", "3", "of", "MP", "(", "Algorithm", ")", "and", "Line", "3", "of", "FW", "(", "Algorithm", ")", "(", "finding", "the", "step", "direction", ")", "are", "identical", "up", "to", "symmetrization", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["Result", "in", "Table", "II", "endorses", "two", "evidences", ":", "i", ")", "network", "utilization", "was", "maximized", "keeping", "preemption", "and", "devolution", "lower", "values", "when", "compared", "to", "RDM", "and", "ATCS", "models", "individually", ";", "and", "ii", ")", "this", "result", "can", "only", "be", "achieved", "in", "case", "BAMCBR", "effectively", "learns", "about", "network", "performance", "metrics", "and", "reconfigure", "BAMs", "to", "achieve", "manager", "'s", "goals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "russian dolls model"}, {"tokens": ["Having", "applied", "a", "conventional", "multi", "-", "user", "uplink", "design", "for", "the", "first", "link", ",", "we", "assumed", "the", "implementation", "of", "RS", "in", "the", "second", "link", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["For", "AC", "-", "OPF", ",", "the", "maximum", "achievable", "gains", "are", "significantly", "lower", "than", "those", "for", "DC", "-", "OPF", "but", "for", "larger", "grids", "classification", "can", "still", "provide", "some", "improvement", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Random", "Walk", "LossRWThe", "VAT", "and", "entropy", "losses", "are", "local", ",", "it", "is", "easy", "to", "see", "that", "each", "point", "'s", "loss", "is", "calculated", "independent", "of", "other", "points", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["While", "Reinforcement", "Learning", "has", "well", "established", "benchmarks", ",", "SRL", "has", "no", "metrics", "nor", "universal", "criterion", "to", "compare", "the", "different", "approaches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["Finding", "high", "-", "influence", "microblog", "users", "with", "an", "improved", "PSO", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "combined", "datasets", "were", ":", "AT", "and", "ATIS", "IntAT", "and", "ClassicLitAT", "and", "CM", "and", "DFG", "and", "DT", "and", "NYR", "10", "and", "SDC", "and", "TEATIS", "Int", "and", "ClassicLitATIS"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "corporate messaging"}, {"tokens": ["Technological", "knowledge", ",", "moral", "and", "psychological", "attributes", ",", "and", "perceptions", "of", "risks", "versus", "benefits", "are", "associated", "with", "support", "for", "GM", "foods", "and", "nanotechnology", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "genetically modified"}, {"tokens": ["SIFT10", "M", "is", "prepared", "for", "the", "purpose", "of", "visualization", "as", "well", "as", "a", "medium", "size", "data", "set", "between", "SIFT1", "M", "and", "SIFT1B.", "Performance", "measurementsTo", "evaluate", "the", "performance", "of", "different", "hashing", "methods", ",", "we", "first", "investigate", "how", "hashing", "methods", "are", "used", "for", "ANN", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "approximate nearest neighbor"}, {"tokens": ["h", "]", "Use", "of", "Single", "UAV", "Systems", "in", "SAR", "Operations", ",", "Mountain", "Avalanche", "Events", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["Classification", "Error", "Rate", "(", "CER", ")", "obtained", "on", "TIMIT", "(", "462", "spks", ")", "and", "Librispeech", "(", "2484", "spks", ")", "speaker", "-"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classification error rate"}, {"tokens": ["Owing", "to", "no", "assumption", "about", "underlying", "signal", "model", ",", "the", "DL", "estimator", "has", "to", "take", "sufficiently", "large", "training", "data", "to", "learn", "an", "effective", "estimator", "from", "scratch", ",", "which", "is", "relatively", "inefficient", "compared", "to", "LS", "or", "LMMSE", "estimators", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["This", "strategy", "avoids", "the", "random", "selection", "of", "RV", "strategy", "and", "provides", "an", "opportunity", "to", "select", "individuals", "who", "have", "contact", "with", "many", "other", "individuals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["The", "first", "scheme", ",", "without", "FEC", ",", "is", "not", "shown", "because", "it", "does", "not", "produce", "overhead", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Moreover", ",", "the", "proposed", "method", "can", "recover", "small", "features", "successfully", "(", "e.g.", "lesions", "in", "ET", "case", ")", "with", "both", "step", "or", "ramp", "intensity", "variations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "emission tomography"}, {"tokens": ["that", "as", "the", "network", "going", "deeper", "and", "wider", "from", "AConvNet", "to", "AlexNetConv", ",", "the", "performance", "on", "SAR", "targets", "is", "decreasing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Feature", "values", "are", "the", "frequencies", "of", "POS", "tag", "sequences", "occurring", "in", "the", "tweet", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["While", "not", "providing", "the", "number", "of", "pixels", "available", "on", "a", "TDW", ",", "the", "advantages", "of", "a", "SDD", "would", "be", "brought", "to", "bear", ",", "and", "might", "produce", "a", "cost", "-", "effective", "compromise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Why", "did", "the", "QA", "system", "fail", "to", "answer", "?"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Because", "of", "the", "prevalence", "of", "research", "into", "the", "impact", "of", "noise", "on", "neural", "networks", ",", "the", "following", "ablation", "study", "is", "separated", "into", "(", "1", ")", "a", "study", "of", "only", "denoise", "and", "(", "2", ")", "a", "study", "of", "remaining", "ISP", "components", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "image signal processor"}, {"tokens": ["a", "denotes", "arsenal", ",", "aE", "-", "autoEDA", ",", "DE", "-", "DataExplorer", ",", "dM", "-", "dataMaid", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "dataexplorer"}, {"tokens": ["Acute", "Pancreatitis", "(", "AP", ")", "is", "one", "of", "the", "most", "common", "gastrointestinal", "disorder", "requiring", "inpatient", "admission", "all", "over", "the", "world", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "acute pancreatitis"}, {"tokens": ["Back", "-", "translation", "was", "also", "studied", "in", "spoken", "language", "understanding", "and", "text", "-", "based", "QA", "as", "a", "data", "augmentation", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["where", "TP", ",", "FP", ",", "FN", ",", "TN", "represent", "true", "positive", ",", "false", "positive", ",", "false", "negative", "and", "true", "negative", ",", "respectively", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["It", "can", "be", "observed", "that", "PAT", "slightly", "improves", "the", "adversarial", "robustness", "but", "loses", "on", "clean", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "perform adversarial training"}, {"tokens": ["However", ",", "this", "method", "suffers", "from", "severe", "coding", "artifacts", "similarly", "to", "conventional", "MDC", "approaches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["Although", "the", "introduction", "of", "the", "LB", "divergence", "to", "rank", "aggregation", "on", "score", "-", "based", "permutations", "is", "briefly", "discussed", "in", ",", "the", "existing", "formulation", "of", "the", "LB", "divergence", "for", "rank", "aggregation", "and", "the", "related", "algorithms", "are", "limited", "to", "a", "supervised", "manner", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["Proposed", "Simple", "Max", "-", "SR", "PA", "Strategy", "for", "NSP", "Beamforming"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["However", ",", "RecoBundles", "and", "TractQuerier", "are", "failing", "in", "properly", "reconstructing", "the", "entirety", "of", "the", "tracts", ":", "RecoBundles", "fails", "to", "reconstruct", "the", "Meyer", "'s", "loop", "of", "the", "OR", "and", "TractQuerier"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optic radiation"}, {"tokens": ["The", "supervised", "training", "results", "in", "an", "unrealistic", ",", "smooth", "appearance", "seen", "in", "the", "MR", "images", "from", "Generatorss", "and", "the", "Simple", "model", ",", "where", "the", "Simple", "model", "also", "fails", "in", "the", "color", "mapping", "of", "the", "cerebrospinal", "fluid", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["Disturbance", "estimationTo", "reduce", "the", "gains", "and", "as", "much", "as", "possible", "with", "maintaining", "the", "robustness", "of", "STA", ",", "the", "only", "way", "is", "to", "make", "and", "slightly", "greater", "than", "the", "necessary", "level", "such", "that", "the", "disturbance", "is", "counteracted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["Future", "InsightsBased", "on", "the", "reviewed", "current", "literature", "focusing", "on", "SAR", "scenarios", "using", "UAVs", ",", "we", "believe", "there", "is", "a", "need", "for", "more", "research", "on", "the", "following", ":", "Data", "fusion", "and", "decision", "fusion", "algorithms", "that", "integrate", "the", "output", "of", "multiple", "sensors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["[", "cloud", ",", "below", "of", "=", "gc", ",", "node", "distance", "=", "2", "cm", "]", "(", "m", ")", "Race", "Classification", ";", "[", "cloud", ",", "below", "of", "=", "init", ",", "node", "distance", "=", "2", "cm", "]", "(", "f", ")", "Race", "Classification", ";", "[", "block3", ",", "below", "left", "of", "=", "m", ",", "node", "distance", "=", "1.5", "cm", "]", "(", "of", ")", "BM", "Age", "Estimator", ";"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "black males"}, {"tokens": ["The", "malware", "extracts", "the", "command", "sent", "from", "the", "CC", "and", "executes", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "covert channels"}, {"tokens": ["In", "this", "paper", "we", "extend", "the", "latent", "force", "framework", "to", "allow", "for", "multiplicative", "interactions", "between", "the", "GP", "and", "the", "latent", "states", "leading", "to", "more", "control", "over", "the", "geometry", "of", "the", "trajectories", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["For", "the", "considered", "FL", "algorithm", ",", "we", "first", "derive", "the", "convergence", "rate", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["We", "find", "the", "data", "reception", "and", "fair", "nodes", "of", "FCFS", ",", "LE", "and", "HP", "do", "not", "vary", "significantly", "from", "N", "=", "150", "to", "300", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low energy"}, {"tokens": ["Building", "on", "the", "work", "of", "on", "developing", "a", "framework", "for", "transparent", "model", "reporting", ",", "we", "identify", "(", "1", ")", "the", "need", "for", "more", "granular", "evaluation", "metrics", "for", "the", "interaction", "between", "a", "RS", "and", "a", "dynamic", "user", "identity", ",", "as", "well", "as", "(", "2", ")", "organizational", "changes", "in", "the", "RSs", "system", "design", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["For", "a", "query", "phrase", "and", "its", "neighboring", "phrases", ",", "the", "regression", "is", "estimated", "as", "follows", ":", "where", "''", "denotes", "the", "concatenation", "operator", ",", "is", "the", "query", "phrase", "whose", "regression", "parameters", "are", "predicted", "and", "is", "the", "set", "of", "region", "proposals", "chosen", "by", "PIN", "for", "neighboring", "phrases", "of", "query", "phrase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "proposal indexing network"}, {"tokens": ["Given", "the", "narrative", "that", "the", "LSTM", "architecture", "addresses", "a", "known", "problem", "for", "s", "-", "RNNs", ",", "we", "expected", "that", "the", "s", "-", "RNN", "performance", "would", "be", "worse", "than", "the", "LSTM", "performance", "on", "the", "SP", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["AA", "has", "also", "been", "proven", "to", "be", "very", "effective", "in", "forensic", "linguistic", "science", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["In", "Section", ",", "we", "develop", "a", "performance", "models", "for", "distributed", "training", "for", "PS", ",", "P2P", ",", "and", "RA", "architectures", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["A", "short", "description", "of", "our", "algorithm", "as", "a", "GPS", "method", "for", "solving", "the", "problem", "stated", "in", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["It", "is", "noted", "in", "Table", "that", ",", "ECS", "-", "DBN", "outperforms", "other", "competing", "algorithms", "with", "comparably", "lower", "variances", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Fitness", "function", ":", "The", "fitness", "function", "of", "GA", "-", "SCP", "is", "the", "performance", "index", ",", ",", "of", "SCP", "central", "plant", "problem", "given", "in", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["Mean", "Recall", "(", "MR", ")", "averages", "such", "measures", "for", "all", "requests", "from", "the", "dataset", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean recall"}, {"tokens": ["Optimized", "by", "one", "pass", "of", "LAP", "solver", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "linear assignment problem"}, {"tokens": ["H", "-", "CRAN", "leverages", "the", "previous", "CC", "/", "EC", "structure", "with", "functional", "splitting", "in", "a", "three", "-", "layer", "architecture", "to", "share", "the", "processing", "tasks", "between", "CC", "and", "EC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["To", "obtain", "more", "insight", "into", "informativeness", "ratings", ",", "we", "asked", "crowd", "workers", "to", "further", "distinguish", "informativeness", "in", "terms", "of", "added", "and", "missed", "information", "with", "respect", "to", "the", "original", "MR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "meaning representation"}, {"tokens": ["In", "particular", ",", "with", "given", "the", "same", "completion", "time", ",", "the", "proposed", "FL", "can", "reduce", "energy", "of", "up", "to", "33.3", ",", "50.2", ",", "and", "37.6", "compared", "to", "EB", "-", "FDMA", ",", "FE", "-", "FDMA", ",", "and", "TDMA", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Tumour", "detectionThe", "classifier", "returns", "a", "probability", "for", "each", "supervoxel", ",", "and", "treating", "this", "problem", "as", "a", "voxelwise", "detection", "problem", ",", "a", "ROC", "curve", "can", "be", "generated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["(", "ROC", ")", "curves", "in", "(", "a", ")", "the", "team", "-", "defence", "and", "(", "b", ")", "team", "-", "offence", "recognition", "task", "are", "shown", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "Logit", "RUM", "model", "does", "allows", "some", "random", "variance", "in", "the", "utilities", "individuals", "in", "the", "population", "derive", "from", "the", "differentiated", "products", ",", "and", "thus", "contains", "some", "degree", "of", "population", "heterogeneity", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random utility maximization"}, {"tokens": ["Now", ",", "each", "predicted", "bounding", "box", "can", "be", "assigned", "to", "TP", ",", "FP", "or", "FN", "for", "each", "class", "individually", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["Furthermore", ",", "Kaur", "and", "Singh", "proposed", "a", "new", "feature", "selction", "leveraging", "mutual", "information", "and", "adaptive", "PSO", "(", "MI", "-", "APSO", ")", "using", "area", "under", "curve", "for", "image", "steganalysis", ",", "MI", "-", "APSO", "has", "also", "inspired", "from", "IFAB", "as", "a", "feature", "selection", "and", "improved", "the", "performance", "of", "image", "steganalysis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["In", "order", "to", "fool", "this", "discriminator", ",", "the", "generator", "should", "generate", "heatmaps", "which", "are", "as", "real", "or", "feasible", "(", "for", "unlabeled", "real", "LR", "image", ")", "as", "possible", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["The", "GPS", "coordinates", "are", "stored", "in", "the", "server", "and", "then", "used", "to", "generate", "the", "map", "showing", "the", "areas", "where", "people", "infected", "with", "dengue", "are", "located", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["After", "a", "MU", "-", "CTS", "is", "received", ",", "the", "AP", "will", "measure", "the", "channel", "through", "the", "training", "sequence", "included", "in", "the", "PHY", "preamble", ",", "and", "then", "uses", "the", "estimated", "CSI", "to", "precode", "the", "simultaneously", "-", "transmitted", "frames", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Consensus", "Attention", "Sum", "ReaderIn", "this", "section", ",", "we", "will", "introduce", "our", "attention", "-", "based", "neural", "network", "model", "for", "Cloze", "-", "style", "reading", "comprehension", "task", ",", "namely", "Consensus", "Attention", "Sum", "Reader", "(", "CAS", "Reader", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "consensus attention sum"}, {"tokens": ["Based", "on", "the", "desirable", "features", "of", "an", "ANN", "method", "in", "practice", "as", "outlined", "above", ",", "we", "adopt", "recall", "as", "the", "main", "indicator", "for", "evaluating", "retrieval", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "approximate nearest neighbor"}, {"tokens": ["denotes", "the", "ECC", "multiplicative", "operation", "."], "acronym_pos": [0, 0, 1, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["Instead", "of", "individual", "CF", "models", "performances", "and", "attack", "types", ",", "we", "compute", "the", "pairwise", "Pearson", "correlation", "between", "each", "pair", "of", "analyzed", "CF", "models", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "hybrid", "ET", "and", "EAA", "approachET", "is", "a", "useful", "and", "powerful", "approach", "to", "combine", "various", "types", "of", "uncertain", "information", "from", "different", "sources", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "evidence theory"}, {"tokens": ["The", "Siemens", "SX1", "is", "released", ",", "coming", "with", "the", "first", "commercial", "mobile", "phone", "AR", "camera", "game", "called", "Mozzies", "(", "also", "known", "as", "Mosquito", "Hunt", ")", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Performance", "evaluation", "of", "efficiency", "of", "supervised", "PIN", "on", "Flickr30k"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["As", "annotated", "SEM", "images", "are", "rare", ",", "most", "likely", "a", "training", "network", "on", "such", "dataset", "will", "lead", "to", "overfitting", "to", "noise", "present", "in", "the", "training", "set", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["TAM", "\"", "denotes", "the", "transparent", "attention", "model", "to", "implement", "the", "function", "Deep", "(", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transparent attention model"}, {"tokens": ["figure", "figure[!h]centerfigures", "/", "cluster_error.pdfOut", "-", "of", "-", "sample", "error", "in", "ACE", "with", "a", "varying", "number", "of", "clusters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "average causal effect"}, {"tokens": ["A", "degree", "-", "corrected", "version", "which", "incoporates", "the", "DC", "-", "SBM", "is", "also", "derived", ",", "in", "which", "the", "soft", "clustering", "is", "achieved", "through", "hard", "clustering", "of", "the", "half", "-", "edges", ",", "rather", "than", "the", "hard", "clustering", "of", "the", "augmented", "graph", "in", "the", "non", "-", "degree", "-", "corrected", "version", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "top", "performing", "methods", "in", "FER", "literature", "exceeds", "98", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["During", "the", "development", "of", "S", "-", "RL", "Toolbox", ",", "we", "learned", "some", "useful", "insights", "on", "SRL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "state representation learning"}, {"tokens": ["Moreover", ",", "the", "number", "of", "latent", "functions", "in", "the", "multi", "-", "output", "GP", "prior", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["This", "improvement", "is", "due", "in", "part", "to", "the", "weighted", "fusion", "strategy", "WF", "(", "and", "over", "the", "baseline", ",", "respectively", ",", "for", "rank", "1", "accuracy", "and", "mAP", ")", "and", "for", "the", "remaining", "part", "to", "the", "WPR", "technique", "(", "and", "for", "rank-1", "accuracy", "and", "mAP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "weighted fusion"}, {"tokens": ["More", "importantly", ",", "the", "analysis", "made", "for", "deriving", "this", "family", "of", "Lagrangians", "can", "serve", "as", "inspiration", "for", "obtaining", "new", "Lagrangian", "families", "which", "solve", "other", "objective", "functions", "with", "intrinsic", "trade", "-", "offs", "such", "as", "the", "IB", "Lagrangian", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Performance", "comparison", "in", "terms", "of", "RMSE", "and", "CER", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "clustering error rate"}, {"tokens": ["e.g.", ",", "Zor", "Yazdi", "cum", "'", "supper", "'", "NP", "sam", "'", "evening", "'"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["SC", "comparisons", "with", "respect", "to", "SNR", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["He", "is", "currently", "pursuing", "a", "Ph.D.", "degree", "from", "the", "Department", "of", "Electrical", "and", "Computer", "Engineering", ",", "Drexel", "University", ",", "Philadelphia", ",", "PA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "philadelphia"}, {"tokens": ["During", "training", ",", "the", "objective", "function", "of", "CTC", "calculates", "the", "loss", ",", "which", "is", "the", "negative", "log", "probability", "of", "target", "labels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["Character", "error", "rate", "(", "CER", ")", "follows", "the", "same", "formula", ",", "but", "with", "characters", "as", "the", "unit", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["The", "recalibration", "output", "resembles", "the", "MAD", "unit", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "map attention decision"}, {"tokens": ["By", "setting", ",", "a", "common", "practice", "in", "GP", "modelling", ",", "we", "just", "learn", "the", "hyper", "-", "parameters", "of", "the", "kernel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["ICA", "algorithm", "initial", "parametersIn", "used", "ICA", "algorithm", ",", "the", "number", "of", "iterations", "is", "200", "and", "the", "number", "of", "members", "of", "the", "initial", "population", "is", "1000", "."], "acronym_pos": [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imperialist competitive algorithm"}, {"tokens": ["We", "calculate", "the", "number", "of", "operations", "based", "on", "our", "software", "implementation", "of", "each", "ISP", "component", "and", "by", "the", "number", "of", "multiply", "and", "accumulate", "operations", "required", "by", "MobileNets(Operations", "are", "counted", "as", "multiply", ",", "add", ",", "and", "simple", "transcendental", "functions", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["For", "example", ",", "compares", "only", "FMM", "and", "FSM", "in", "spite", "of", "the", "fact", "that", "GMM", "and", "UFMM", "were", "already", "published", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["The", "UAV", "is", "equipped", "with", "control", "processor", "and", "GPS", "module", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Based", "on", "the", "probability", "estimation", ",", "the", "trained", "DBN", "classifier", "provides", "a", "prediction", "as", "In", "practice", ",", "the", "parameters", "of", "DBN", "are", "massively", "optimized", "by", "statistic", "gradient", "descent", "with", "respect", "to", "the", "negative", "log", "-", "likelihood", "loss", "over", "the", "training", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "details", "of", "the", "PNN", "/", "RNN", "components", "and", "the", "merging", "network", "are", "explained", "in", "the", "following", "sections", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Basic", "FrameworkThe", "goal", "of", "LR", "is", "to", "train", "from", "the", "probability", "of", "variable", "being", "0", "or", "1", "given", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["But", "we", "adapt", "MP", "-", "TS", "to", "our", "setting", "as", "it", "gives", "the", "better", "empirical", "performance", "and", "shown", "to", "achieve", "optimal", "regret", "bound", "for", "Bernoulli", "distributions", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["regulates", "the", "measure", "of", "decrease", "of", "the", "objective", "function", "for", "each", "step", "produced", "by", "the", "GPS", "method", ",", "as", "follows:[Strong", "Hyp", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["Considering", "the", "effect", "of", "a", "given", "property", "by", "promoting", "the", "semantic", "rules", "of", "AML", ",", "alleviates", "the", "state", "space", "explosion", "problem", "and", "hence", "makes", "our", "approach", "efficient", "and", "terminating", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["The", "optimal", "EB", "design", "could", "be", "easily", "extended", "to", "energy", "multicast", "that", "maximizes", "the", "sum", "harvested", "energy", "at", "receivers", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy beam"}, {"tokens": ["Similar", "to", "most", "Monte", "-", "Carlo", "methods", "(", "like", "GP", "-", "REPS", ")", ",", "Black", "-", "DROPS", "is", "a", "purely", "black", "-", "box", "model", "-", "based", "policy", "search", "algorithm", ";", "i.e.", ",", "one", "can", "swap", "the", "model", "types", ",", "reward", "functions", "and/or", "initialization", "procedure", "with", "minimal", "effort", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "objective", "of", "TR", "is", "to", "find", "the", "time", "-", "domain", "signal", "to", "be", "added", "to", "the", "original", "time", "-", "domain", "signal", "to", "reduce", "the", "PAPR", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tone reservation"}, {"tokens": ["Parameters", "NDL", ",", "NPNF", ",", "NSIM", "and", "Topic", "Words", "belong", "to", "the", "maximum", "scoring", "DI", "in", "the", "person", "'s", "document", "list", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "document index"}, {"tokens": ["Given", "that", "the", "typical", "UE", "is", "associated", "with", "a", "BS", "in", "tier", "at", "distance", "and", "observes", "at", "least", "one", "MBS", ",", "CCDF", "of", "y", "iswhere", "represents", "the", "number", "of", "points", "in", "that", "are", "in", "the", "desired", "set", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["compares", "the", "sum", "secrecy", "rate", "against", "different", "number", "of", "transmit", "antennas", "at", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Following", "three", "schemes", "are", "compare", ":", "OPT", ":", "It", "represents", "the", "joint", "optimization", "solution", "where", "the", "power", "allocation", "over", "different", "sub", "-", "carriers", "at", "BS", ",", "sub", "-", "carrier", "assignment", "to", "different", "users", ",", "and", "relay", "selection", "for", "each", "of", "the", "user", "are", "found", "simultaneously", ",", "as", "given", "in", "section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Rebuild", "processing", "can", "be", "parallelized", "with", "the", "CD", ",", "ID", ",", "and", "GRD", "RAID1", "organizations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["While", "it", "is", "difficult", "to", "train", "IRN", "and", "PRN", "without", "this", "information", ",", "we", "provide", "methodologies", "to", "train", "PIN", "with", "ground", "truth", "(", "supervised", ")", "and", "without", "ground", "truth", "(", "weakly", "-", "supervised", ")", "annotations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "proposal indexing network"}, {"tokens": ["The", "second", "vulnerability", "may", "result", "from", "any", "malicious", "behaviour", "of", "in", "the", "OT", "executions", "of", "set", "inclusion", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["However", ",", "in", "the", "streaming", "environment", "and", "in", "algorithms", "like", "OEC", ",", "the", "number", "of", "clusters", "dynamically", "changes", "and", "starts", "from", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["AUC", "is", "based", "on", "the", "ROC", "curve", ",", "which", "is", "generated", "by", "plotting", "a", "cumulative", "distribution", "function", "of", "the", "true", "-", "positive", "rate", "with", "respect", "to", "the", "false", "-", "positive", "rate", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "shifted", "and", "inverted", "matrix", "is", "used", "in", "a", "PI", "-", "type", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["2", ")", "Another", "line", "of", "research", "casts", "DA", "recognition", "as", "a", "multi", "-", "label", "classification", "problem", "to", "accommodate", "the", "CDA", "scenario", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "concurrent dialogue acts"}, {"tokens": ["As", "such", ",", "we", "present", "a", "modified", "version", "of", "TS", "while", "retaining", "the", "fundamental", "principles", "TS", "is", "based", "on", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Tabu", "SearchTabu", "Search", "(", "TS", ")", "was", "first", "introduced", "by", "Fred", "Glover", "as", "a", "general", "iterative", "metaheuristic", "for", "solving", "combinatorial", "optimization", "problems", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["In", "order", "to", "obtain", "appropriate", "costs", ",", "in", "our", "proposed", "approach", "each", "chromosome", "represents", "misclassification", "costs", "for", "different", "classes", ",", "and", "the", "final", "evolved", "best", "chromosome", "is", "chosen", "as", "the", "misclassification", "costs", "for", "ECS", "-", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["Using", "the", "Hopkins155", "dataset", "we", "compared", "the", "distribution", "of", "the", "iteration", "number", "when", "the", "process", "converged", "between", "our", "proposed", "method", "in", "the", "Fine", "-", "Tuning", "Step", "and", "RV", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "random voting"}, {"tokens": ["Specifically", ",", "the", "objective", "of", "this", "work", "was", "to", "examine", "the", "potential", "robustness", "of", "the", "RS", "transmission", "method", "in", "multi", "-", "pair", "massive", "MIMO", "relay", "systems", "obeying", "mostly", "to", "the", "FD", "design", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["Conclusion", "In", "conclusion", ",", "the", "experiments", "show", "that", "the", "proposed", "strategy", "is", "able", "to", "generate", "accurate", "and", "robust", "automated", "VAT", "and", "SAT", "segmentations", "in", "water", "-", "fat", "MRI", "scans", "with", "the", "help", "of", "the", "U", "-", "Net", "architecture", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Residual", "Splash", "(", "RS", ")", "is", "an", "extension", "of", "RBP", "for", "multi", "-", "core", "parallelization", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["This", "stems", "from", "the", "fact", "that", "the", "SCM", "representation", "space", "can", "be", "more", "discriminative", "than", "the", "DSCN", "for", "this", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial compositional model"}, {"tokens": ["proposed", "chaotic", "binary", "PSO", "(", "CBPSO", ")", "for", "solving", "the", "ELD", "problems", "of", "micro", "-", "grids", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Section", "sec", ":", "basics", "introduces", "some", "background", "concepts", "on", "STL", "and", "on", "discrete", "topologies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "signal temporal logic"}, {"tokens": ["and", "Table", "show", "the", "comparison", "of", "our", "MSC", "-", "trackers", "with", "several", "deep", "CF", "trackers", "with", "deep", "features", "on", "OTB", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correlation filter"}, {"tokens": ["When", "paired", "with", "word", "distributions", ",", "these", "approaches", "have", "achieved", "promising", "results", "performing", "various", "AA", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["The", "PRR", "is", "indicated", "by", ",", "where", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0], "long_form": "packet reception rate"}, {"tokens": ["With", "rich", "texture", "information", "in", "those", "unlabeled", "SAR", "slices", ",", "a", "deep", "stacked", "convolutional", "auto", "-", "encoders", "is", "trained", "to", "reconstruct", "the", "slices", ",", "generating", "a", "series", "of", "hierarchical", "convolution", "layers", "capable", "of", "extracting", "efficient", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Finally", ",", "we", "demonstrated", "the", "effectiveness", "and", "efficiency", "of", "GPA", "against", "the", "state", "-", "of", "-", "the", "-", "arts", "on", "various", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["The", "LDPC", "has", "not", "been", "implemented", "for", ",", "since", "the", "regularity", "constraints", "would", "have", "given", "either", "a", "diagonal", "matrix", "(", "same", "as", "DI", ")", ",", "or", "a", "relatively", "dense", "matrix", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "direct inspection"}, {"tokens": ["Another", "objective", "was", "to", "propose", "a", "series", "of", "adaptive", "FEC", "-", "based", "content-", "and", "video", "-", "aware", "mechanisms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Our", "proposed", "DBF", "uses", "the", "LTE", "air", "interface", "in", "both", "licensed", "and", "unlicensed", "bands", "via", "the", "LTE", "carrier", "aggregation", "feature", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["ROC", "curves", "are", "well", "suited", "to", "the", "problem", "of", "vibration", "-", "based", "diagnosis", "applications", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Therefore", ",", "we", "introduce", "a", "binary", "variable", ",", "where", ",", "for", "TBS", ",", "HAP", ",", "and", "satellite", "station", ",", "respectively", ",", "is", "equal", "to", "1", "if", "BS", "is", "associated", "with", "user", "over", "the", "RB", "and", "0", "otherwise", ",", "and", "is", "given", "as", "follows", ":", "We", "assume", "that", "each", "BS", "can", "be", "associated", "with", "multiple", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resource blocks"}, {"tokens": ["This", "hybrid", "model", "has", "a", "BF", "multi", "-", "classifier", ",", "an", "AF", "multi", "-", "classifier", ",", "a", "CNN", "model", ",", "and", "a", "final", "multi", "-", "classifier", ",", "as", "shown", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic feature"}, {"tokens": ["The", "results", "based", "on", "the", "ROC", "scores", "are", "shown", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["CF", "is", "mathematically", "similar", "to", "link", "prediction", ",", "where", "the", "goal", "is", "essentially", "matrix", "completion", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["To", "train", "a", "DBN", ",", "typically", "each", "RBM", "is", "pre", "-", "trained", "initially", "from", "the", "bottom", "to", "the", "top", "in", "a", "layer", "-", "wise", "manner", "and", "subsequently", "the", "whole", "network", "is", "fine", "-", "tuned", "with", "supervised", "learning", "methods", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["For", "a", "faster", "implementation", "of", "OLS", ",", "readers", "can", "refer", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["Authors", "enhanced", "the", "accuracy", "of", "classification", "significantly", "for", "SPAM", "and", "CC", "-", "PEV", "up", "to", "10", "percent", ",", "and", "14", "percent", "for", "different", "steganography", "algorithms", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subtractive pixel adjacency matrix"}, {"tokens": ["In", "the", "proposed", "approach", ",", "the", "anti", "-", "predatory", "activity", "and", "the", "foraging", "activity", "have", "been", "used", "to", "help", "the", "particles", "to", "escape", "from", "the", "predators", "in", "the", "classical", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "power system operations"}, {"tokens": ["We", "notice", "that", ",", "in", "most", "noisy", "scenarios", ",", "the", "magnitude", "-", "based", "features", ",", "LMS", "and", "RLMS", ",", "perform", "worse", "than", "the", "phase", "-", "based", "features", ",", "IF", ",", "BPD", ",", "GD", "and", "MGD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "baseband phase difference"}, {"tokens": ["In", "this", "algorithm", ",", "the", "velocity", "of", "each", "particle", "is", "simultaneously", "updated", "using", "PSO", "and", "gravitational", "search", "algorithm", "(", "GSA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["The", "time", "complexity", "of", "OLS", "is", "slightly", "higher", "than", "OMP", "which", "is", "caused", "by", "the", "difference", "in", "the", "atom", "selection", "process", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["At", "each", "time", "slot", ",", "the", "EM", "provides", "the", "energy", "level", "report", "to", "the", "MEC", "server", ",", "through", "the", "pull", "mode", "procedure", "(", "e.g.", ",", "File", "Transfer", "Protocol", ")", ",", "thus", "the", "EB", "level", "is", "known", ",", "enabling", "the", "provision", "of", "the", "required", "computation", "and", "communication", "resources", ",", "i.e.", ",", "the", "VM", "and", "laser", "drivers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy buffer"}, {"tokens": ["In", "this", "paper", ",", "we", "propose", "FatSegNet", ",", "a", "novel", "fully", "automated", "deep", "learning", "pipeline", "based", "on", "our", "CDFNet", "architecture", "to", "localize", "and", "segment", "VAT", "and", "SAT", "on", "abdominal", "Dixon", "MR", "images", "from", "the", "Rhineland", "Study", ",", "an", "ongoing", "large", "population", "-", "based", "cohort", "study", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Regarding", "the", "SRL", "literature", ",", "very", "diverse", "environments", "are", "used", ",", "without", "common", "metrics", "or", "visualizations", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["The", "issue", "of", "legacy", "IS", "interfacing", "with", "new", "projects", "is", "considered", "a", "critical", "success", "factor", "by", "Fui", "-", "Hoon", "Nah", ",", "Lee", "-", "Shang"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["In", "a", "direct", "comparison", ",", "the", "verification", "rate", "on", "PaSC", "equals", "only", "0.22", "at", "0.001", "FAR", ",", "in", "contrast", "to", "the", "more", "controlled", "databases", "MBE", "(", "0.997", ")", ",", "GBU", "(", "0.8", ")", "and", "LFW", "(", "0.54", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "false acceptance rate"}, {"tokens": ["Step", "5", ":", "In", "this", "step", ",", "the", "CAG", "accepts", "the", "EV", "'s", "request", "for", "registration", "and", "generates", "a", "public", "-", "private", "key", "pair", "(", ")", "for", "it", "using", "ECC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["Importantly", ",", "the", "predictive", "GP", "posterior", "distribution", "remains", "accurate", "and", "fitted", "to", "the", "signal", "without", "revisiting", "data", "during", "iterations", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["GS", "*", "-", "a", "simulating", "system", "that", "imitates", "Google", "Scholar", "'s", "ranking", "function", "-", "in", "terms", "of", "Precision", "-", "at-", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "google scholar 's"}, {"tokens": ["The", "MP", "architecture", "improves", "performance", "especially", "when", "small", "metallic", "implants", "are", "dominated", "by", "the", "non", "-", "metal", "regions", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mask pyramid"}, {"tokens": ["It", "is", "because", "that", "the", "LDOF", "framework", "takes", "into", "account", "both", "regular", "optical", "flow", "energy", "and", "the", "feature", "technique", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "large displacement optical flow"}, {"tokens": ["While", "optimization", "of", "the", "display", "path", "in", "Figure", "fig", ":", "landscape", "is", "a", "well", "studied", "problem", ",", "the", "role", "and", "(", "co-)optimization", "of", "the", "ISP", "for", "CNN", "inference", "is", "relatively", "unexplored", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["we", "see", "when", "is", "large", ",", "e.g.", ",", "0.8", ",", "the", "larger", "weight", "is", "allocated", "on", "the", "CF", "task", "to", "optimise", "the", "joint", "likelihood", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "iteration", "in", "avoids", "the", "ill", "-", "conditioned", "covariance", "matrices", "Hansen1998", "involved", "in", "GP", "when", "sampling", "rates", "are", "high", "Steinke2008,Reichert2011", "and", "it", "is", "faster", "than", "direct", "matrix", "inversion", "in", "a", "serial", "implementation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "training", "and", "development", "subsets", "have", "similar", "spoofing", "algorithms", "/", "conditions", "in", "both", "the", "LA", "and", "PA", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "physical access"}, {"tokens": ["Figure", "show", "that", "the", "results", "for", "the", "SDD", "are", "skewed", "toward", "Unsuitable", "for", "the", "search", "tasks", "while", "the", "participants", "found", "the", "TDW", "was", "generally", "well", "suited", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Using", "as", "little", "information", "as", "possible", "(", "i.e.", "DADA", "(", ")", "andno", "communication", "prediction", ")", ",", "the", "policy", "performance", "does", "not", "scale", "with", "morethan", "two", "GPUs", "due", "to", "a", "too", "huge", "amount", "of", "transfers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["In", "this", "context", "we", "would", "also", "like", "to", "point", "out", "that", "a", "textbook", "with", "an", "IS", "-", "orientation", "would", "be", "a", "welcome", "addition", "to", "the", "large", "existing", "variety", "of", "CS", "-", "oriented", "books", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["This", "corollary", "allows", "us", "to", "better", "understand", "why", "the", "addition", "of", "allows", "for", "the", "exploration", "of", "the", "IB", "curve", "in", "deterministic", "scenarios", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "particular", ",", "LR", "was", "tuned", "through", "random", "search", "on", "a", "log", "-", "scale", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "learning rate"}, {"tokens": ["Instead", "of", "using", "weight", "-", "functions", "that", "act", "over", "the", "observed", "data", ",", "we", "introduce", "change", "-", "windows", "influencing", "each", "latent", "GP", "ending", "up", "with", "latent", "processes", "representing", "specific", "sound", "events", "that", "happen", "at", "certain", "segments", "of", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["shows", "a", "realization", "of", "a", "Cox", "Point", "Process", "driven", "by", "PLP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "poisson line process"}, {"tokens": ["We", "denote", "the", "output", "of", "the", "unit", "on", "level", "as", "MAD", "vector", ":", "equation^(m", ")", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["Though", "the", "proposed", "metric", "correlates", "better", "with", "human", "judgments", ",", "there", "is", "still", "scope", "for", "improvement", "especially", "for", "document", "QA", "and", "visual", "QA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0], "long_form": "question answering"}, {"tokens": ["Energy", "Efficiency", "of", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAMEnergy", "efficiency", "is", "the", "ratio", "of", "ergodic", "sum", "channel", "capacity", "(", ")", "and", "the", "total", "transmitted", "power", "by", "the", "BS", "for", "direct", "transmissions", "and", "transmission", "power", "from", "CCU", "for", "relaying", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["This", "last", "problem", "can", "be", "addressed", "by", "using", "multi", "-", "task", "GPR", "(", "MT", "-", "GPR", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0], "long_form": "gaussian process regression"}, {"tokens": ["So", "the", "MD", "strategy", "is", "winning", "for", "player", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["+", "dB.First", ",", "the", "evaluation", "of", "distance", "distribution", "of", "nearest", "LOS", "/", "NLOS", "SBS", "to", "typical", "UE", "and", "association", "probability", "have", "been", "provided", "in", "Figs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "GMM", "classifier", "predicts", "binary", "class", "for", "each", "individual", "patch", "using", "the", "extracted", "and", "values", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Then", "she", "derives", "a", "new", "DH", "output", "for", "the", "next", "root", "KDF", "chain", "with", "her", "new", "ratchet", "private", "key", "to", "derive", "a", "new", "RK", "and", "a", "sending", "CK", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "root key"}, {"tokens": ["PIN", "indexing", "performance"], "acronym_pos": [1, 0, 0], "long_form": "proposal indexing network"}, {"tokens": ["Even", "though", "the", "DMN", "has", "not", "yet", "been", "applied", "to", "our", "task", "of", "structured", "QA", ",", "some", "recent", "works", ",", "such", "as", "the", "relatively", "simple", "embedding", "-", "based", "work", "of", "Bordes", "et", "al", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "SAR", "system", "wase", "able", "to", "personalize", "to", "the", "children", "with", "ASD", "who", "demonstrated", "cognitive", "gains", ",", "supporting", "the", "effectiveness", "of", "the", "approach", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["In", "both", "cases", ",", "the", "proposed", "technique", "shows", "state", "-", "of", "-", "the", "-", "art", "accuracy", "compared", "with", "different", "DCNN", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Here", ",", "it", "is", "particularly", "noted", "that", "all", "selected", "transmit", "antennas", "are", "used", "to", "emit", "AN", "but", "only", "one", "of", "them", "emits", "APM", "symbol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["That", "is", "why", "a", "novel", "scheme", "is", "proposed", "here", "by", "utilizing", "the", "time", "slot", "of", "relaying", "in", "the", "case", "of", "CNOMA", "-", "SWIPT", "-", "PS", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "results", "in", "indicate", "that", "our", "method", "outperformed", "all", "the", "baseline", "methods", "on", "the", "scores", ",", "except", "that", "AdditiveGraphScan", "achieved", "the", "highest", "EMS", "score", "(", "761.08", ")", "on", "the", "water", "network", "data", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elevated mean scan statistic"}, {"tokens": ["SRS", "at", "component", "interface", "can", "be", "obtain", "by", "In", "this", "example", ",", "between", "equipment", "and", "component", "interfaces", "is", "extracted", "from", "the", "same", "FEM", "model", "as", "shown", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["In", "this", "paper", ",", "we", "tackle", "the", "cloud", "detection", "problem", "by", "presenting", "a", "framework", "based", "on", "deep", "pyramid", "network", "architecture", "(", "DPN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "deep pyramid network"}, {"tokens": ["Though", ",", "sulemBLEU2018", "recently", "demonstrated", "that", "BLEU", "is", "inappropriate", "for", "the", "evaluation", "of", "TS", "approaches", "when", "sentence", "splitting", "is", "involved", ",", "since", "it", "negatively", "correlates", "with", "structural", "simplicity", ",", "thus", "penalizing", "sentences", "that", "present", "a", "simplified", "syntax", ",", "and", "presents", "no", "correlation", "with", "the", "grammaticality", "and", "meaning", "preservation", "dimensions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["We", "train", "the", "model", "for", "epochs", "with", "early", "stopping", "patience", "of", "for", "both", "the", "LA", "and", "PA", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "physical access"}, {"tokens": ["In", "PA", ",", "both", "the", "training", "and", "development", "sets", "has", "bonafide", "utterances", ",", "and", "and", "spoofed", "utterances", "in", "the", "training", "and", "development", "sets", ",", "respectively", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["Unlike", "VQA", ",", "which", "uses", "a", "knowledge", "graph", "to", "extract", "better", "image", "features", "and", "hence", "better", "answer", "questions", "about", "the", "image", ",", "CNet", "-", "NIC"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "neural image caption"}, {"tokens": ["LearningThe", "first", "FL", "design", "aimed", "to", "protect", "the", "data", "privacy", "by", "ensuring", "each", "participant", "would", "keep", "its", "data", "locally", "and", "uniquely", "transmit", "model", "parameters", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["One", "suitable", "way", "to", "solve", "this", "problem", "is", "to", "use", "the", "zero", "crossing", "course", "deviation", "as", "an", "intuitive", "criterion", "to", "obtain", "the", "segmentation", "of", "paths", ",", "and", "apply", "GMM", "to", "cluster", "the", "selected", "features", "of", "the", "segmented", "path", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["theoremTheorem[section]corollary[theorem]Corollarylemma[theorem]Lemmaconjecture[theorem]Conjectureproposition[theorem]Propositiondefinition[theorem]Definitionexample[theorem]Exampleremark[theorem]Remarkclaim[theorem]Claimnotation[theorem]Notationopenproblem[theorem]Open", "Problem", "Fast", "Actively", "Secure", "OT", "Extension", "for", "Short", "Secrets", "Arpita", "Patra", "Indian", "Institute", "of", "Science", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "random", "variable", "is", "dependent", "on", "the", "PLP", "i.e.", ",", "depends", "on", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["Firstly", "we", "do", "SVD", "to", "the", "channel", "between", "the", "BS", "and", "th", "user", ",", "and", "the", "data", "stream", "is", "desired", "to", "be", "transmitted", "through", "the", "strongest", "channel", "path", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "word", "for", "'", "lamb", "'", "(", "*", "uarna-", ")", "shows", "this", "behavior", "across", "the", "board:[noitemsep]MP", "warrag", "NP", "barra", ";", "Parthian", "warrag", ";", "Awromani", "vaera", ";", "Balochi", "gwarag", ";", "S", "Bashkardi", "vark", ";", "Gurani", "varala", ",", "valala", "("], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Figure", "shows", "a", "few", "noisy", "sample", "patches", "in", "SEM", "images", "with", "the", "corresponding", "segmentations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Figure", "also", "compares", "the", "impact", "of", "varying", "the", "kernel", "bandwidth", "parameters", "for", "functional", "varifolds", "using", "similarity", "angle", "between", "pairs", "of", "these", "selected", "fibers", "(", "top", "right", ":", "CST", "(", "R", ")", ",", "bottom", "left", ":", "CC", ",", "bottom", "right", ":", "IFOF", "(", "R", ")", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "corpus callosum"}, {"tokens": ["For", "Pro", "-", "InGame", "data", ",", "the", "highest", "accuracy", "is", "75.22", "using", "LR", "with", "a", "single", "time", "-", "series", "feature", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["More", "specifically", ",", "the", "SAR", "land", "cover", "classification", "trained", "model", "performs", "better", "in", "higher", "layers", "due", "to", "the", "large", "scale", "dataset", "with", "abundant", "SAR", "image", "information", "and", "the", "similar", "task", "of", "classification", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Due", "to", "the", "fact", "that", "groups", "possess", "a", "large", "amount", "of", "NSS", "information", "of", "natural", "images", ",", "to", "reduce", "residual", ",", "a", "good", "estimation", "of", "the", "group", "sparse", "coefficients", "of", "the", "original", "image", "is", "obtained", "by", "the", "external", "NSS", "prior", "based", "on", "GMM", "learning", "and", "the", "group", "sparse", "coefficients", "of", "noisy", "image", "is", "used", "to", "approximate", "the", "estimation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["What", "'s", "more", ",", "the", "number", "of", "cooperative", "SBSs", "of", "UE", "is", "calculated", "byThe", "average", "number", "of", "cooperative", "SBSs", "is", "further", "calculated", "byLetting", ",", "the", "average", "achievable", "rate", "with", "distance", "constraint", "considering", "the", "same", "number", "of", "cooperative", "SBSs", "is", "expressed", "aswithThe", "increment", "in", "the", "average", "achievable", "rate", "compared", "the", "received", "signal", "power", "constraint", "with", "the", "distance", "constraint", "considering", "same", "number", "of", "cooperative", "SBSs", "is", "given", "byNetwork", "Energy", "EfficiencyThe", "average", "achievable", "rate", "can", "be", "improved", "by", "adopting", "SBS", "cooperation", "strategies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["The", "smallest", "CC", "phases", "for", "the", "S3", "(", ")", ",", "and", "S4", "(", ")", "batteries", "are", "68", "and", "10", "SOC", "respectively", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["By", "incorporating", "DMII", ",", "the", "average", "unknown", "word", "rate", "in", "testing", ",", "using", "the", "IFD", "ten", "-", "fold", "split", ",", "drops", "from", "6.8", "to", "1.1", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "icelandic frequency dictionary"}, {"tokens": ["By", "using", "FJ", ",", "generic", "classes", "are", "formalised", "in", ",", "a", "true", "module", "system", "is", "constructed", "in", ",", "inner", "classes", "are", "modelled", "in", ",", "the", "existence", "of", "principal", "typings", "is", "shown", "in", ",", "transactional", "mechanisms", "are", "discussed", "in", ",", "union", "types", "are", "proposed", "in", ",", "cyclic", "objects", "with", "coinductive", "operations", "are", "introduced", "in", ",", "a", "co", "-", "contextual", "type", "checker", "is", "described", "in", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "featherweight java"}, {"tokens": ["This", "property", "is", "different", "from", "conventional", "adaption", "laws", "based", "on", "low", "-", "pass", "filters", ",", "which", "begin", "to", "adjust", "the", "gains", "only", "after", "the", "convergence", "of", "STA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["Full", "description", "of", "the", "components", "of", "the", "system", "modeled", "by", "AML", "is", "given", "in", "Figures", "and", "of", "Appendix", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["The", "metaphor", "which", "we", "chose", "to", "depict", "in", "our", "analysis", "is", "that", "of", "RS", "as", "'", "traps", "'", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["CNN", "architecture", "for", "SRL", "methods", "."], "acronym_pos": [0, 0, 0, 1, 0, 0], "long_form": "state representation learning"}, {"tokens": ["The", "WIAT", "-", "II", "was", "used", "as", "a", "pre", "-", "post", "comparison", "measure", "to", "determine", "achievement", "gains", "over", "the", "SAR", "intervention", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["We", "seek", "to", "understand", "if", "this", "increased", "robustness", "is", "caused", "by", "differences", "between", "the", "student", "and", "teacher", "architectures", ",", "and", "so", "we", "use", "ARD", "to", "distill", "a", "teacher", "network", "onto", "a", "student", "network", "with", "an", "identical", "architecture", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["In", "the", "extended", "work", ",", "two", "novel", "schemes", ",", "maximum", "group", "receive", "power", "plus", "null", "-", "space", "projection", "scheme", "and", "Max", "-", "SLNR", "plus", "maximum", "-", "AN", "-", "leakage", "-", "and", "-", "noise", "ratio", "scheme", ",", "were", "proposed", "to", "improve", "the", "secrecy", "sum", "-", "rate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Both", "coordinate", "and", "subordinate", "clauses", ",", "as", "well", "as", "various", "types", "of", "phrasal", "elements", "are", "addressed", "by", "our", "TS", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "tree structures"}, {"tokens": ["The", "channel", "gain", "between", "the", "BS", "and", "user", "in", "epoch", "is", "denoted", "by", ",", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["On", "the", "other", "hand", ",", "we", "notice", "a", "notable", "gap", "achieved", "by", "using", "the", "GP", "method", "instead", "of", "the", "dual", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["In", "this", "experiment", ",", "NN", "models", "are", "used", "to", "segment", "cardiac", "cine", "MR", "images", "in", "the", "dataset", "described", "in", "Sec", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["Similar", "to", "DE", "of", "digit", ",", "the", "DE", "of", "digit", "also", "increases", "with", "width", "and", "plateaus", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["We", "notice", "that", "the", "number", "of", "dimensioned", "PRBs", "for", "outdoor", "users", "is", "always", "higher", "when", "users", "are", "modeled", "according", "to", "Cox", "process", "driven", "by", "PLP", "than", "spatial", "PPP", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["Carina", "nebula", "mosaic", "from", "http://www.hubblesite.org].", "Comparison", "of", "the", "success", "rates", "of", "the", "TDW", "and", "SDD", "for", "10", "non", "-", "astronomers", "(", "top", "panel", ")", ",", "12", "astronomers", "(", "middle", "panel", ")", ",", "and", "eight", "collaborative", "pairs", "of", "non", "-", "astronomers", "(", "bottom", "panel", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Perpendicular", "Vegetation", "Index", "(", "PVI", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0], "long_form": "perpendicular vegetation index"}, {"tokens": ["[", "CC", ",", "1000", "runs", ",", "24", "clust", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "connected caveman"}, {"tokens": ["For", "example", ",", "if", "an", "institution", "has", "a", "PP", "(", ")", "of", "and", "the", "MAD", "is", "percentage", "points", ",", "then", "in", "half", "of", "the", "cases", "switching", "to", "metrics", "would", "yield", "an", "outcome", "equivalent", "to", "a", "PP", "(", ")", "between", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "median absolute difference"}, {"tokens": ["The", "parallel", "execution", "of", "PSO", "executed", "in", "a", "decomposed", "network", "procedure", "is", "found", "to", "explore", "the", "local", "search", "space", "effectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Denote", "as", "the", "welfare", "-", "minimizing", "SSS", "under", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "stochastically stable states"}, {"tokens": ["In", "our", "work", "CDA", "is", "applied", "to", "the", "GEI", "features", "of", "the", "robust", "human", "body", "of", "the", "training", "dataset", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "canonical discriminant analysis"}, {"tokens": ["We", "obtained", "a", "calibration", "improvement", "over", "TS", "on", "the", "first", "hyperparameter", "search", "in", "many", "of", "the", "experiments", "performed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature scaling"}, {"tokens": ["Following", "the", "previous", "workaj16", ",", "we", "measure", "the", "performance", "of", "GPA", ",", "HARP", ",", "and", "Random", "in", "micro", "-", "F1", "score", "and", "macro", "-", "F1", "score", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["It", "can", "be", "seen", "that", "both", "the", "proposed", "system", "(", "TPIB", "-", "ITL", ")", "and", "the", "TPIB", "system", "outperform", "the", "baseline", "IB", "system", "in", "most", "cases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["DMD", "isTo", "illustrate", ",", "we", "consider", "an", "MPC", "problem", "with", "a", "discrete", "control", "space", "and", "use", "the", "categorical", "distribution", "as", "the", "basic", "control", "distribution", "in", "eq", ":", "independent", "control", "distribution", ",", "i.e.", ",", "we", "set", ",", "where", "is", "the", "probability", "of", "choosing", "each", "control", "among", "at", "the", "predicted", "time", "step", "and", "denotes", "the", "probability", "simplex", "in", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["However", "for", "the", "time", "constant", ",", "BOA", "has", "a", "higher", "value", "as", "compared", "to", "GA", "and", "DE", "but", "registers", "the", "same", "value", "of", "as", "compared", "to", "these", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Now", "the", "key", "question", "is", "how", "to", "derive", "the", "gradient", "of", "MAD", "vector", "and", "how", "to", "interpret", "its", "functionality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["Discussion", "and", "ConclusionsIn", "this", "study", ",", "we", "proposed", "an", "augmented", "RNN", "model", "that", "can", "easily", "boost", "an", "existing", "RNN", "session", "model", "by", "estimating", "high", "-", "order", "user", "-", "contextual", "preference", "using", "the", "PNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "product - based neural network"}, {"tokens": ["Performance", "of", "various", "classifiers", "(", "LR", ",", "NB", ",", "RF", ",", "SVM", ")", "using", "the", "features", "derived", "from", "all", "four", "architectures", "AlexNet", ",", "GoogLeNet", ",", "VGG", ",", "and", "ResNet", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["It", "is", "worth", "mentioning", "that", "one", "source", "of", "power", "saving", "is", "due", "to", "centralizing", "the", "processing", "at", "the", "CC", "and", "taking", "advantage", "multiplexing", "gain", "among", "all", "cells", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["An", "interesting", "choice", "is", "the", "quadratic", "link", "function", "of", "for", "which", "integrations", "over", "the", "data", "domain", ",", "which", "are", "necessary", "for", "sparse", "GP", "inference", ",", "can", "be", "(", "for", "specific", "kernel", ")", "computed", "analytically.(For", "a", "frequentist", "nonparametric", "approach", "to", "this", "model", ",", "see", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["For", "the", "CNS", "dataset", ",", "extraversion", "is", "the", "most", "important", "predictor", "of", "the", "first", "principal", "component", ",", "while", "openness", ",", "extraversion", "and", "neuroticism", "account", "for", "the", "second", "component", "(", "see", "Table", "and", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["Performance", "of", "three", "combinations", "of", "submissions", "of", "the", "RUSSE", "shared", "task", "compared", "to", "the", "best", "scores", "for", "the", "HJ", "/", "RT", "/", "AE", "datasets", "across", "all", "submissionsRDT", ":", "Russian", "Distributional", "ThesaurusWhile", "four", "resources", "presented", "above", "are", "accurate", "and", "represent", "different", "types", "of", "semantic", "relations", ",", "their", "coverage", "(", "222", "-", "1519", "source", "words", ")", "makes", "them", "best", "suited", "for", "evaluation", "and", "training", "purposes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ruthes"}, {"tokens": ["Con", "-", "TS", "-", "RTP", "with", "Improved", "Reliability", "ConstraintsIn", "order", "for", "the", "aggregator", "to", "ensure", "safe", "operation", "of", "the", "distribution", "grid", "while", "running", "the", "Con", "-", "TS", "-", "RTP", "algorithm"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["The", "objective", "of", "this", "study", "is", "to", "bridge", "this", "gap", "by", "proposing", "a", "new", "learning", "framework", "for", "the", "PSO", "and", "its", "variants", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["While", "it", "remains", "to", "be", "seen", "which", "of", "the", "many", "variants", "of", "LSTMs", "can", "learn", "SP", "languages", "well", ",", "this", "result", "speaks", "to", "the", "larger", "point", "that", "the", "judicial", "use", "of", "formal", "language", "theory", "can", "illuminate", "the", "inner", "workings", "of", "RNNs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["The", "distributions", "of", "capillary", "diameter", ",", "length", ",", "and", "tortuosity", "varied", "little", "between", "young", "and", "old", "mice", "or", "between", "WT", "and", "AD", "genotype", "(", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "wild type"}, {"tokens": ["Specifically", ",", "it", "first", "selects", "the", "first", "atom", "and", "then", "select", "the", "remaining", "(", ")", "atoms", "based", "on", "OLS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "orthogonal least square"}, {"tokens": ["Spectral", "patches", "for", "the", "HMM", "-", "GMM", "modelling", "were", "taken", "from", "the", "non", "-", "time", "-", "differenced", "spectrogram", ",", "of", "size", "five", "frames", "after", "the", "frame", "under", "consideration", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["]", "images", "/", "clustering", "/", "aPY_ACC[CIFAR10", "]", "fig", ":", "ACC_CIFAR10", "images", "/", "clustering", "/", "CIFAR10_ACCClustering", "results", "(", "ACC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "accuracy"}, {"tokens": ["Wrapper", "-", "based", "FS", "is", "a", "special", "kind", "of", "filter", "-", "based", "FS", "such", "that", "wrapper", "-", "based", "FS", "has", "capability", "of", "using", "some", "hyper", "-", "parameter", "function", "for", "evaluation", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feature selection"}, {"tokens": ["This", "produces", "a", "model", "with", "a", "ROC", "curve", "containing", "a", "greater", "area", "underneath", "than", "any", "of", "the", "other", "models", "that", "were", "explored", "in", "this", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "channel", "path", "loss", "is", "modeled", "as", "(", "dB", ")", ",", "where", "(", "m", ")", "is", "the", "distance", "between", "the", "vehicles", "/", "eavesdropper", "and", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["DTP", "and", "FPL", "predict", "object", "centroids", "only", ",", "so", "IOU", "metrics", "are", "not", "applicable", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic trajectory predictor"}, {"tokens": ["Automating", "OARs", "segmentation", "has", "the", "benefit", "of", "both", "reducing", "the", "time", "and", "improving", "the", "quality", "of", "RT", "planning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "radiation therapy"}, {"tokens": ["Results", "show", "that", "BNN", "improves", "upon", "non", "-", "Bayesian", "baselines", "by", "a", "large", "margin", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian neural networks"}, {"tokens": ["In", "order", "to", "decode", "the", "confidential", "messages", "sent", "from", "the", "BS", "to", "all", "destination", "users", ",", "the", "eavesdroppers", "are", "assumed", "to", "locate", "closer", "to", "the", "BS", "than", "the", "destination", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["An", "illustration", "of", "the", "importance", "of", "the", "MGM", "GAN", "in", "such", "cases", "is", "evident", "when", "looking", "at", "what", "the", "transformations", "did", "to", "second", "cell", "type", "population", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["app12", "Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs", "where", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["Research", "questions", "RQ1", "and", "RQ2", "investigated", "how", "the", "casters", "seek", "information", "onscreen", ",", "so", "we", "used", "IFT", "constructs", "to", "discover", "the", "types", "of", "information", "casters", "sought", "and", "how", "they", "unearthed", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information foraging theory"}, {"tokens": ["A", "base", "station", "(", "BS", ")", "or", "a", "VUE", "can", "act", "as", "the", "centralized", "controller", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "order", "to", "evaluate", "the", "method", "with", "limited", "target", "data", "and", "balance", "the", "training", "numbers", "of", "each", "category", ",", "we", "select", "the", "elaborated", "types", "of", "Cargo", ",", "Container", "Ship", "and", "Bulk", "Carrier", "of", "GRD", "mode", "(", "with", "resolution", "of", "10", "m", ")", "and", "VV", "polarization", "in", "our", "experiments", ",", "filtering", "those", "ship", "chips", "with", "the", "size", "larger", "than", "70", "70", "pixel", "to", "ensure", "the", "sufficient", "image", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ground range detected"}, {"tokens": ["To", "ensure", "that", "the", "estimated", "CCR", "is", "not", "biased", "by", "avoidable", "issues", "in", "the", "sample", "preparation", "and", "acquisition", "steps", ",", "the", "images", "listed", "in", "have", "been", "removed", "from", "the", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["Goodness", "of", "fitFor", "classical", "ODE", ",", "the", "goodness", "of", "fit", "indicator", "measures", "how", "close", "the", "estimated", "O", "-", "D", "demand", "mean", "can", ",", "if", "loaded", "into", "the", "network", "following", "a", "deterministic", "traffic", "assignment", "model", "(", "UE", "or", "SUE", ")", ",", "reproduce", "the", "observed", "traffic", "conditions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equilibrium"}, {"tokens": ["Our", "linear", "convergence", "rate", "of", "MP", "is", "expressed", "in", "terms", "of", "a", "new", "quantity", "called", "the", "minimal", "intrinsic", "directional", "width", "of", "the", "atoms", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["Adaptive", "FS", "-", "Table", "shows", "the", "LR", "+", "-norm", "models", "performance", "comparison", "of", "adaptive", "and", "global", "approaches", "for", "feature", "selection", "with", "all", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["In", "the", "(", ")", "-th", "(", ")", "phase", "with", "allocated", "time", ",", "all", "MTCGs", "in", "simultaneously", "transmit", "the", "decoded", "data", "from", "the", "served", "MTCDs", "to", "the", "BS", "by", "using", "the", "NOMA", "strategy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "intuition", "behind", "the", "proposed", "approach", "is", "that", "a", "term", "will", "be", "out", "of", "-", "context", "in", "a", "given", "bag", "-", "of", "-", "terms", "if", "the", "MACS", "score", "of", "terms", "minus", "the", "given", "term", "is", "low", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean average conceptual similarity"}, {"tokens": ["In", ",", "the", "authors", "proposed", "an", "AN", "-", "aided", "zero", "forcing", "synthesis", "approach", "for", "secure", "multi", "-", "beam", "DM", ",", "and", "the", "dynamic", "multi", "-", "beam", "DM", "was", "achieved", "by", "randomly", "changing", "the", "AN", "vector", "at", "the", "symbol", "rate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Phl", "pl", ",", "MMP", "pr", "/parr/", "NP", "par(r", ")", "'"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["recently", "proposed", "a", "principled", "approach", "to", "incorporate", "these", "ideas", "into", "GP", "modeling", "and", "were", "able", "to", "outperform", "other", "robust", "models", "in", "long", "-", "term", "predictions", "and", "showcase", "improved", "performance", "for", "model", "-", "based", "policy", "search", "on", "a", "real", "robot", "with", "noise", "and", "latencies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Formalizing", "Personalization", "in", "SAR", "To", "address", "the", "challenge", "of", "long", "-", "term", "personalization", "in", "SAR", "in", "a", "principled", "way", ",", "we", "present", "a", "solution", "to", "the", "problem", "as", "a", "controller", "-", "based", "environment", "which", "we", "define", "as", "hierarchical", "human", "-", "robot", "learning", "(", "hHRL", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "continuous", "version", "cNrGA", "(", "where", "'", "c", "'", "stands", "for", "continuous", ")", "inherits", "the", "BSP", "tree", "to", "store", "the", "entire", "search", "history", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["We", "report", "both", "the", "DP", "rates", "at", "the", "conventional", "threshold", "of", "20", "pixels", "(", "DPR", ")", "and", "the", "OS", "rates", "at", "the", "threshold", "of", "0.5", "(", "OSR", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "overlap success"}, {"tokens": ["For", "ID", "is", "equivalent", "to", "BM", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["New", "Persian", "and", "related", "dialects", "tend", "to", "show", "zVb", "or", "zVw", "(", "e.g.", ",", "NP", "zaban", ",", "zuwan", "'", "tongue", "'", "*", "hijuana-", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["However", ",", "the", "duration", "of", "each", "session", "varied", "considerably", ",", "ranging", "from", "176", "frames", "in", "emotion", "processing", "to", "401", "frames", "in", "working", "memory", ",", "with", "TR", "of", "5520", "ms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "temporal resolution"}, {"tokens": ["[", "GPS", "]"], "acronym_pos": [0, 1, 0], "long_form": "global positioning system"}, {"tokens": ["Note", "that", "the", "first", "atom", "selected", "by", "OMP", "is", "identical", "to", "OLS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "orthogonal least square"}, {"tokens": ["GP", "-", "UCB", "with", "Future", "Variance"], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["It", "is", "worth", "recalling", "that", "HR", "images", "have", "annotations", "associated", "with", "them", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["avgredundancyequationViewFEC", "Performance", "Evaluation", "and", "Resultssec", ":", "vfec", ":", "evaluationThe", "main", "objective", "of", "the", "ViewFEC", "mechanism", "is", "to", "reduce", "the", "network", "overhead", "introduced", "by", "FEC", "-", "based", "schemes", "while", "maintaining", "videos", "with", "an", "acceptable", "level", "of", "quality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Orbit", "Selection", "for", "Descent", "InitiationFollowing", "the", "choice", "of", "an", "orbital", "descent", "strategy", "(", "no", "direct", "descent", "from", "LTT", ")", ",", "parameters", "of", "the", "descent", "orbit", "were", "studied", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lunar transfer trajectory"}, {"tokens": ["When", "the", "STA", "'s", "backoff", "counter", "reaches", "zero", ",", "a", "function", "that", "considers", "the", "number", "of", "STAs", "in", "the", "network", ",", "the", "current", "channel", "state", "and", "the", "MPR", "capability", "of", "the", "AP", "is", "used", "to", "schedule", "STAs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["LTE", "and", "WiFi", "represent", "the", "air", "interfaces", "used", "in", "a", "band", ";", "blank", "box", "means", "the", "spectrum", "is", "not", "used", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Since", "SAR", "contexts", "often", "involve", "long", "-", "term", "goals", ",", "success", "is", "better", "assessed", "via", "intermediate", "measures", "of", "progress", "toward", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["t]The", "relationship", "between", "the", "target", "task", "(", "OpenSARShip", "recognition", ")", "and", "different", "source", "tasks", "(", "ImageNet", "classification", ",", "SAR", "scene", "image", "reconstruction", ",", "SAR", "scene", "image", "classification", ",", "MSTAR", "target", "recognition", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["The", "TPIB", "-", "ITL", "system", "showed", "an", "absolute", "improvement", "of", "2.3", "with", "respect", "to", "the", "baseline", "IB", "system", "on", "AMI-2", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Experimental", "SetupPhrase", "Indexing", "Network", "(", "PIN", ")"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0], "long_form": "phrase indexing network"}, {"tokens": ["Contrastive", "divergence", "(", "CD", ")", "is", "a", "training", "technique", "used", "for", "RBMs", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "contrastive divergence"}, {"tokens": ["In", "this", "paper", ",", "first", ",", "describe", "characteristics", "and", "essential", "services", "of", "AR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "augmented reality"}, {"tokens": ["The", "overall", "AR", "improvement", "of", "merging", "all", "strategies", "could", "obtain", "a", "recall", "of", "74.22", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average recall"}, {"tokens": ["Nikmehr", "and", "Ravadanegh", ",", "proposed", "the", "optimum", "power", "dispatch", "of", "micro", "-", "grids", "considering", "probabilistic", "model", "using", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "power system operations"}, {"tokens": ["Table", "provides", "experimental", "results", "showing", "that", "the", "proposed", "multi", "-", "task", "network", "can", "handle", "lost", "modalities", ",", "achieving", "similar", "BA", "score", "as", "when", "separate", "models", "for", "each", "modality", "are", "developed", "(", "see", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "balanced accuracy"}, {"tokens": ["The", "Aitor", "and", "HSCNN+", "are", "two", "recent", "DCNN", "based", "state", "-", "of", "-", "the", "-", "art", "SSR", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["To", "implement", "set", "operations", "over", "the", "std::vector", "data", "structure", ",", "we", "keep", "the", "values", "sorted", "and", "make", "use", "of", "the", "functions", "provided", "by", "STL", "(", "std::set_intersection", ",", "std::set_union", ",", "std::set_difference", ",", "std::set_symmetric_difference", ",", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard template library"}, {"tokens": ["In", "the", "downlink", ",", "a", "Group", "RTS", "is", "used", "to", "signal", "the", "selected", "STAs", ",", "which", "reply", "sequentially", "with", "a", "CTS", "before", "the", "AP", "transmits", "to", "them", "simultaneously", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["C.U.", "Castellanos", ",", "D.L.", "Villa", ",", "C.", "Rosa", ",", "K.I.", "Pedersen", ",", "F.D.", "Calabrese", ",", "Per", "-", "Henrik", "Michaelsen", "and", "J.", "Michel", ",", "\"", "Performance", "of", "Uplink", "Fractional", "Power", "Control", "in", "UTRAN", "LTE", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "long term evolution"}, {"tokens": ["With", "only", "the", "upscattering", "partitioned", ",", "the", "downscatter", "only", "groups", ",", "which", "are", "half", "of", "the", "groups", "in", "this", "case", ",", "are", "always", "solved", "by", "every", "energy", "set", "solved", "with", "GS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gauss seidel"}, {"tokens": ["a", ")", "and", "ANN", "(", "Fig", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["However", ",", "in", "general", ",", "the", "mean", "field", "approach", "provides", "good", "results", ",", "as", "illustrated", "in", "figure", ",", "where", "we", "show", "how", "many", "of", "the", "tested", "configurations", "outperformed", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "temperature scaling"}, {"tokens": ["The", "combined", "datasets", "were", ":", "AT", "and", "ATIS", "IntAT", "and", "ClassicLitAT", "and", "CM", "and", "DFG", "and", "DT", "and", "NYR", "10", "and", "SDC", "and", "TEATIS", "Int", "and", "ClassicLitATIS"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "corporate messaging"}, {"tokens": ["Blockchain", "'", "has", "unequivocally", "been", "the", "fastest", "growing", "DSA", "skill", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["Improving", "the", "speed", "of", "ARD", "by", "reducing", "the", "number", "of", "attack", "stepsAnother", "way", "to", "improve", "the", "speed", "of", "ARD", "training", "is", "to", "reduce", "the", "number", "of", "attack", "steps", "in", "order", "to", "reduce", "the", "number", "of", "gradient", "calculations", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["In", "this", "section", ",", "we", "present", "our", "approaches", "to", "pre", "-", "process", "abstracts", "of", "the", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Wi", "-", "Fi", "AP", "1", "and", "Wi", "-", "Fi", "AP", "2", "are", "placed", "at", "distances", "of", "6", "feet", "and", "15", "feet", "from", "the", "LTE", "-", "U", "BS", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["At", "(", "with", "vaccinating", "720", "nodes", "out", "of", "total", "364", "K", "nodes", ")", ",", "the", "average", "outbreak", "size", "for", "RV", "strategy", "is", "about", "624", "infections", "in", "the", "DDT", "network", "and", "912", "infections", "in", "the", "GDT", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["We", "train", "these", "baseline", "QA", "models", "on", "DRCD", "training", "set", "and", "compare", "the", "performance", "between", "DRCD", "dev", "set", "and", "ODSQA", "testing", "set", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["For", "example", ",", "if", "the", "end", "user", "is", "looking", "for", "the", "'", "nearby", "Italian", "restaurant", "'", ",", "QA", "systems", "suffice", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["a", "show", "that", "the", "margin", "of", "defeat", "for", "our", "method", "against", "CF", "-", "based", "recommendations", "is", "considerably", "smaller", "in", "the", "uninterestedness", "question", ",", "which", "points", "towards", "the", "gap", "between", "our", "method", "and", "CF", "-", "based", "recommendations", "being", "smaller", "than", "the", "gap", "between", "the", "popularity", "-", "based", "baselines", "and", "our", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "practical", "difference", "is", ",", "while", "the", "SBM", "so", "far", "and", "the", "latent", "feature", "model", "allow", "one", "and", "multiple", "1", "'s", "in", "each", ",", "respectively", ",", "the", "MMSBMs", "allow", "non", "-", "binary", "and", "non", "-", "negative", "weights", "in", ",", "subject", "to", "the", "constraint", "that", "these", "weights", "sum", "to", "1", "for", "each", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Even", "worse", ",", "the", "ontological", "nature", "of", "CDs", "would", "be", "affected", "by", "events", "that", "had", "no", "causal", "connection", "to", "the", "CD", "and", "did", "not", "change", "its", "structure", "in", "any", "way", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "chemical diagram"}, {"tokens": ["This", "was", "caused", "by", "the", "fact", "that", "CDA", "'s", "name", "was", "presented", "unabbreviated", ":", "Christen", "Democratisch", "Appel", ",", "which", "was", "the", "only", "party", "with", "a", "special", "character", "(", "e", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "christen democratisch appel"}, {"tokens": ["The", "TIM", "frame", "tells", "a", "mobile", "client", "whether", "the", "AP", "has", "some", "buffered", "data", "for", "the", "mobile", "device", "or", "not", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Related", "WorkThe", "idea", "of", "using", "neural", "networks", "to", "estimate", "the", "outcome", "of", "an", "FEM", "simulation", "is", "not", "new", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["Average", "precision", "(", "AP", ")", "for", "object", "detection", "on", "the", "ILSVRC", "val2", "set", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["In", "addition", ",", "the", "proposed", "NOMA", "-", "OAM", "-", "MDMA", "scheme", "provides", "significantly", "SC", "than", "other", "compared", "schemes", "for", "higher", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["Quite", "different", "from", "the", "English", "SRL", ",", "we", "found", "that", "labels", "confusion", "happens", "less", "frequently", "than", "other", "error", "types", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["For", "example", ",", "SAR", "has", "helped", "participants", "develop", "motor", ",", "behavioral", "and", "cognitive", "skills", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["To", "avoid", "it", ",", "we", "adapt", "the", "continual", "GP", "prior", "idea", "within", "the", "predictive", "expressions", "to", "the", "multiple", "output", "setting", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Using", "PVC", "or", "varying", "the", "beam", "voltage", "of", "an", "SEM", ",", "a", "reverse", "engineer", "can", "distinguish", "between", "the", "active", "cell", "and", "filler", "cells", "due", "to", "variation", "in", "doping", "concentration", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["As", "for", "STL", "formulae", ",", "our", "algorithms", "work", "with", "a", "bottom", "-", "up", "approach", "on", "the", "syntax", "tree", "of", ",", "iteratively", "computing", "the", "temporal", "signals", "of", "each", "subformula", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "signal temporal logic"}, {"tokens": ["When", "the", "packets", "per", "round", "is", "set", "to", "30", "and", "the", "network", "size", "is", "increased", "to", "60", ",", "DE", "-", "based", "deployment", "achieves", "almost", "twice", "as", "GSA", ",", "and", "around", "more", "than", "the", "ABC", "-", "based", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["UAV", "ApplicationsSearch", "and", "Rescue", "(", "SAR", ")"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0], "long_form": "search and rescue"}, {"tokens": ["Corresponding", "to", "CF", "task", ",", "and", "here", "represent", "user", "and", "publisher", "features", "'", "weights", "and", "latent", "vectors", ",", "while", "and", "are", "separately", "depicted", "to", "represent", "ad", "features", "'", "weights", "and", "latent", "vectors", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "objective", "function", "is", "constructed", "by", "considering", "both", "target", "-", "generation", "and", "attention", "-", "focusing", "as", "follows", ":", "with", "a", "tunable", "parameter", "(", ")", ",", "which", "trades", "off", "the", "impact", "of", "AN", "and", "FN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["FSCP", "is", "compared", "with", "2", "reference", "cases", "where", "files", "are", "cached", "at", "EC", "(", "1", ")", "and", "CC", "(", "2", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Computation", "and", "Transmission", "Model-2.5emThe", "FL", "procedure", "between", "users", "and", "the", "BS.-2emThe", "FL", "procedure", "between", "the", "users", "and", "their", "serving", "BS", "is", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["TS", "has", "been", "shown", "to", "be", "empirically", "superior", "in", "comparison", "to", "UCB", "based", "algorithms", "for", "various", "MAB", "problems", "byNIPS11_chapelle2011empirical", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Note", "that", "the", "solid", "yellow", "circle", "denotes", "the", "performance", "of", "ECS", "-", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["In", "our", "first", "subset", "of", "experiments", ",", "we", "evaluate", "the", "performance", "of", "the", "continual", "GP", "approach", "for", "the", "case", "of", "single", "-", "output", "scenarios", "where", "streaming", "data", "is", "real", "-", "valued", ",", "assumed", "Gaussian", "distributed", "and", "we", "aim", "to", "perform", "sequential", "non", "-", "linear", "regression", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["G", "-", "CTS", "is", "sent", "out", "by", "the", "AP", "when", "the", "number", "of", "available", "antennas", "reaches", "zero", "or", "the", "duration", "of", "the", "-nd", "contention", "round", "drains", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Similarly", ",", "a", "study", "presented", "DSA", "and", "ECDSA", "algorithms", "in", "detail", "and", "discussed", "that", "these", "algorithms", "become", "unsuitable", "for", "signing", "messages", "(", "integrity", ")", "if", "applied", "incorrectly", ",", "as", "this", "study", "has", "focused", "on", "the", "parameters", "validation", "of", "DSA", "/", "ECDSA", "to", "ensure", "strong", "security", "for", "these", "algorithms", "against", "different", "attacks", ";", "also", ",", "the", "author", "proved", "that", "these", "algorithms", "become", "strong", "if", "the", "parameters", "are", "well", "-", "validated", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "digital signature algorithm"}, {"tokens": ["As", "the", "left", "-", "half", "part", "of", "'", "K", "'", "looks", "like", "a", "'", "1", "'", ",", "the", "AN", "model", "outputs", "a", "'", "1", "'", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["Since", "CUB", "is", "mostly", "bounded", "by", "atomic", "operations", ",", "ECC", "does", "not", "have", "much", "effect", "on", "its", "performance", "on", "Tesla", "K40c", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["However", ",", "the", "convergence", "properties", "of", "GPS", "methods", "can", "be", "further", "strengthened", "if", "additional", "criteria", "are", "met", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["POS", "tag", ":"], "acronym_pos": [1, 0, 0], "long_form": "part of speech"}, {"tokens": ["To", "this", "end", ",", "we", "propose", "a", "feature", "map", "selection", "unit", ",", "called", "MAD", ",", "to", "actively", "help", "find", "useful", "neuron", "activations", "among", "feature", "channels", "(", "see", "red", "area", "in", "Figure", "fig", ":", "pipeline", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["Furthermore", "an", "authoring", "environment", "is", "developed", "to", "create", "the", "AR", "scenes", "for", "the", "maintenance", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["-", "FEC", "can", "provide", "enhanced", "video", "quality", ",", "especially", "over", "higher", "distances", ",", "however", ",", "it", "is", "equally", "important", "to", "do", "so", "with", "lower", "network", "overhead", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["shows", "the", "average", "sum", "-", "rate", "with", "total", "number", "of", "receive", "antennas", "at", "the", "BS", ",", "and", "two", "values", "of", "the", "number", "of", "selected", "users", "and", "versus", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Moreover", ",", "the", "FEC", "overhead", "amount", "introduced", "by", "this", "mechanism", "was", "48", "(", "without", "taking", "into", "account", "the", "feedback", "messages", "overhead", ")", ",", "which", "is", "higher", "than", "the", "proposed", "mechanisms", "as", "shown", "in", "Chapters", ",", ",", "and", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "DCI", "bits", "for", "both", "LTE", "and", "NR", "are", "set", "to", "12", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "results", "of", "fitting", "the", "microcanonical", "SBM", "(", "Section", ")", "suggested", "an", "optimal", "of", "32", "groups", ",", "each", "containing", "two", "cliques", ",", "mean", "that", "the", "model", "suffers", "from", "underfitting", "rather", "than", "overfitting", ",", "due", "to", "the", "fact", "that", "the", "maximum", "detectable", "is", "(", "proportional", "to", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Therefore", ",", "the", "aforementioned", "memory", "technologies", "are", "protected", "against", "the", "conventional", "charge", "probing", "techniques", "like", "SKPM", ",", "SCM", ",", "PVC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "scanning capacitance microscopy"}, {"tokens": ["b", ")", "Table", "for", "ablation", "experiments", "under", "different", "settings", "on", "synthesized", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["Evaluation", "of", "Data", "augmentation", ":", "The", "FER", "dataset", "are", "relatively", "small", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["Therefore", ",", "we", "study", "how", "autoencoders", ",", "a", "classic", "deep", "neural", "network", "used", "for", "DR", ",", "can", "also", "be", "used", "for", "DE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "dimension estimation"}, {"tokens": ["SAR", "'s", "ability", "to", "perceive", ",", "respond", ",", "and", "adapt", "to", "user", "behavior", "is", "especially", "critical", "in", "the", "ASD", "context", ",", "as", "users", "with", "ASD", "vary", "greatly", "in", "symptoms", "and", "severities", ",", "underscoring", "the", "need", "for", "personalization", ",", "as", "our", "work", "also", "demonstrates", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Problem", "is", "formulated", "into", "a", "standard", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0], "long_form": "geometric programming"}, {"tokens": ["Moreover", ",", "the", "Lyapunov", "'s", "theorem", "was", "adopted", "to", "prove", "the", "convergence", "of", "the", "proposed", "scheme", "to", "the", "optimal", "solutions", "of", "the", "subcarrier", ",", "FJ", "power", ",", "and", "prices", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["In", "fact", ",", "since", "the", "same", "RB", "might", "be", "allocated", "to", "the", "more", "than", "one", "user", "in", "different", "TBSs", "simultaneously", "in", "the", "ground", "tier", ",", "an", "inter", "-", "cell", "interference", "might", "be", "caused", "to", "some", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resource blocks"}, {"tokens": ["The", "MS", "can", "conveniently", "transmit", "its", "data", "to", "another", "MS", "that", "have", "good", "channel", "with", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["The", "values", "of", "the", "innermost", "hidden", "layer", "are", "not", "appropriate", "for", "DE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "dimension estimation"}, {"tokens": ["As", "it", "will", "be", "shown", "in", "the", "sequel", ",", "the", "choice", "of", "the", "PS", "ratios", "affects", "the", "system", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "cover", "difference", "(", "CD", ")", "is", "where", "is", "the", "number", "of", "categories", ",", "and", "and", "represent", "the", "subset", "and", "probability", "measure", "of", "the", "label", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cover difference"}, {"tokens": ["In", "the", "APSO", "algorithm", ",", "fuzzy", "rules", "have", "been", "used", "to", "tune", "the", "inertial", "weight", "of", "PSO", "whereas", "a", "self", "-", "adaptive", "adjustment", "approach", "has", "been", "used", "to", "adjust", "other", "parameters", "of", "PSO", ",", "such", "as", "the", "cognitive", "and", "social", "parameters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Angle", "features", "from", "skeleton", "and", "HOG", "features", "from", "RGB", "are", "extracted", "for", "this", "purpose", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "histogram of oriented gradient"}, {"tokens": ["We", "first", "observe", "that", "consistency", "of", "generalPSPs", "can", "be", "reduced", "to", "consistency", "of", "scPSPs", "by", "computing", "the", "DAG", "of", "SCCs", ",", "and", "checking", "consistencySCC", "-", "wise", "etessamiyannakakis", ":", "Take", "any", "bottom", "SCC", ",", "and", "checkthe", "consistency", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strongly connected components"}, {"tokens": ["Then", ",", "DE", "and", "GSA", "are", "utilized", "to", "locate", "the", "optimal", "positions", "of", "second", "-", "phase", "relay", "nodes", "for", "lifetime", "maximization", "with", "guaranteed", "cost", "and", "connectivity", "constraints", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Thus", ",", "DeepStereo", "is", "far", "slower", "than", "previous", "methods", "SFM", "based", "methods", "such", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "structure from motion"}, {"tokens": ["The", "three", "topics", "are", ":", "i", ")", "performance", "of", "the", "continual", "GP", "model", "under", "single", "-", "output", "streaming", "observations", ",", "ii", ")", "resistance", "to", "propagation", "errors", "when", "reusing", "variational", "approximations", ",", "including", "fitting", "to", "the", "appearance", "of", "tasks", ",", "non", "-", "Gaussian", "data", "and", "heterogeneous", "multi", "-", "output", "settings", ",", "iii", ")", "applicability", "to", "real", "world", "problems", "with", "multi", "-", "dimensional", "online", "data", ",", "potentially", "configured", "as", "asymmetric", "channels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Constraints", "peak_power", "and", "betac", "indicate", "the", "limits", "of", "the", "transmit", "power", "levels", "and", "PS", "ratios", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "occurrence", "probability", "of", "TI", "1(orange", ")", "and", "TI", "2(green", ")", "in", "corresponding", "interactive", "locations", "(", "WAPs", "/", "Voronoi", "cells", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["Although", "CC", "-", "CV", "is", "the", "well", "-", "known", "charging", "mechanism", ",", "some", "devices", "charge", "batteries", "to", "an", "extra", "0.15", "V", "to", "reduce", "charging", "hardware", "implementation", "complexity", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant charging"}, {"tokens": ["Table", "compares", "the", "output", "generated", "by", "the", "TS", "systems", "RegenT", "and", "YATS", "on", "a", "sample", "sentence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["ICC", "is", "always", "higher", "than", "that", "of", "a", "single", "measurement", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["NP", "gurbah", "'", "cat", "'", "(", "cf", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["OP_FSDF_Equalm", "to", "Eq", ":", "MGF_SSDF", ",", "yields", "the", "following", "closed", "-", "form", "expression", "for", "of", "rate", "-", "selective", "RS", "over", "IID", "Nakagami-", "fading", "channels", "with", "integer", ":", "Performance", "Analysis", "of", "ODF", "Relaying", "SchemesIn", "this", "section", ",", "the", "performance", "of", "ODF", "relaying", "schemes", "with", "repetitive", "and", "RS", "-", "based", "transmission", "over", "INID"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["For", "example", ",", "replacing", "GI", "with", "FI", ",", "the", "Boolean", "formula", "isomorphism", "problem", ",", "and", "an", "-complete", "property", "on", "GI", "with", "a", "-complete", "property", "on", "FI", "yields", "a", "-complete", "equivalence", "relation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph isomorphism"}, {"tokens": ["*", "p(a)rdanku-", "NP", "palang", "'", "panther", "'", ";", "cf", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Based", "on", "two", "real", "-", "world", "benchmarking", "hyperspectral", "datasets", ",", "we", "demonstrate", "that", "class", "dependent", "OLS", "based", "methods", "outperform", "several", "baseline", "methods", "including", "traditional", "SRC", "and", "the", "support", "vector", "machine", "classifier", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["and", "is", "the", "computation", "time", "for", "the", "optimal", "bandwidth", "selection", "using", "PSO", "and", "outliers", "removal", "using", "thresholding", "scheme", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Differential", "Evolution", "(", "DE", ")", "is", "a", "widely", "implemented", "population", "based", "evolutionary", "optimization", "technique", "which", "is", "simple", ",", "robust", ",", "fast", "and", "requiring", "minimal", "control", "parameters", "capable", "of", "solving", "non", "-", "linear", "and", "non", "-", "differentiable", "optimization", "problems", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["In", "this", "work", ",", "we", "improve", "CDA", "recognition", "with", "an", "adapted", "CRNN", "which", "models", "the", "interactions", "between", "long", "-", "range", "context", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concurrent dialogue acts"}, {"tokens": ["In", "the", "VCC", ",", "drivers", "can", "access", "cloud", "services", ",", "e.g.", ",", "processing", "services", ",", "from", "Service", "Providers", "(", "SPs", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vehicular cloud computing"}, {"tokens": ["Considering", "the", "GMI", "of", "PM-8QAM", "as", "a", "baseline", ",", "4D-64PRS", "can", "provide", "gains", "of", "dB", "at", "an", "AIR", "between", "and", "bit/4D", "-", "sym", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "achievable information rates"}, {"tokens": ["In", "addition", ",", "the", "extrinsic", "evaluation", "that", "was", "carried", "out", "based", "on", "the", "task", "of", "Open", "IE", "verified", "that", "downstream", "semantic", "applications", "profit", "from", "making", "use", "of", "our", "proposed", "structural", "TS", "approach", "as", "a", "preprocessing", "step", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["In", "Table", "we", "find", "that", "for", "the", "PA", "task", ",", "the", "same", "CNN", "performs", "much", "better", "when", "trained", "on", "the", "last", "seconds", "of", "audio", "(", "model", "B", ")", "than", "on", "the", "first", "seconds", "(", "model", "A", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["An", "example", "of", "an", "AML", "model", "is", "illustrated", "in", "Figure", "which", "consists", "of", "two", "actors", ",", "namely", "and", "with", "the", "mailbox", "capacities", "of", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["Since", "the", "value", "of", "of", "the", "network", "is", "affected", "by", "the", "maximum", "BC", "node", "and", "sometimes", ",", "it", "may", "happen", "that", "maximum", "BC", "node", "appears", "in", "user", "'s", "route", "which", "leads", "to", "congestion", "in", "the", "route", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["The", "reasons", "for", "that", "are", ":", "(", "1", ")", "the", "available", "transmission", "time", "decreases", "as", "the", "number", "of", "STAs", "involved", "in", "the", "parallel", "transmission", "increases", ";", "and", "(", "2", ")", "the", "collision", "probability", "increases", "as", "more", "antennas", "are", "employed", "at", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access part"}, {"tokens": ["Finally", ",", "the", "corresponding", "ground", "truth", "material", "(", "i.e.", "most", "similar", "ground", "truth", "material", ")", "is", "determined", "by", "measuring", "its", "highest", "SAD", "similarity", "score", "with", "the", "estimated", "endmembers", "in", "the", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["Total", "training", "time", "(", "in", "minutes", ")", "(", ")", "centering", "Training", "and", "prediction", "runtime", "comparison", "of", "LR"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "logistic regression"}, {"tokens": ["CF", "PredictionFor", "the", "CF", "task", ",", "we", "use", "a", "factorisation", "machine", "as", "our", "prediction", "model", "."], "acronym_pos": [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Recall", "that", "MP", "and", "OMP", "approximate", "in", "the", "least", "-", "squares", "sense", ",", "i.e.", ",", "they", "aim", "at", "minimizing", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["Therefore", ",", "the", "traffic", "load", "of", "the", "AP", "is", "set", "to", "be", "times", "higher", "than", "that", "of", "each", "STA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Due", "to", "the", "fact", "that", "the", "groups", "contain", "a", "rich", "amount", "of", "NSS", "information", "of", "natural", "images", ",", "we", "can", "achieve", "a", "good", "estimation", "of", "by", "the", "NSS", "prior", "of", "natural", "images", "based", "on", "GMM", "learning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "results", "for", "KDE", "are", "not", "reported", ",", "since", "it", "is", "always", "outperformed", "by", "the", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["and", "show", "an", "example", "of", "BSP", "tree", "expansion", "and", "search", "space", "partitioning", "in", "a", "2-dimensional", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["Sensor", "nodes", "that", "are", "connected", "to", "the", "AP", "construct", "the", "backbone", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "mean", "and", "variance", "predictions", "of", "this", "GP", "are", "computed", "using", "a", "kernel", "vector", ",", "and", "a", "kernel", "matrix", ",", "with", "entries", "and", "where", "is", "the", "kernel", "of", "the", "GP", ":", "The", "formulation", "above", "allows", "us", "to", "combine", "observations", "from", "the", "prior", "and", "the", "real", "-", "world", "smoothly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["However", ",", "this", "scheme", "does", "not", "achieve", "satisfactory", "performance", "for", "SAR", "application", "because", "of", "the", "prominent", "discrepancy", "between", "SAR", "and", "optical", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Also", ",", "the", "location", "of", "each", "particle", "is", "updated", "as", ":", "The", "pseudo", "code", "of", "the", "PSO", "algorithm", "is", "shown", "in", "Algorithm", "3", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["It", "is", "known", "when", "is", "a", "deterministic", "function", "of", ",", "the", "IB", "curve", "can", "not", "be", "explored", "and", "another", "Lagrangian", "has", "been", "proposed", "to", "tackle", "this", "problem", ":", "the", "squared", "IB", "Lagrangian", ":", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Seed", "OT", "Phase", ":", "chooses", "at", "random", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["A", "UE", ",", "configured", "with", "DC", "/", "MC", "as", "shown", "in", "Fig", ".", ","], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Therefore", ",", "we", "set", "a", "cut", "-", "off", "(", "10", ")", "to", "remove", "all", "words", "(", "in", "LScD", ")", "appearing", "in", "not", "greater", "than", "10", "documents", "in", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Modelling", "the", "task", "as", "an", "IB", "alleviates", "this", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "the", "second", "approach", ",", "we", "consider", "the", "effect", "of", "holes", "when", "the", "typical", "UE", "is", "associated", "with", "an", "MBS", "and", "by", "incorporating", "the", "serving", "hole", ",", "and", "an", "analytical", "expression", "for", "SINR", "coverage", "probability", "is", "derived", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["RB", ":", "coefficients", "."], "acronym_pos": [1, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["This", "result", "suggests", "that", "the", "low", "FR", "given", "by", "the", "front", "-", "end", "has", "a", "severe", "impact", "on", "the", "back", "-", "end", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "frame recall"}, {"tokens": ["This", "estimate", "can", "then", "be", "plugged", "in", "eqn.graph_lik_hard_re", "to", "obtainWhile", "did", "not", "use", "the", "profile", "log", "-", "likelihood", "mainly", "for", "model", "selection", ",", "it", "can", "be", "seen", "as", "a", "precedent", "in", "moving", "from", "the", "non", "model", "-", "based", "modularity", "to", "a", "criterion", "based", "on", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "stochastic block model"}, {"tokens": ["CNOMA", "-", "OAM", "scheme", "provides", "higher", "SC", "than", "conventional", "CNOMA", "and", "OMA", "-", "OAM", "which", "is", "shown", "in", "Fig.6", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["The", "proposed", "Exact", "-", "MBR", "codes", "can", "be", "implemented", "via", "fast", "Fourier", "transforms", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["novelty_detection", "compares", "the", "AUC", "of", "normative", "models", "derived", "by", "sMT", "-", "GPTR", "and", "NP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "neural processes"}, {"tokens": ["MUD", "schemesMUIC", "Schemes", "for", "Simultaneous", "Downlink", "TransmissionsAlthough", "simultaneous", "downlink", "transmissions", "from", "the", "AP", "to", "multiple", "STAs", "can", "be", "seen", "as", "a", "combination", "of", "several", "single", "-", "user", "transmissions", ",", "STAs", "'", "random", "and", "independent", "locations", "make", "it", "very", "challenging", "to", "jointly", "null", "multi", "-", "user", "interference", "at", "the", "STA", "side", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["In", "the", "first", "two", "cases", "the", "CD", "might", "or", "might", "not", "be", "about", "molecules", "that", "exist", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "chemical diagram"}, {"tokens": ["Jeff", "Dean", "proposed", "Parameter", "-", "Server", "Framework", "(", "PS", ")", ",", "which", "uses", "a", "parameter", "server", "to", "store", "the", "newest", "weight", "parameters", "of", "CNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["We", "measure", "performance", "in", "terms", "of", "MSE", "loss", "for", "CF", "tasks", "and", "accuracy", "for", "CTR", "prediction", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Using", "the", "DC", "-", "SBM", "eqn.graph_ypq_kn11", ",", "the", "rate", "that", "edges", "are", "removed", "depends", "on", "the", "group", "memberships", "of", "and", ",", "while", "the", "rate", "that", "edges", "are", "added", "is", "the", "product", "of", "the", "edge", "-", "removal", "rate", "and", ",", "which", "is", "the", "same", "term", "used", "in", "the", "static", "model", "eqn.graph_ypq_kn11", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Our", "proposed", "NP", "-", "based", "approach", "extends", "their", "effort", "in", "applying", "deep", "architectures", "to", "normative", "modeling", "from", "two", "perspectives", ":", "i", ")", "it", "provides", "the", "possibility", "of", "bimodal", "normative", "modeling", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["Typing", "rules", "adds", "intersection", "types", "and", "-expressions", "to", "FJ", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "featherweight java"}, {"tokens": ["For", "fair", "comparison", ",", "all", "these", "DCNN", "based", "competitors", "and", "the", "spectral", "dictionary", "in", "the", "Arad", "are", "retrained", "on", "the", "training", "set", "utilized", "in", "the", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["The", "steps", "of", "a", "GPS", "method", "are", "presented", "in", "Alg", ".", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["Thus", ",", "we", "further", "partition", "the", "original", "training", "and", "development", "datasets", "for", "both", "LA", "and", "PA", ",", "ensuring", "non", "-", "overlap", "in", "spoofing", "attack", "conditions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["The", "located", "at", "belongs", "to", "the", "cooperative", "set", "of", "UE", "only", "if", ",", "where", "is", "the", "received", "signal", "power", "threshold", "at", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["In", "addition", ",", "as", "shown", "in", "Table", ",", "the", "proposed", "method", "also", "performs", "better", "than", "two", "baselines", ",", ",", "DCNN", "and", "MCNet", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["In", "fact", ",", "GS", "may", "fail", "to", "converge", "when", "is", "included", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gauss seidel"}, {"tokens": ["Thirdly", ",", "average", "ranks", "show", "that", "ECS", "-", "DBN", "is", "ranked", "first", "across", "most", "of", "the", "benchmark", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["We", "fit", "the", "model", "and", "DAC", "/", "PDP", "curves", "to", "10", "of", "the", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial dependence plots"}, {"tokens": ["The", "relay", "acts", "as", "an", "auctioneer", "(", "seller", ")", "which", "provides", "the", "relay", "and", "FJ", "powers", "to", "the", "sources", "of", "SU", "pairs", ",", "i.e.", ",", "bidders", "(", "buyers", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["In", "the", "proposed", "approach", "the", "velocity", "is", "not", "bounded", ",", "that", "is", ",", "there", "is", "no", "need", "to", "specify", "and", "adjust", ",", "which", "has", "significant", "influence", "on", "the", "exploration", "/", "exploitation", "trade", "-", "off", "in", "the", "other", "binary", "versions", "of", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "particle swarm optimization"}, {"tokens": ["While", "we", "get", "the", "best", "recommendation", "accuracy", "results", "for", "the", "unpersonalized", "MP", "algorithm", "in", "UC1", ",", "the", "personalized", "CF", "approach", "provides", "the", "best", "results", "for", "the", "more", "complex", "UC2", ",", "UC3", "and", "UC4", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "most popular"}, {"tokens": ["The", "left", "and", "right", "columns", "are", "the", "output", "results", "of", "AN", "and", "FAN", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["S/", "NP", "bes", "'", "more'PIr", "*", "uahista-"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["describe", "the", "challenges", "of", "QA", "over", "knowledge", "bases", "using", "natural", "languages", ",", "and", "elaborate", "the", "various", "techniques", "used", "by", "existing", "QALD", "systems", "to", "overcome", "those", "challenges", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "proposed", "OPA", "strategy", "is", "a", "general", "-", "form", "PA", "strategy", "suitable", "for", "any", "beamforming", "scheme", ",", "and", "may", "be", "applied", "to", "any", "given", "bemaforming", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["Then", "we", "define", "the", "IB", "Lagrangian", "asHere", "is", "the", "Lagrange", "multiplier", "which", "controls", "the", "trade", "-", "off", "between", "the", "information", "of", "retained", "and", "the", "compression", "of", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Penney", "penney_chilling_2016", "also", "starts", "with", "an", "ITS", "model", "to", "understand", "the", "impact", "of", "the", "Edward", "Snowden", "revelations", "on", "page", "views", "to", "\"", "terrorism", "-", "related", "\"", "Wikipedia", "articles", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interrupted time series"}, {"tokens": ["The", "simulating", "system", "GS", "*", "has", "a", "mediocre", "performance", ",", "probably", "because", "it", "does", "not", "differentiate", "in", "which", "domains", "an", "author", "has", "received", "the", "citations", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "google scholar 's"}, {"tokens": ["However", ",", "OLS", "does", "not", "always", "give", "the", "sparsest", "solution", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["PS", "drives", "are", "used", "several", "hours", "a", "day", ",", "while", "ES", "drives", "are", "powered", "up", "all", "the", "time", ",", "but", "disks", "may", "be", "powered", "down", "in", "archival", "storage", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "personal storage"}, {"tokens": ["The", "results", "on", "the", "Newsela", "dataset", ",", "depicted", "in", "the", "middle", "part", "of", "Table", ",", "support", "our", "findings", "on", "the", "Wikilarge", "corpus", ",", "indicating", "that", "our", "TS", "approach", "can", "be", "applied", "in", "a", "domain", "independent", "manner", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["A", "distinct", "proposal", "to", "enhance", "video", "transmission", "over", "wireless", "local", "area", "networks", "are", "based", "on", "a", "method", "which", "adapts", "in", "real", "-", "time", "the", "amount", "of", "FEC", "redundancy", "and", "the", "transmission", "rate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "this", "example", ",", "the", "geometric", "stiffening", "effect", "is", "captured", "by", "the", "RB", "with", "high", "accuracy", ",", "with", "as", "few", "as", "basis", "elements", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["Differential", "Evolution", "(", "DE", ")", "will", "be", "used", "to", "test", "the", "effectiveness", "of", "the", "predictive", "methodology", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["With", "such", "setting", ",", "the", "conditional", "probability", "for", "CF", "in", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["A", "true", "negative", "(", "TN", ")", "represents", "an", "individual", "who", "is", "non", "-", "depressed", "and", "is", "also", "predicted", "as", "non", "-", "depressed", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true negative"}, {"tokens": ["ht][Dispatch", "plan", "(", "black", ")", ",", "measured", "prosumption", "realization", "(", "shaded", "area", ")", ",", "measured", "active", "power", "flow", "at", "the", "GCP", "(", "dashed", "red", ")", ".", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "grid connection point"}, {"tokens": ["Monz", "monz2003drq", "finds", "a", "negative", "result", "when", "applying", "blind", "feedback", "for", "QA", "in", "TREC", "9", ",", "10", "and", "11", ",", "and", "a", "neutral", "result", "for", "TREC", "7", "and", "8", "'s", "ad", "hoc", "retrieval", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["cm", "3cGender", "Set", "1", "&", "Rey", "Audio", "and", "Verbal", "Learning", "Test", "&", "FA", "Cingulum", "L", "&", "FA", "Medial", "lemniscus", "L", "&", "FA", "Cingulum"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0], "long_form": "fractional anisotropy"}, {"tokens": ["Results", "ROC", "curve", "for", "Mean", "method", ",", "BoFT", "method", "and", "proposed", "GRTM", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["However", ",", "the", "duration", "of", "each", "session", "varied", "considerably", ",", "ranging", "from", "176", "frames", "in", "emotion", "processing", "to", "401", "frames", "in", "working", "memory", ",", "with", "TR", "of", "5520", "ms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "temporal resolution"}, {"tokens": ["The", "maximum", "across", "all", "sensor", "locations", "was", "33.24", "for", "the", "LMEM", ",", "29.38", "for", "the", "RF", "model", "and", "10.91", "for", "the", "ANN", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Given", "an", "active", "TI", "during", "[", "]", ",", "the", "active", "duration", "of", "the", "edge", "(", "TI", ")", "is", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["ROC", "curves", "for", "effect", "of", "vector", "length"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Real", "DataWe", "use", "the", "SDR", "technology", "to", "build", "our", "testbeds", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "software defined radio"}, {"tokens": ["DBP", "is", "NP", "-", "complete", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["In", "other", "words", ",", "given", "angle", "and", "range", ",", "the", "confidential", "message", "power", "can", "be", "transmitted", "and", "collected", "inside", "a", "small", "neighborhood", "around", "the", "desired", "position", ",", "outside", "which", "there", "exists", "very", "weak", "receive", "power", "seriously", "corrupted", "by", "AN", "and", "the", "confident", "messages", "can", "not", "be", "detected", "successfully", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Under", "this", "scenario", ",", "we", "will", "analyze", "the", "optimal", "sparse", "-term", "representation", "using", "OMP", ",", "OLS", "and", "COLS", ",", "where", "equals", "to", "2", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["Hyperparameter", "TuningEAP", "has", "following", "three", "hyperparameters", ":", "The", "self", "preference", "serves", "a", "similar", "purpose", "as", "in", "AP", ",", "i.e.", ",", "it", "indicates", "the", "interest", "of", "a", "data", "point", "to", "become", "a", "local", "exemplar", ",", "forming", "a", "spherical", "subcluster", "around", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["0.4intable", "tabularplcccccc", "cccccc", "&", "&", "6cTesla", "K40c", "(", "ECC", "on", ")", "&"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["Results", "are", "shown", "only", "for", "the", "units", "of", "assessment", "with", "the", "lowest", "MAD", "between", "metrics", "and", "peer", "review", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "median absolute difference"}, {"tokens": ["In", "addition", "to", "PSO", "variants", ",", "two", "other", "search", "paradigms", ",", "GA", "and", "ACO", ",", "have", "been", "included", "as", "benchmarking", "algorithms", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["For", "each", "campaign", ",", "we", "have", "chosen", "the", "features", "based", "on", "the", "quality", "ofthe", "ROC", "measure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Moreover", ",", "in", "the", "case", "of", "the", "discussed", "wave", "propagation", "problem", ",", "formulated", "in", "terms", "of", "the", "scattered", "field", "over", "the", "half", "-", "space", "and", "when", "the", "used", "Green", "'s", "functions", "are", "those", "of", "a", "semi", "-", "infinite", "medium", ",", "the", "problem", "simplifies", "even", "more", ",", "since", "there", "are", "no", "remote", "forces", "originating", "at", "the", "far", "surface", "of", "the", "BEM", "domain", ",", "labeled", "in", "fig", ":", "coupling", ",", "to", "be", "carried", "over", "to", "the", "FEM", "domain", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "finite element method"}, {"tokens": ["To", "verify", "that", "there", "is", "no", "significant", "bias", "in", "perturbation", "ICC", "towards", "one", "image", ",", "we", "first", "calculated", "the", "difference", "between", "the", "perturbation", "ICCs", "of", "the", "same", "feature", "for", "every", "feature", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["Finally", ",", "assuming", "a", "linear", "array", "response", "at", "the", "BS", "side", "the", "channel", "matrix", "is", "given", "(", ")", "(", "defined", "at", "the", "top", "of", "this", "page", ")", ",", "where", "denotes", "the", "clusters", "seen", "by", "the", "th", "user", "and", ",", "where", "denotes", "the", "spacing", "between", "two", "antenna", "elements", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Navigation", "SystemResearchers", "are", "developing", "navigation", "systems", "that", "do", "not", "utilize", "GPS", "signals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "global positioning system"}, {"tokens": ["It", "consists", "of", "one", "AP", "and", "STAs", "with", "an", "error", "-", "free", "channel", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Having", "the", "best", "classifier", "at", "hand", ",", "we", "are", "ready", "to", "approximate", "the", "empirical", "upper", "bound", "in", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "average precision"}, {"tokens": ["The", "values", "of", "are", "selected", "so", "that", "the", "number", "of", "parameters", "in", "an", "LR", "network", "is", "similar", "to", "the", "number", "of", "parameters", "of", "its", "MLconv", "counterpart", "with", "given", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low rank"}, {"tokens": ["In", "particular", ",", "GPA", "reduces", "the", "running", "time", "by", "33.33", "compared", "to", "HARP", "on", "the", "Enron", "dataset", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["Abundant", "text", "data", "available", "in", "the", "form", "of", "emails", ",", "tweets", ",", "blogs", "and", "electronic", "version", "of", "books", "has", "opened", "new", "venues", "for", "authorship", "attribution", "and", "led", "to", "a", "surge", "of", "interest", "in", "AA", "among", "academic", "communities", "as", "well", "as", "corporate", "establishments", "and", "government", "agencies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["Slightly", "over", "two", "-", "thirds", "of", "each", "of", "the", "two", "sets", "have", "the", "\"", "with", "CF", "\"", "condition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["For", "example", ",", "given", "a", "sentence", ":", "Andy", "gives", "a", "book", "to", "John", ",", "in", "SRL", "context", ",", "Andy", "and", "John", "are", "labeled", "as", "AGENT", "and", "PATIENT", "or", "BENEFACTOR", "respectively", ",", "but", "in", "ER", "context", ",", "they", "are", "labeled", "as", "PERSON", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["*", "tablecentertabularccccMethod", "&", "Mean", "&", "Building", "&", "Road", "FCNfcn", "&", "77.64", "&", "70.44", "&", "73.32", "ResNetresnet", "&", "78.46", "&", "69.15", "&", "76.44", "tabularcenter", "Aerial", "image", "semantic", "segmentation", "IoU.", "tab", ":", "seg", "table", "tablecentertabularcccccMethod", "&", "WeightedCov", "&", "AP", "&", "Re-50", "&", "Pr-50", "FCN", "&", "39.74", "&", "8.04", "&", "19.64", "&", "18.38", "FCN", "+", "Open", "&", "43.19", "&", "16.45", "&", "24.55", "&", "36.09", "ResNet", "&", "38.70", "&", "10.47", "&", "21.30", "&", "21.93", "ResNet", "+", "Open", "&", "41.10", "&", "22.92", "&", "22.78", "&", "43.78", "tabularcenter"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Robust", "accuracy", "is", "with", "respect", "to", "a", "-step", "PGD", "attack", "as", "in", "[", "15].Appendix", "E", ":", "Sensitivity", "of", "ARD", "to", "temperature", "and", "Compared", "to", "knowledge", "distillation", "for", "preserving", "robustness", ",", "ARD", "is", "less", "sensitive", "to", "the", "temperature", "parameter", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Structure", "of", "a", "simple", "feed", "-", "forward", "ANNRecurrent", "Neural", "Networks", "(", "RNN", ")", "is", "a", "type", "of", "ANN", "in", "which", "hidden", "layer", "neurons", "has", "self", "-", "connections", "which", "means", "output", "depends", "not", "only", "on", "the", "present", "inputs", "but", "also", "on", "the", "previous", "neuron", "state", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Comparison", "of", "Ideal", "Throughput", "with", "Actual", "System", "Throughput", "for", "RA", ",", "P2P", ",", "and", "PS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "parameter server"}, {"tokens": ["For", "example", ",", "when", "PBS", "changes", "titles", "from", "AP", ",", "the", "core", "information", "does", "not", "change", "and", "little", "bias", "seems", "to", "be", "introduced", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "associated press"}, {"tokens": ["the", "difference", "between", "CDP", "and", "LDP", "will", "be", "more", "clear", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["The", "LSC", "is", "more", "than", "70", "times", "as", "large", "as", "the", "Reuters", "corpus", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["app2", "Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs", "where", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["Then", "test", "the", "performance", "of", "the", "generated", "ECS", "-", "DBN", "on", "test", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "the", "following", "discussion", ",", "the", "CMA", "-", "ES", "method", "extended", "by", "the", "global", "optimum", "invariant", "symmetry", "breaking", "is", "denoted", "by", "CM", "-", "ES", "-", "INV", "-", "SB", ",", "CMA", "-", "ES", "extended", "by", "the", "proposed", "global", "optimum", "variant", "symmetry", "breaking", ",", "described", "by", "Algorithm", ",", "is", "denoted", "by", "CMA", "-", "ES", "-", "SB", "and", "CMA", "-", "ES", "with", "global", "optimum", "variant", "ideal", "symmetry", "breaking", "using", "brute", "force", "search", "is", "denoted", "by", "CMA", "-", "ES", "-", "SB", "-", "BF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "brute force search"}, {"tokens": ["followed", "this", "same", "approach", "by", "applying", "on", "a", "contrasted", "and", "etched", "dataset", "of", "steel", ",", "acquired", "by", "SEM", "and", "LOM", "imaging", "which", "was", "also", "used", "in", "this", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Binary", "cross", "entropy", ",", "squared", "-", "sum", "and", "CTC", "losses", "are", "backpropagated", "through", "the", "whole", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["In", "particular", ",", "they", "found", "that", "upon", "synchronization", "with", "a", "legitimate", "AP", ",", "a", "device", "can", "\"", "acquire", "\"", "the", "same", "clock", "skew", "as", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["shows", "that", "the", "length", "of", "the", "charging", "time", "curve", "is", "equivalent", "to", "the", "CC", "phase", "length", "determined", "from", "the", "voltage", "curve", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": [":", "FWLMO", "is", "equivalent", "(", "up", "to", "the", "sign", ")", "to", "the", "one", "used", "for", "MP", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["The", "PSO", "is", "based", "on", "the", "simulation", "of", "common", "animal", "social", "behaviors", ",", "for", "instances", ":", "fish", "schooling", ",", "bird", "flocking", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["This", "paper", "employs", "a", "generalized", "version", "of", "the", "chi", "-", "squared", "detector", "and", "in", "using", "the", "GMM", "representation", "of", "the", "noise", "distributions", "allows", "us", "to", "develop", "the", "GMM", "representation", "of", "the", "residual", "distribution", "and", "then", "compute", "statistics", "about", "the", "distance", "measure", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Despite", "the", "correlation", "between", "the", "third", "frame", "labeled", "in", "our", "experiments", "as", "neutral", "and", "the", "fourth", "frame", "labeled", "as", "the", "facial", "expression", ",", "the", "MFP", "-", "CNN", "framework", "performs", "well", "among", "existing", "FER", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["In", "ET", ",", "DS", "structure", "is", "applied", "to", "represent", "uncertainty", ",", "which", "is", "capable", "of", "describing", "both", "aleatory", "and", "epistemic", "uncertainty", "attribute", "of", "variables", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "evidence theory"}, {"tokens": ["The", "second", "component", ",", "the", "extractor", ",", "then", "generates", "candidate", "tuples", "by", "first", "identifying", "pairs", "of", "NP", "arguments", "and", "then", "heuristically", "designating", "each", "word", "in", "between", "as", "part", "of", "a", "relation", "phrase", "or", "not", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "noun phrase"}, {"tokens": ["M.", "Jalloul", ",", "A.M.", "El", "-", "Hajj", "and", "Z.", "Dawy", ",", "\"", "Uplink", "Interference", "Co", "-", "ordination", "/", "Avoidance", "in", "LTE", "Systems", ",", "\"", "Proc", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Furthermore", ",", "GMM", "is", "initialised", "times", "and", "the", "best", "result", "is", "reported", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["One", "Stage", "vs", "Two", "StageWe", "also", "embed", "the", "spirit", "of", "deconvolution", "and", "MAD", "unit", "in", "a", "single", "stage", "manner", ",", "where", "the", "SSD", "detector", "is", "invoked", "as", "the", "prototype", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["MVF", "prediction", "using", "the", "proposed", "system", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["In", "other", "words", ",", "we", "align", "the", "GPS", "sensor", "data", "with", "the", "pre", "-", "defined", "environment", "signatures", "when", "the", "supervised", "learning", "algorithm", "recognizes", "the", "environment", "signatures", "as", "the", "CroPark", "vehicle", "drives", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Numerical", "results", "illustrate", "the", "system", "'s", "behavior", "versus", "various", "parameters", "and", "show", "that", "the", "performance", "of", "the", "proposed", "scheme", "is", "very", "close", "to", "that", "of", "the", "optimal", "branch", "-", "and", "-", "bound", "method", "and", "that", "GP", "outperforms", "the", "dual", "problem", "-", "based", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["This", "indicates", "that", "PA", "have", "little", "efficacy", "in", "predicting", "the", "future", "popularity", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "preferential attachment"}, {"tokens": ["The", "next", "two", "lines", "configure", "PSO", "parameters", "and", ",", "and", "the", "inertia", "weight", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["However", ",", "the", "cost", "of", "even", "a", "full", "ISP", "is", "minuscule", "in", "comparison", "to", "any", "relevant", "CNN", "architecture", ",", "so", "the", "improvements", "in", "accuracy", "prove", "worthwhile", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Regardless", "of", "their", "conceptual", "differences", ",", "UTAUT", ",", "TPB", ",", "and", "TAM", "have", "gained", "considerable", "evidence", "that", "supports", "them", "as", "relevant", "ones", "to", "understand", "the", "complexities", "of", "the", "technology", "-", "mediated", "relationships", "between", "buyers", "and", "sellers", "through", "E", "-", "commerce", "platforms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "technology acceptance model"}, {"tokens": ["For", "this", "reason", ",", "SR", "models", "should", "be", "trained", "by", "taking", "into", "account", "the", "final", "goal", "and", "in", "some", "cases", "it", "'s", "not", "required", "to", "reconstruct", "a", "HR", "intensity", "image", "for", "HR", "analysis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], "long_form": "high - resolution"}, {"tokens": ["Statistically", "significant", "difference", "between", "improvement", "and", "worsening", ",", "MRD", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "mean rank difference"}, {"tokens": ["Multi", "-", "RAT", "Dual", "ConnectivityMulti", "-", "RAT", "Dual", "Connectivity", "(", "MR", "-", "DC", ")", "is", "a", "generalization", "of", "DC", "described", "in", "Section", ",", "where", "dual", "connectivity", "is", "established", "with", "LTE", "and", "5", "G", "radio", "network", "for", "a", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["State", "-", "of", "-", "the", "-", "art", "DST", "models", "are", "typically", "trained", "in", "a", "supervised", "manner", "from", "manual", "annotations", "at", "the", "turn", "level", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["However", ",", "the", "galaxy", "search", "results", "show", "that", "the", "astronomers", "tended", "to", "perform", "equally", "well", "on", "both", "the", "SDD", "and", "the", "TDW", "(", "c.f", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["t", "]", "MSTAR", "Dataset", "OpenSARShip", "for", "SAR", "Target", "RecognitionHuang", "et", "al", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["The", "DBF", "is", "actively", "under", "3GPP", "LTE", "standardization", ",", "where", "the", "unlicensed", "band", "is", "a", "secondary", "carrier", "in", "carrier", "aggregation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["To", "construct", "a", "DBN", ",", "the", "hidden", "layer", "of", "previous", "RBM", "is", "regarded", "as", "the", "visible", "layer", "of", "its", "subsequent", "RBM", "in", "the", "deep", "structure", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "Lovasz", "Bregman", "(", "LB", ")", "divergence", "for", "rank", "aggregation", "on", "the", "score", "-", "based", "permutations", "is", "initially", "introduced", "in", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["The", "predictive", "display", "proposed", "here", "has", "two", "major", "components", ":", "slave", "-", "tool", "tracking", "by", "correcting", "the", "hand", "-", "eye", "transform", "in", "real", "-", "time", "to", "calculate", "an", "accurate", "prediction", "and", "stereoscopic", "AR", "rendering", "to", "display", "the", "prediction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["In", ",", "a", "model", "based", "on", "the", "SBM", "was", "proposed", "for", "object", "shape", "modeling", "that", "represents", "the", "physical", "local", "part", "of", "the", "objects", "as", "a", "union", "of", "convex", "polytopes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "shape boltzmann machine"}, {"tokens": ["This", "OR", "is", "subsequently", "shown", "to", "have", "significant", "performance", "advantages", "over", "single", "-", "hop", "communications", "for", "both", "first", "and", "second", "-", "order", "outage", "statistics", "in", "the", "presence", "of", "interference", ",", "both", "theoretically", "and", "empirically", "in", "terms", "of", "signal", "-", "to", "-", "interference", "-", "plus", "-", "noise", "-", "ratio", "(", "SINR)The", "performance", "of", "closely", "-", "located", "WBANs", "will", "be", "interference", "limited", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "opportunistic relaying"}, {"tokens": ["Tok", "delimited", "by", "three", "tags", ",", "[", "CLS", "]", ",", "[", "SEP", "]", "and", "[", "EOS", "]", "(", "beginning", ",", "SEP", "and", "end", "of", "sentence", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "separator"}, {"tokens": ["For", "long", "-", "axis", "4Ch", "view", "images", ",", "LV", ",", "myocardium", ",", "RV", ",", "LA", "and", "RA", "were", "manually", "annotated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["CE", ":", "context", "encoder", ",", "SI", ":", "semantic", "inpainting", ","], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "semantic inpainting"}, {"tokens": ["MPIspeedup", "-", "hdf5", "for", "equivalent", "scaling", "data", "up", "to", "384", "cores", ")", ",", "(", "b", ")", "PSC", "Bridges", ",", "and", "(", "c", ")", "LSU", "SuperMIC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["AR", "assumes", "everything", "to", "be", "static", "while", "real", "world", "is", "very", "dynamic", ",", "as", "there", "are", "many", "things", "that", "keep", "on", "changing", "like", "people", "passing", "by", ",", "weather", "conditions", ",", "color", "of", "buildings", "as", "they", "may", "be", "repainted", "over", "a", "gap", "of", "few", "years", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["In", "this", "paper", ",", "we", "propose", "two", "variants", "of", "PNN", ",", "namely", "IPNN", "and", "OPNN", ",", "as", "will", "be", "discussed", "later", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["In", "GA", "-", "SCP", "and", "GA", "-", "RSSD", ",", "GA", "employs", "the", "following", "steps", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["To", "implement", "FL", "over", "wireless", "networks", ",", "the", "wireless", "devices", "must", "transmit", "their", "local", "training", "results", "over", "wireless", "links", ",", "which", "can", "affect", "the", "performance", "of", "FL", "due", "to", "limited", "wireless", "resources", "(", "such", "as", "time", "and", "bandwidth", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["In", "order", "to", "adjust", "the", "FEC", "redundancy", "and", "the", "transmission", "rate", ",", "the", "receivers", "periodically", "send", "the", "packet", "error", "rate", "information", "to", "the", "Access", "Point", "(", "AP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "access point"}, {"tokens": ["In", "PSO", "is", "classified", "into", "three", "different", "versions", ":", "classical", "PSO", ",", "scale", "-", "free", "PSO", "and", "binary", "PSO", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Zoom", "Network", "for", "Object", "Detectionsec", ":", "zoom", "-", "network", "-", "with", "-", "recursive", "-", "training", "-", "for", "-", "object", "-", "detectionWe", "now", "verify", "our", "proposed", "method", "in", "the", "context", "of", "object", "detection", "and", "embed", "the", "MAD", "unit", ",", "which", "is", "for", "selecting", "feature", "maps", "from", "various", "branches", "in", "the", "network", ",", "with", "region", "proposal", "generation", "in", "an", "end", "-", "to", "-", "end", "learning", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["PSO", "based", "DED", "tasks", "are", "analyzed", "to", "attract", "the", "attention", "of", "researchers", "in", "this", "particular", "area", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Thus", ",", "we", "propose", "a", "SEM", "or", "LOM", "image", "segmentation", "-", "based", "microstructural", "classification", "approach", "using", "a", "FCNN", "and", "max", "-", "voting", "scheme", "to", "classify", "each", "object", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["However", ",", "they", "can", "be", "reconstructed", "from", "the", "RB", "approximation", "of", "the", "deformation", "gradient", ",", "uniquely", "up", "to", "rigid", "body", "motion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["On", "ImageNet", ",", "our", "method", "also", "outperforms", "the", "traditional", "BNN", "method", "and", "XNOR", "-", "net", ",", "using", "AlexNet", "by", "a", "margin", "of", "and", "top-", "accuracy", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary neural networks"}, {"tokens": ["The", "same", "energy", "SAD", "as", "used", "in", "the", "i", "-", "vector", "system", "filters", "out", "nonspeech", "frames", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "speech activity detection"}, {"tokens": ["Spectrum", "kernel", "as", "part", "of", "SK", "has", "been", "applied", "to", "many", "different", "applications", ",", "including", "text", ",", "DNA", ",", "and", "protein", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "string kernel"}, {"tokens": ["The", "publicly", "available", "dataset", "consists", "of", "(", "per", "class", ")", "cine", "stacks", "of", "2D", "MR", "image", "sequences", "which", "are", "annotated", "at", "ED", "and", "ES", "phases", "by", "a", "clinical", "expert", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["A", "sensor", "node", "can", "transfer", "data", "outside", "if", "and", "only", "if", "there", "exists", "a", "path", "from", "the", "sensor", "to", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["epiniere", ",", "ICM", ",", "Inserm", "U", "1127", ",", "CNRS", "UMR", "7225", ",", "Sorbonne", "Universite", ",", "F-75013", ",", "Paris", ",", "FranceMultiple", "sclerosis", "(", "MS", ")", "is", "a", "demyelinating", "disease", "of", "the", "central", "nervous", "system", "(", "CNS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "central nervous system"}, {"tokens": ["The", "top", "value", ",", "corresponding", "to", ",", "defines", "the", "WF", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "weighted fusion"}, {"tokens": ["The", "ANN", "architecture", "is", "typically", "split", "into", "three", "types", "of", "layers", ":", "one", "input", "layer", ";", "one", "or", "more", "hidden", "layers", ";", "and", "one", "output", "layer", "(", "c.f", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["c", "c", "c", "c", "c", "c", "c", "&", "3cSensitivity", "&", "3cSpecificity", "&", "ET", "&", "WT", "&", "TC", "&", "ET", "&", "WT", "&", "TC", "Development", "set", "&", "0.735", "&", "0.851", "&", "0.664", "&", "0.998", "&", "0.994", "&", "0.997", "Validation", "set", "&", "0.723", "&", "0.879", "&", "0.619", "&", "0.998", "&", "0.994", "&", "0.998", "Results", "for", "BraTS", "2017", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "whole tumor"}, {"tokens": ["These", "meshes", "are", "then", "rigidly", "aligned", "using", "Generalised", "Procrustes", "Analysis", "(", "GPA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "generalized procrustes analysis"}, {"tokens": ["PIN", "consistently", "outperforms", "QRC", "(", "Results", "provided", "by", "authors", ")", "in", "Top", "3", "and", "Top", "5", "retrieval", "showcasing", "its", "effectiveness", "in", "indexing", "the", "proposals", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["P.", "Frank", ",", "A.", "Muller", ",", "H.", "Droste", "and", "J.", "Speidel", ",", "\"", "Cooperative", "interference", "-", "aware", "joint", "scheduling", "for", "the", "3GPP", "LTE", "uplink", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Latency", "CCDF", "of", "the", "entire", "cell", "area", "with", "SC", ",", "legacy", "MC", "and", "the", "proposed", "MC", "activation", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "single connectivity"}, {"tokens": ["Interleaved", "Declustering", "(", "ID", ")", "ID", "organizes", "disks", "into", "clusters", "with", "disks", "per", "cluster", ","], "acronym_pos": [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["Ageing", "coupled", "with", "RLS", "and", "SBM", "can", "reach", "the", "optimum", "by", "local", "moves", ",", "which", "respectively", "yields", "upper", "bounds", "of", "and", "for", "arbitrarily", "small", "constant", "on", "their", "runtimes", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard bit mutations"}, {"tokens": ["gray!40&Retrained&LR", ",", "DT", ",", "MLP&Great", "accuracy", ";", "acceptable", "overhead", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["If", "this", "polynomial", "is", ",", "then", "the", "corresponding", "MVF", "consists", "of", "the", "vectors", "and", "vectors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching vector families"}, {"tokens": ["Interventions", "on", "the", "PA", "task"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "physical access"}, {"tokens": ["Previous", "slice", "by", "slice", "segmentation", "approaches", "validated", "their", "methods", "on", "LR", "annotations", ";", "however", ",", "we", "see", "that", "the", "produced", "label", "maps", "are", "far", "off", "from", "the", "true", "underlying", "ventricular", "geometry", "and", "it", "can", "be", "a", "limiting", "factor", "for", "the", "analysis", "of", "ventricle", "morphology", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["WM", "Age", "Estimator", ";", "[", "block3", ",", "below", "left", "of", "=", "f", ",", "node", "distance", "=", "1.5", "cm", "]", "(", "om", ")", "BF", "Age", "Estimator", ";", "[", "block3", ",", "below", "right", "of", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "black females"}, {"tokens": ["The", "D2D", "Relays", "that", "connect", "to", "BS", "are", "using", "their", "sensors", "to", "calculate", "a", "pool", "of", "frequencies", "to", "use", "for", "assigning", "to", "D2D", "cluster", "mode", "clients", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Nevertheless", "CF", "has", "two", "widely", "known", "problems", "which", "are", "sparsity", "and", "cold", "start", "(", "CS", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["In", "most", "DCNN", "-", "DCF", "based", "works", ",", "features", "employed", "for", "training", "correlation", "filters", "are", "directly", "extracted", "by", "a", "deep", "neural", "network", "pretrained", "on", "image", "classification", "dataset", "without", "any", "fine", "-", "tuning", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Focusing", "on", "the", "computational", "cost", "of", "obtaining", "a", "solution", "of", "the", "full", "OPF", "problem", "suggests", "the", "use", "of", "another", "loss", "function", "that", "measures", "this", "cost", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["As", "we", "see", ",", "BIPCM", "outperforms", "MLPC", "by", "about", "0.2", "dB", "with", "SC", "decoding", ",", "while", "it", "behaves", "marginally", "better", "than", "MLPC", "with", "SCL", "decoding", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "successive cancellation"}, {"tokens": ["In", "our", "experiments", ",", "we", "find", "that", "ARD", "student", "models", "decisively", "outperform", "adversarially", "trained", "networks", "of", "identical", "architecture", "in", "terms", "of", "robust", "accuracy", ",", "surpassing", "state", "-", "of", "-", "the", "-", "art", "methods", "on", "standard", "robustness", "benchmarks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Given", "the", "LSC", ",", "we", "also", "intend", "to", "create", "scientific", "dictionary", "where", "words", "are", "extracted", "from", "the", "texts", "of", "abstracts", "in", "LSC", "to", "be", "used", "on", "measuring", "the", "information", "of", "words", "for", "subject", "categories", "in", "the", "process", "of", "quantification", "of", "meaning", "of", "texts", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["We", "design", "a", "3D", "Faster", "R", "-", "CNN", "for", "nodule", "detection", ",", "and", "propose", "GBM", "with", "deep", "3D", "DPN", "features", ",", "raw", "nodule", "CT", "pixels", "and", "nodule", "size", "for", "nodule", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dual path network"}, {"tokens": ["Then", "there", "exist", "a", "player", "MD", "strategy", "and", "a", "player", "MD", "strategy", "such", "that", "for", "all", "states", ":"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["Due", "to", "these", "problem", ",", "the", "BA", "do", "not", "always", "give", "correct", "estimates", "of", "the", "camera", "parameters", "and", "inverse", "depth", "values", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bundle adjustment"}, {"tokens": ["The", "output", "of", "GSP", "is", "normalized", "by", "it", "'s", "mean", "and", "standard", "deviation", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global statistics pooling"}, {"tokens": ["The", "typical", "UE", "is", "assumed", "to", "be", "at", "the", "origin", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Since", "we", "know", "that", "lower", "layers", "in", "a", "multi", "-", "layer", "model", "converge", "to", "their", "final", "representations", "more", "quickly", "than", "higher", "layers", ",", "it", "is", "likely", "that", "models", "learn", "local", "lexical", "categories", "like", "POS", "earlier", "than", "they", "learn", "higher", "-", "level", "linguistic", "categories", "like", "semantic", "class", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["shows", "values", "of", "calculated", "for", "both", "OEC", "and", "sk", "-", "means", "(", "with", "clusters", ")", "in", "the", "LG", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["The", "best", "estimate", "for", "is", "obtained", "by", "the", "mean", "of", "the", "distributionThe", "GP", "-", "PF", "method", "is", "summarized", "in", "Algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "overall", "size", "of", "the", "data", "after", "the", "preparation", "to", "detect", "one", "or", "two", "Wi", "-", "Fi", "APs", "is", "of", "about", "382", "MB", ",", "where", "the", "Wi", "-", "Fi", "APs", "are", "on", "opposite", "sides", "of", "LTE", "-", "U", "BSS", "and", "placed", "at", "6", "feet", "distance", "from", "the", "LTE", "-", "U", "BSS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "our", "experiments", ",", "we", "report", "a", "number", "of", "different", "results", ":", "1", ")", "Training", "a", "DST", "model", "with", "the", "usual", "turn", "-", "level", "supervision", "on", "the", "different", "domains", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["Each", "word", "is", "represented", "by", "its", "lemma", "along", "its", "linguistic", "factors", "(", "POS", "tag", ",", "tense", ",", "gender", ",", "number", "and", "person", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["NP", "barg", "*", "uarka-", ";", "this", "variant", "surfaces", "in", "the", "Dari", "dialect", "of", "New", "Persian", "as", "balg", "(", "[", "160]Korn2005", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["OT", "Extension", "Phase", "II", ":", "For", "every", ",", "computes", "and", "sends", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["We", "then", "computed", "the", "mean", "and", "standard", "deviation", "of", "the", "CCC", "across", "stories", ",", "reported", "in", "Table", ",", "to", "evaluate", "the", "models", "'", "robustness", "to", "variations", "in", "the", "training", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["have", "derived", "a", "metric", "they", "call", "a", "magic", "barrier", "-", "the", "lower", "bound", "on", "the", "root", "-", "mean", "-", "square", "error", "that", "can", "be", "attained", "by", "an", "optimal", "RS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "recommender systems"}, {"tokens": ["Dynamic", "modeling", "and", "analysis", "of", "PCM", "-", "controlled", "DCM", "-", "operating", "buck", "converters", "-", "a", "reexamination", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "peak current mode"}, {"tokens": ["Activity", "space", "rank", "turnover", ",", "&", "&", "&", "CNS", "dataset", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["Specifically", ",", "we", "develop", "a", "bidirectional", "MTL", "RNNs", "to", "jointly", "learn", "the", "long", "-", "range", "contextual", "information", "from", "two", "directions", "(", "from", "cervical", "vertebrae", "to", "sacral", "vertebrae", "and", "the", "other", "way", "around", ")", "for", "both", "the", "identification", "and", "localization", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multi - task learning"}, {"tokens": ["The", "proposed", "GP", "contour", "estimation", "method", "succeeded", "in", "obtaining", "themore", "accurate", "contour", "of", "the", "objects", "in", "comparison", "with", "the", "earlier", "approaches", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Also", ",", "we", "could", "benefit", "from", "deep", "learning", "to", "classify", "risk", "given", "the", "FOE", "and", "detected", "objects", "as", "input", ",", "bypassing", "the", "formulation", "as", "an", "image", "retrieval", "problem", "and", "using", "EMD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "earth mover 's distance"}, {"tokens": ["When", "used", "in", "an", "ML", "system", ",", "an", "ISP", "can", "be", "considered", "a", "hardware", "feature", "extractor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Results", "obtained", "via", "weighted", "least", "square", "regression", "(", "see", "Tables", "for", "the", "CNS", "dataset", "and", "S2", "in", "Supplementary", "Material", "for", "the", "MDC", "dataset", ")", "reveal", "that", "the", "social", "metrics", "are", "significant", "predictors", "for", "spatial", "metrics", "(", "p", "value", "in", "all", "cases", "except", "for", "M4", "in", "the", "MDC", "dataset", ")", ",", "and", "they", "typically", "have", "more", "importance", "than", "factors", "such", "as", "gender", ",", "time", ",", "coverage", "and", "age", "group", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["Such", "a", "function", "solves", "SP", "in", ".For", "brevity", ",", "we", "set", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "splitting problem"}, {"tokens": ["Private", "and", "Shared", "Encoder", "Due", "to", "the", "fact", "that", "various", "languages", "have", "different", "syntactic", "structures", ",", "using", "the", "same", "set", "of", "word", "embeddings", "is", "not", "enough", "to", "properly", "align", "English", "and", "Chinese", "for", "QA", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["For", "memory", ",", "we", "assume", "the", "worst", "case", "scenario", "for", "the", "ISP", "-", "that", "the", "ISP", "must", "read", "raw", "images", "from", "DRAM", "rather", "than", "streaming", "raw", "images", "directly", "from", "the", "image", "sensor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Therefore", ",", "similar", "to", "the", "DI", "case", ",", "one", "can", "consider", "binary", "coefficients", "for", ",", "i.e.", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "direct inspection"}, {"tokens": ["the", "coordinated", "scenario", ",", "STAs", "utilize", "the", "MAC", "random", "mechanism", "to", "contend", "for", "the", "channel", ",", "while", "let", "the", "AP", "to", "decide", "who", "will", "be", "involved", "in", "the", "followed", "parallel", "transmissions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["This", "work", "tackles", "the", "challenge", "of", "mitigating", "the", "rate", "saturation", "by", "leveraging", "the", "RS", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "relay station"}, {"tokens": ["This", "result", "indicates", "that", "the", "SE", "reduces", "the", "randomness", "by", "giving", "more", "weight", "on", "exploring", "part", "in", "QA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "quantum annealing"}, {"tokens": ["Similarity", "MeasuresCosine", "Distance", "(", "CD", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0], "long_form": "cosine distance"}, {"tokens": ["We", "derive", "an", "expression", "for", "the", "boundary", "of", "the", "stability", "region", "and", "prove", "that", "the", "RA", "with", "priority", "scheme", "encloses", "the", "stability", "region", "of", "the", "conventional", "RA", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random access"}, {"tokens": ["SP", "stringsets", "can", "also", "be", "defined", "with", "a", "finite", "set", "of", "-subsequences", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["The", "overhead", "is", "minimal", "in", "comparison", "with", "the", "gains", "of", "the", "PAP", "optimization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["The", "Convex", "IB", "LagrangianExploring", "the", "IB", "curveClearly", ",", "a", "situation", "like", "the", "one", "depicted", "in", "Theorem", "is", "not", "desirable", ",", "since", "we", "can", "not", "aim", "for", "different", "levels", "of", "compression", "or", "performance", "."], "acronym_pos": [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Most", "run", "time", "of", "DDE", "-", "MGM", "during", "modeling", "is", "consumed", "on", "searching", "the", "list", "for", "accumulating", "new", "transitions", "to", "existing", "ones", ",", "so", "larger", "grid", "size", "results", "in", "longer", "run", "time", "as", "shown", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["FJ", "has", "been", "shown", "to", "be", "suitable", "also", "in", "dealing", "with", "semantics", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "featherweight java"}, {"tokens": ["This", "section", "presents", "the", "pre", "-", "processing", "steps", "for", "creating", "an", "ordered", "list", "of", "words", "from", "the", "LSC", "and", "the", "description", "of", "Leicester", "Scientific", "Dictionary", "(", "LScD", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["This", "result", "is", "of", "particular", "interest", "to", "us", ",", "since", "it", "provides", "a", "closed", "-", "form", "way", "to", "introduce", "Bayesian", "online", "learning", "into", "GP", "models", ",", "allowing", "us", "to", "naturally", "avoid", "any", "data", "revisiting", ",", "only", "passing", "past", "parameters", "forward", "and", "fixing", "the", "posterior", "-", "prior", "recursion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["NP"], "acronym_pos": [1], "long_form": "new persian"}, {"tokens": ["The", "rebuilding", "of", "a", "failed", "disk", "for", "the", "CD", "organization", "can", "be", "parallelized", "by", "copying", "from", "and", "into", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["OT", "is", "performed", "for", "every", "block", ",", "the", "parties", "have", "to", "engage", "in", "1-out", "-", "of-", "OT", "protocols", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["A", "Conceptual", "view", "of", "DI", "is", "presented", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "dependency injection"}, {"tokens": ["Hence", ",", "although", "the", "labels", "are", "different", ",", "we", "hypothesize", "that", "there", "is", "some", "useful", "information", "from", "ER", "that", "can", "be", "leveraged", "to", "improve", "overall", "SRL", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["This", "could", "enable", "UAVs", "to", "fly", "autonomously", "over", "places", "where", "GPS", "signals", "are", "unavailable", "or", "unreliable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Since", "FL", "involves", "an", "exchange", "of", "a", "learning", "model", "between", "users", "and", "the", "BS", ",", "both", "computation", "and", "communication", "latencies", "are", "determined", "by", "the", "learning", "accuracy", "level", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "practice", ",", "this", "is", "achieved", "through", "the", "use", "of", "demodulation", "reference", "signals", ",", "called", "DMRS", "in", "LTE", "-", "A", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "this", "case", ",", "BS", "transmits", "information", "signal", "for", "and", "independently", "in", "different", "time", "slots", "with", "total", "transmit", "power", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["This", "is", "related", "with", "the", "noise", "variance", "(", "one", "of", "hyperparameters", "of", "the", "GP", ")", ",", "as", "explained", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "2D", "-", "learning", "framework", "retains", "all", "the", "key", "features", "of", "the", "original", "PSO", ",", "despite", "the", "extra", "learning", "dimension", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["It", "was", "already", "known", "that", "MD", "strategies", "are", "sufficient", "for", "safety", "and", "reachabilityobjectives", "in", "countable", "finitely", "branching", "MDPs"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["These", "raw", "images", "are", "then", "processed", "by", "an", "ISP", "to", "generate", "RGB", "images", "(", "Figure", "fig", ":", "tiger", "-", "rgb", ")", ",", "which", "are", "consumed", "either", "by", "a", "display", "for", "human", "viewing", "or", "by", "a", "CV", "algorithm", "for", "inference", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["SEM", "provides", "information", "about", "the", "die", "surface", ",", "i.e.", ",", "the", "XY", "plane", "of", "the", "die", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Their", "data", "is", "not", "collected", "by", "the", "BS", "before", "the", "nodes", "exhaust", "the", "energy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["This", "causes", "issues", "when", "pre", "-", "training", "MLS", "data", "as", "TLS", "data", "exhibits", "very", "different", "artefacts", "to", "MLS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "terrestrial laser scanning"}, {"tokens": ["We", "choose", "to", "use", "loss", "rather", "than", "accuracy", "for", "CF", "because", "we", "would", "like", "to", "differentiate", "when", "the", "quality", "of", "our", "predictions", "are", "closer", "to", "the", "target", "(", "e.g.", "we", "want", "to", "differentiate", "between", "predicted", "ratings", "of", "and", "for", "a", "target", "of", ")", "in", "our", "results", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["In", "this", "paper", ",", "we", "will", "explore", "the", "specialized", "regulations", "and", "approaches", "specific", "to", "SAR", "target", "recognition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Let", "the", "following", "adaptive", "mechanism", "be", "introduced", "to", "STA", ":", "lawwhere", "and", "are", "scalar", "variables", ",", "is", "a", "constant", "defined", "as", "the", "minimum", "gain", "magnitude", "of", "to", "prevent", "the", "loss", "of", "robustness", ",", "positive", "constants", "and", "satisfy", "new_inequality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["These", "two", "measures", "are", "based", "on", "MDR", "motsinger2006multifactor", ",", "which", "is", "a", "procedure", "that", "collapses", "the", "selected", "interacted", "data", "set", "into", "a", "four", "variable", "table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multifactor dimensionality reduction"}, {"tokens": ["Choose", "a", "variable", "that", "violates", "the", "property", "(", "i.e.", ",", "and", "for", "all", ")", "so", "that", "all", "components", "in", "lower", "SCCs", "satisfy", "the", "property", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "strongly connected components"}, {"tokens": ["They", "split", "the", "QA", "process", "into", "two", "steps", ";", "first", "they", "build", "an", "entity", "-", "centric", "index", "to", "search", "the", "target", "entity", ",", "whereby", "in", "the", "second", "step", "they", "expand", "the", "property", "mention", "with", "WordNet", "and", "ConceptNet", "to", "match", "the", "target", "entity", "with", "the", "searched", "entity", "property", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Adaptive", "FEC", "-", "based", "techniques", "that", "are", "able", "to", "assure", "a", "high", "QoE", "for", "end", "-", "users", "are", "a", "convenient", "means", "of", "delivering", "video", "data", "to", "wireless", "users", "in", "this", "case", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["SummaryWe", "have", "demonstrated", "that", "the", "relative", "charging", "rate", "within", "the", "CC", "phase", "of", "a", "battery", "increases", "as", "the", "FCC", "decreases", "and", "based", "on", "this", "C", "-", "rate", "we", "have", "also", "proposed", "an", "FCC", "estimation", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["For", "example", ",", "opting", "for", "a", "latent", "feature", "model", "not", "only", "deviates", "from", "an", "SBM", ",", "but", "also", "increases", "the", "computation", "complexity", "because", "the", "number", "of", "latent", "variable", "combination", "increases", "from", "to", ",", "thus", "in", "turn", "prompting", "for", "an", "efficient", "and", "scalable", "inference", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["The", "second", "experiment", "was", "performed", "with", "a", "non", "-", "adaptive", "video", "-", "aware", "FEC", "mechanism", "(", "Video", "-", "aware", "FEC", ")", ",", "where", "a", "fixed", "amount", "of", "38", "of", "redundancy", "was", "added", "only", "to", "I-", "and", "P", "-", "frames", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Hence", "for", "many", "practical", "applications", ",", "FB", "satisfying", "the", "NPR", "property", "are", "better", "choices", "as", "long", "as", "the", "distortions", "are", "within", "the", "limits", "specified", "by", "the", "applications", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "near perfect reconstruction"}, {"tokens": ["Inception", "score", "(", "IS", ")", "is", "the", "most", "widely", "adopted", "metric", "of", "generative", "models", ",", "which", "estimates", "the", "diversity", "of", "the", "generated", "samples", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["The", "first", "point", "of", "entry", "is", "to", "include", "GP", "as", "a", "machine", "learning", "option", "since", "a", "number", "of", "successful", "biomedical", "applications", "have", "been", "reported", "(", "e.g.", ",", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Occupations", "just", "above", "this", "threshold", "appeared", "more", "consistent", "with", "the", "definition", "of", "DSA", "skills", "given", "in", "sec", ":", "intro", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["They", "are", "known", "as", "closed", "domain", "QA", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["Restricted", "by", "the", "volume", "and", "power", "consumption", ",", "the", "amount", "of", "the", "antennas", "at", "the", "users", "is", "far", "less", "than", "the", "BS", "thus", "we", "can", "search", "for", "the", "best", "analog", "beamforming", "vector", "in", "the", "beamsteering", "codebook", "exhaustedly", "as", "and", "it", "wo", "n't", "take", "much", "overhead", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["PSO", "follows", "two", "simple", "yet", "essential", "steps", "to", "have", "completed", "optimization", "process", "to", "find", "the", "minimum", "optimum", "or", "maximum", "optimum", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["For", "example", ",", "for", "sentiment", ",", "we", "generate", "continuations", "for", "each", "of", "the", "3", "sentiment", "values", "and", "compare", "to", "BS", "and", "TS", "with", "3", "continuations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "temperature - based sampling"}, {"tokens": ["Here", ",", "we", "realize", "the", "CF", "approach", "in", "a", "similar", "way", "but", "instead", "of", "calculating", "user", "similarities", ",", "we", "calculate", "similarities", "between", "datasets", "and", "services", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["With", "regards", "to", "delays", ",", "our", "model", "predicts", "tails", "that", "are", "stochastically", "dominated", "by", "the", "delay", "of", "a", "typical", "customer", "of", "an", "equivalent", "PS", "queue", "(", "see", "Figure", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "processor sharing"}, {"tokens": ["We", "finally", "show", "results", "on", "BraTS", "2017", "Training", "and", "Validation", "sets", ",", "showing", "that", "while", "the", "results", "obtained", "for", "the", "WT", "segmentation", "are", "competitive", "with", "other", "participants", "'", "algorithms", ",", "we", "are", "not", "able", "to", "properly", "capture", "the", "less", "common", "regions", "(", "TC", "or", "ET", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["The", "last", "factor", "in", "channelGain", ",", ",", "corresponds", "to", "fading", "distribution", "between", "BS", "in", "tier", "and", "user", "over", "RB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "resource blocks"}, {"tokens": ["The", "PI", "=", "TRUE", "prints", "the", "prediction", "intervals", "used", "in", "nnar", "models", ",", "but", "may", "take", "long", "time", "processing", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "prediction intervals"}, {"tokens": ["Therefore", ",", "we", "can", "design", "a", "similar", "incremental", "approach", "as", "in", "the", "case", "of", "NFA", "or", "NCA", ",", "and", "find", "the", "minimum", "for", "which", "the", "-Safra", "construction", "is", "GFG", ",", "or", "DBP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "determinisable by pruning"}, {"tokens": ["This", "represents", "the", "link", "conditions", "and", "is", "used", "to", "determine", "the", "connection", "and", "throughput", "between", "a", "user", "and", "an", "eNodeB.", ":", "We", "represent", "the", "throughput", "space", "matrix", "as", ":", "The", "throughput", "space", "matrix", "entries", "(", "'s", ")", "is", "defined", "as", "throughput", "per", "RB", "between", "the", "user", "and", "eNodeB", "and", "is", "calculated", "on", "the", "basis", "of", "MCS", "values", "with", "respect", "to", "SINR", "levels", "as", "given", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resource blocks"}, {"tokens": ["Table", "shows", "accuracy", "and", "BS", "of", "all", "tested", "methodologies", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "brier score"}, {"tokens": ["Increasing", "the", "accuracy", "of", "this", "approximation", "and", "the", "efficiency", "of", "the", "methods", "are", "two", "fundamental", "challenges", "in", "GP", "based", "emulation", "[", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "comparison", "between", "CDP", "and", "LDP", "is", "in", "the", "Table", "Comparison", "between", "LDP", "and", "CDP", "Randomized", "Response", "Technique"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["It", "is", "done", "by", "calculating", "the", "probability", "distribution", "over", "which", "sequences", "the", "TP", "is", "currently", "in", ",", "and", "subsequently", ",", "by", "calculating", "a", "distribution", "over", "the", "predicted", "clusters", "for", "the", "next", "input", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["Obtaining", "the", "MAP", "estimate", "In", "general", ",", "a", "proper", "definition", "of", "the", "posterior", "mode", "would", "be", "necessary", ",", "because", "the", "GP", "posterior", "is", "over", "a", "space", "of", "functions", ",", "which", "is", "an", "infinite", "dimensional", "object", "and", "does", "not", "have", "a", "density", "with", "respect", "to", "Lebesgue", "measure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["AML", "natural", "semantic", "rules", ":", ",", ",", "and", "denote", "a", "sequence", "of", "statements", ",", "send", "actions", ",", "and", "method", "names", ",", "respectively", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["Therefore", ",", "there", "is", "a", "need", "for", "a", "descriptive", "approach", "that", "define", "a", "conceptual", "view", "of", "QA", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["Adaptive", "Video", "-", "aware", "FEC", "-", "based", "Mechanism", "(", "ViewFEC)sec", ":", "viewfecMotivated", "by", "the", "open", "issues", "afore", "-", "identified", ",", "this", "section", "proposes", "and", "validates", "the", "adaptive", "cross", "-", "layer", "VIdEo", "-", "aWare", "FEC", "-", "based", "Mechanism", "with", "Unequal", "Error", "Protection", "scheme", "(", "ViewFEC", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["BS", ":", "batch", "size", "."], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "batch size"}, {"tokens": ["It", "can", "also", "be", "shown", "via", "Pearl", "'s", "backdoor", "criterionppearl2009causality", "that", "the", "ACE", "may", "be", "defined", "in", "terms", "of", "the", "Specific", "Causal", "Effect", "(", "SCE),align"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average causal effect"}, {"tokens": ["As", "observed", "in", "Table", ",", "DTP", "struggles", "to", "train", "these", "deep", "networks", ",", "even", "when", "given", "the", "advantage", "and", "allowed", "to", "use", "an", "adaptive", "learning", "rate", "unlike", "the", "other", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "difference target propagation"}, {"tokens": ["Actively", "Secure", "OT", "Extension", "for", "Short", "SecretsWe", "make", "the", "KK13", "OT", "extension", "protocol", "secure", "against", "a", "malicious", "receiver", "by", "adding", "a", "consistency", "check", "that", "relies", "on", "linearity", "of", "WH", "code", "and", "adds", "a", "communication", "of", "bits", "irrespective", "of", "the", "number", "of", "extended", "OTs", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["By", "utilizing", "the", "hybrid", "ET", "and", "EAA", "approach", ",", "the", "probability", ",", "possibility", ",", "and", "interval", "measures", ",", "described", "as", "wind", "generation", "and", "load", "deviation", ",", "can", "be", "fully", "considered", "in", "UC", "problem", "to", "demonstrate", "the", "aleatory", "and", "epistemic", "uncertainties", "of", "scheduling", "costs", "in", "the", "form", "of", "P", "-", "boxes", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "evidence theory"}, {"tokens": ["This", "label", "-", "switching", "algorithm", "is", "also", "incorporated", "by", "in", "the", "inference", "algorithm", "for", "their", "dynamic", "SBM", ",", "which", "will", "be", "discussed", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Some", "of", "the", "challenges", "of", "FL", "over", "wireless", "networks", "have", "been", "studied", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["GCS", "computes", "the", "optimal", "trajectory", "of", "the", "SAR", "mission", "then", "each", "UAV", "will", "received", "its", "path", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["The", "base", "station", "(", "BS", ")", "with", "antennas", "communicates", "to", "users", "simultaneously", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Age", "differences", "are", "not", "present", "within", "the", "sample", "of", "students", "participating", "in", "the", "CNS", "study", ",", "and", "they", "are", "not", "estimated", "to", "be", "relevant", "with", "respect", "to", "spatial", "behaviour", "in", "the", "MDC", "study", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["While", "is", "characterised", "by", "the", "original", "SBM", ",", "the", "resulting", "is", "characterised", "by", "another", "SBM", ",", "which", "results", "in", ",", "and", "so", "on", ",", "until", "there", "is", "only", "one", "group", "at", "the", "top", "level", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Data", "for", "Question", "Answering", "Dialogue", "SystemsWith", "respect", "to", "QA", "dialogue", "systems", ",", "two", "datasets", "have", "been", "created", "based", "on", "the", "human", "interactions", "from", "technical", "chats", "or", "forums", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Specifically", ",", "given", "a", "set", "of", "related", "items", "that", "belong", "to", "a", "class", ",", "BS", "scores", "a", "new", "item", "by", "estimating", "its", "normalized", "marginal", "probability", "that", "the", "item", "belongs", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian sets"}, {"tokens": ["In", "above", "formula", ",", "we", "calculate", "the", "time", "that", "takes", "workers", "to", "push", "the", "gradients", "to", "the", "PS", ",", "where", "model", "size", "divided", "by", "the", "number", "of", "workers", "which", "is", "our", "formula", "to", "calculate", "the", "gradients", "size", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["Taking", "GDP", "for", "the", "NN", "as", "an", "example", ",", "its", "SSC", "is", "interpreted", "as", "follows", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gross domestic product"}, {"tokens": ["For", "RV", "generation", ",", "we", "only", "focus", "on", "a", "particular", "LSH", "family", "called", "hamming", "-", "hash", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["In", "other", "words", ",", "it", "provides", "the", "coupling", "of", "components", "of", "what", "is", "know", "as", "multi", "-", "output", "GP", "in", "the", "machine", "learning", "community", "and", "cokriging", "in", "geostatistics", "[", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Each", "SP", "within", "an", "SM", "shares", "an", "instruction", "unit", ",", "dedicated", "to", "the", "management", "of", "the", "instruction", "flow", "of", "the", "threads", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "streaming processors"}, {"tokens": ["LR", "does", "not", "consider", "combinations", "and", "dependencies", "of", "features", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Figure", "shows", "an", "overview", "of", "interacting", "MB", "-", "MF", "reinforcement", "learning", "paradigm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "model - based"}, {"tokens": ["Conversely", ",", "many", "studies", "rely", "exclusively", "on", "pre", "-", "processed", ",", "densely", "annotated", "public", "datasets", "like", "UC", "Merced", "or", "Postdam", "because", "data", "extraction", "requires", "knowledge", "of", "geospatial", "standards", "and", "tools", "like", "Geographic", "Information", "Systems", "and", "RS", "image", "processing", "software", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["To", "resolve", "the", "feasibility", "issue", ",", "we", "provide", "a", "low", "-", "complexity", "UE", "selection", "algorithm", "based", "on", "bisection", "search", "method", "to", "maximize", "the", "number", "of", "admitted", "UEs", "that", "can", "achieve", "their", "QoS", "targets", ",", "and", "its", "complexity", "only", "increases", "logarithmically", "with", "the", "number", "of", "UEs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["During", "the", "synthesis", "of", "various", "sounds", ",", "the", "MVF", "parameter", "can", "be", "used", "as", "a", "boundary", "frequency", "to", "separate", "the", "voiced", "and", "unvoiced", "components", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["In", "particular", ",", "to", "achieve", "a", "target", "FER", "of", ",", "a", "design", "SNR", "of", "dB", "is", "a", "better", "choice", "for", "both", "BIPCM", "and", "MLPC", "with", "the", "SC", "decoder", ",", "while", "a", "design", "SNR", "of", "dB", "is", "a", "better", "choice", "for", "both", "BIPCM", "and", "MLPC", "with", "the", "SCL", "decoder", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "successive cancellation"}, {"tokens": ["Since", "the", "CSI", "in", "is", "unknown", ",", "we", "consider", "the", "following", "data", "rate", "for", "UE", "on", "SC", "(", "bit", "/", "s", "/"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["when", "is", "trained", "on", "generated", "LR", "images", "validating", "our", "hypothesis", "that", "subsampled", "images", "on", "which", "many", "super", "-", "resolution", "networks", "are", "trained", "may", "not", "be", "a", "correct", "representative", "of", "real", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["Given", "an", "input", "data", "sample", "from", "the", "dataset", ",", "the", "DBN", "with", "hidden", "layer(s", ")", "presents", "a", "complex", "feature", "mapping", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Therefore", ",", "each", "antenna", "can", "form", "independent", "beams", ",", "so", "that", "the", "multiple", "streams", "created", "by", "SVC", "-", "encoding", "are", "divided", "into", "parts", "and", "each", "part", "is", "assigned", "to", "a", "beam", "to", "be", "concurrently", "transmitted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scalable video coding"}, {"tokens": ["For", "HP", "scheduling", ",", "the", "nodes", "with", "high", "PRR", "occupy", "the", "SDTP", "for", "multiple", "super", "frames", "until", "they", "finish", "the", "transmissions", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high prr"}, {"tokens": ["Terminal", "OEC", "clusters", "on", "dataset", "."], "acronym_pos": [0, 1, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["table", "tabular[t]ll", "2cGender", "Set", "1", "&", "RAVLT", "Total", "(", "1", "-", "5", ")", "&", "FA", "Cingulum", "L", "Set", "2", "&", "FA", "Medial", "lemniscus", "L", "&", "FA", "Cingulum", "(", "hippocampus", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "fractional anisotropy"}, {"tokens": ["Regardless", "of", "their", "conceptual", "differences", ",", "UTAUT", ",", "TPB", ",", "and", "TAM", "have", "gained", "considerable", "evidence", "that", "supports", "them", "as", "relevant", "ones", "to", "understand", "the", "complexities", "of", "the", "technology", "-", "mediated", "relationships", "between", "buyers", "and", "sellers", "through", "E", "-", "commerce", "platforms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "technology acceptance model"}, {"tokens": ["Comparison", "of", "exact", "and", "upper", "bounded", "average", "SEP", "for", "different", "RIS", "-", "assisted", "scenarios", "under", "BPSK", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "symbol error probability"}, {"tokens": ["Time", "series", "TS", ":", "indicates", "the", "precise", "time", "when", "an", "original", "post", "or", "comment", "is", "added", "to", "a", "page", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time series"}, {"tokens": ["We", "also", "find", "the", "CC", "phase", "length", "from", "the", "reference", "voltage", "curve", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant current"}, {"tokens": ["We", "observe", "that", "the", "squared", "error", ",", "defined", "in", "(", ")", ",", "of", "ICA", "is", ",", "whereas", "that", "from", "DMD", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["The", "OT", "extension", "protocols", "have", "been", "introduced", "to", "theoretically", "circumvent", "the", "above", "limitation", "of", "OTs", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["While", "driving", "the", "sliding", "variable", "to", "the", "sliding", "mode", "surface", ",", "one", "gain", "of", "the", "STA", "automatically", "converges", "to", "an", "adjacent", "area", "of", "the", "perturbation", "magnitude", "in", "finite", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["Suppose", "that", "there", "are", "participants", "and", "aggregators", "in", "the", "FL", "framework", ",", "and", "the", "threshold", "for", "decryption", "of", "Threshold", "-", "Paillier", "cryptosystem", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["HMC", "and", "tab", ":", "MD", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["Implementation", "of", "state", "of", "the", "art", "deep", "nets", "should", "be", "enabled", "with", "the", "minimum", "effort", ",", "and", "the", "opportunity", "to", "apply", "them", "on", "RS", "images", "must", "be", "granted", "to", "non", "-", "developers", ",", "namely", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["For", "the", "method", "to", "solve", "the", "TTP", "minimization", "problem", ",", "simulation", "results", "validate", "the", "performance", "advantages", "in", "terms", "of", "power", "savings", "compared", "with", "the", "naive", "equal", "bandwidth", "unit", "allocation", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "total transmit power"}, {"tokens": ["e.g.", ",", "Pazand", "guzurg", ":", "NP", "buzurg", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "new persian"}, {"tokens": ["In", "our", "experiments", ",", "ARD", "students", "exhibit", "higher", "robust", "accuracy", "than", "adversarially", "trained", "models", "with", "identical", "architecture", ",", "and", "ARD", "often", "exhibits", "higher", "natural", "accuracy", "simultaneously", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["To", "that", "end", ",", "we", "introduce", "a", "hierarchical", "framework", "for", "Human", "Robot", "Learning", "(", "hHRL", ")", "that", "decomposes", "SAR", "interventions", "into", "computationally", "tractable", "state", "-", "action", "subspaces", "contained", "with", "a", "meta", "-", "controller", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["For", "the", "SDD", ",", "the", "comments", "suggest", "that", "the", "environment", "was", "well", "suited", "to", "examining", "very", "large", "images", "in", "a", "broad", "context", ",", "when", "the", "entire", "image", "could", "be", "seen", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Observe", "in", "this", "figure", "that", "the", "EQPO", "algorithm", "performs", "optimally", "-", "in", "the", "sense", "that", "no", "suboptimal", "routes", "are", "included", "in", "the", "OPF", "-", "for", "about", "130", "CFEs", "and", "then", "exhibits", "an", "error", "floor", "around", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal pareto front"}, {"tokens": ["During", "this", "measurement", ",", "the", "stereoscopic", "AR", "rendering", "ran", "asynchronously", "at", "36fps", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["(", "E", ",", "F", ")", "RV", "strategyfig", ":", "nvaca-1.0emfigure", "Node", "level", "vaccination", "is", "more", "efficient", "than", "the", "population", "level", "vaccination", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["Since", "the", "POGS", "approach", "is", "focused", "on", "machinery", "fault", "detection", ",", "the", "ROC", "curve", "is", "utilized", "to", "validate", "the", "superior", "detection", "performance", "of", "POGS", "compared", "to", "other", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["MethodologyIn", "Section", "5", ",", "we", "mainly", "discuss", "how", "to", "encode", "questions", "and", "generate", "BQ", "and", "why", "we", "exploit", "the", "Co", "-", "Attention", "Mechanism", "VQA", "algorithm", "to", "answer", "the", "query", "question", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["ProtocolAccording", "to", "the", "NOMA", "concept", ",", "BS", "transmits", "a", "combination", "of", "messages", "to", "both", "users", "and", "the", "selected", "relay", "as-0.0emwhere", "is", "the", "transmit", "power", "of", "the", "BS", "and", "denotes", "the", "information", "symbol", "to", ",", "and", "denotes", "the", "power", "allocation", "coefficient", ",", "such", "that", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["It", "can", "be", "suppressed", "without", "loss", "in", "the", "original", "signal", ",", "by", "a", "high", "-", "pass", "digital", "filter", "or", "by", "the", "use", "of", "a", "standard", "Wavelet", "Transform", "(", "WT", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "wavelet transform"}, {"tokens": ["Related", "worksWe", "mainly", "review", "four", "kinds", "of", "MDC", "methods", ":", "MD", "quantizers", ",", "correlating", "transform", "-", "based", "MDC", "methods", ",", "sampling", "-", "based", "MDC", "and", "standard", "-", "compliant", "MDC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0], "long_form": "multiple description coding"}, {"tokens": ["FAR", ",", "FRR", "and", "Average", "Error", "Rate", "(", "AER", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "false acceptance rate"}, {"tokens": ["The", "EE", "is", "significantly", "higher", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "than", "other", "schemes", "which", "is", "shown", "in", "Figure", "9", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "value", "of", "is", "proportional", "to", "network", "capacity", "(", ")", "inversely", "proportional", "to", "the", "BC", "of", "the", "node", "with", "maximum", "BC", "value", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["We", "used", "TS", "for", "feature", "search", "while", "Random", "Forest", "as", "a", "learning", "method", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["RS", "demonstrates", "linear", "speedup", "in", "the", "number", "of", "cores", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["We", "were", "able", "to", "show", "that", "machine", "learning", "methods", ",", "and", "the", "GCNN", "model", "in", "particular", ",", "can", "generalize", "to", "fairly", "larger", "instances", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["proposed", "a", "hybrid", "algorithm", "using", "an", "enhanced", "gradient", "-", "based", "optimization", "method", "and", "a", "simplified", "PSO", "for", "solving", "ELD", "problems", "of", "power", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["A", "GPS", "receiver", "calculates", "its", "position", "by", "carefully", "timing", "the", "signals", "sent", "by", "the", "constellation", "of", "GPS", "satellites", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "global positioning system"}, {"tokens": ["ROC", "comparison", "with", "state", "-", "of", "-", "the", "-", "art", "methods", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["In", "practice", ",", "this", "is", "equivalent", "to", "computing", "the", "gain", "of", "computational", "cost", "of", "the", "perfect", "regressor", "or", "classifier", ":", "performing", "a", "warm", "-", "start", "OPF", "calculation", "using", "the", "value", "of", "the", "primal", "variables", "at", "the", "solution", "for", "the", "former", "and", "performing", "a", "reduced", "OPF", "problem", "with", "the", "exact", "set", "of", "binding", "constraints", "for", "the", "latter", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["The", "ANN", "model", "was", "trained", "using", "the", "Adam", "optimizer", "with", "an", "initial", "learning", "rate", "of", "0.001", ",", "in", "order", "to", "minimize", "a", "mean", "squared", "error", "between", "the", "predicted", "and", "the", "measured", "magnetic", "fields", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "cross", "-", "correlation", "(", "CC", ")", "between", "the", "training", "and", "validation", "data", "was", "used", "as", "a", "feature", "for", "classification", ",", "and", "CRR", "="], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cross - correlation"}, {"tokens": ["At", "the", "last", "stage", ",", "the", "estimated", "equivalent", "channel", "is", "fed", "back", "to", "the", "BS", "and", "the", "digital", "beamforming", "matrix", "can", "be", "set", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "ACO", "is", "responsible", "for", "making", "a", "joint", "analysis", "of", "all", "the", "information", "gathered", "by", "the", "other", "modules", ",", "establishing", "the", "most", "suitable", "amount", "of", "redundancy", "to", "each", "FEC", "block", ";", "FEC", "Blocks", "-", "The", "FEC", "blocks", "are", "built", "and", "a", "specific", "amount", "of", "redundancy", "designed", "by", "the", "ACO", "is", "assigned", "to", "each", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "efficacy", "of", "the", "proposed", "framework", "is", "demonstrated", "by", "adapting", "one", "of", "the", "popular", "PSO", "variant", ",", "UPSO", ",", "by", "considering", "two", "different", "induction", "algorithms", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "voltage", "for", "a", "specific", "SOC", "of", "a", "battery", "with", "reduced", "capacity", "is", "higher", "than", "that", "of", "a", "new", "battery", "until", "the", "CC", "phase", "ends", ",", "and", "the", "larger", "the", "capacity", "loss", ",", "the", "smaller", "the", "SOC", "level", "at", "which", "the", "CC", "phase", "of", "charging", "is", "terminated", "and", "the", "voltage", "reaches", "its", "maximum", "value", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["For", "classification", "on", "these", "time", "-", "series", "data", ",", "GBM", "is", "the", "best", "method", "overall", "from", "a", "general", "perspective", "but", "can", "not", "be", "guaranteed", "to", "be", "the", "best", "so", "other", "algorithms", "need", "to", "be", "considered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["MRC", "is", "considered", "at", "CEU", "to", "combine", "direct", "and", "relay", "link", "and", "perform", "ID", "effectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information decoding"}, {"tokens": ["While", "the", "shapes", "of", "the", "lines", "are", "similar", ",", "UDP", "POS", "no", "longer", "consistently", "dominates", "the", "other", "tasks", "in", "recurrent", "layer", "correlation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Moreover", ",", "it", "has", "not", "been", "well", "studied", "as", "to", "how", "cost", "-", "sensitive", "learning", "could", "improve", "DBN", "performance", "on", "imbalanced", "data", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "v", "-", "rescale", "thermostat", "was", "applied", "in", "MD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "molecular dynamics"}, {"tokens": ["where", ":", "To", "improve", "performance", "in", "applications", "that", "have", "a", "known", "-", "limited", "vocabulary", ",", "we", "applied", "a", "CER", "-", "based", "vocabulary", "matching", "system", "using", "dynamic", "programming", "as", "shown", "in", "(", ")", ",", "where", "is", "the", "vocabulary", "set", "and", "is", "the", "word", "prediction", "based", "on", "the", "sequence", "prediction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["In", "this", "case", ",", "Cox", "process", "driven", "by", "PLP", "can", "be", "approximated", "by", "a", "spatial", "PPP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["Those", "with", "a", "high", "-", "level", "trust", "of", "scientists", "and", "regulators", "are", "more", "accepting", "of", "GM", "foods", ";", "in", "contrast", ",", "distrust", "of", "the", "agricultural", "/", "food", "industry", ",", "contrasted", "with", "trust", "in", "environmental", "watchdogs", ",", "predicts", "opposition", "to", "GM", "foods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "genetically modified"}, {"tokens": ["Since", "analytical", "inference", "is", "impossible", ",", "introduced", "an", "interesting", "Markov", "chain", "Monte", "-", "Carlo", "sampler", "which", "allows", "for", "(", "asymptotically", ")", "exact", "inference", "for", "a", "Gaussian", "process", "density", "model", ",", "where", "the", "GP", "is", "passed", "through", "a", "sigmoid", "link", "function.(See", "for", "an", "alternative", "model", "allowing", ",", "however", ",", "only", "for", "approximate", "inference", "schemes", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["DL", "allows", "researchers", "in", "RS", "to", "move", "beyond", "usual", "approaches", "and", "tackle", "a", "number", "of", "problems", "with", "solid", "results", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["As", "evaluation", "dataset", ",", "we", "reuse", "questions", "from", "the", "QALD7", "benchmark", "task", "4", "\"", "QA", "over", "Wikidata", "\"", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["GP", "can", "probabilistically", "estimate", "the", "unobserved", "data", "point", ",", ",", "based", "on", "the", "observed", "data", ",", ",", "assuming", "that", "the", "both", "observed", "data", "point", "and", "unobserved", "data", "can", "be", "represented", "as", "asample", "from", "a", "multivariate", "Gaussian", "distributionwhere", "is", "the", "covariance", "matrix", "and", "is", "an", "vector", "containing", "the", "covariances", "between", "and", "given", "byand", "is", "defined", "by", "the", "Matern", "covariance", "function", "as", "follows", ":", "where", ",", ",", ",", "are", "a", "pair", "of", "data", "point", ",", "is", "the", "characteristic", "length", "scale", ",", "is", "the", "Euclidean", "distance", "between", "the", "points", "and", "and", "is", "the", "modified", "Bessel", "function", "of", "order", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "CTC", "has", "powerful", "capability", "to", "automatically", "align", "ground", "truth", "of", "a", "line", "with", "the", "text", "line", "image", ",", "so", "that", "the", "system", "learns", "from", "lines", "and", "do", "not", "need", "words", "and", "characters", "segmentation", "for", "the", "inputs", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["For", "each", "investigated", "grid", ",", "particles", "and", "iterations", "of", "PSO", "were", "run", ",", "using", "the", "Optim.jl", "package", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["You", "may", "not", "copy", "or", "distribute", "the", "data", "in", "whole", "or", "in", "part", "without", "the", "written", "consent", "of", "Clarivate", "Analytics(Use", "of", "the", "LSC", "is", "subject", "to", "acceptance", "of", "request", "of", "the", "link", "by", "email", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["During", "the", "LTE", "-", "U", "OFF", "duration", ",", "it", "listens", "to", "the", "configured", "co", "-", "channel", "for", "signals", "and", "measures", "its", "indicator", "RF", "power", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["A", "total", "of", "class", "labels", "(", "165", "+", "1", "for", "CTC", "blank", "label", ")", "are", "used", "for", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["If", "the", "D2D", "-", "R", "accepts", "the", "proposal", ",", "it", "requests", "from", "a", "number", "of", "agents", "to", "connect", "to", "the", "contacted", "D2D", "-", "R", ",", "or", "it", "can", "send", "the", "excess", "clients", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["The", "most", "important", "result", "is", "that", "preconditioned", "RQI", "can", "be", "muchfaster", "than", "PI", "in", "general", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["However", ",", "instead", "of", "using", "just", "single", "POS", "tags", ",", "we", "created", "sequences", "containing", "bi", "-", "gram", ",", "tri", "-", "gram", "and", "4-gram", "POS", "tags", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "part of speech"}, {"tokens": ["In", "this", "paper", ",", "an", "efficient", "DL", "model", "using", "ANN", "for", "Disease", "-", "NER", "has", "been", "developed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["ExperimentsWe", "test", "the", "LTE", "on", "a", "compositionally", "defined", "image", "dataset", ",", "using", "a", "range", "of", "different", "metrics", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "language transmission engine"}, {"tokens": ["Even", "though", "the", "hybrid", "approach", "has", "good", "model", "performance", "and", "privacy", "guarantees", ",", "it", "comes", "with", "long", "training", "time", "and", "high", "data", "transmission", "cost", "and", "can", "not", "deal", "with", "participants", "dropping", "out", "during", "the", "FL", "process", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["MCC", "computation", "is", "done", "at", "the", "end", "of", "each", "iteration", ",", "to", "find", "the", "parent", "community", "of", "the", "deleted", "node", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal connected component"}, {"tokens": ["where", "a", "multi", "-", "antenna", "BS", "supports", "single", "-", "antenna", "users", "through", "intelligent", "reflections", "without", "a", "clear", "LOS", "path", "between", "the", "users", "and", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["For", "both", "the", "proposed", "scheme", "with", "OT", "and", "the", "ICAPC", "algorithm", ",", "as", "grows", ",", "the", "sum", "SE", "of", "DUs", "with", "is", "first", "lower", "and", "then", "higher", "than", "that", "of", "the", "case", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal training"}, {"tokens": ["RV", "process", "is", "divided", "into", "trials", "and", "iterations", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random voting"}, {"tokens": ["By", "means", "of", "standard", "implementation", ",", "such", "occurrences", "are", "usually", "treated", "with", "cutbacks", "of", "the", "load", "increment", ",", "which", "is", "detrimental", "to", "the", "runtime", "of", "the", "FEM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "finite element method"}, {"tokens": ["The", "authors", "formulated", "a", "minimum", "-", "secrecy", "-", "rate", "maximization", "problem", "by", "jointly", "optimizing", "the", "beamformer", "at", "the", "BS", "and", "reflecting", "coefficients", "(", "both", "discrete", "and", "continuous", ")", "at", "the", "RIS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "margin", "shrinks", "as", "the", "complexity", "increases", "but", "the", "proposed", "structure", "consistently", "outperforms", "LR", "when", "training", "the", "network", "from", "scratch", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "low rank"}, {"tokens": ["classifiertabularccccc2*Classifier", "Type", "&", "4cAccuracy", "2", "-", "5", "&", "BF", "Multi", "-", "classifier", "&", "AF", "Multi", "-", "classifier", "&", "Profile", "Image", "CNN", "&", "Overall", "Decision", "Tree", "&", "0.721", "&", "0.618", "&", "5", "*", "0.790", "&", "0.721", "1", "-", "3", "5", "-", "5", "SVM", "&", "0.739", "&", "0.352", "&", "&", "0.800", "1", "-", "3", "5", "-", "5", "AdaBoost", "&", "0.790", "&", "0.704", "&", "&", "0.850", "1", "-", "3", "5", "-", "5", "GradientBoosting", "&", "0.816", "&", "0.738", "&", "&", "0.842", "1", "-", "3", "5", "-", "5", "Random", "Forest", "&", "0.796", "&", "0.708", "&", "&", "0.899", "tabulartable*table*[ht]performance", "with", "different", "feature", "setstab", ":", "featuretabularl", "c"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic feature"}, {"tokens": ["The", "probabilistic", "serial", "(", "PS", ")", "mechanism", "belongs", "to", "the", "class", "of", "\"", "simultaneous", "eating", "\"", "mechanisms", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["ConclusionIn", "this", "work", ",", "we", "propose", "a", "new", "end", "-", "to", "-", "end", "3D", "DCNN", ",", "named", "NoduleNet", ",", "for", "solving", "pulmonary", "nodule", "detection", ",", "false", "positive", "reduction", "and", "segmentation", "jointly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["From", "a", "logical", "perspective", ",", "the", "only", "difference", "between", "the", "SL", "and", "SP", "classes", "is", "the", "way", "in", "which", "order", "is", "represented", "in", "strings", ":", "SL", "classes", "use", "the", "successor", "relation", "and", "SP", "classes", "use", "the", "precedence", "relation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["The", "result", "in", "table", "shows", "that", "the", "proposed", "solution", "can", "improve", "the", "decoding", "performance", "of", "Seq2Seq", "models", ",", "outperforming", "Tf", "-", "Idf", "in", "three", "data", "sets", ",", "as", "compared", "to", "Seq2Seq", "with", "standard", "beam", "(", "BS", ")", "and", "heuristic", "-", "based", "only", "beam", "decoding", "(", "BS++", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard beam search"}, {"tokens": ["Our", "primary", "goal", "is", "to", "demonstrate", "that", "the", "predictive", "mechanism", "of", "the", "continual", "GP", "remains", "stable", "when", ",", "all", "over", "the", "input", "domain", ",", "i.e.", "it", "does", "not", "forget", "past", "visited", "regions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "ontology", "of", "structural", "diagramsDifferent", "types", "of", "CD", "(", "such", "as", "2D", "wireframe", ",", "3D", "ball", "and", "stick", ")", "obey", "different", "diagrammatic", "syntaxes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "chemical diagram"}, {"tokens": ["Although", "both", "CC", "-", "CV", "and", "DLC", "exhibit", "similar", "temperature", "variation", "pattern", ",", "the", "average", "temperature", "of", "CC", "-", "CV", "models", "is", "higher", "than", "the", "DLC", "models", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant charging"}, {"tokens": ["We", "also", "find", "that", "the", "RA", "system", "achieves", "a", "high", "overlapping", "between", "computation", "time", "and", "communication", "time", "than", "PS", "and", "P2P", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["FIG", "/", "count_based", "fig", ":", "count_based[Generalizing", "counts", "via", "CF", "(", "sec", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "novelty", "is", "two", "-", "fold", ":", "(", "i", ")", "unlike", "standard", "multi", "-", "armed", "bandit", "settings", ",", "the", "arms", ";", "and", "(", "ii", ")", "unlike", "standard", "GP", "regression", ",", "the", "measurements", "in", "our", "problem", "are", "image", "(", ",", "vector", "measurements", ")", "whose", "quality", "depends", "on", "the", "altitude", "at", "which", "the", "UAV", "flies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "CST", "is", "more", "difficult", "to", "reconstruct", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0], "long_form": "corticospinal tract"}, {"tokens": ["In", "the", "RV", "algorithm", ",", "the", "iteration", "termination", "criteria", "is", "set", "by", "the", "number", "of", "trials", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random voting"}, {"tokens": ["In", ",", "the", "authors", "considered", "an", "RIS", "-", "assisted", "large", "-", "scale", "antenna", "system", "in", "which", "a", "BS", "communicates", "with", "a", "single", "-", "antenna", "user", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "the", "spatial", "domain", ",", "the", "LR", "intensity", "measurements", "are", "used", "as", "the", "object", "constraints", "to", "ensure", "the", "solution", "convergence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["In", "each", "iteration", ",", "both", "the", "MP", "/", "OMP", "and", "the", "FW", "algorithm", "query", "a", "so", "-", "called", "linear", "minimization", "oracle", "(", ")", "which", "solves", "the", "optimization", "problem", "for", "given", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["Here", ",", "to", "further", "clarify", "the", "working", "mechanism", "of", "AON", ",", "we", "elaborate", "the", "roles", "of", "the", "major", "components", "HN", ",", "VN", ",", "CN", "and", "FG", "in", "AON", ",", "and", "show", "the", "placement", "trends", "of", "texts", "in", "some", "real", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "filter gate"}, {"tokens": ["Although", "the", "local", "exemplars", "obtained", "so", "are", "more", "meaningful", "than", "AP", ",", "the", "clusters", "obtained", "by", "Hierarchical", "Affinity", "Propagation", "are", "still", "globular", "at", "each", "layer", "and", "there", "is", "limited", "information", "about", "the", "local", "structure", "of", "the", "clusters", "beyond", "local", "exemplars", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["Artificial", "Neural", "Network", "(", "ANN", ")", "is", "used", "as", "the", "first", "mathematical", "model", "for", "classification", ";", "this", "approach", "trains", "classifier", "from", "training", "data", "so", "that", "it", "can", "assign", "a", "new", "image", "to", "the", "class", "using", "its", "knowledge", ",", "i.e.", "it", "evaluates", "the", "training", "error", "based", "on", "inputs", "and", "minimizes", "it", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["TractQuerier", "showed", "severe", "oversegmentation", "of", "both", "the", "CST", "and", "OR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "optic radiation"}, {"tokens": ["Comparisons", "of", "the", "FER", "methods", "by", "the", "proposed", "CNN", "architectures", "and", "the", "stat", "-", "of", "-", "the", "art", "methods", "on", "CK+", "dataBASE", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["table[t]tabularccccc3", "-", "52c", "&", "3cHuman", "Preference1csystem", "1", "&", "system", "2", "&", "1", "&", "2", "&", "neither", "BS", "&", "TS", "&", "43", "&", "16", "&", "29", "BS", "&", "reranking", "&", "18", "&", "30", "&", "15", "BS", "&", "predicted", "&", "38", "&", "29", "&", "19", "TS", "&", "reranking", "&", "18", "&", "38", "&", "16TS", "&", "predicted", "&", "18", "&", "27", "&", "34reranking", "&", "predicted", "&", "27", "&", "24", "&", "21tabularHuman", "preferences", "when", "given", "three", "continuations", "from", "each", "pair", "of", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "beam search"}, {"tokens": ["Further", ",", "depending", "on", "the", "task", "(", "document", "QA", ",", "knowledge", "-", "base", "QA", "or", "visual", "QA", ")", "the", "importance", "of", "these", "words", "may", "vary", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "work", "mentioned", "above", "employ", "neural", "networks", ",", "but", "incorporate", "only", "a", "small", "amount", "of", "question", "-", "answering", "pairs", "to", "build", "their", "QA", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["As", "it", "can", "be", "seen", ",", "our", "proposed", "HybridAlpha", "has", "very", "similar", "training", "time", "to", "\"", "FL", "-", "no", "-", "privacy", "\"", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["The", "learning", "dynamics", "are", "similar", "to", "those", "for", "tag", "prediction", ",", "but", "the", "UDP", "POS", "tagger", "decreases", "dramatically", "in", "all", "correlations", "while", "the", "GMB", "-", "trained", "taggers(PTB", "POS", ",", "SEM", "(", "fine", ")", ",", "and", "SEM", "(", "coarse", ")", ")", "often", "increase", "slightly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["A", "quantitative", "bound", "for", "expected", "accuracy", "/", "error", "is", "derived", "by", "considering", "both", "the", "CC", "and", "neural", "network", "smoothness", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "cover complexity"}, {"tokens": ["The", "prediction", "runtime", "comparison", "of", "Global", "-", "INF", "and", "LR", "approach", "is", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Repeat", "with", "the", "new", "bottom", "SCC", "until", "all", "SCCs", "are", "processed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "strongly connected components"}, {"tokens": ["pull", "(", ")", ")", ",", "and", "to", "push", "the", "gradients", "to", "the", "PS", "(", "i.g", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["While", "ECS", "-", "DBN", "improves", "the", "overall", "performance", ",", "it", "also", "provides", "a", "mechanism", "to", "trade", "off", "the", "performance", "between", "the", "majority", "class", "and", "the", "minority", "class", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Taguchi", "'s", "method", "is", "one", "of", "the", "DOE", "techniques", "that", "was", "developed", "in", "1979", "to", "improve", "the", "quality", "of", "goods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "design of experiment"}, {"tokens": ["IntroductionIntelligent", "Transportation", "System", "(", "ITS", ")", "is", "one", "of", "the", "leading", "smart", "systems", "which", "have", "been", "developed", "to", "obtain", "reliable", "transportation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intelligent transportation system"}, {"tokens": ["Related", "models", "and", "methods", "for", "graphs", "to", "the", "SBM", "are", "discussed", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Another", "point", "of", "interest", "is", "its", "simplicity", "when", "applied", "to", "the", "multi", "-", "output", "GP", "setting", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Then", ",", "we", "can", "consider", "the", "point", "of", "the", "IB", "curve", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "Figure", ",", "a", "malicious", "attacker", "masquerades", "as", "an", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["This", "is", "a", "great", "enhancement", "over", "both", "non", "-", "adaptive", "and", "adaptive", "FEC", "mechanisms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["This", "solution", "requires", "the", "additional", "communication", "to", "exchange", "the", "PAT", "values", ",", "what", "is", "performed", "every", "iterations", ",", "thus", "introducing", "the", "additional", "communication", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival time"}, {"tokens": ["For", "MSE", "and", "Mean", "CC", "of", "one", "frame", "pair", ",", "we", "take", "the", "average", "of", "square", "error", "and", "local", "cross", "correlation", "over", "the", "masked", "region", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cross - correlation"}, {"tokens": ["Since", "the", "processing", "of", "the", "SP", "is", "not", "influenced", "by", "the", "context", ",", "the", "SP", "works", "identically", "as", "in", "the", "baseline", "case", "(", "e.g.", "the", "cluster", "usage", "and", "SP", "outputs", "are", "the", "same", "in", "both", "experiments", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial pooler"}, {"tokens": ["Different", "view", "angle", "combinations", "(", "from", "to", ")", "between", "training", "and", "testing", "data", "are", "used", "to", "estimate", "the", "recognition", "performances", "based", "on", "CDA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "canonical discriminant analysis"}, {"tokens": ["In", "some", "SAR", "operations", ",", "UAVs", "need", "to", "be", "operated", "for", "extended", "periods", "of", "time", "over", "disaster", "stricken", "regions", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["We", "can", "see", "that", "2D", "CNN", "MTL", "only", "achieves", "classification", "accuracy", "and", "mm", "localization", "error", "which", "is", "much", "worse", "than", "its", "3D", "counterpart", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multi - task learning"}, {"tokens": ["By", "observing", "the", "results", ",", "the", "authors", "claim", "that", "MU", "-", "MAC", "outperforms", "MPT", "-", "only", "MAC", "in", "terms", "of", "the", "maximum", "number", "of", "supported", "STAs", ",", "and", "this", "gain", "will", "further", "increase", "as", "the", "AP", "employs", "more", "transmitting", "antennas", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["By", "employing", "the", "fast", "algorithm", "of", "PSRS", "code", ",", "we", "expected", "that", "the", "encoding", "time", "of", "Exact", "-", "MBR", "codes", "can", "be", "reduced", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Then", ",", "according", "to", "(", ")", ",", "the", "SINR", "at", "the", "-th", "destination", "user", "isAnd", "according", "to", "(", ")", ",", "the", "SINR", "at", "the", "-th", "eavesdropper", "intending", "to", "intercept", "the", "-th", "destination", "user", "isNow", ",", "according", "to", "(", ")", ",", "(", ")", "and", "(", ")", ",", "the", "optimization", "problem", "that", "maximizes", "the", "worst", "-", "case", "system", "sum", "secrecy", "rate", "under", "the", "constraint", "of", "the", "total", "transmit", "power", "of", "the", "BS", "is", "constructed", "as", "shown", "in", "(", ")", "on", "the", "following", "page", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["But", "one", "can", "construct", "a", "Pseudo", "-", "Marginal", "MCMC", "method", "using", "an", "Expectation", "Propagation", "approximation", "to", "the", "GP", "posterior", "and", "importance", "sampling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Working", "together", "on", "the", "SDD", ",", "these", "participants", "found", "ceding", "control", "to", "someone", "else", "to", "be", "frustrating", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["So", "far", ",", "for", "a", "topic", "model", "or", "SBM", ",", "incorporating", "an", "HDP", "means", "that", "the", "quantity", "corresponds", "to", "is", "potentially", "infinite", "and", "to", "be", "modelled", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Paper", "Sentence", "Classification", "(", "PSC", ")"], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "paper sentence classification"}, {"tokens": ["introduced", "a", "new", "hybrid", "optimization", "algorithm", "called", "improved", "coordinated", "aggregation", "-", "based", "PSO", "(", "ICA", "-", "PSO", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], "long_form": "power system operations"}, {"tokens": ["The", "process", "is", "iterated", "until", "the", "GMM", "converges", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "authors", "claim", "that", "there", "has", "been", "an", "improvement", "in", "the", "QoE", "for", "end", "-", "users", ",", "however", ",", "the", "main", "objective", "of", "this", "scheme", "is", "to", "ensure", "the", "continuity", "of", "video", "playback", "with", "unpredictable", "channel", "variations", "and", "avoid", "unnecessary", "FEC", "redundancy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Our", "contributions", "are", "as", "follows:0em", "[", "-", "]", "we", "review", "composition", "functions", "used", "in", "textual", "relational", "learning", "and", "show", "that", "they", "lack", "expressiveness", "(", "section", ")", ";", "[", "-", "]", "we", "draw", "analogies", "with", "existing", "SRL", "models", "(", "section", ")", "and", "design", "new", "compositions", "inspired", "from", "SRL", "(", "section", ")", ";", "[", "-", "]", "we", "perform", "extensive", "experiments", "to", "test", "composition", "functions", "and", "show", "that", "some", "of", "them", "can", "improve", "the", "learning", "of", "representations", "and", "their", "downstream", "uses", "(", "section", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "statistical relational learning"}, {"tokens": ["In", "order", "to", "analyze", "the", "transferability", "of", "features", "in", "different", "layers", "on", "SAR", "target", "recognition", "case", ",", "we", "adopt", "the", "method", "of", "qualifying", "the", "generality", "versus", "specificity", "of", "features", "in", "each", "layer", "of", "a", "deep", "CNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["The", "participant", "surveys", "support", "this", "conclusion", "and", "provide", "the", "user", "'s", "perspective", "on", "the", "SAR", "'s", "ability", "to", "adapt", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "most", "typical", "approximation", ",", "called", "DC", "-", "OPF", ",", "makes", "the", "problem", "convex", "and", "reduces", "the", "number", "of", "variables", "and", "constraints", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["They", "demonstrated", "that", "the", "ECC", "/", "ECDSA", "algorithm", "provides", "high", "performance", "in", "e", "-", "banking", "applications", "because", "these", "algorithms", "use", "small", "keys", "and", "an", "appropriate", "computation", "cost", "for", "these", "applications", "compared", "to", "other", "public", "key", "algorithms", "(", "such", "as", "RSA", ",", "DSA", ",", "and", "DH", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "digital signature algorithm"}, {"tokens": ["Therefore", ",", "the", "amount", "of", "time", "required", "to", "charge", "one", "percent", "should", "be", "equal", "for", "every", "SOC", "update", "within", "the", "CC", "-", "phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "constant charging"}, {"tokens": ["Furthermore", ",", "FID", "is", "less", "sensitive", "to", "noise", "than", "IS", "and", "can", "detect", "intra", "-", "class", "mode", "collapse", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["We", "also", "know", "at", "the", "points", "in", "the", "IB", "curve", "where", "and", "at", "the", "points", "in", "the", "IB", "curve", "where", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "observational", "counterpart", "of", "the", "ACE", "may", "formally", "be", "defined", "as", ":", "align", "eq2", "ACE", ":"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "average causal effect"}, {"tokens": ["In", "Figure", "7", ",", "the", "influence", "of", "over", "SC", "is", "plotted", "for", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["To", "maximize", "each", "user", "'s", "transmission", "rate", ",", "the", "users", "must", "adjust", "their", "transmit", "power", "and", "the", "BS", "must", "determine", "the", "decoding", "order", "of", "the", "messages", "transmitted", "from", "the", "users", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Base", "on", "the", "features", ",", "we", "use", "the", "auto", "-", "encoder", "network", "to", "get", "the", "deep", "features", ",", "which", "will", "be", "fed", "into", "the", "GMM", "Classifiers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Here", ",", "we", "present", "an", "application", "of", "NP", "to", "multivariate", "normative", "modeling", "of", "clinical", "neuroimaging", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["&", "CER", "2*Nair", "&", "IAM", "&", "None", "&", "59.30", "&", "IAM", "&", "Sup", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["The", "energy", "varying", "trend", "is", "essential", "to", "determine", "an", "RS", "'s", "potential", "energy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["Additionally", ",", "we", "add", "a", "Kullback", "-", "Leibler", "divergence", "term", "(", ")", "to", "maximize", "SAD", "score", "distributions", "between", "the", "original", "and", "the", "reconstructed", "samples", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": [":", "We", "give", "an", "example", "for", "Exact", "-", "MBR", "codes", "over", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["From", "simulation", "results", "and", "complexity", "analysis", ",", "the", "proposed", "Max", "-", "SR", "is", "the", "optimal", "TAS", "scheme", "among", "the", "three", "TAS", "methods", "in", "terms", "of", "SR", "performance", "while", "the", "proposed", "leakage", "-", "based", "method", "achieves", "a", "SR", "performance", "near", "to", "the", "proposed", "Max", "-", "SR", "method", "with", "far", "low", "complexity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["It", "provides", "two", "main", "advantages", "over", "the", "state", "-", "of", "-", "the", "-", "art", "medical", "image", "SR", "model", "proposed", "in", ":", "(", "I", ")", "the", "network", "generates", "image", "features", "in", "the", "LR", "image", "grid", "rather", "than", "early", "upsampling", "of", "the", "features", ",", "which", "reduces", "memory", "and", "computation", "requirements", "significantly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Due", "to", "the", "limited", "space", ",", "we", "only", "show", "the", "top", "five", "best", "and", "worse", "cases", "ranked", "by", "the", "improvement", "percentage", "between", "the", "CER", "measure", "obtained", "with", "a", "system", "trained", "with", "just", "synthetic", "data", "or", "after", "writer", "adaptation", "using", "this", "low", "amount", "of", "samples", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["Once", "we", "have", "the", "analog", "precoder", ",", "the", "BS", "can", "send", "training", "signals", "to", "the", "users", "to", "get", "the", "knowledge", "of", "the", "equivalent", "channel", ",", "which", "has", "much", "fewer", "elements", "and", "lower", "dimension", "compared", "with", "the", "propagation", "channel", "and", "contains", "the", "contribution", "of", "scattering", "paths", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["This", "model", "has", "the", "advantage", "over", "GMM", "that", "the", "number", "of", "distributions", "are", "determined", "automatically", "though", "it", "is", "not", "used", "as", "widely", "as", "GMM", "especially", "by", "the", "astronomy", "community", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["a", "macrocell", "UE", "is", "covered", "by", "a", "femtocell", "BS", "(", "i.e.", ",", "within", "a", "distance", "of", "from", "a", "femtocell", "BS", ")", ",", "under", "closed", "access", ",", "the", "UE", "still", "connects", "to", "the", "macrocell", "BS", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Throughout", "this", "paper", "we", "use", "HR", "and", "LR", "to", "denote", "high", "and", "low", "resolutions", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["The", "charging", "controller", "applies", "Constant", "Current", "-", "Constant", "Voltage", "(", "CC", "-", "CV", ")", "charging", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["The", "ROC", "curve", "of", "BwDppCpd", "and", "RuLISF", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Above", "this", ",", "RS", "is", "robust", "in", "HD", "and", "FD", "scenarios", "because", "it", "can", "mitigate", "the", "multi", "-", "user", "interference", "taking", "place", "in", "the", "second", "link", "of", "both", "HD", "and", "FD", "cases", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["In", "comparison", ",", "the", "number", "of", "branching", "nodes", "in", "the", "complete", "dataset", "used", "to", "train", "the", "GCNN", "model", "is", "100,000", "for", "training", ",", "and", "20,000", "for", "validation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["Highly", "efficient", "energy", "consumption", "from", "AR", "devices", "is", "desired", "due", "to", "their", "limited", "battery", "life", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Hence", ",", "the", "paper", "solves", "the", "first", "optimization", "problem", "by", "solving", "the", "following", "optimization", "problem", ":", "where", "represents", "the", "optimal", "placement", "of", "ET", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "energy transmitters"}, {"tokens": ["This", "model", "has", "been", "decomposed", "with", "ICA", ",", "and", "used", "for", "video", "motion", "editing", "and", "analysis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["Each", "network", "agent", "is", "represented", "by", "a", "queue", ",", "that", "holds", "data", "packets", "which", "are", "intended", "for", "the", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["RobustnessIn", "order", "to", "study", "the", "robustness", "of", "the", "proposed", "algorithm", "to", "possible", "uncertainty", "in", "cluster", "localization", ",", "we", "assume", "the", "well", "-", "known", "SAGE", "algorithm", "as", "a", "means", "to", "estimate", "DoAs", "and", "delays", "at", "the", "BS", ",", "operating", "offline", ",", "as", "mentioned", "above", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["ConclusionWe", "proposed", "a", "new", "h", "-", "NSF", "model", "with", "trainable", "MVF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "maximum voice frequency"}, {"tokens": ["(", "ECC", "off", ")", "&", "Our", "Histogram", "&", "27.6", "&", "22.2", "&", "17.8", "&", "14.5", "&", "11.7", "&", "8.7", "&", "7.6", "&", "7.1", "&", "&", "CUB", "&", "8.4", "&", "6.8", "&", "6.2", "&", "5.8", "&", "5.6", "&", "5.4", "&", "5.1", "&", "4.8", "&", "&", "Speedup", "vs.", "CUB", "&", "3.29x", "&", "3.28x", "&", "2.89x", "&", "2.50x", "&", "2.10x", "&", "1.61x", "&", "1.50x", "&", "1.50x", "2", "-", "11", "&", "3*GeForce", "GTX", "1080", "&", "Our", "Histogram", "&", "56.7", "&", "51.4", "&", "45.4", "&", "39.8", "&", "33.9", "&", "28.4", "&", "24.8", "&", "20.0", "&", "&", "CUB", "&", "42.4", "&", "35.2", "&", "30.9", "&", "27.1", "&", "24.4", "&", "22.3", "&", "19.3", "&", "14.8", "&", "&", "Speedup", "vs.", "CUB", "&", "1.34x", "&", "1.46x", "&", "1.47x", "&", "1.47x", "&", "1.39x", "&", "1.28x", "&", "1.29x", "&", "1.35x"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["In", "this", "method", ",", "the", "voiced", "excitation", "consisting", "of", "pitch", "synchronous", "PCA", "residual", "frames", "is", "low", "-", "pass", "filtered", ",", "while", "the", "unvoiced", "part", "is", "high", "-", "pass", "filtered", "according", "to", "the", "MVF", "contour", "as", "a", "cutoff", "frequency", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["compute", "-", "IO", "-", "scaling", "-", "clusters", "subfigure", "Comparison", "of", "the", "performance", "of", "the", "RMSD", "task", "across", "different", "clusters", "(", "SDSC", "Comet", ",", "PSC", "Bridges", ",", "LSU", "SuperMIC", ")", "with", "MPI", "-", "IO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["[", "HAP", "]", "]"], "acronym_pos": [0, 1, 0, 0], "long_form": "high altitude platform"}, {"tokens": ["This", "section", "describes", "all", "steps", "in", "order", "for", "the", "LSC", "to", "be", "collected", ",", "cleaned", "and", "made", "available", "to", "researchers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["To", "make", "full", "use", "of", "fingerprints", "collected", "during", "walking", ",", "GP", "is", "employed", "to", "train", "a", "regression", "model", "for", "each", "access", "point", "separately", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["\"", "666320647509921794", "\"", ",", "\"", "text", "\"", ":", "\"", "RT", "@ZeikBaard", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "retweets"}, {"tokens": ["Overall", "resultsTo", "further", "understand", "the", "MINT", "-", "FEC", "achievements", ",", "a", "comparison", "against", "CLM", "-", "UEP", "and", "uavFEC", "is", "given", "in", "Figure", "fig", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Lcdp", "and", "eq", ":", "Leqpo_P_ord", "that", "the", "EQPO", "algorithm", "achieves", "a", "parallel", "complexity", "reduction", "against", "the", "CDP", "method", "by", "a", "factor", "on", "the", "order", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classical dynamic programming"}, {"tokens": ["Specifically", ",", "we", "havewhere", "is", "the", "variance", "matrix", "and", "every", "-th", "latent", "dimension", "has", "its", "own", "GP", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "embedding", "-", "based", "SRL", "models", ",", "entities", "have", "vector", "representations", "in", "and", "a", "scoring", "function", "reflects", "truth", "values", "of", "relations", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "statistical relational learning"}, {"tokens": ["STL", "performs", "the", "worst", "since", "it", "combines", "the", "data", "from", "all", "the", "tasks", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "single task learning"}, {"tokens": ["Finally", ",", "we", "computed", "the", "SAMSA", "and", "SAMSAabl", "score", "of", "each", "system", ",", "which", "are", "the", "first", "metrics", "that", "explicitly", "target", "syntactic", "aspects", "of", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "tree structures"}, {"tokens": ["Moreover", ",", "for", "the", "latter", "transmit", "SNR", ",", "the", "improvement", "on", "the", "of", "pure", "RS", "with", "increasing", "is", "very", "small", ",", "while", "performance", "of", "rate", "-", "selective", "RS", "is", "irrespective", "of", ";", "the", "smaller", "the", ",", "the", "smaller", "the", "gains", "from", "relaying", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["If", "a", "UE", "connected", "to", "a", "macro", "cell", "requests", "for", "DC", "with", "a", "SC", ",", "for", "instance", ",", "the", "SRC", "might", "decide", "to", "perform", "RLC", "layer", "processing", "at", "the", "data", "plane", "node", "(", "d", "-", "eNB", "/", "d", "-", "gNB", ")", "of", "either", "the", "macro", "cell", "or", "SC", "according", "to", "the", "resources", "and", "capabilities", "available", "at", "the", "respective", "cells", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "radio link control"}, {"tokens": ["However", ",", "by", "iteratively", "checking", "and", "adding", "violated", "constraints", ",", "and", "then", "solving", "the", "reduced", "OPF", "problem", "until", "all", "constraints", "of", "the", "full", "problem", "are", "satisfied", ",", "this", "issue", "can", "be", "avoided", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["In", "our", "approach", "the", "D2DMHR", "/", "D2DR", "are", "using", "proximity", "services", "to", "broadcast", "the", "connection", "information", "(", "i.e.", "WDR", ",", "coordinates", ")", "in", "each", "change", "of", "the", "Transmission", "Mode", "of", "the", "UE", "to", "D2D", "Relay", "or", "D2D", "Multi", "-", "Hop", "Relay"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["We", "validate", "the", "feature", "combining", "nodule", "size", "with", "raw", "3D", "cropped", "nodule", "pixels", ",", "employ", "GBM", "as", "a", "classifier", ",", "and", "obtain", "86.12", "test", "accuracy", "averagely", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["Experiments", "under", "closed", "-", "set", "assumption", "produced", "near", "perfect", "attribution", "accuracy", "in", "AA", "task", "involving", "36", "authors", "using", "only", "most", "frequent", "words", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["In", "summary", ",", "MD", "quantizers", "always", "involve", "complicated", "index", "assignments", ",", "especially", "when", "more", "than", "two", "descriptions", "are", "expected", "to", "be", "generated", "by", "users", ",", "whose", "complexity", "is", "always", "very", "high", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["ROC", "curves", "(", "with", "AUROC", "indicated", ")", "for", "disease", "detection", "models", "for", "MVP", "(", "A", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["This", "bridges", "the", "gap", "to", "implicit", "computational", "complexity", "(", "ICC", "for", "short", ")", "theory", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "implicit computational complexity"}, {"tokens": ["eq", ":", "cond", ",", "which", "combines", "both", "explicit", "and", "implicit", "covariance", "function", "constructions", ",", "we", "may", "use", "the", "expectations", "from", "the", "variational", "distribution", "to", "make", "the", "conditional", "GP", "prior", "behave", "as", "the", "former", "posterior", "indicates", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "MINT", "-", "FEC", "mechanism", "uses", "the", "same", "set", "as", "uavFEC", ",", "which", "was", "explained", "in", "Section", "sec", ":", "uavFEC", ":", "design", "and", "Algorithm", "algo", ":", "uavFEC", ":", "redudancyOutput", "defines", "it", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["ii", ")", "for", "outdoor", "users", "(", "e.g.", ",", "pedestrians", "or", "vehicular", ")", ",", "we", "characterize", "at", "first", "the", "random", "distribution", "of", "roads", "in", "a", "typical", "cell", "coverage", "area", "by", "a", "PLP", "and", "then", "we", "consider", "the", "random", "distribution", "of", "users", "in", "this", "system", "of", "roads", "according", "to", "a", "linear", "PPP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["We", "used", "cropped", "raw", "SEM", "or", "LOM", "images", "as", "input", "to", "FCNNs", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["tab", ":", "mscoco", "shows", "that", "adding", "the", "object", "pathway", "to", "the", "AttnGAN", "increases", "the", "IS", "of", "our", "baseline", "model", "(", "the", "pretrained", "model", "provided", "by", "the", "authors", ")", "from", "to", ",", "while", "the", "FID", "is", "roughly", "the", "same", "as", "for", "the", "baseline", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["Adding", "PRN", "along", "with", "PIN", ",", "we", "achieve", "5.83", "improvement", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "proposal indexing network"}, {"tokens": ["Connectionist", "Temporal", "Classification", "(", "CTC", ")", "removes", "the", "need", "to", "forcefully", "align", "the", "input", "stream", "with", "character", "prediction", "locations", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["We", "also", "investigate", "the", "impact", "of", "different", "building", "widths", "(", "i.e.", ",", ")", "using", "the", "GD", "and", "PSO", "algorithms", "(", "see", "Figure", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Specifically", ",", "their", "best", "result", "was", "achieved", "by", "using", "a", "pre", "-", "trained", "Inception", "model", "that", "reached", "ICC", "of", "and", "with", "two", "expert", "pathologists", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["It", "is", "remarkable", "that", "in", "10,000", "words", ",", "the", "coverage", "of", "the", "NAWL", "is", "90.9", ",", "with", "a", "frequency", "of", "572", "in", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["NCE", "'s", "theoretical", "guarantees", "depend", "on", ",", "yet", "small", "values", "work", "well", "in", "practice", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "noise contrastive estimation"}, {"tokens": ["So", "the", "EE", "can", "be", "derived", "as", "below", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "[", "34", "-", "35],OMA", "-", "SWIPT", "-", "PS", "-", "OAMFor", "a", "fair", "comparison", "with", "the", "prposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", ",", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "is", "also", "devised", "in", "this", "paper", "as", "benchmark", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["BS", "2", ".24"], "acronym_pos": [1, 0, 0], "long_form": "bidirectional similarity"}, {"tokens": ["There", "are", "more", "advanced", "variations", "of", "GMM", "such", "as", "Dirichlet", "process", "Gaussian", "mixture", "model", "(", "DPGMM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["An", "un", "-", "coded", "(", "FEC", ")", "data", "rate", "of", "0.75", "(", "1.5", ")"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Minimum", "Read", "ESQ", "(", "MR", "-", "ESQ", ")", ":"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "minimum read"}, {"tokens": ["Under", "the", "constrained", "of", "information", "collection", ",", "IMV", "strategy", "still", "performs", "well", "compared", "to", "RV", "strategy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random vaccination"}, {"tokens": ["Jurgen", "Fruend", "present", "AR", "-", "PDA", ",", "a", "concept", "for", "building", "a", "wireless", "AR", "system", "and", "a", "special", "prototype", "of", "palm", "-", "sized", "hardware", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["The", "time", "step", "for", "FEM", "simulation", "needs", "to", "be", "small", "enough", "to", "satisfy", "the", "sampling", "requirement", "of", "all", "analysed", "frequency", "range", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["Information", "BottleneckInformation", "bottleneck", "(", "IB", ")", "tends", "to", "enforce", "an", "upper", "bound", "on", "the", "mutual", "information", "between", "the", "latent", "representation", "learned", "by", "the", "encoder", "and", "the", "original", "input", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "E2E", "throughput", "is", "considered", "for", "URLLC", "traffic", "targeting", "a", "UE", ",", "and", "is", "measured", "from", "the", "CN", "to", "the", "UE", "PDCP", "layer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["BPR", "-", "SLIM", "uses", "the", "BPR", "optimization", "criterion.(The", "computation", "of", "the", "CF", "comparative", "models", "hasbeen", "done", "with", "the", "publicly", "available", "software", "library", "MyMediaLite", "http://www.mymedialite.net/."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["MMDA", "consistently", "achieved", "better", "WER", "and", "obtained", "small", "improvements", "in", "CER", "(", "see", "table", ",", "parts", "2", "and", "3", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["Subsequently", ",", "it", "computes", "using", "ECC", "multiplicative", "operation", "over", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["Previous", "work", "on", "Multi", "-", "Task", "learning", "on", "Semantic", "Role", "Labeling", "by", "did", "not", "report", "any", "significant", "improvement", "for", "SRL", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["In", "a", "WPCN", "with", "multi", "-", "antenna", "BS", ",", "however", ",", "it", "is", "generally", "challenging", "to", "obtain", "the", "globally", "optimal", "time", "and", "power", "allocation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["If", "we", "look", "into", "the", "protocol", "of", ",", "after", "the", "OT", "protocol", ",", "receiver", "will", "be", "getting", "a", "hash", "applied", "on", "XOR", "of", "the", "pads", "corresponding", "to", "his", "inputs", "and", "is", "given", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "cover", "difference", "(", "CD", ")", "is", "where", "is", "the", "number", "of", "categories", ",", "and", "and", "represent", "the", "subset", "and", "probability", "measure", "of", "the", "label", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cover difference"}, {"tokens": ["Table", "shows", "the", "training", ",", "validation", "and", "test", "results", "of", "DBN", "with", "7", "different", "combinations", "of", "sensor", "signals", ",", "i.e.", ",", "force", ",", "torque", ",", "vibration", ",", "force", "and", "torque", "(", "F", "-", "T", ")", ",", "force", "and", "vibration", "(", "F", "-", "Vib", ")", ",", "torque", "and", "vibration", "(", "T", "-", "Vib", ")", ",", "all", "force", ",", "torque", "and", "vibration", "signals", "(", "F", "-", "T", "-", "Vib", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Experimentssec", ":", "experiment", "In", "this", "section", ",", "three", "versions", "of", "our", "proposed", "model", "with", "incremental", "improvements", "are", "evaluated", "against", "a", "CNN", "baselinepkim2014convolutional", "and", "the", "state", "-", "of", "-", "the", "-", "art", "approach", "for", "CDA", "recognitionqu2019user", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "concurrent dialogue acts"}, {"tokens": ["Recent", "advances", "in", "GMM", "include", "minimum", "spanning", "tree", "and", "bidirectional", "analysis", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["DeepStereo", "generates", "high", "-", "quality", "novel", "views", "on", "the", "KITTI", "dataset", ",", "where", "older", "SFM", "based", "methods", "such", "as", "do", "not", "work", "at", "all", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "structure from motion"}, {"tokens": ["Unlike", ",", "the", "CCC", "also", "takes", "into", "account", "the", "difference", "between", "the", "means", "of", "both", "vectors", ",", "penalizing", "bias", "in", "the", "model", "'s", "predictions", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["[", "]", "Comparison", "of", "TS", "-", "RF", "with", "GA", "-", "LR", "Wrapper", "Method", "Results", "show", "that", "TS", "-", "RF", "achieved", "higher", "accuracy", "at", "reduced", "no", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["However", ",", "the", "duration", "of", "each", "session", "varied", "considerably", ",", "ranging", "from", "176", "frames", "in", "emotion", "processing", "to", "401", "frames", "in", "working", "memory", ",", "with", "TR", "of", "5520", "ms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "temporal resolution"}, {"tokens": ["Note", "that", "PI", "allocations", "are", "attractive", "because", "they", "avoid", "provider", "lock", "-", "in", "and", "the", "associated", "renumbering", "cost", "if", "the", "customer", "changes", "ISP", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["It", "was", "verified", "analytically", "and", "via", "simulations", "that", "the", "gain", "of", "the", "PS", "protocol", "is", "superior", "to", "that", "of", "the", "TS", "protocol", "in", "terms", "of", "outage", "probability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["RRH", "3", "and", "RRH", "5", "are", "not", "in", "any", "UE", "'s", "candidate", "serving", "set", ",", "and", "thus", "the", "power", "constraints", "associated", "with", "RRH", "3", "and", "RRH", "5", "in", "C3", "can", "be", "removed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["*", "center", "featMap", "center", "Effect", "of", "MAD", "unit", "in", "learning", "crucial", "attention", "information", "of", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["lossDistfiguretable[!ht", "]", "MINT", "-", "FEC", "Simulation", "parameters", "center", "tabularll", "Parameters", "&", "Value", "Display", "sizes", "&", "1920x1080", ",", "1280x720", ",", "and", "800x600", "Frame", "rate", "mode", "&", "Constant", "Frame", "rate", "&", "29.970"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["IntroductionIntroductionDimension", "estimation", "(", "DE", ")", "is", "the", "process", "of", "determining", "the", "intrinsic", "dimensionality", "of", "data", "(", "e.g.", ",", "see", "Chapter", "3", "in", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["In", "Tables", ",", "and", ",", "each", "row", "corresponds", "to", "SAD", "or", "RMSE", "performance", "of", "different", "methods", "for", "a", "single", "material", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["For", "the", "EMS", "statistic", ",", "we", "consider", "the", "ratio", "of", "observed", "and", "expected", "counts", "as", "the", "feature", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elevated mean scan statistic"}, {"tokens": ["This", "effect", "can", "also", "be", "inferred", "from", "lower", "values", "in", "ET", "and", "TC", "dice", "coefficients", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["In", "this", "study", ",", "we", "developed", "FRRUnet", "(", "full", "resolution", "residual", "U", "-", "Net", ")", ",", "a", "hybrid", "DCNN", "that", "exploited", "the", "inherent", "advantages", "of", "both", "the", "U", "-", "Net", "and", "the", "FRRnet", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["For", "the", "SBM", ",", "the", "transition", "probabilities", "satisfy", "detailed", "balance", ":", "equation", "t^SBM_st"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Suppose", "there", "are", "solutions", "in", "the", "BSP", "tree", ";", "many", "leaf", "nodes", "are", "located", "deeper", "than", ",", "while", "many", "nodes", "are", "shallower", "than", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["The", "probability", "that", "the", "typical", "UE", "is", "associated", "with", "a", "BS", "in", "tier", "for", "is", "where", "is", "the", "exclusion", "radius", "of", "the", "interferer", "BSs", "in", "tier", ",", "when", "typical", "UE", "is", "associated", "with", "a", "BS", "in", "tier", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["ConclusionLooking", "at", "the", "recent", "advancements", "in", "AR", "Technologies", "viz", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["CoordNPs", "lack", "endocentricity", ":", "neither", "conjunct", "NP", "solely", "determines", "the", "features", "of", "the", "NP", "as", "a", "whole", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "noun phrase"}, {"tokens": ["This", "LQE", "metric", "exploits", "the", "correlation", "between", "the", "LQI", ",", "PRR", "and", "SNR", "metrics", "to", "obtain", "a", "link", "estimation", "in", "a", "fast", "way", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "packet reception rate"}, {"tokens": ["The", "KK13", "OT", "extension", "protocol", "is", "known", "to", "provide", "the", "best", "communication", "complexity", "among", "the", "existing", "constructions", "when", "the", "input", "length", "of", "the", "sender", "is", "'", "short", "'", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "range", "of", "degree", "degree", "correlation", "coefficients", ",", "and", "BC", "-", "BC", "coefficient", ",", "are", "scaled", "from", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["[", "CC", "-", "CV", "DLC][DLC", "Fast", "Charging", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0], "long_form": "constant charging"}, {"tokens": ["Both", "SRQM", "and", "TI", "values", "were", "computed", "for", "all", "frames", "in", "the", "432", "uncompressed", "sequences", "in", "the", "training", "dataset", "at", "various", "resolutions", "from", "38402160", "to", "480270", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal information"}, {"tokens": ["Water", "showing", "the", "advantage", "of", "AIA", "over", "other", "integrating", "schemes", "in", "sampling", "with", "HMC", "(", "left", ")", "and", "MD", "(", "right", ")", "simulations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["It", "is", "known", "that", "per", "-", "missioned", "BC", "'s", "like", "the", "one", "we", "used", "as", "a", "private", "BC", "for", "IoT", "network", "is", "although", "efficient", "but", "in", "a", "limited", "nodes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["avg_plot_k_k40_on.pdf[Key", "-", "only", ":", "K40c", "(", "ECC", "off", ")", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["Mixed", "Decoding", "(", "MD", ")"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "mixed decoding"}, {"tokens": ["Ground", "truth", "annotations", "comprise", "GD", "-", "enhancing", "tumor", "(", "ET", ",", "label", "4", ")", ",", "peritumoral", "edema", "(", "ED", ",", "label", "2", ")", ",", "necrotic", "and", "non", "-", "enhancing", "tumor", "(", "CNR", "/", "NET", ",", "label", "1", ")", "as", "described", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["[", "b]0.5", "Plot", "of", "FAR", "and", "FAR", "[", "b]0.49", "Inter", "and", "Intra", "class", "distribution", "Some", "statistics", "[", "!"], "acronym_pos": [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "false acceptance rate"}, {"tokens": ["RB", ":", "identification", ":", "definiton", ",", "The", "missing", "term", ",", "cf", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["Comparing", "to", "AA", ",", "EAA", "is", "able", "to", "record", "the", "first", "and", "second", "order", "correlations", "between", "variables", "and", "noise", "symbols", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affine arithmetic"}, {"tokens": ["Usually", ",", "the", "'", "learning", "'", "in", "most", "of", "the", "existing", "PSO", "based", "approaches", "is", "focused", "on", "identifying", "the", "promising", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Unlike", "PSO", ",", "the", "other", "search", "paradigms", "like", "GA", ",", "ACO", "can", "be", "adapted", "comparatively", "easily", "without", "any", "major", "changes", "in", "their", "learning", "strategies", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Assuming", "is", "a", "set", "of", "observations", ",", "we", "can", "query", "the", "GP", "at", "a", "new", "input", "point", "as", "follows", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["To", "evaluate", "the", "performance", "of", "morphological", "disambiguation", ",", "we", "have", "tested", "the", "MD", "performance", "of", "our", "models", ",", "which", "are", "trained", "with", "the", "training", "portion", "of", "our", "dataset", ",", "on", "the", "test", "portion", "of", "a", "frequently", "used", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "morphological disambiguation"}, {"tokens": ["Meanwhile", ",", "we", "employ", "a", "FN", "to", "evaluate", "whether", "the", "glimpse", "vectors", "are", "reasonable", "and", "provide", "a", "feedback", "to", "help", "AN", "generate", "more", "reasonable", "glimpse", "vectors", "so", "that", "the", "AN", "can", "pay", "attention", "properly", "on", "the", "right", "regions", "of", "target", "characters", "in", "the", "processed", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["Evaluation", "on", "object", "detection", "shows", "that", "our", "approach", "can", "achieve", "an", "higher", "AP", "with", "less", "proposals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["In", "2011", ",", "when", "the", "winning", "architecture", "was", "not", "a", "DCNN", "yet", ",", "the", "classification", "error", "amounted", "to", "percent", "and", "only", "five", "years", "later", ",", "in", "2016", ",", "it", "was", "possible", "to", "lower", "the", "error", "to", "three", "percent", ",", "which", "is", "even", "lower", "than", "the", "human", "error", "rate", "of", "about", "five", "percent", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["However", ",", "our", "model", "differs", "from", "typical", "implementations", "of", "HG", "and", "OT", "in", "that", "the", "optimal", "structure", "does", "not", ",", "in", "general", ",", "decompose", "into", "a", "unique", "combination", "of", "the", "input", "constituents", "(", "entity", "and", "relation", "embeddings", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimality theory"}, {"tokens": ["Due", "to", "the", "fact", "that", "there", "is", "no", "endmember", "ground", "truth", "available", "for", "these", "datasets", ",", "we", "used", "the", "average", "spectra", "of", "the", "pixels", "for", "each", "material", "as", "the", "ground", "truth", "in", "SAD", "comparisons", "as", "proposed", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["The", "application", "of", "2-D", "learning", "approach", "to", "adapt", "PSO", "variants", "is", "illustrated", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["For", "example", ",", "PEAS", "+", "IFT", "revealed", "a", "costly", "foraging", "problem", "for", "the", "casters", "due", "to", "the", "relative", "inaccessibility", "of", "some", "Actuator", "patches", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information foraging theory"}, {"tokens": ["We", "can", "observe", "that", "OT", "outperforms", "other", "variants", "in", "this", "setup", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["In", "our", "approach", "the", "energy", "gained", "by", "the", "BS", "when", "we", "apply", "clustering", "is", "the", "same", "as", "in", "the", "work", "in", "comparison", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Our", "error", "analysis", "reveals", "some", "different", "obstacles", "from", "English", "SRL", "to", "work", "on", "in", "the", "future", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["In", "Figure", "10", ",", "the", "impact", "of", "over", "EE", "is", "plotted", "for", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Intuitively", ",", "the", "details", "tab", "(", "DE", ",", "blue", ")", "helps", "users", "to", "click", "on", "nearby", "concepts", "at", ",", "more", "often", "than", "local", "search", "(", "LS", ",", "pink", ")", ",", "which", "is", "more", "likely", "to", "reach", "concepts", "at", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "local search"}, {"tokens": ["In", "a", "similar", "manner", "to", "particle", "degeneration", "in", "the", "SIS", "PF", ",", "particle", "collapse", "can", "occur", "in", "the", "SIR", "PF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "sequential importance resampling"}, {"tokens": ["Right", ":", "our", "bipartite", "GCNN", "architecture", "for", "parametrizing", "our", "policy", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["These", "fields", "already", "use", "state", "-", "of", "-", "the", "-", "art", "embeddings", "such", "as", "Word2Vec", "and", "would", "thus", "naturally", "fall", "into", "our", "CSG", "framework", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["In", "this", "case", ",", "their", "GPS", "location", "can", "be", "updated", "later", "and", "an", "option", "to", "do", "so", "can", "be", "given", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Non", "-", "archaic", "l", "can", "also", "be", "found", "in", "NP", "sikar", "'", "hunt", "'", "vs.", "Bandari", ",", "Bakhtiyari", "eskal", ",", "S.", "Bashkardi", "sekal", "'", "mountain", "sheep", "'", ",", "if", "from", "a", "verbal", "root", "*", "skar-", "with", "no", "good", "Indo", "-", "European", "cognates", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Using", "88", "features", "including", "pitch", ",", "Mel", "-", "PLP", ",", "and", "TRAP", "-", "DCT", "input", "into", "a", "bottleneck", "DNN", ",", "they", "are", "able", "to", "improve", "the", "CER", "to", "40.2", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "perceptual linear prediction"}, {"tokens": ["This", "will", "lead", "to", "an", "algorithm", "which", ",", "unlike", "the", "SBM", ",", "will", "cluster", "the", "nodes", "according", "to", "the", "two", "factions", "in", "the", "karate", "club", ",", "as", "would", "be", "expected", "in", "a", "community", "-", "finding", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "weight", "is", "adjustable", "through", "minimizing", "the", "difference", "between", "the", "summation", "of", "the", "output", "signal", "and", "a", "reference", "that", "is", "known", "by", "both", "the", "AP", "and", "STAs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "access part"}, {"tokens": ["And", "therefore", ",", "introducing", "an", "IB", "into", "adversarial", "learning", "framework", "combines", "the", "respective", "advantages", "in", "this", "aspect", "and", "makes", "distilling", "domain", "-", "invariant", "information", "between", "different", "domains", "more", "effectively", "and", "efficiently", ",", "which", "is", "proven", "in", "the", "experiment", "of", "this", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "centralized", "techniques", "the", "BS", "completely", "manages", "the", "UE", "nodes", ",", "even", "when", "they", "(", "UEs", ")", "are", "communicating", "directly", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["TLS", "produces", "point", "clouds", "of", "tree", "surfaces", "in", "3D", "space", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "terrestrial laser scanning"}, {"tokens": ["This", "method", "provides", "good", "SE", "and", "scalability", "for", "a", "wide", "range", "of", "QoS", "requirements", "for", "both", "D2D", "links", "and", "CUEs", "and", "can", "be", "easily", "implemented", "in", "5", "G", "LTE", "-", "A", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["UPSO", "combines", "the", "global", "and", "local", "versions", "of", "PSO", "through", "unification", "factor", ",", "''", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["We", "show", "that", "ECS", "-", "DBN", "offers", "an", "effective", "solution", "of", "good", "performance", "to", "imbalanced", "classification", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["From", "a", "logical", "perspective", ",", "SP", "stringsets", "can", "thus", "be", "expressed", "as", "the", "conjunction", "of", "negative", "literals", "where", "literals", "correspond", "to", "a", "model", "-", "theoretic", "representation", "of", "strings", "where", "the", "order", "of", "the", "elements", "is", "given", "by", "the", "precedence", "relation", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["The", "effects", "of", "GMM", "parameters", "are", "also", "explained", "for", "further", "analysis", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "aim", "of", "the", "ACDC'17", "challenge", "(", "https://www.creatis.insa-lyon.fr/Challenge/acdc/", ")", "is", "to", "compare", "the", "performance", "of", "automatic", "methods", "for", "the", "classification", "of", "MR", "image", "examinations", "in", "terms", "of", "healthy", "and", "pathological", "cases", ":", "infarction", ",", "dilated", "cardiomyopathy", ",", "and", "hypertrophic", "cardiomyopathy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["Therefore", ",", "this", "list", "represents", "occupations", "where", "DSA", "skills", "are", "already", "important", ",", "or", "have", "reached", "a", "minimum", "threshold", "of", "DSA", "skill", "intensity", "and", "where", "DSA", "skills", "are", "likely", "to", "become", "more", "important", "for", "the", "occupation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["In", "order", "to", "convert", "the", "optimization", "problem", "formulated", "in", "of", "-", "Nm_con", "to", "a", "GP", "standard", "form", ",", "we", "propose", "to", "apply", "approximation", "for", "only", "constraint", "Pm_con", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["w.", "&", "Dec", "&", "&", "&", "&", "&", "&", "APSP", "&", "Section", "subsubsec", ":", "APSPshortpathsDec2", "reachability", "&", "Dec", "&", "&", "&", "&", "&", "&", "BMM", "&", "abboud2014popular", "(", "SC", ",", "BPMatch", ")", "&", "&", "&", "&", "&", "&", "&", "BMM", "&", "abboud2014popular", "shortest", "paths", "&", "Dec", "&", "&", "&", "&", "&", "&", "BMM", "&", "Theorem", "Thm", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strongly connected"}, {"tokens": ["Our", "model", "extends", "PNN", "with", "the", "ability", "to", "use", "helpful", "modules", "selectively", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "progressive neural networks"}, {"tokens": ["For", "performance", "comparison", ",", "simulation", "results", "for", "CCU", "(", ")", "capacity", ",", "CEU", "(", ")", "capacity", "and", "SC", "of", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "are", "also", "provided", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["It", "means", "that", "the", "input", "data", "are", "clustered", "as", "separate", "groups", "where", "the", "elements", "from", "a", "single", "group", "share", "the", "same", "ID", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "input data"}, {"tokens": ["Matthew", "'s", "Correlation", "Coefficient", "(", "MCC", ")", "is", "another", "measure", "of", "binary", "classification", "performance", "that", "has", "been", "extended", "to", "handle", "multi", "-", "class", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["If", "player", "does", "not", "have", "value", "-", "decreasing", "transitions", "then", "player", "wins", "with", "the", "MD", "strategy", "from", "Lemma", "lem", ":", "reach", "-", "opt", "-", "uniform", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["However", ",", "before", "we", "present", "our", "strategy", ",", "we", "explain", "the", "standard", "GP", "-", "UCB", "algorithm", "and", "then", "present", "the", "two", "changes", "we", "make", "to", "the", "algorithm", "(", "future", "variance", "and", "dynamic", "windows", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["we", "have", "that", "the", "theoretically", "maximum", "AR", "and", "EL", "are", "both", "3000", "due", "to", "our", "episode", "termination", "criterion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "accumulated reward"}, {"tokens": ["In", "BA", "model", ",", "appearance", "of", "new", "connections", "totally", "depends", "on", "the", "addition", "of", "new", "nodes", "to", "the", "system", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "barabasi albert"}, {"tokens": ["The", "PS", "adapts", "one", "-", "to", "-", "all", ",", "and", "all", "-", "to", "-", "one", "collective", "communication", "topology", "for", "exchanging", "the", "gradients", "and", "model", "between", "servers", "and", "workers", "using", "different", "mechanisms", "such", "as", "Google", "gRPC", "protocol", ",", "a", "default", "communication", "protocol", "of", "TensorFlow", "framework", "based", "on", "TCP", ",", "as", "illustrated", "in", "Figure", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["SC", "comparisons", "with", "respect", "to", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["The", "proposed", "ECS", "-", "DBN", "is", "chosen", "as", "the", "control", "algorithm", "for", "comparison", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "results", "show", "four", "of", "the", "six", "languages", "were", "learned", "remarkably", "well", ",", "but", "overfitting", "arguably", "occurred", "with", "the", "simplest", "SL", "language", "and", "undergeneralization", "with", "the", "most", "complex", "SP", "pattern", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "adaptive", "mechanisms", "(", "uavFEC", ",", "CLM", "-", "UEP", ",", "and", "MINT", "-", "FEC", ")", "allow", "a", "better", "use", "of", "the", "network", "resources", ",", "as", "also", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["As", "highlighted", "in", ",", "early", "upsampling", "introduces", "redundant", "computations", "in", "the", "HR", "space", "since", "no", "additional", "information", "is", "added", "into", "the", "model", "by", "performing", "transposed", "convolutions", "at", "an", "early", "stage", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["In", "addition", ",", "there", "is", "no", "impact", "of", "on", "SC", "of", "CNMOMA", "-", "SWIPT", "-", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "time switching"}, {"tokens": ["In", "fact", ",", "the", "ARD", "model", "is", "nearly", "as", "robust", "as", "its", "teacher", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["NP", "barg", "'", "leaf'PIr", "*", "uafra-", "MP"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["(", "c", ")", "Another", "way", "to", "reduce", "variance", "relative", "to", "humans", "is", "to", "improve", "the", "automatic", "metric", "evaluation", ";", "here", "using", "ROUGE-1", "instead", "of", "VecSim", "improves", "the", "DE", "from", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "data efficiency"}, {"tokens": ["Because", "the", "energy", "equation", "will", "be", "used", ",", "so", "the", "FEM", "is", "only", "efficient", "for", "the", "small", "deformation", "of", "the", "elastic", "object", ",", "such", "as", "apply", "to", "the", "plastic", "material", "requires", "less", "deformation", "or", "the", "object", "consists", "less", "control", "elements", "needed", "to", "be", "computed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element methodgm97"}, {"tokens": ["The", "basic", "metrics", "used", "for", "estimating", "the", "quality", "of", "a", "link", "are", "three", ":", "RSSI", ",", "LQI", "and", "PRR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "packet reception rate"}, {"tokens": ["The", "standard", "form", "of", "GP", "is", "defined", "as", "follows", ":", "where", "and", "are", "posynomial", "and", "are", "monomial", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Activation", "function", "output", "should", "not", "be", "used", "for", "DE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "dimension estimation"}, {"tokens": ["By", "using", "the", "GMM", "model", ",", "the", "likelihood", "of", "a", "given", "group", "is", ":", "where", "is", "the", "total", "number", "of", "mixture", "components", "selected", "from", "the", "GMM", ",", "and", "the", "GMM", "model", "is", "parameterized", "by", "mean", "vectors", ",", "covariance", "matrices", ",", "and", "mixture", "weights", "of", "mixture", "components", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["One", "OT", "unit", "is", "adopted", "as", "depicted", "in", "Fig", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["In", "order", "to", "resolve", "the", "shortcomings", "of", "the", "AP", "score", ",", "some", "works", "have", "attempted", "to", "introduce", "alternative", "or", "complementary", "evaluation", "measures", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "single", "condensation", "method", "is", "employed", "to", "convert", "this", "constraint", "to", "posynomial", "as", "described", "below", ":", "The", "single", "condensation", "method", "for", "GP", "involves", "upper", "bounds", "on", "the", "ratio", "of", "a", "posynomial", "over", "a", "posynomial", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["In", "this", "section", "we", "will", "modify", "AP", "to", "develop", "a", "new", "algorithm", "which", "inherits", "the", "positive", "aspects", "of", "AP", "while", "alleviating", "its", "'", "shortcomings", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["The", "questions", "and", "targets", "were", "processed", "to", "produce", "IR", "queries", "as", "per", "the", "default", "configuration", "for", "the", "QA", "framework", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["Domain", "transferA", "key", "issue", "that", "remains", "unexplored", "by", "many", "of", "the", "existing", "methods", "within", "DST", "is", "domain", "adaptation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["The", "upcast", "rule", "[", "T", "-", "UCAST", "]", "is", "the", "natural", "generalisation", "of", "the", "homonymous", "rule", "of", "FJ", "to", "intersection", "types", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "featherweight java"}, {"tokens": ["On", "the", "other", "hand", ",", "while", "the", "DC", "-", "SBM", "revealed", "the", "two", "known", "factions", "that", "the", "original", "SBM", "failed", ",", "the", "likelihood", "ratio", "test", "by", "suggested", "that", "there", "were", "not", "enough", "evidence", "to", "suggest", "that", "the", "network", "was", "generated", "by", "DC", "-", "SBM", "(", "against", "the", "original", "SBM", ")", ",", "even", "when", "the", "inhomogeneous", "degree", "distribution", "prompted", "the", "degree", "correction", "in", "the", "first", "place", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["In", "fact", ",", "approximately", "60", "of", "words", "appear", "in", "only", "1", "document", "in", "LSC", "(", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Moreover", ",", "the", "zoom", "was", "not", "visually", "active", "with", "the", "image", "jumping", "between", "zoom", "levels", "rather", "than", "scaling", "dynamically", ",", "as", "participants", "were", "used", "to", "on", "their", "SDD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "standard desktop display"}, {"tokens": ["OAM", "is", "integrated", "with", "CNOMA", "-", "SWIPT", "-", "PS", "protocol", "to", "achieve", "higher", "channel", "capacities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["In", "the", "baseline", "case", ",", "without", "FEC", ",", "a", "sharp", "decline", "in", "the", "video", "quality", "after", "400", "m", "is", "perceived", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "pairwise", "graph", "registration", "problem", "can", "be", "subsequently", "solved", "using", "generic", "GM", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "graph matching"}, {"tokens": ["Due", "to", "this", ",", "it", "is", "important", "to", "employ", "adaptive", "FEC", "mechanisms", ",", "such", "as", "neuralFEC", "to", "protect", "the", "contents", "of", "the", "video", "taking", "into", "account", "its", "motion", "intensity", "characteristics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["descriptionfigure[Key", "-", "only", ":", "K40c", "(", "ECC", "on", ")", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["The", "generalization", "of", "the", "model", "was", "studied", "by", "testing", "an", "independent", "dataset", "annotated", "by", "our", "expert", "consisting", "of", "6", "separate", "3D", "MPM", "images", "acquired", "from", "1", "AD", "and", "5", "WT", "mice", "(", "Table", ")", "and", "the", "results", "are", "summarizes", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "wild type"}, {"tokens": ["According", "to", "the", "EHS", "protocol", ",", "is", "transmitted", "directly", "to", "CEU", "from", "BS", "with", "full", "power", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["For", "the", "network", "designed", "through", "BA", "model", ",", "it", "was", "shown", "that", "the", "BC", "is", "related", "to", "the", "degree", "via", "the", "relation", "where", ",", "and", "are", "power", "law", "exponents", "for", "degree", "and", "BC", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["In", "addition", ",", "it", "is", "a", "reasonable", "assumption", "that", "for", "cellular", "end", "-", "users", "there", "is", "usually", "one", "critical", "flow", "using", "UE", "'s", "isolated", "queue", "at", "BS", "when", "users", "are", "running", "delay", "sensitive", "applications", "such", "as", "virtual", "reality", ",", "real", "time", "gaming", ",", "real", "time", "streaming", ",", "real", "time", "video", "conferencing", ",", "etc", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", ",", "the", "link", "quality", "is", "predicted", "by", "an", "application", "framework", "which", "tracks", "the", "direction", "of", "travel", "of", "mobile", "phones", "at", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["The", "hypothesized", "prediction", "of", "the", "sample", "is", "the", "member", "of", "the", "maximum", "probability", "among", "classes", ",", "can", "be", "obtained", "by", "using", "the", "following", "equation", ":", "The", "proposed", "cost", "-", "sensitive", "learning", "method", "only", "concerns", "the", "output", "layer", "of", "a", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["Comparing", "DE", "-", "SB", "with", "DE", "using", "ideal", "separation", "by", "brute", "force", "symmetry", "breaking", "(", "DE", "-", "SB", "-", "BF", ")", "on", "the", "syn5", ",", "sinc", "and", "inc", "-", "sinc", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "brute force search"}, {"tokens": ["Three", "graph", "scan", "statistics", "were", "considered", ",", "including", "Kulldorff", "'s", "scan", "statistic", ",", "expectation", "-", "based", "Poisson", "scan", "statistic", "(", "EBP", ")", ",", "and", "elevated", "mean", "scan", "statistic", "(", "EMS", ",", "Equation", "(", ")", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "elevated mean scan statistic"}, {"tokens": ["Codifica\u00e7\u00e3o", "das", "meta", "-", "heur\u00edsticasAs", "meta", "-", "heur\u00edsticas", "de", "estado", "\u00fanico", "HC", ",", "SA", ",", "TS", "e", "ILS", "foram", "modeladas", "conforme"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["ECS", "-", "DBN", "is", "also", "computationally", "more", "efficient", "than", "some", "popular", "resampling", "methods", "on", "large", "scale", "datasets", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Here", ",", "by", "employing", "2", "state", "-", "of", "-", "the", "-", "art", "object", "detection", "benchmarks", ",", "and", "analyzing", "more", "than", "15", "models", "over", "4", "large", "scale", "datasets", ",", "we", "I", ")", "carefully", "determine", "the", "upper", "bound", "in", "AP", ",", "which", "is", "91.6", "on", "VOC", "(", "test2007", ")", ",", "78.2", "on", "COCO", "(", "val2017", ")", ",", "and", "58.9", "on", "OpenImages", "V4", "(", "validation", ")", ",", "regardless", "of", "the", "IOU", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Base", "ModelOur", "proposed", "models", "extend", "end", "-", "to", "-", "end", "style", "SRL", "systems", "using", "deep", "bi", "-", "RNN", "to", "combine", "mechanisms", "that", "consider", "multiple", "predicate", "interactions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["For", "instance", ",", "in", "the", "case", "of", "the", "column", ",", "the", "NLPD", "is", "evaluated", "on", "the", "same", "test", "-", "samples", "as", "the", "GP", "model", "does", "at", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "size", "of", "is", "determined", "by", "the", "total", "number", "of", "backbone", "devices", ",", "that", "is", ",", "total", "number", "of", "RNs", ",", "CHs", ",", "and", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["This", "restriction", "would", "not", "impose", "a", "real", "restriction", "in", "the", "operations", "of", "ISPs", "using", "the", "/32", "for", "PA", "allocations", ",", "but", "would", "negatively", "affect", "the", "intermediaries", "that", "want", "to", "resell", "PI", "allocations", "out", "of", "a", "/32", ",", "since", "it", "would", "prevent", "all", "the", "end", "sites", "obtaining", "an", "allocation", "out", "of", "a", "single", "/32", "to", "use", "different", "origin", "ASes", "in", "their", "ROAs", "(", "which", "is", "what", "they", "would", "naturally", "do", "when", "announcing", "a", "PI", "block", "in", "the", "interdomain", "routing", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider aggregatable"}, {"tokens": ["Thus", ",", "this", "is", "the", "main", "reason", "why", "ANN", "is", "useful", "in", "practice", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "approximate nearest neighbor"}, {"tokens": ["The", "absence", "of", "any", "optimization", "in", "the", "choice", "of", "which", "and", "how", "many", "resources", "to", "test", "produces", "a", "utility", "which", ",", "for", "low", ",", "is", "lower", "than", "the", "DI", "approach", "proposed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "direct inspection"}, {"tokens": ["The", "incidence", "of", "finding", "a", "household", "is", "measured", "within", "a", "distance", "of", "at", "most", "100", "m", "from", "the", "nearest", "populated", "pixel", "in", "our", "building", "dataset", ",", "thereby", "accounting", "for", "the", "limited", "accuracy", "of", "the", "survey", "location", "data", "(", "see", "SI", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "satellite imagery"}, {"tokens": ["Searching", "for", "the", "that", "best", "matches", "the", "observations", "can", "be", "seen", "as", "a", "model", "identification", "procedure", ",", "which", "could", "be", "solved", "via", "minimizing", "the", "mean", "squared", "error", ";", "nevertheless", ",", "the", "authors", "formulate", "it", "in", "a", "way", "so", "that", "they", "can", "exploit", "the", "GP", "framework", "to", "jointly", "optimize", "for", "the", "kernel", "hyper", "-", "parameters", "and", "the", "mean", "parameters", ",", "which", "allows", "the", "modeling", "procedure", "to", "balance", "between", "non", "-", "parametric", "and", "parametric", "modeling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "ICC", "difference", "of", "each", "feature", "can", "not", "be", "considered", "independent", "as", "many", "features", "are", "known", "to", "be", "correlated", ",", "which", "affects", "the", "choice", "for", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["Evaluations", "on", "EfficiencyIn", "this", "experiment", ",", "we", "evaluate", "the", "efficiency", "of", "GPA", "by", "comparing", "with", "HARP", "on", "all", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["However", ",", "the", "most", "dominant", "periodic", "component", "can", "not", "be", "simply", "determined", "in", "terms", "of", "the", "value", "of", "the", "energy", "of", "the", "component", "captured", "by", "the", "subspace", ",", "as", "done", "in", "MP", "or", "SP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["Moreover", ",", "PS", "based", "SWIPT", "is", "considered", "at", "[", "16,18,22]."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["systemThe", "results", "in", "Section", "sec", ":", "stages", "demonstrate", "that", "most", "components", "of", "an", "ISP", "have", "a", "beneficial", "impact", "on", "CNN", "performance", "to", "a", "greater", "or", "lesser", "extent", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["As", "for", "STL", ",", "the", "quantitative", "semantics", "of", "SSTL", "is", "sound", "with", "respect", "to", "the", "Boolean", "semantics", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "signal temporal logic"}, {"tokens": ["This", "was", "elected", "due", "to", "the", "the", "highly", "inaccurate", "prediction", "from", "the", "AR", "rendering", "when", "relying", "on", "the", "kinematic", "calibration", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["The", "GMM", "speaker", "model", "is", "adapted", "with", "the", "UBM", "-", "based", "training", "data", "of", "each", "speaker", "'s", "data", "to", "make", "the", "system", "faster", ",", "stable", ",", "and", "having", "better", "performance", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["the", "impact", "of", "optimizing", "the", "PS", "ratios", "by", "comparing", "it", "to", "two", "other", "cases", ":", "i", ")", "assuming", "the", "absence", "of", "RF", "EH", "(", "i.e.", ",", ")", "so", "that", "the", "relays", "are", "using", "the", "RE", "only", "and", "ii", ")", "assuming", "fixed", "PS", "ratios", "for", "all", "the", "relays", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["MGF_SSDF", ",", "a", "closed", "-", "form", "expression", "for", "of", "rate", "-", "selective", "RS", "over", "INID"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Section", "3", "the", "design", "and", "implementation", "of", "CNet", "-", "NIC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "neural image caption"}, {"tokens": ["Use", "permitted", "under", "Creative", "Commons", "License", "Attribution", "4.0", "International", "(", "CC", "BY", "4.0", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "creative commons"}, {"tokens": ["Results", "are", "shown", "for", "the", "CNS", "and", "MDC", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["TP", "and", "TN", "are", "the", "examples", "where", "the", "rupture", "propagates", "or", "arrests", ",", "respectively", ",", "and", "the", "models", "predict", "them", "correctly", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true negative"}, {"tokens": ["DiscussionTaken", "together", ",", "these", "results", "extend", "previous", "work", "and", "demonstrate", "that", "modified", "FA", "learning", "algorithms", "can", "perform", "with", "accuracy", "competitive", "with", "BP", "even", "for", "deep", "CNNs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["such", "minimum", "information", "leakage", "can", "be", "used", "to", "express", "the", "conditioned", "min", "-", "entropy", "of", "RV", "(", "for", ")", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["firstly", "employed", "DCNN", "to", "extract", "hierarchical", "convolutional", "features", "for", "learning", "multiple", "correlation", "filters", ",", "which", "achieved", "impressive", "performance", "on", "public", "benchmarks", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["One", "advantage", "of", "MAD", "is", "that", "the", "learned", "weights", "enforced", "on", "each", "feature", "channel", "is", "predicted", "on", "-", "the", "-", "fly", "based", "on", "the", "input", "context", ",", "which", "is", "more", "suitable", "than", "the", "fixed", "enforcement", "of", "a", "convolutional", "kernel", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["Clustering", "with", "Selected", "FeaturesFigure", "fig_ACC", "and", "Figure", "fig_NMI", "show", "the", "clustering", "performance", "in", "terms", "of", "ACC", "and", "NMI", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "accuracy"}, {"tokens": ["The", "bottleneck", "of", "the", "incremental", "determinisation", "is", "then", "to", "test", "whether", "a", "Rabin", "automaton", "is", "GFG", "(", "or", "DBP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["Epoch", "-", "wise", "CTC", "loss", "and", "validation", "error", "are", "represented", "graphically", "in", "Figure", "5", "and", "Figure", "6", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["LTE", "-", "eMBMS", "permits", "the", "transmission", "of", "a", "specific", "modes", "called", "MBMS", "over", "Single", "Frequency", "Networks", "(", "MBSFN", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "the", "AN", "component", ",", "alignment", "factors", "between", "target", "labels", "andfeatures", "are", "generated", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["Fraudulent", "Services", "(", "FS", ")", "Domains", "and", "IP", "addresses", "engaged", "in", "the", "distribution", "or", "provisioning", "of", "bogus", "or", "fraudulent", "services", "or", "applications", "such", "as", "the", "promotion", "of", "comments", ",", "likes", ",", "ratings", ",", "votes", "or", "any", "variations", "thereof", "de2014paying", ",", "Ikram:2017:MCD", ",", "farooqicharacterizing", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fraudulent services"}, {"tokens": ["In", "this", "paper", ",", "we", "tackle", "the", "cloud", "detection", "problem", "by", "presenting", "a", "framework", "based", "on", "deep", "pyramid", "network", "architecture", "(", "DPN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "deep pyramid network"}, {"tokens": ["After", "that", ",", "AA", "theory", "was", "developed", "and", "has", "been", "applied", "to", "OPF", "problems", "in", "power", "systems", ",", "which", "can", "take", "the", "correlation", "among", "variables", "into", "account", "and", "yield", "much", "tighter", "lower", "and", "upper", "bounds", "compared", "to", "IA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "interval analysis"}, {"tokens": ["Defining", "DSA", "Categories", "Detecting", "Skill", "Shortages", "from", "Job", "AdsIn", "this", "section", ",", "we", "propose", "five", "labour", "demand", "variables", "for", "detecting", "skill", "shortages", "from", "job", "ads", "data", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["Flowchart", "of", "the", "PSO", "algorithm", "."], "acronym_pos": [0, 0, 0, 1, 0, 0], "long_form": "power system operations"}, {"tokens": ["The", "error", "bars", "are", "set", "to", "(", "95", "of", "the", "measurements", "for", "the", "normal", "distribution)Table", "presents", "the", "benchmark", "results", "related", "to", "PRR", "in", "comparison", "with", "the", "ring", "algorithm", ",", "executed", "on", "48", "nodes", "with", "1Gbps", "Ethernet", "interconnecting", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pre - reduced ring"}, {"tokens": ["The", "collaborative", "filtering", "(", "CF", ")", "method", "is", "a", "ceiling", "and", "not", "a", "baseline", ",", "because", "the", "primary", "target", "audience", "of", "a", "cold", "-", "start", "questionnaire", "comprises", "users", "who", "have", "no", "editing", "history", "since", "they", "have", "just", "created", "an", "account", ",", "and", "CF", "is", "unusable", "in", "the", "absence", "of", "existing", "history", "for", "the", "user", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": [":", "There", "is", "no", "statistical", "meaningful", "difference", "between", "classifier", "and", "sensitivity", ",", "precision", ",", "f", "measure", ",", "specificity", ",", "MCC", "and", "accuracy", "parameters", "of", "classifiers", "with", "95", "confidence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["blackInvoking", "the", "boosting", "method", "alone", "into", "the", "pipeline", "(", "denoted", "as", "'", "ZIP", "MAD", "B", "'", ",", "using", "all", "features", "in", "the", "nine", "blocks", ")", "could", "enhance", "the", "detection", "performance", "to", "some", "extent", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["A", "survey", "of", "papers", "and", "reports", "of", "the", "period", "2003", "-", "2016", "addressing", "various", "aspects", "of", "economic", "load", "dispatch", "using", "the", "PSO", "algorithm", "have", "been", "presented", "in", "this", "paper", "along", "with", "a", "brief", "discussion", "of", "a", "simple", "ELD", "model", "and", "the", "classical", "PSO", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power system operations"}, {"tokens": ["vmp_1a.pdfvmp_1b.pdfAverage", "outbreak", "sizes", "for", "different", "vaccination", "strategies", "at", "various", "vaccination", "rates", "in", "post", "-", "outbreak", "vaccinationfig", ":", "vmpffigure", "The", "proposed", "vaccination", "strategy", "(", "IMV", ")", "shows", "the", "significant", "improvements", "in", "reducing", "the", "final", "average", "outbreak", "sizes", "compared", "to", "the", "AV", "and", "RV", "strategies", "(", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["Based", "on", "this", "intuition", ",", "we", "can", "identify", "the", "poison", "target", "class", "as", "the", "class", "where", "the", "GMM", "clusters", "have", "the", "lowest", "similarity", "measure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["From", "the", "aspect", "of", "run", "time", ",", "DDE", "-", "MGM", "can", "not", "beat", "most", "online", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Therefore", ",", "the", "number", "of", "bits", "of", "a", "successful", "downlink", "transmission", "(", ")", "is", ":", "where", "is", "the", "probability", "that", "a", "transmission", "is", "from", "the", "AP", ",", "and", "is", "the", "number", "of", "aggregated", "frames", "in", "an", "A", "-", "MPDU", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["In", "Augmented", "RealityFeature", "Extraction", "is", "the", "second", "step", "in", "AR", "Process", ",", "though", "it", "composes", "of", "six", "stages", "as", "shown", "in", "figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Finally", ",", "we", "adapt", "recent", "fast", "adversarial", "training", "methods", "to", "ARD", "for", "accelerated", "robust", "distillation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["CF", "algorithms", "analyze", "the", "interactions", "between", "users", "and", "entities", ",", "e.g.", ",", "datasets", "and", "services", "alike", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "CSI", "is", "assumed", "available", "at", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access part"}, {"tokens": ["It", "is", "very", "difficult", "to", "use", "GPS", "for", "avoiding", "collisions", "in", "an", "indoor", "environment", ",", "usually", "indoor", "is", "a", "GPS", "denied", "environment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["If", "the", "AP", "has", "data", "for", "the", "client", ",", "the", "client", "sends", "PS", "-", "Poll", "frame", "in", "return", "to", "receive", "the", "buffered", "data", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "default", "DCNN", "architecture", "for", "image", "classification", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Because", "of", "the", "simple", "implementation", "and", "quick", "convergence", "rates", "of", "PSO", ",", "it", "has", "been", "adapted", "in", "many", "practical", "applications", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["ApproximationsIn", "order", "to", "convert", "the", "optimization", "problem", "formulated", "in", "Rmax", "-", "epsilon", "to", "a", "GP", "standard", "form", ",", "we", "propose", "to", "apply", "approximations", "for", "the", "objective", "and", "constraint", "functions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Once", "the", "experiment", "had", "been", "completed", "on", "the", "SDD", ",", "the", "participant", "was", "then", "shown", "a", "new", "set", "of", "images", "and", "targets", "on", "the", "TDW", ",", "again", "given", "2", "minutes", "for", "each", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Experimental", "EvaluationThe", "proposed", "DDE", "-", "MGM", "is", "evaluated", "on", "three", "datasets", "-", "UCI", "character", "trajectories", ",", "MSR", "Action3D", ",", "and", "PAMAP", "outdoor", "activities", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["The", "OntoNotes", "corpus", "consists", "of", "multiple", "genres", "of", "text", ",", "annotated", "with", "syntactic", "and", "semantic", "information", ",", "but", "we", "only", "use", "POS", "and", "dependency", "parsing", "annotations", "in", "this", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Empirical", "Study", "for", "Threshold", "SelectionFigure", "shows", "the", "performance", "comparison", "of", "flat", "LR", "approach", "against", "our", "best", "TD", "approach", ",", "Global", "-", "INF", "with", "varying", "selection", "of", "threshold", "in", "the", "interval", "[", ",", "]", "(", "performance", "deteriorates", "after", ")", "with", "step", "-", "size", "0.1", "for", "CLEF", "and", "DMOZ", "-", "SMALL", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Furthermore", ",", "much", "of", "this", "development", "is", "the", "same", "for", "an", "arbitrary", "demand", "function", ",", "rather", "than", "a", "RUM", ";", "see", ",", "e.g.", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "random utility maximization"}, {"tokens": ["[", "IB", "Lagrangian", "and", "IB", "convex", "Lagrangian", "connection", "]", "Let", "be", "the", "IB", "Lagrangian", "and", "the", "convex", "IB", "Lagrangian", "."], "acronym_pos": [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["We", "see", "that", "our", "best", "model", ",", "k=4", "and", "lr=1.0", ",", "gives", "a", "slight", "increase", "of", "0.1", "CER", "vs", "the", "baseline", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["Our", "CPN", ":", "(", "PN", "+", "VAT", ")", "&", "95.66", "0.21", "&", "44.63", "0.21", "&", "64.02", "0.20"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["Performance", "numbers", "of", "FG", "and", "BSP", "show", "such", "tendency", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["Itis", "proposed", "in", "that", "LTE", "small", "cells", "usefrequency", "-", "hopping", "and", "time", "-", "hopping", "in", "the", "TV", "whitespace", "band", "toreduce", "interference", "from", "other", "devices", "in", "the", "band", ";", "whereas", "thisstudy", "proposes", "a", "channel", "-", "sensing", "based", "channel", "access", "scheme", "for", "LTEsmall", "cells", "to", "access", "the", "band", "and", "reduce", "interference", ",", "which", "may", "also", "be", "applicable", "to", "the", "newStudy", "Item", "(", "SI", ")", "\"", "Licensed", "-", "Assisted", "Access", "using", "LTE", "\"", "which", "was", "recently", "approved", "for", "3GPP", "Rel-13", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Results", "from", "the", "CNS", "dataset", "reported", "in", "Table", "show", "that", "for", "all", "metrics", "holds", "in", "more", "than", "of", "cases", "on", "average", "(", "MDC", ":", ",", "see", "Supplementary", "Material", "Table", "S1", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["The", "second", "reference", "case", "is", "when", "all", "the", "requested", "files", "are", "placed", "at", "the", "CC", "together", "with", "full", "centralization", "of", "network", "functions", ",", "introducing", "extra", "delay", "and", "consuming", "the", "highest", "x", "-", "haul", "bandwidth", ",", "with", "the", "advantage", "of", "minimized", "power", "consumption", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Actual", "size", "of", "the", "images", "is", "in", "the", "range", "of", "pixelsFigure", "shows", "some", "sample", "LR", "images", "generated", "from", "the", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["To", "solve", "a", "problem", "by", "ICA", "algorithm", ",", "firstly", "an", "accurate", "definition", "of", "countries", "should", "be", "presented", ",", "and", "then", "cost", "function", "should", "be", "determined", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imperialist competitive algorithm"}, {"tokens": ["Digital", "signatures", "in", "ECDSA", "have", "better", "efficiency", "in", "devices", "with", "constrained", "-", "resource", "than", "DSA", "and", "RSA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "digital signature algorithm"}, {"tokens": ["Roughly", "speaking", ",", "GDP", "guarantee", "ensures", "that", "the", "output", "of", "Algorithm", "when", "executed", "on", "data", "set", "does", "not", "depend", "\"", "too", "much", "\"", "on", "any", "one", "entry", "of", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["Our", "goal", "is", "to", "design", "a", "deep", "network", "to", "reduce", "the", "distribution", "discrepancy", "across", "domains", "in", "order", "that", "the", "generalization", "error", "in", "the", "target", "domain", "can", "be", "bounded", "by", "source", "risk", "plus", "the", "distribution", "discrepancy", "across", "domains", ",", "whereOverallAs", "is", "shown", "in", "Figure", ",", "DADA", "consists", "of", "a", "feature", "extractor", ",", "a", "class", "predictor", "and", "two", "joint", "discriminators", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dual adversarial domain adaptation"}, {"tokens": ["To", "encode", "the", "interdependence", "of", "the", "phrases", ",", "we", "suggest", "to", "use", "the", "phrase", "categories(from", "PIN", ")", "of", "source", "and", "target", "phrases", "embedded", "as", "a", "one", "-", "hot", "-", "vector", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["Em", "MD", ",", "o", "conhecimento", "\u00e9", "gerado", "a", "partir", "do", "fornecimento", "de", "dados", "a", "um", "algoritmo", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "massa de dados"}, {"tokens": ["In", ",", "a", "hybrid", "layered", "MD", "video", "coding", "algorithm", "uses", "the", "H.264/AVC", "encoder", "to", "compress", "a", "video", "at", "low", "bit", "rates", "as", "the", "base", "layer", ",", "and", "then", ",", "four", "-", "bit", "streams", "are", "divided", "into", "two", "groups", "as", "two", "description", "enhancement", "layers", "after", "3D", "dual", "-", "tree", "discrete", "wavelet", "transform", "and", "3D", "-", "SPIHT", "encoding", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["in", "propose", "a", "distributed", "MU", "-", "MIMO", "MAC", "protocol", "that", "modifies", "RTS", "and", "CTS", "frames", "to", "estimate", "the", "channel", ",", "based", "on", "which", ",", "the", "AP", "is", "able", "to", "concurrently", "transmit", "frames", "to", "multiple", "STAs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Hence", ",", "the", "RB", "model", "is", "equivalent", "to", "the", "FEM", ",", "but", "with", "basis", "functions", "that", "are", "globally", "supported", "in", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["In", "the", "protocol", "is", "supposed", "to", "input", "a", "publicly", "known", "dummy", "element", "to", "the", "OT", ",", "but", "he", "can", "deviate", "from", "the", "protocol", "by", "inputting", "some", "other", "elements", "to", "the", "OT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "share", "auction", "is", "an", "appropriate", "solution", "since", "it", "allows", "to", "allocate", "the", "FJ", "power", "to", "the", "sources", "in", "a", "distributed", "manner", "with", "the", "limited", "local", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["As", "illustrated", "by", "the", "comparison", "to", "the", "IB", "baseline", ",", "this", "improvement", "is", "obtained", "only", "when", "carefully", "incorporating", "this", "synthetic", "experience", "via", "a", "short", "horizon", "and", "the", "TD-", "trick", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imaginary batches"}, {"tokens": ["It", "is", "evident", "that", "during", "the", "VAT", "training", ",", "convergence", "occurred", "much", "sooner", "than", "the", "corresponding", "vanilla", "(", "column", "nepochs", "with", "(", "e", ")", "indicates", "exit", "/", "ending", "epoch", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["OT", "5", ".24"], "acronym_pos": [1, 0, 0], "long_form": "optimal transport"}, {"tokens": ["More", "interestingly", ",", "the", "proposed", "quantitative", "trust", "measure", "further", "improves", "model", "performance", "when", "incorporated", "into", "either", "hybrid", "or", "CF", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["We", "perform", "experiments", "with", "PS", ",", "P2P", ",", "and", "RA", "architecture", "and", "compare", "it", "to", "our", "model", "results", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": [",", "we", "present", "the", "MAB", "heuristic", "titled", "Con", "-", "TS", "-", "RTP", "adopted", "to", "the", "electricity", "pricing", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["In", "this", "proposal", "we", "are", "discussing", "mainly", "both", "the", "Tessellation", "Shader", "-", "TS", ",", "which", "allows", "to", "refine", "simpler", "meshes", "into", "finer", "ones", ",", "and", "the", "Fragment", "Shader", "-", "FS", ",", "which", "is", "used", "to", "apply", "lighting", ",", "color", "blending", ",", "process", "and", "render", "a", "fragment", ",", "for", "example", "a", "pixel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fragment shader"}, {"tokens": ["Network", "ModelWe", "consider", "a", "typical", "HetNet", "consisting", "of", "one", "macrocell", "BS", "and", "MBSs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "base station"}, {"tokens": ["PS", "is", "a", "physics", "-", "motivated", "framework", "for", "artificial", "intelligence", "developed", "in", "Ref", ".", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "projective simulation"}, {"tokens": ["is", "defined", "as", "Definitions", "and", "exploit", "GMM", "to", "represent", "the", "optimal", "weight", "function", "for", "the", "inner", "products", ",", "as", "it", "is", "general", "and", "can", "universally", "approximates", "the", "possible", "weight", "functions", "that", "define", "a", "finite", "inner", "product", "for", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["In", "this", "step", ",", "user", "needs", "to", "upload", "the", "local", "FL", "parameters", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["OT", "Extension", "Phase"], "acronym_pos": [1, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["DL", "Channel", "Estimator", "Different", "from", "the", "LS", "and", "LMMSE", "estimators", ",", "the", "DL", "estimator", "learns", "a", "set", "of", "training", "data", "drawn", "from", "certain", "statistical", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["We", "define", "the", "following", "abstract", "kernel", "formulation", ":", "where", "can", "be", "any", "compatible", "GP", "kernel", "in", "the", "literature", "(", "we", "use", "the", "Rational", "Quadratic", "and", "the", "Matern", "covariance", "functions", "in", "and", "respectively", ")", "that", "is", "applied", "on", "categories", "(", "or", "clusters", ")", "of"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "PRR", "has", "the", "lowest", "time", "of", "communication", ":", "31.9ms", "(", "average", "elapsed", "time", "of", "all", "-", "reduce", ")", "as", "well", "as", "the", "total", "time", "of", "training", ":", "78.6s", ",", "SLT", "is", "slightly", "worse", "having", "33.1ms", "and", "78.8s", "respectively", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pre - reduced ring"}, {"tokens": ["In", "general", ",", "the", "candidate", "set", "of", "RRHs", "for", "serving", "UEs", "and", "the", "CSI", "estimation", "set", "of", "RRHs", "for", "each", "UE", "are", "determined", "based", "on", "UEs", "'", "locations", "that", "may", "be", "the", "task", "of", "the", "upper", "-", "layer", ",", "which", "is", "beyond", "the", "scope", "of", "this", "paper", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["[", "]", "Results", "for", "continual", "single", "-", "output", "GP", "classification", "over", "probit", "toy", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Using", "this", "reduced", "number", "of", "modes", ",", "the", "GMM", "expression", "of", "the", "distribution", "of", "residual", "is", "shown", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Results", "from", "TS", "and", "our", "approach", "differ", "from", "table", "as", "we", "only", "pick", "the", "DNNs", "used", "in", "the", "explicit", "techniques", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature scaling"}, {"tokens": ["By", "comparing", "with", "other", "resampling", "methods", ",", "ECS", "-", "DBN", "outperforms", "on", "G", "-", "mean", "and", "precision", "metrics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Therefore", ",", "it", "is", "urgent", "to", "diagnose", "this", "dangerous", "diseases", "accurately", "in", "the", "critical", "early", "phase", "of", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "acute pancreatitis"}, {"tokens": ["Each", "pixel", "in", "the", "line", "sensor", "is", "mapped", "to", "a", "row", "in", "DMD", "array", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "digital micro - mirror device"}, {"tokens": ["Thus", ",", "NP", "-", "hardness", "of", "the", "non", "-", "emptiness", "problem", "follows", "from", "NP", "-", "hardness", "of", "membership", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "non - emptiness problem"}, {"tokens": ["When", "considering", "constraints", "prob1-prob3", "in", "Con", "-", "TS", "-", "RTP", ",", "the", "algorithm", "will", "select", "more", "conservative", "price", "signals", "each", "day", "that", "can", "guarantee", "the", "distribution", "system", "'s", "constraints", "are", "met", "with", "high", "probability", "by", "using", "the", "information", "in", "the", "updated", "prior", "distributions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["Phase", "change", "memory", "(", "PCM", ")", "can", "also", "be", "another", "alternative", "for", "secured", "NVM", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phase change memory"}, {"tokens": ["Intuitively", ",", "the", "UE", "with", "a", "smaller", "should", "have", "a", "higher", "priority", "to", "be", "removed", "since", "it", "has", "the", "largest", "gap", "away", "from", "its", "rate", "targets", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["We", "first", "carried", "out", "a", "conventional", "optimization", "of", "the", "cross", "-", "entropy", "loss", "and", "starting", "from", "this", "parameterization", "of", "the", "NN", "we", "further", "optimized", "the", "meta", "-", "loss", "through", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Despite", "the", "vast", "literature", "on", "MP", "-", "type", "methods", "which", "typically", "gives", "recovery", "guarantees", "for", "sparse", "signals", ",", "surprisingly", "little", "is", "known", "about", "MP", "algorithms", "in", "terms", "of", "optimization", ",", "i.e.", ",", "how", "many", "iterations", "are", "needed", "to", "reach", "a", "defined", "target", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["However", ",", "RA", "is", "limited", "by", "the", "slowest", "directed", "communication", "link", "between", "neighbors", "and", "available", "network", "bandwidth", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["Fourth", ",", "most", "effective", "QA", "and", "RC", "models", "highly", "rely", "on", "explicit", "inter", "-", "sentence", "matching", "between", "questions", "and", "passages", ",", "whereas", "BERT", "only", "applies", "self", "-", "attention", "layers", "over", "the", "concatenation", "of", "a", "question", "-", "passage", "pair", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["CD", "is", "used", "to", "represent", "learning", "using", "full", "steps", "of", "alternating", "Gibbs", "sampling", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "contrastive divergence"}, {"tokens": ["In", "this", "section", ",", "we", "investigate", "the", "papers", "which", "have", "adopted", "PSO", "for", "steganalysis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Both", "varieties", "of", "crossover", "involve", "swapping", "different", "parts", "of", "a", "pair", "of", "parents", "in", "random", "locations", "based", "on", "POS", "tags", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "part of speech"}, {"tokens": ["Positive", "numbers", "show", "success", "favoured", "the", "TDW", ",", "negative", "results", "favoured", "the", "SDD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "standard desktop display"}, {"tokens": ["It", "is", "still", "worthwhile", "to", "mention", "that", "(", "2017", ")", "explored", "transfer", "learning", "for", "the", "BiDAF", "model", "for", "MR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "machine reading"}, {"tokens": ["We", "use", "boundary", "and", "reconstruction", "OCC", "framework", "for", "OSELM", "and", "OPIUM", "based", "online", "learning", "approach", "and", "are", "termed", "as", "OSELM", "-", "B", ",", "OSELM", "-", "AE", ",", "OPIUM", "-", "B", ",", "and", "OPIUM", "-", "AE", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "one class classifier"}, {"tokens": ["for", "an", "example", "of", "a", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["the", "actual", "direction", "angle", "between", "the", "BS", "and", "the", "-th", "eavesdropper", "is", "expressed", "aswhere", "is", "the", "estimated", "direction", "angle", "between", "the", "BS", "and", "the", "-th", "eavesdropper", ",", "denotes", "the", "estimation", "error", "which", "is", "assumed", "to", "follow", "the", "Von", "Mises", "distribution", "over", "the", "interval", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Increasing", "vaccination", "rates", "further", "for", "RV", "and", "AV", "strategies", "show", "that", "the", "RV", "strategy", "requires", "75", "of", "nodes", "to", "be", "vaccinated", "in", "both", "networks", "and", "the", "AV", "strategy", "requires", "vaccination", "of", "40", "nodes", "in", "DDT", "network", "and", "35", "in", "GDT", "network", "to", "contain", "disease", "spreading", "within", "the", "outbreaks", "of", "1", "K", "infections", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["Then", ",", "each", "latent", "function", "is", "assumed", "to", "be", "drawn", "from", "an", "independent", "GP", "prior", ",", "such", "that", ",", "where", "is", "any", "valid", "covariance", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Results", "of", "CC", "method", "using", "top", "5", "single", "label", "classifers", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classifier chain"}, {"tokens": ["Geometric", "Dimensions", "of", "the", "FEM", "model", "Illustration", "of", "tuned", "resonant", "platform", "model", "General", "contact", "algorithm", "based", "on", "\"", "hard", "contact", "\"", "(", "no", "penetration", ")", "behaviour", "is", "used", "for", "the", "impact", "between", "the", "projectile", "and", "the", "resonant", "bar", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["To", "this", "end", ",", "we", "first", "train", "a", "deep", "network", "which", "generates", "LR", "images", "from", "HR", "images", "and", "tries", "to", "model", "the", "distribution", "of", "real", "LR", "images", "in", "pixel", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["The", "original", "GCP", "presented", "in", "Section", "sec", ":", "GCP", "consists", "in", "using", "a", "vertex", "partition", "to", "then", "determine", "a", "multiedge", "\"", "grid", "\"", "partition", "(", "see", "top", "-", "left", "matrix", "of", "Figure", "fig", ":", "schemes):such", "that", "two", "multiedges", "and", "are", "in", "the", "same", "multiedge", "subset", "if", "and", "only", "if", "their", "source", "vertices", "are", "both", "in", "and", "their", "target", "vertices", "are", "both", "in", ":", "In", "other", "terms", ",", "the", "induced", "two", "-", "dimensional", "partitioning", "of", "the", "multiedge", "set", "is", "the", "Cartesian", "product", "of", "a", "one", "-", "dimensional", "partitioning", "of", "the", "vertex", "set", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph compression problem"}, {"tokens": ["The", "analysis", "in", "this", "section", "reveals", "that", "the", "transferability", "of", "features", "is", "influenced", "by", "the", "generality", "of", "the", "transferred", "network", "and", "the", "distant", "between", "the", "source", "and", "the", "target", "tasks", ",", "that", "is", "to", "say", ",", "the", "network", "and", "the", "source", "tasks", "both", "have", "an", "impact", "on", "transferring", "to", "SAR", "target", "recognition", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Automating", "OARs", "segmentation", "has", "the", "benefit", "of", "both", "reducing", "the", "time", "and", "improving", "the", "quality", "of", "RT", "planning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "radiation therapy"}, {"tokens": ["This", "motivates", "us", "to", "propose", "the", "following", "approach", "to", "transform", "Problem", "(", ")", "into", "a", "standard", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "geometric programming"}, {"tokens": ["the", "bisection", "UE", "selection", "algorithm", ",", "the", "complexity", "of", "which", "increases", "logarithmically", "with", "the", "number", "of", "UEs", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["However", ",", "this", "is", "not", "straightforward", ",", "because", "standard", "labeled", "datasets", "commonly", "used", "for", "CNN", "experiments", "consist", "of", "RGB", "images", ",", "which", "have", "already", "been", "processed", "from", "raw", "sensor", "data", "with", "fixed", "ISP", "settings", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "image signal processor"}, {"tokens": ["(", "Q", ")", "Magnitude", "of", "the", "correlation", "between", "history", "and", "PI", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "purchase intention"}, {"tokens": ["In", ",", "a", "metric", "combined", "with", "OT", "in", "primal", "form", "with", "an", "energy", "distance", "results", "in", "a", "highly", "discriminative", "feature", "representation", "with", "unbiased", "gradients", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Achievable", "sum", "rate", "versus", "SNR", "with", "different", "number", "of", "users", "and", "the", "antennas", "at", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Determination", "of", "element", "size", "in", "FEM"], "acronym_pos": [0, 0, 0, 0, 0, 1], "long_form": "finite element method"}, {"tokens": ["The", "nodes", "'", "color", "represents", "the", "worst", "-", "case", "SSS", "at", "(", "blue", ",", "green", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastically stable states"}, {"tokens": ["ht", "]", "MINT", "-", "FEC", "Simulation", "parameters", "Five", "different", "schemes", "were", "simulated", "as", "follows", ":", "(", "1", ")", "without", "any", "FEC", "mechanism", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Table", "shows", "the", "total", "number", "of", "images", "used", "in", "training", ",", "the", "total", "number", "of", "images", "with", "Cardiomegaly", "and", "the", "AUC", "of", "ROC", "(", "mean", "and", "standard", "deviation", ")", "corresponding", "to", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["If", "the", "shaping", "is", "properly", "designed", ",", "the", "effective", "SNR", "decrease", "is", "less", "than", "the", "AIR", "increase", ",", "and", "therefore", ",", "an", "overall", "performance", "improvement", "is", "observed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "achievable information rates"}, {"tokens": ["TS", "algorithm", "parameters", "are", "mentioned", "in", "Table"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["However", ",", "this", "approach", "has", "higher", "computation", "because", "the", "input", "is", "the", "MR", "image", "which", "has", "the", "same", "size", "as", "the", "HR", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "middle resolution"}, {"tokens": ["We", "explore", "two", "strategies", "in", "pursuit", "of", "the", "upper", "bound", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "average precision"}, {"tokens": ["UTF8bkaiProposed", "ApproachASR", "errors", "are", "inevitable", ",", "and", "they", "can", "hinder", "the", "reasoning", "of", "QA", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["Eliminating", "Doppler", "Effects", "Through", "Intelligent", "ReflectionIn", "this", "section", ",", "we", "focus", "on", "a", "simple", "scenario", "in", "which", "the", "direct", "link", "is", "blocked", "by", "an", "obstacle", "while", "the", "communication", "between", "the", "BS", "and", "the", "MS", "is", "established", "through", "a", "reflection", "from", "an", "IO", "as", "shown", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["BF", "affords", "more", "importance", "to", "the", "first", "appearance", "of", "a", "word", ",", "and", "the", "others", "an", "equally", "less", "importance", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary function"}, {"tokens": ["fig", ":", "denoisedenoise.eps[MobileNet", "accuracy", "with", "a", "range", "of", "ISP"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "image signal processor"}, {"tokens": ["Similar", "to", "Algorithm", "3", "in", "Section", "III", ",", "Algorithm", "4", "is", "done", "at", "the", "BS", "side", "before", "executing", "the", "FL", "scheme", "in", "Algorithm", "1", ",", "which", "will", "not", "affect", "the", "latency", "of", "the", "FL", "process", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["table*[ht]threeparttableResults", "for", "Multi", "-", "label", "Music", "Genre", "Classification", "of", "Albumstbl", ":", "resultstabularlccccccccModality", "&", "Target", "&", "Settings", "&", "Params", "&", "Time", "&", "AUC", "&", "C@1", "&", "C@3", "&", "C@5", "Audio", "&", "logistic", "&", "timbre", "-", "mlp", "&", "0.01", "M", "&", "1s", "&", "0.792", "&", "0.04", "&", "0.14", "&", "0.22", "Audio", "&", "logistic", "&", "low-3x3", "&", "0.5", "M", "&", "390s", "&", "0.859", "&", "0.14", "&", "0.34", "&", "0.54", "Audio", "&", "logistic", "&", "high-3x3", "&", "16.5", "M", "&", "2280s", "&", "0.840", "&", "0.20", "&", "0.43", "&", "0.69", "Audio", "&", "logistic", "&", "low-4x96", "&", "0.2", "M", "&", "140s", "&", "0.851", "&", "0.14", "&", "0.32", "&", "0.48", "Audio", "&", "logistic", "&", "high-4x96", "&", "5", "M", "&", "260s", "&", "0.862", "&", "0.12", "&", "0.33", "&", "0.48", "Audio", "&", "logistic", "&", "low-4x70", "&", "0.35", "M", "&", "200s", "&", "0.871", "&", "0.05", "&", "0.16", "&", "0.34", "Audio", "&", "logistic", "&", "high-4x70", "&", "7.5", "M", "&", "600s", "&", "0.849", "&", "0.08", "&", "0.23", "&", "0.38", "Audio", "&", "cosine", "&", "low-3x3", "&", "0.33", "M", "&", "400s", "&", "0.864", "&", "0.26", "&", "0.47", "&", "0.65", "Audio", "&", "cosine", "&", "high-3x3", "&", "15.5", "M", "&", "2200s", "&", "0.881", "&", "0.30", "&", "0.54", "&", "0.69", "Audio", "&", "cosine", "&", "low-4x96", "&", "0.15", "M", "&", "135s", "&", "0.860", "&", "0.19", "&", "0.40", "&", "0.52", "Audio", "&", "cosine", "&", "high-4x96", "&", "4", "M", "&", "250s", "&", "0.884", "&", "0.35", "&", "0.59", "&", "0.75", "Audio", "&", "cosine", "&", "low-4x70", "&", "0.3", "M", "&", "190s", "&", "0.868", "&", "0.26", "&", "0.51", "&", "0.68", "Audio", "(", "A", ")", "&", "cosine", "&", "high-4x70", "&", "6.5", "M", "&", "590s", "&", "0.888", "&", "0.35", "&", "0.60", "&", "0.74", "Text", "&", "logistic", "&", "VSM", "&", "25", "M", "&", "11s", "&", "0.905", "&", "0.08", "&", "0.20", "&", "0.37", "Text", "&", "logistic", "&", "VSM+Sem", "&", "25", "M", "&", "11s", "&", "0.916", "&", "0.10", "&", "0.25", "&", "0.44", "Text", "&", "cosine", "&", "VSM", "&", "25", "M", "&", "11s", "&", "0.901", "&", "0.53", "&", "0.44", "&", "0.90", "Text", "(", "T", ")", "&", "cosine", "&", "VSM+Sem", "&", "25", "M", "&", "11s", "&", "0.917", "&", "0.42", "&", "0.70", "&", "0.85"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vector space model"}, {"tokens": ["Initially", "the", "BC", "is", "started", "with", "the", "first", "block", "called", "genesis", "or", "initial", "block", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": [".tif'.pngComment", "on", "Adv", "-", "BNN"], "acronym_pos": [0, 0, 0, 0, 1], "long_form": "bayesian neural networks"}, {"tokens": ["This", ",", "for", "instance", ",", "may", "be", "the", "reason", "why", "\"", "pi", "\"", "does", "not", "appear", "in", "LSC", "as", "it", "is", "commonly", "used", "by", "the", "symbol", "(", "pi", ")", "in", "math", "world", "and", "not", "many", "articles", "include", "formulas", "in", "abstract", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Therefore", ",", "reverse", "engineering", "of", "such", "NVMs", "has", "always", "been", "considered", "as", "a", "challenging", "task", ";", "even", "after", "the", "recent", "advancements", "in", "FA", "tools", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "failure analysis"}, {"tokens": ["Then", ",", "the", "AP", "analyzes", "all", "the", "information", "received", ",", "selects", "and", "signals", "those", "allowed", "STAs", "to", "transmit", "simultaneously", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["RA", "overlaps", "the", "computation", "of", "gradients", "at", "lower", "layers", "in", "a", "deep", "neural", "network", "with", "the", "transmission", "of", "gradients", "at", "higher", "layers", ",", "which", "reducing", "training", "time", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["However", ",", "using", "CC", "-", "CV", ",", "a", "battery", "is", "charged", "to", "a", "maximum", "4.2", "V."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant current"}, {"tokens": ["Section", "2", "describes", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "system", "model", "and", "the", "proposed", "protocol", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "details", "of", "the", "SAR", "system", ",", "study", "design", ",", "data", "collection", ",", "and", "outcomes", "measures", "are", "described", "next", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["As", "shown", "in", "the", "NCE", "evaluation", "on", "ranking", "list", "2", "and", "3", "in", "Table", ",", "it", "was", "found", "that", "1", "improvement", "of", "NCE", "value", "indicated", "a", "substantial", "improvement", "over", "the", "diversity", "in", "the", "results", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["The", "OEC", ":", "Facts", "about", "the", "language", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0], "long_form": "oxford english corpus"}, {"tokens": ["Still", ",", "we", "propose", "that", "a", "RS", "which", "has", "a", "lower", "overall", "score", "would", "more", "readily", "allow", "for", "the", "user", "to", "change", "their", "preference", "at", "their", "own", "will", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["For", "this", "test", ",", "GA", ",", "ACO", "and", "BPSO", "were", "selected", "for", "the", "benchmarking", ";", "since", "the", "remaining", "PSO", "variants", "are", "based", "on", "BPSO", ",", "their", "performance", "in", "terms", "of", "time", "is", "not", "likely", "to", "significantly", "differ", "from", "BPSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Consequently", ",", "the", "extra", "layer", "that", "the", "multi", "-", "output", "GP", "adds", "for", "correlating", "latent", "functions", ",", "is", "also", "used", "for", "the", "sparse", "approximation", ",", "inducing", "a", "two", "-", "step", "conditioning", "on", "the", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "Section", "sec", ":", "hypergrid", ",", "we", "show", "that", "Lipschitz", "testers", "over", "the", "hypergrid", "domain", "can", "be", "used", "to", "test", "for", "GDP", "when", "the", "data", "sets", "are", "drawn", "uniformly", "from", "the", "hypergrid", "domain", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["Zoom", "Network", "Training", "with", "MAD", "Unitsec", ":", "training", "-", "with", "-", "recursive", "-", "regressionfigure"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["However", ",", "we", "propose", "a", "deep", "learning", "based", "approach", "for", "RV", "segmentation", ",", "aiming", "better", "generalization", "and", "usability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["Particularly", ",", "the", "case", "of", "is", "dangerous", "because", "the", "function", "approaches", "0-strong", "convexity", "as", "increases", ",", "so", "the", "power", "IB", "Lagrangian", "performs", "poorly", "when", "low", "are", "used", "to", "find", "high", "performances", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["A", "neural", "network", "that", "predicts", "the", "binding", "status", "of", "constraints", "of", "the", "system", "is", "used", "to", "generate", "an", "initial", "reduced", "OPF", "problem", ",", "defined", "by", "removing", "the", "predicted", "non", "-", "binding", "constraints", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["&", "ECS", "-", "DBN", "&", "9977.39", "148.55", "&", "1280.28", "ADASYN", "-", "DBN", "&", "12697.79", "1287.39", "&", "4000.68", "SMOTE", "-", "DBN", "&", "13992.46", "1772.37", "&", "5295.35", "SMOTE", "-", "borderline1-DBN", "&", "14031.35", "1135.55", "&", "5334.24", "SMOTE", "-", "borderline2-DBN", "&", "14310.19", "764.11", "&", "5613.08", "SMOTE", "-", "SVM", "-", "DBN", "&", "20942.94", "6609.65", "&", "12245.83", "DBN", "&", "8697.11", "8308.22", "&", "-", "ConclusionIn", "this", "paper", ",", "an", "evolutionary", "cost", "-", "sensitive", "deep", "belief", "network", "(", "ECS", "-", "DBN", ")", "is", "proposed", "for", "imbalanced", "classification", "problem", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Packets", "are", "fragmented", "if", "necessary", "and", "queued", "for", "transmission", "on", "a", "NIC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "network interface card"}, {"tokens": ["The", "above", "proposals", "on", "what", "to", "teach", "are", "extremely", "relevant", "for", "IS", "practitioners", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information systems"}, {"tokens": ["This", "is", "because", "the", "larger", "targets", "can", "be", "found", "with", "relative", "ease", "in", "a", "large", "image", ",", "even", "when", "it", "is", "presented", "subsampled", "on", "a", "SDD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "standard desktop display"}, {"tokens": ["preformanceThe", "MINT", "-", "FEC", "goal", "is", "to", "improve", "on", "uavFEC", "(", "Section", "sec", ":", "uavFEC", ")", "to", "ensure", "an", "even", "higher", "perceived", "QoE", "for", "end", "-", "users", ",", "while", "avoiding", "unnecessary", "network", "overhead", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["also", "used", "this", "weighted", "SBM", "to", "clarify", "the", "meaning", "of", "zeros", "in", "valued", "graphs", ",", "as", "they", "could", "mean", "a", "non", "-", "edge", ",", "an", "edge", "with", "weight", "zero", ",", "or", "missing", "data", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Furthermore", ",", "also", "uses", "TS", "as", "the", "calibration", "technique", ",", "and", "proposes", "a", "method", "for", "re", "-", "calibrating", "outputs", "in", "regression", "problems", ";", "which", "manifest", "the", "interest", "and", "power", "of", "developing", "techniques", "that", "aim", "at", "re", "-", "calibrating", "outputs", "of", "a", "model", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature scaling"}, {"tokens": ["GPS", "does", "n't", "work", "in", "indoor", "environments", "because", "of", "the", "low", "signal", "received", "inside", "the", "buildings", "(", "obstacles", "such", "as", "concrete", ",", "block", "the", "GPS", "signal", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Number", "of", "words", "before", "and", "after", "removing", "words", "appearing", "in", "not", "greater", "than", "10", "documents", "in", "the", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["The", "proposed", "OLS", "-", "based", "classificationThe", "recent", "work", "in", "demonstrates", "that", "operating", "SRC", "in", "a", "class", "-", "wise", "manner", "can", "significantly", "improve", "the", "classification", "performance", "of", "SRC", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["Multiple", "description", "quantizersFor", "quantization", "-", "based", "MDC", "methods"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0], "long_form": "multiple description coding"}, {"tokens": ["We", "also", "evaluate", "how", "well", "our", "model", "is", "performing", "for", "individual", "patients", ";", "our", "model", "exhibits", "relative", "increase", "in", "patient", "-", "wise", "accuracy", "on", "the", "SC", "-", "task", "and", "increase", "on", "the", "RS", "-", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subset compared"}, {"tokens": ["In", "the", "case", "of", "the", "regular", "ring", "algorithm", ",", "its", "value", "depends", "on", "the", "process", "only", ",", "however", "for", "PRR", "it", "also", "regards", "the", "pre", "-", "steps", "performed", "by", "the", "involved", "processes", "(", "line", ":", "14", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pre - reduced ring"}, {"tokens": ["The", "3D", "DPN26", "Faster", "R", "-", "CNN", "using", "only", "14", "of", "the", "parameters", "preforms", "better", "than", "the", "3D", "Res18", "Faster", "R", "-", "CNN", ",", "which", "demonstrates", "the", "superior", "suitability", "of", "the", "3D", "DPN", "for", "detection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "dual path network"}, {"tokens": ["Due", "to", "the", "distance", "between", "unlabeled", "SAR", "images", "reconstruction", "task", "and", "the", "OpenSARship", "recognition", ",", "the", "transferability", "of", "features", "in", "decreases", "to", "be", "specific", "just", "in", "layer", "2", "while", "the", "MSTAR", "recognition", "task", "much", "more", "similar", "with", "our", "target", "task", "results", "in", "more", "general", "features", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Furthermore", ",", "in", "this", "case", ",", "the", "CF", "approach", ",", "which", "analyzes", "the", "18,593", "interactions", "between", "users", "and", "services", "in", "a", "personalized", "manner", ",", "provides", "better", "results", "than", "MP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Therefore", "they", "constitute", "highly", "scalable", "solutions", "that", "can", "be", "easily", "implemented", "in", "the", "next", "generation", "networks", ",", "e.g.", ",", "LTE", "Release", "13", "and", "onward", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["By", "Corollary", ",", "the", "conditioned", "min", "-", "entropy", "of", "RV", "over", "measured", "to", "be", "Correctness", "with", "Regardless", "Computational", "PowerWe", "are", "here", "to", "discuss", "the", "correctness", "of", "in", "recovering", "from", "a", "sketch", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["This", "poorer", "performance", "in", "the", "SP", "experiments", "challenges", "the", "narrative", "in", "the", "deep", "learning", "literature", "that", "LSTMs", "solve", "the", "problem", "of", "learning", "long", "-", "term", "dependencies", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Many", "different", "SRL", "approaches", "have", "been", "proposed", "(", "see", "for", "a", "review", ")", ",", "but", "comparing", "their", "performances", "is", "challenging", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["A", "simple", "form", "of", "RNN", "which", "contains", "an", "ANN", "with", "the", "previous", "set", "of", "hidden", "unit", "activations", "feeding", "back", "into", "the", "network", "along", "with", "the", "inputs", "is", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Related", "workThere", "are", "numerous", "interactions", "between", "SRL", "and", "NLP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "statistical relational learning"}, {"tokens": ["Mean", "ROC", "curves", "with", "95", "confidence", "intervals", "for", "the", "perfusion", "-", "supervoxel", "classification", "(", "blue", ")", "and", "the", "entire", "pieces", "-", "of", "-", "parts", "method", "(", "red", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["generate", "a", "set", "of", "QA", "pairs", "given", "a", "KB", "entity", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Given", "that", "the", "number", "of", "global", "iterations", "is", "in", "sys1eq5_1", ",", "the", "total", "energy", "consumption", "of", "all", "users", "that", "participate", "in", "FL", "will", "be:-.5em-2emAsynchronous", "implementation", "for", "the", "FL", "algorithm.-2emHereinafter", ",", "the", "total", "time", "needed", "for", "completing", "the", "execution", "of", "the", "FL", "algorithm", "is", "called", "completion", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Thus", ",", "we", "carry", "out", "both", "adversarial", "training", "and", "ARD", "with", "FGSM", "-", "based", "PGD", "attacks", "similarly", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["*", "uahara-", "MP", "wahar", "NP", "bahar", "'", "spring'PIr"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["The", "cover", "complexity", "(", "CC", ")", "is", "The", "CD", "is", "defined", "as", "the", "difference", "between", "the", "mean", "of", "SC", "and", "the", "mean", "of", "MC", ",", "since", "each", "category", "occurs", "with", "the", "same", "probability", "(", ")", "in", "the", "data", "sets", "mostly", "used", "in", "practice", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "self cover"}, {"tokens": ["Cognitive", "Management", ",", "Bandwidth", "Allocation", "Model", ",", "Case", "-", "Based", "Reasoning", ",", "Resource", "Allocation", ",", "MAM", ",", "RDM", ",", "ATCS", ",", "GBAM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "russian dolls model"}, {"tokens": ["So", ",", "the", "achieved", "SC", "of", "the", "proposed", "scheme", "is", "significantly", "higher", "than", "other", "techniques", "due", "to", "the", "increasing", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["A", "decentralized", "approach", "using", "a", "non", "-", "cooperative", "CSG", "is", "proposed", "in", "which", "the", "nodes", "employ", "the", "MC", "and", "the", "SV", "cost", "sharing", "schemes", "for", "minimization", "of", "network", "power", "in", "incentive", "-", "independent", "networks", "and", "social", "cost", "in", "incentive", "-", "mandatory", "networks", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cost sharing game"}, {"tokens": ["Last", "but", "not", "the", "least", ",", "we", "found", "that", "back", "-", "translation", ",", "which", "has", "been", "applied", "on", "text", "QA", "to", "improve", "the", "performance", "of", "models", ",", "also", "improve", "the", "SQA", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["It", "is", "obvious", "that", "ECS", "-", "DBN", "consumes", "less", "average", "computational", "time", "than", "other", "competing", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "addition", ",", "the", "distribution", "of", "the", "width", "of", "the", "ICC", "95", "confidence", "intervals", "is", "assessed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["(", "b", ")", "Ienco", "model", "(", ")", "DiscussionOperational", "deep", "learning", "framework", "for", "RS", "imagesOur", "first", "goal", "was", "to", "provide", "a", "generic", "DL", "framework", "for", "RS", "images", "processing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["These", "BQ", "are", "the", "output", "of", "Module", "1", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["To", "capture", "natural", "in", "-", "home", "interactions", ",", "the", "SAR", "system", "was", "fully", "autonomous", "and", "could", "be", "turned", "on", "and", "off", "whenever", "the", "family", "desired", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["With", "upscatter", "partitioning", ",", "each", "downscatter", "-", "only", "group", "is", "solved", "with", "GS", "-", "which", "is", "a", "one", "-", "group", "-", "sized", "Krylov", "solve", "and", "converges", "the", "group", "on", "the", "first", "multigroup", "iteration", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gauss seidel"}, {"tokens": ["Moreover", ",", "those", "methods", "of", "transferring", "among", "natural", "images", "are", "probably", "not", "applicable", "in", "SAR", "targets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Brown", "corpus", "is", "sampled", "from", "a", "wide", "variety", "of", "different", "types", "of", "sources", "such", "as", "novels", ",", "news", ",", "editorials", ",", "reviews", "and", "many", "more", ";", "while", "the", "LSC", "is", "sampled", "from", "scientific", "abstracts", "and", "proceeding", "papers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["There", "are", "two", "general", "types", "of", "classifiers", "depending", "on", "architecture", "which", "are", "BP", "-", "DBNs", "and", "Associate", "Memory", "DBNs", "(", "AM", "-", "DBN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "deep belief network"}, {"tokens": ["A", "DMP", "executed", "on", "the", "Arm", "-", "Ball", "environment", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic movement primitives"}, {"tokens": ["We", "claim", "that", "the", "BQ", "can", "help", "Module", "2", "get", "the", "correct", "answer", "to", "increase", "the", "VQA", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["For", "a", "threshold", ",", "the", "GMM", "distribution", ",", "using", "Theorem", ",", "predicts", "a", "false", "alarm", "rate", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Then", ",", "As", "we", "see", ",", "by", "the", "upper", "bound", "on", "the", "IB", "Lagrangian", "from", "Equation", "(", ")", ",", "if", "the", "point", "exists", ",", "any", "can", "be", "the", "slope", "of", "the", "tangent", "line", "to", "that", "ensures", "concavity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Cell", "AssociationWe", "consider", "the", "following", "cell", "association", "rule", ":", "The", "typical", "UE", "is", "associated", "with", "the", "strongest", "BS", "in", "terms", "of", "long", "-", "term", "averaged", "received", "power", "at", "the", "typical", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["This", "suggests", "that", "ECS", "-", "DBN", "could", "provide", "lesser", "variance", "in", "predictions", "so", "as", "to", "enhance", "the", "stability", "of", "the", "diagnostic", "module", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["For", "DE", "we", "use", "the", "innermost", "hidden", "layer", "values", "from", "AE", "to", "estimate", "dimension", "and", "hence", "we", "do", "not", "use", "activation", "function", "in", "the", "innermost", "hidden", "layer", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["In", "the", "(", ")", "-th", "(", ")", "phase", "with", "allocated", "time", ",", "after", "having", "successfully", "decoded", "the", "messages", "in", "the", "last", "phases", ",", "MTCGs", "in", "simultaneously", "transmit", "the", "gathered", "data", "to", "the", "BS", "based", "on", "the", "NOMA", "principle", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["All", "predicted", "bounding", "boxes", "are", "listed", "in", "a", "table", "with", "their", "respective", "validity", "(", "TP", ",", "FP", ",", "FN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["Thus", ",", "in", "contrast", "tosimpler", "problems", "such", "as", "GP", "regression", "or", "classification", ",", "it", "is", "impossible", "to", "reduce", "inference", "to", "finite", "dimensionalintegrals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Thus", ",", "as", "opposed", "to", "CS", ",", "IS", "'s", "primary", "focus", "is", "on", "an", "organization", "\u2019s", "mission", "and", "objectives", "and", "the", "application", "of", "information", "technology", "to", "further", "these", "goals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["OT", "allows", "the", "sender", "to", "send", "the", "receiver", "'s", "selected", "input", "while", "preserving", "the", "secrecy", "of", "the", "sender", "'s", "other", "inputs", "on", "the", "one", "hand", "and", "the", "choice", "of", "the", "receiver", "on", "the", "other", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["So", ",", "the", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "provides", "comparatively", "lower", "SC", "w.r.t", "than", "the", "proposed", "scheme", "which", "is", "illustrated", "in", "Figure", "6", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["tab", ":", "real_data_results", "shows", "the", "results", "for", "the", "mean", "squared", "error", "between", "the", "conditional", "expectation", "curve", "and", "the", "DAC", "/", "PDP", "curves", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "partial dependence plots"}, {"tokens": ["Even", "though", "CNNs", "are", "exceptional", "in", "their", "ability", "to", "adapt", "to", "various", "input", "representations", ",", "co", "-", "optimization", "of", "the", "ISP", "and", "network", "architecture", "may", "also", "enable", "reduction", "in", "the", "size", "of", "the", "CNN", "model", "at", "the", "same", "prediction", "accuracy", ",", "again", "reducing", "latency", "and", "energy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["As", "the", "order", "of", "send", "actions", "in", "the", "labels", "of", "an", "AML", "semantic", "model", "are", "the", "same", "as", "the", "order", "of", "their", "corresponding", "send", "statements", ",", "we", "implement", "this", "property", "during", "the", "construction", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["Wilcoxon", "Paired", "Signed", "-", "Rank", "TestIn", "order", "to", "substantiate", "whether", "the", "results", "of", "ECS", "-", "DBN", "and", "other", "kinds", "of", "imbalance", "learning", "methods", "differ", "in", "a", "statistically", "significant", "way", ",", "a", "nonparametric", "statistical", "test", "known", "as", "Wilcoxon", "paired", "signed", "-", "rank", "test", "is", "conducted", "at", "the", "5", "significance", "level", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["NP", "suru(dan)/sarayPIr", "*", "crauni-"], "acronym_pos": [1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["BA", "stands", "for", "balanced", "accuracy", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "balanced accuracy"}, {"tokens": ["We", "define", "the", "claimed", "MD", "strategy", "for", "all", "with", "to", "be", "the", "MD", "strategy", "from", "Lemma", "reachp", "-", "opt", "-", "max", "for", "and", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["First", ",", "a", "new", "class", "of", "repair", "-", "by", "-", "transfer", "codes", "are", "proposed", "at", "MBR", "points", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Pose", "estimation", "results", "of", "two", "different", "versions", ":", "CorrNet", "and", "CorrNet", "w/o", "CC", "on", "the", "LineMOD", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "correlation constraints"}, {"tokens": ["Rebuild", "processing", "can", "be", "parallelized", "with", "the", "CD", ",", "ID", ",", "and", "GRD", "RAID1", "organizations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "group rotate declustering"}, {"tokens": ["Because", "in", "case", "of", "TS", "based", "SWIPT", ",", "there", "is", "no", "impact", "of", "[", "22].", "Because", "is", "only", "used", "for", "energy", "harvesting", "for", "PS", "based", "SWIPT", "protocols", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["It", "is", "also", "shown", "that", ",", "the", "CI", "based", "acoustic", "representation", "within", "the", "i", "-", "Vector", "based", "speaker", "ID", "system", "is", "more", "successful", "(", "98", ")", "vs.", "the", "GMM", "-", "UBM", "based", "system", "(", "94", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Denote", "the", "channel", "between", "MTCG", "and", "the", "BS", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "base station"}, {"tokens": ["de", "erros", "(", "FEC", ")", ";", "FEC", "orientado", "ao", "v\u00eddeo", ";", "Qualidade", "de", "experi\u00eancia", "(", "QoE", ")", ";", "Concep\u00e7\u00e3o", "cross", "-", "layer", ";", "Prote\u00e7\u00e3o", "desigual", "dos", "dados"], "acronym_pos": [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Their", "QA", "system", "includes", "tasks", "of", "named", "entity", "tagging", ",", "question", "classification", ",", "information", "retrieval", "and", "answer", "extraction", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["ii", ")", "Being", "both", "efficient", "and", "effective", ",", "PNN", "outperforms", "major", "state", "-", "of", "-", "the", "-", "art", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["As", "for", "RS", "-", "based", "transmission", ",", "the", "gains", "from", "RS", "diminish", "as", "increases", ";", "the", "smaller", "the", ",", "the", "greater", "the", "gain", "from", "relaying", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["As", "a", "result", ",", "denoting", "the", "number", "of", "BS", "antennas", "and", "RIS", "elements", "(", "reflecting", "meta", "-", "surfaces", ")", "by", "and", ",", "respectively", ",", "the", "received", "signal", "at", "user", "can", "be", "expressed", "aswhere", "is", "the", "precoded", "data", "vector", ",", "is", "the", "matrix", "of", "channel", "coefficients", "of", "the", "BS", "-", "RIS", "link", ",", "is", "the", "vector", "of", "channel", "coefficients", "between", "the", "RIS", "and", "user", ",", "and", "is", "the", "AWGN", "sample", "at", "this", "user", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "anomaly", "score", "for", "each", "test", "query", "is", "computed", "as", ",", "where", "is", "the", "number", "of", "fitted", "GMMs", "and", "is", "the", "density", "assigned", "by", "GMM", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["In", "WMD", ",", "we", "use", "word", "embeddings", "to", "capture", "word", "level", "semantics", "and", "FS", "helps", "us", "to", "capture", "sentence", "level", "semantics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "frame semantic"}, {"tokens": ["It", "turns", "out", "that", "this", "approach", "has", "a", "limited", "resolution", "on", "the", "standard", "SBM", ":", "the", "maximum", "number", "of", "blocks", "that", "can", "be", "resolved", "scales", "as", "for", "a", "fixed", "average", "degree", ",", "where", "is", "the", "number", "of", "vertices", "of", "the", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "SL", "and", "SP", "classes", "are", "among", "the", "simplest", "in", "a", "mathematically", "well", "-", "understood", "hierarchy", "of", "subregular", "classes", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["However", ",", "these", "differences", "are", "not", "significant", "and", "the", "classifiers", "with", "AF", "features", "removed", "still", "perform", "at", "least", "as", "well", "as", "the", "GP", "and", "HP", "baselines", "(", "for", "the", "event", "type", "Ferguson", "riots", ")", ",", "or", "outperform", "the", "baselines", "(", "for", "all", "other", "event", "types", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "hawkes processes"}, {"tokens": ["typically", "converges", "more", "quickly", "than", "PI", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0], "long_form": "power iteration"}, {"tokens": ["MCC", "can", "be", "used", "for", "problems", "with", "uneven", "class", "sizes", "and", "is", "still", "considered", "a", "balanced", "measure", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["DMD", "is", "a", "generalization", "of", "mirror", "descent", "beck2003mirror", "to", "problems", "involving", "dynamic", "comparators", "(", "in", "this", "case", ",", "the", "in", "dynamic", "regret", "in", "eq", ":", "dynamic", "regret", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["NP", "-is", ";", "cf", "."], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Afterwards", ",", "the", "FEC", "blocks", "are", "built", "using", "the", "original", "frame", "and", "the", "redundancy", "(", "10", ")", "and", "then", "the", "blocks", "are", "sent", "(", "11", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["We", "show", "that", "previous", "GANs", "change", "the", "data", "far", "more", "than", "necessary", "because", "they", "match", "data", "distributions", "and", "not", "manifolds", ",", "while", "the", "MGM", "GAN", "truly", "aligns", "manifolds", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["Results", "for", "the", "exponential", "IB", "Lagrangian", "in", "the", "Fashion", "MNIST", "dataset", "with", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["PIr", "*", "PIr", "*", "changes", "into", "OP", "(", "MP", ",", "NP", "h", ")", "in", "most", "conditioning", "environments", ",", "though", "it", "may", "develop", "into", "MP", "word", "-", "initially", ",", "e.g.", ",", "PIr", "*", "axta-"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["gun_drilling_results_all_metric_byalg_cmp_others.eps", "Illustration", "of", "the", "performance", "between", "different", "machine", "learning", "algorithms", ",", "i.e.", "DBN", "and", "SVM", ",", "MLP", ",", "KNN", ",", "GB", ",", "LR", ",", "AdaBoost", ",", "Lasso", ",", "and", "SGD", ",", "on", "gun", "drilling", "imbalanced", "dataset", "in", "terms", "of", "accuracy", ",", "G", "-", "Mean", ",", "AUC", ",", "precision", ",", "F1-score", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Like", "AP", ",", "after", "every", "iteration", "we", "check", "for", "the", "sum", "of", "all", "incoming", "messages", "to", ",", "i.e.", ",", ",", "for", "convergence", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["Two", "solutions", "and", "have", "been", "evaluated", "and", "inserted", "into", "the", "BSP", "tree", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["where", "basis", "pursuit", "denoising", "(", "BPD", ")", "was", "used", "to", "exploit", "sparse", "features", "in", "various", "domains", "to", "detect", "faults", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basis pursuit denoising"}, {"tokens": ["The", "model", "maps", "the", "input", "HR", "intensity", "image", "(", "xx", ")", "to", "the", "latent", "space", "and", "generates", "a", "-dim", "representation", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["In", "this", "example", ",", "the", "token", "\"", "interferes", "\"", "is", "tagged", "by", "VBZ", "as", "its", "POS", "tag", "which", "indicates", "that", "it", "is", "a", "form", "of", "a", "verb", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Ideally", ",", "the", "AN", "is", "generated", "to", "be", "in", "the", "null", "space", "of", "node", "'s", "receiving", "channel", ",", "and", "thus", ",", "does", "not", "affect", "but", "degrades", "the", "receivers", "'", "channels", "Negi", ":", "TWC:2008", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["They", "are", "the", "first", "metrics", "that", "explicitly", "target", "syntactic", "aspects", "of", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "target syntactic"}, {"tokens": ["Robustness", "of", "RS", "in", "FD", "systems?-ComparisonsThe", "metric", ",", "we", "employ", ",", "to", "shed", "light", "on", "this", "meaningful", "question", "is", "the", "theoretical", "DE", "sum", "-", "rate", "and", "the", "corresponding", "Monte", "Carlo", "simulation", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["WM", "Age", "Estimator", ";", "[", "block3", ",", "below", "left", "of", "=", "f", ",", "node", "distance", "=", "1.5", "cm", "]", "(", "om", ")", "BF", "Age", "Estimator", ";", "[", "block3", ",", "below", "right", "of", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "black females"}, {"tokens": ["The", "saturated", "condition", "means", "that", "both", "the", "AP", "and", "STAs", "always", "have", "frames", "to", "transmit", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["[", "b]Left", ":", "speedups", "of", "IA", "on", "GMB", "on", "unweighted", "synthetic", "graphs", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "incremental approximation"}, {"tokens": ["ID", "-", "Interleaved", "Declustering", "."], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["one", "of", "the", "D2D", "UEs", "is", "connected", "to", "a", "BS", "or", "Access", "Point", "and", "provides", "access", "to", "another", "D2D", "UE", ".."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["The", "Benamou", "-", "Brenier", "form", "of", "this", "metric", "of", "order", "involves", "solving", "a", "smoothy", "OT", "problem", "over", "any", "probabilities", "and", "in", "using", "the", "continuity", "equation", "showed", "in", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Wireless", "Transmission-.5emAfter", "local", "computation", ",", "all", "users", "upload", "their", "local", "FL", "parameters", "to", "the", "BS", "via", "frequency", "domain", "multiple", "access", "(", "FDMA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["When", "the", "MR", "of", "all", "ROIs", "were", "calculated", ",", "we", "focused", "on", "two", "sub", "-", "measurements", "to", "provide", "a", "better", "inference", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "morphological richness"}, {"tokens": ["Below", "we", "present", "an", "OT", "functionality", "parameterized", "using", "three", "parameters", "that", "denotes", "the", "string", "length", "of", "the", "sender", "'s", "inputs", ",", "that", "refers", "to", "-out", "-", "of-", "OTs", "and", "that", "denotes", "the", "number", "of", "instances", "of", "the", "OTs", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "LR", "model", ",", "for", "binary", "classification", "tasks", ",", "computes", "the", "probability", "of", "the", "target", "to", "be", "1", "(", "readmission", "risk", ")", ",", "given", "the", "input", "variables", ",", "as", ":", "equation", "eqn", ":", "lr", "p(y"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["This", "dataset", "is", "to", "highlight", "the", "advantage", "of", "DDE", "-", "MGM", "in", "robustness", "to", "length", "variation", "and", "misalignment", "of", "the", "time", "series", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["For", "each", "of", "the", "45", "functions", "we", "establish", "the", "baseline", "performance", "of", "DE", "without", "meta", "model", "by", "running", "it", "with", "a", "budget", "of", "evaluations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Fortunately", ",", "the", "DMP", "co", "-", "processor", "of", "the", "MPU6050", "already", "implements", "these", "features", "very", "efficiently", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "digital motion processor"}, {"tokens": ["Related", "WorkFrom", "a", "list", "of", "classical", "methods", "to", "improve", "calibration", "(", "such", "as", "Histogram", "Binning", ",", "Isotonic", "Regression", ",", "Platt", "Scaling", ",", "Bayesian", "Binning", "into", "Quantiles", ")", ";", "TS", "has", "been", "reported", "as", "one", "of", "the", "best", "techniques", "for", "the", "computer", "vision", "tasks", "of", "interest", "in", "our", "current", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature scaling"}, {"tokens": ["In", "what", "follows", "we", "briefly", "survey", "previous", "reflections", "on", "the", "content", "of", "logic", "and", "formal", "methods", "courses", "that", "practitioners", "really", "need", "and", "their", "integration", "into", "the", "curricula", ",", "and", "propose", "how", "to", "adapt", "the", "proposed", "ideas", "for", "the", "context", "of", "IS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "information systems"}, {"tokens": ["ConclusionIn", "our", "work", ",", "we", "proposed", "an", "optimum", "PA", "strategy", "of", "maximizing", "SR", "in", "secure", "DM", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["Figure", "presents", "the", "ROC", "curve", "in", "respect", "of", "PAC", "and", "MI", "class", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["This", "section", "presents", "the", "DE", "of", "the", "user", "rate", "during", "the", "data", "transmission", "with", "RS", "in", "the", "second", "link", ",", "which", "takes", "place", "for", "time", "slots", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["It", "is", "dominated", "by", "the", "social", "circle", "stability", "(", "CNS", ":", ",", "MDC", ":", ")", "and", "the", "activity", "space", "stability", "(", "CNS", ":", ",", "MDC", ":", ")", "for", "both", "datasets", "(", "see", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["There", "should", "be", "an", "alternate", "solution", "for", "indoor", "navigation", "instead", "of", "using", "GPS", "like", "outdoor", "navigation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["These", "convergence", "guarantees", "of", "NCE", "are", "not", "affected", "by", "choice", "of", "distributions", "and", "(", "see", ",", "Corollary", "5", ")", ";", "however", ",", "its", "performance", "is", "empirically", "dependent", "on", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "noise contrastive estimation"}, {"tokens": ["In", "his", "paper", ",", "Spohrer", "also", "envisions", "possible", "application", "cases", "for", "mobile", "AR", ",", "and", "social", "implications", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["The", "gap", "is", "much", "smaller", "for", "AP", "at", "IOU=0.5", "which", "is", "about", "10", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Therefore", ",", "both", "papers", "introduce", "an", "alternative", "called", "the", "RT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "reparameterization trick"}, {"tokens": ["07-steinberger", "-", "al", "incorporate", "AR", "into", "a", "more", "complex", "scoring", "method", "(", "LSA", "representation", ")", "to", "improve", "its", "performance", "even", "with", "an", "imperfect", "anaphoric", "resolver", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "anaphora resolution"}, {"tokens": ["This", "further", "motivates", "our", "work", "of", "creating", "a", "new", "large", "scale", "AS2", "dataset", ",", "ASNQ", ",", "which", "is", "two", "orders", "of", "magnitudes", "larger", "than", "datasets", "such", "as", "TREC", "-", "QA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "question answering"}, {"tokens": ["Usually", ",", "the", "BPM", "languages", "conform", "to", "graphical", "notations", "(", "e.g.", ",", "BPMN", ",", "EPC", ",", "ARIS", ")", ",", "targeted", "to", "human", "comprehension", "rather", "than", "computational", "ends", "(", "process", "design", "/", "modelling", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "business process modelling"}, {"tokens": ["Therefore", ",", "our", "approach", "is", "applicable", "as", "long", "as", "the", "length", "of", "the", "CC", "phase", "is", "higher", "than", "zero", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "constant current"}, {"tokens": ["The", "main", "contributions", "of", "this", "paper", "are", "three", "-", "fold", ":", "Considering", "the", "fractal", "characteristic", "of", "cellular", "coverage", ",", "the", "anisotropic", "path", "loss", "model", "is", "proposed", "to", "analyze", "the", "SBS", "cooperation", "performance", "of", "random", "small", "-", "cell", "networks;Based", "on", "the", "anisotropic", "path", "loss", "model", ",", "the", "average", "achievable", "rates", "of", "the", "SBS", "cooperation", "strategies", "with", "distance", "and", "received", "signal", "power", "constraints", "are", "derived", "for", "fractal", "small", "-", "cell", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["Formally", ",", "we", "denote", "the", "dataset", "for", "CF", "as", "and", "an", "observation", "is", "denoted", "as", ",", "where", "is", "a", "feature", "vector", "containing", "the", "attributes", "from", "the", "user", "and", "the", "publisher", "and", "is", "the", "binary", "label", "indicating", "whether", "the", "user", "visits", "the", "publisher", "or", "not", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["the", "base", "grid", "mesh", "is", "going", "to", "be", "displaced", "accordingly", "to", "the", "heightmap", "in", "the", "Vertex", "Shader", ",", "the", "base", "grid", "mesh", "geometry", "is", "going", "to", "be", "refined", "with", "TS", "based", "on", "visibility", ",", "the", "terrain", "is", "rasterized", ",", "once", "we", "have", "the", "terrain", "curvature", ",", "in", "the", "FS", ",", "lighting", "and", "color", "blending", "are", "going", "to", "be", "applied", ",", "the", "terrain", "is", "rendered", ",", "through", "user", "interaction", "the", "LOD", "is", "going", "to", "be", "dynamically", "applied", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fragment shader"}, {"tokens": ["Fraudulent", "Services", "(", "FS", ")", "Domains", "and", "IP", "addresses", "engaged", "in", "the", "distribution", "or", "provisioning", "of", "bogus", "or", "fraudulent", "services", "or", "applications", "such", "as", "the", "promotion", "of", "comments", ",", "likes", ",", "ratings", ",", "votes", "or", "any", "variations", "thereof", "de2014paying", ",", "Ikram:2017:MCD", ",", "farooqicharacterizing", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fraudulent services"}, {"tokens": ["To", "summarize", ",", "in", "this", "work", "we", ":", "propose", "a", "selection", "method", ",", "based", "on", "modeling", "image", "representations", "with", "a", "GMM", ",", "for", "finding", "visually", "similar", "images", "to", "a", "given", "dataset", ",", "propose", "a", "selection", "method", ",", "based", "on", "class", "scoring", "heuristics", ",", "for", "finding", "rich", "labeled", "images", ",", "apply", "both", "methods", "independently", "and", "jointly", "in", "weak", "supervision", "selection", "for", "semantic", "segmentation", "to", "reduce", "the", "amount", "of", "required", "training", "examples", "while", "increasing", "performance", ",", "and", "present", "results", "towards", "characterizing", "the", "image", "domain", "of", "a", "dataset", "through", "GMM", "modeling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["This", "indicates", "that", "OEC", "does", "not", "produce", "a", "good", "model", "of", "the", "data", "which", "matches", "the", "visual", "assessment", "of", "the", "clusters", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["Following", "the", "RS", "principles", ",", "we", "have", "to", "evaluate", "the", "SINRs", "of", "both", "common", "and", "private", "messages", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["was", "the", "first", "to", "use", "convolutional", "neural", "networks", "to", "learn", "the", "mapping", "between", "ZF", "and", "FS", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "fully sampled"}, {"tokens": ["DE", ",", "GSA", ",", "and", "ABC", "have", "been", "shown", "as", "promising", "evolutionary", "tools", "for", "finding", "global", "optima", "for", "a", "variety", "of", "optimization", "problems", "with", "large", "search", "space", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Furthermore", ",", "the", "influence", "of", "different", "time", "scales", "and", "GMM", "components", "are", "analyzed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["There", "are", "other", "types", "of", "recommender", "systems", ",", "usually", "derivations", "or", "hybrids", "of", "content", "-", "based", "and", "CF", "based", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Based", "on", "the", "probability", "estimation", ",", "the", "trained", "DBN", "classifier", "is", "naturally", "given", "predictions", "as", "In", "practical", ",", "the", "parameters", "of", "DBN", "are", "massively", "optimized", "by", "statistic", "gradient", "descent", "with", "respect", "to", "the", "negative", "log", "-", "likelihood", "loss", "function", "over", "the", "training", "set", "with", "the", "number", "of", "data", "sample", "pairs", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["There", "are", "three", "types", "of", "MRI", "scans", "that", "were", "collected", "from", "the", "subjects", ":", "(", "1", ")", "FA", ",", "the", "fractional", "anisotropy", "MRI", "gives", "information", "about", "the", "shape", "of", "the", "diffusion", "tensor", "at", "each", "voxel", ",", "which", "reflects", "the", "differences", "between", "an", "isotropic", "diffusion", "and", "a", "linear", "diffusion", ";", "(", "2", ")", "FLAIR", ",", "Fluid", "attenuated", "inversion", "recovery", "is", "a", "pulse", "sequence", "used", "in", "MRI", ",", "which", "uncovers", "the", "white", "matter", "hyperintensity", "of", "the", "brain", ";", "(", "3", ")", "GRAY", ",", "gray", "MRI", "images", "revealing", "the", "gray", "matter", "of", "the", "brain", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fractional anisotropy"}, {"tokens": ["PI", "allocations", "contribute", "to", "the", "size", "of", "the", "global", "routing", "tables", "as", "they", "can", "not", "be", "aggregated", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider independent"}, {"tokens": ["In", "this", "section", ",", "we", "compare", "the", "performance", "of", "the", "proposed", "method", "with", "state", "-", "of", "-", "the", "-", "art", "FER", "methods", "on", "the", "CK+", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["The", "channels", "from", "the", "AP", "to", "the", "th", "vehicle", "and", "the", "eavesdropper", "are", "denoted", "as", "and", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Therefore", ",", "to", "obtain", "an", "accurate", "DCNN", "based", "SSR", "approach", ",", "it", "is", "crucial", "to", "adaptively", "determine", "the", "receptive", "field", "size", "and", "the", "RGB", "-", "to", "-", "spectrum", "mapping", "function", "for", "each", "pixel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Furthermore", ",", "it", "is", "known", "that", "RS", "is", "applicable", "in", "multi", "-", "user", "settings", "with", "imperfect", "CSIT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["Note", "that", "ranks", "of", "the", "systems", "were", "obtained", "using", "the", "HJ", ",", "RT", "and", "AE", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "ruthes"}, {"tokens": ["The", "greedy", "search", "in", "BS", "2", "was", "slightly", "more", "likely", "to", "verbatim", "copy", ",", "for", "example", "in", "the", "oil", "image", "where", "it", "obtained", "an", "innovation", "capacity", "of", "as", "opposed", "to", "and", "achieved", "by", "OT", "and", "random", "convolution", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["FAN", "TrainingWe", "combine", "a", "ResNet", "-", "based", "feature", "extractor", ",", "AN", "and", "FN", "into", "one", "network", ",", "as", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["The", "integer", "stabilizes", "these", "incremental", "estimates", "by", "temporarily", "disabling", "the", "OEC", "guard", "zone", "and", "new", "cluster", "detection", "tests", "until", "the", "current", "cluster", "contains", "points", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["For", "the", "RNRF", "strategy", ",", "the", "BS", "randomly", "selects", "a", "near", "user", "and", "a", "far", "user", "from", "the", "two", "groups", "of", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["As", "a", "result", ",", "the", "SC", "is", "enhanced", "for", "the", "CNOMA", "-", "OAM", "scheme", "by", "utilizing", "the", "CNOMA", "and", "OAM", "concept", "effectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["Given", "an", "NCA", ",", "it", "is", "NP", "-", "complete", "to", "check", "whether", "it", "is", "DBP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "determinisable by pruning"}, {"tokens": ["Level", "-", "wise", "error", "for", "TD", "-", "LR", "and", "Global", "-", "INF", "approach", "centering", "Table", "shows", "mean", "and", "(", "standard", "deviation", ")", "of", "error", "rate", "across", "five", "runs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Finally", ",", "the", "number", "of", "GMM", "components", "also", "influences", "the", "predicting", "accuracy", ",", "but", "the", "improvement", "is", "not", "as", "significant", "as", "the", "hierarchical", "structure", "and", "time", "scales", "(", "see", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["For", "the", "sample", "shown", "in", "figure", ",", "despite", "the", "presence", "of", "speckle", "noise", ",", "the", "proposed", "networks", "achieves", "a", "CCR", "of", "99", "while", "HOSVD", "achieves", "a", "lower", "score", "of", "90", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["Proposed", "approachThe", "aim", "of", "this", "work", "is", "to", "go", "further", "from", "solely", "self", "-", "adapting", "the", "parameters", "in", "EAs", "towards", "self", "-", "modifying", "the", "structure", "of", "operators", "using", "GP", "techniques", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Previous", "worksThe", "exact", "regenerating", "codes", "at", "MSR", "and", "MBR", "points", "have", "been", "proposed", "in", "recent", "years", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["We", "train", "layer", "LightCNN", "models", "using", "the", "training", "split", "of", "TinyFace", "dataset", "under", "the", "following", "settings", ":", "[", "]", "[", "h]0.5[h]0.5Verification", "performance", "on", "Tinyface", "dataset", "under", "different", "settings", "(", "a", ")", "LightCNN", "trained", "from", "scratch", "(", "b", ")", "Using", "Inception", "-", "ResNet", "pretrained", "on", "MsCeleb-1MSetting", "L1", ":", "Train", "networks", "on", "generated", "LR", "images", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["The", "original", "OT", "extension", "of", "provides", "security", "against", "a", "malicious", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "model", "can", "be", "described", "by", "the", "following", "equations", ":", "where", ",", ",", ",", ",", "is", "the", "GP", "kernel", "function", ",", "and", "denotes", "a", "generic", "likelihood", "function", "for", "the", "th", "variable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Section", "specializes", "this", "framework", "to", "the", "Logit", "RUM", "model", ",", "equivalent", "to", "the", "\"", "attraction", "demand", "model", "\"", "being", "used", "by", "some", "researchers", "in", "revenue", "management", "(", "e.g.", ",", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random utility maximization"}, {"tokens": ["When", "the", "aim", "is", "not", "to", "draw", "the", "IB", "curve", "but", "to", "find", "a", "specific", "level", "of", "performance", ",", "we", "can", "exploit", "the", "value", "convergence", "phenomenon", "in", "order", "to", "design", "a", "stable", "performance", "targeted", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Hawkes", "Processes", "(", "HP", ")", "reported", "by", "lukasik2016hawkes", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "hawkes processes"}, {"tokens": ["is", "selected", "by", "the", "electricity", "consumer", "as", "a", "PPC", "contract", "with", "the", "utility", "in", "Madeira", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "peak power contract"}, {"tokens": ["A", "highly", "cited", "study", "compared", "seven", "existing", "techniques", ",", "including", "linear", "regression", ",", "ANN", ",", "SVM", "and", "their", "variants", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Fn", "MINT", "-", "FEC", "utilises", "the", "same", "core", "structure", "of", "uavFEC", ",", "so", "once", "all", "the", "fuzzy", "rules", "and", "sets", "are", "defined", ",", "they", "are", "employed", "in", "real", "-", "time", "in", "the", "fuzzy", "logic", "controller", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": [",", "'", "sr", ";", "NP", "ars", ",", "askPIr"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["[", "CC", ",", "100", "runs", ",", "12", "clust", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "connected caveman"}, {"tokens": ["While", "BP", "and", "DTP", "will", "fail", "in", "this", "setting", ",", "DFA", "and", "FA", "will", "not", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["Our", "first", "result", "is", "the", "metric", "of", "correlation", "measure", "between", "the", "RV", "pair", "and", "their", "input", "pair", "(", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["In", ",", "a", "ranking", "method", "in", "ET", "using", "probability", "bounds", "is", "proposed", ",", "but", "this", "method", "can", "not", "distinguish", "fitness", "values", "with", "large", "overlaps", "in", "probability", "bounds", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "evidence theory"}, {"tokens": ["proposed", "a", "new", "hybrid", "chaotic", "PSO", "with", "implicit", "filtering", "(", "HPSO", "-", "IF", ")", "algorithm", "for", "solving", "ELD", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["[", "Top", "]", "CSG", "c", "-", "measure", "alongside", "with", "test", "error", "rates", "for", "3", "CNN", "models", "on", "four", "10-class", "datasets.[Bottom", "]"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["sim_results", "shows", "the", "matches", "between", "the", "DAC", "and", "PDP", "curves", "with", "the", "conditional", "expectation", "curves", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial dependence plots"}, {"tokens": ["In", "random", "vaccination", "(", "RV", ")", ",", "a", "proportion", "of", "neighbour", "nodes", "are", "randomly", "chosen", "for", "vaccination", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["In", "[", "10", "]", ",", "BS", "to", "CEU", "link", "was", "idle", "for", "the", "existing", "HS", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["*", "ciaua-(ka-", ")", "MP", "siyah", "NP", "syah", "'", "black'PIr", "*", "ciaina-(mrga-", ")", "MP", "sen", "murw", "'", "a", "fabulous", "bird", "'", "NP", "simur", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "new persian"}, {"tokens": ["shows", "the", "errorbar", "plot", "comparison", "of", "the", "performance", "between", "ECS", "-", "DBN", "and", "different", "resampling", "methods", "with", "different", "evaluation", "metrics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Given", "the", "maximum", "number", "of", "fitness", "evaluations", "is", ",", "the", "depth", "of", "a", "BSP", "tree", "to", "record", "the", "entire", "search", "history", "is", ",", "where", "represents", "the", "minimum", "integer", "that", "is", "greater", "than", "or", "equal", "to", "the", "real", "number", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["To", "address", "the", "above", "-", "mentioned", "challenges", ",", "we", "propose", "HybridAlpha", ",", "an", "efficient", "approach", "for", "privacy", "-", "preserving", "FL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "federated learning"}, {"tokens": ["The", "first", "challenge", "of", "employing", "Massive", "MIMO", "is", "the", "limited", "space", "at", "the", "AP", ",", "since", "antennas", "are", "required", "to", "be", "placed", "at", "the", "least", "half", "wavelength", "apart", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["We", "designed", "two", "types", "of", "PNN", ":", "IPNN", "based", "on", "inner", "product", "and", "OPNN", "based", "on", "outer", "product", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Also", ",", "each", "UE", "is", "assumed", "to", "measure", "its", "channel", "vectors", "to", "its", "nearest", "RRHs", ",", "i.e.", ",", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "first", "one", ",", "Cross", "-", "FaceResolution", "-", "LF", "-", "Test", ",", "uses", "small", "and", "medium", "faces", "(", "determined", "by", "the", "resolution", ")", "for", "training", ",", "while", "using", "high", "resolution", "faces", "(", "LF", "-", "Large", "Faces", ")", "for", "testing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "large faces"}, {"tokens": ["The", "BS", "can", "estimate", "the", "direction", "of", "arrival", ",", "and", "hence", "the", "direction", "of", "the", "scattering", "objects", "should", "be", "available", "at", "the", "BS", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["OS", "\"", "refers", "to", "the", "output", "stride", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "output stride"}, {"tokens": ["The", "RF", "classifier", "accurately", "predicts", "218", "test", "cases", "as", "TN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "true negative"}, {"tokens": ["In", "this", "paper", ",", "we", "show", "that", "the", "performance", "of", "DE", "and", "CMA", "-", "ES", "are", "highly", "sensitive", "to", "the", "presence", "of", "multiple", "global", "optima", ",", "and", "that", "symmetries", "are", "also", "an", "issue", "on", "the", "performance", "of", "EA", "'s", "without", "crossover", "operators", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["This", "is", "not", "required", "for", "symmetry", "breaking", "approaches", "which", "map", "each", "solution", "cadidate", "exactly", "to", "the", "selected", "partition", ",", "such", "as", "DE", "-", "INV", "-", "SB", "or", "DE", "-", "SB", "-", "BF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Von", "Mises", "DistributionSince", "the", "BS", "is", "assumed", "to", "have", "the", "imperfect", "knowledge", "of", "the", "direction", "angles", "toward", "the", "eavesdroppers", ","], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["End", "-", "to", "-", "End", "TransmissionThis", "section", "presents", "the", "data", "transmission", "and", "the", "uplink", "estimation", "phases", "of", "the", "multipair", "decode", "-", "and", "-", "forward", "FD", "model", "as", "well", "as", "the", "RS", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "rate saturation"}, {"tokens": ["->additional", "-", "module1/additional", "-", "module2,additional", "-", "module2/additional", "-", "module3", "Use", "of", "Multi", "-", "UAV", "Systems", "in", "SAR", "Operations", ",", "Locate", "GPS", "Coordinates", "for", "the", "Missing", "Persons", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["MAM", "disadvantages", "in", "relation", "to", "other", "models", "(", "RDM", "and", "ATCS", ")", "is", "that", "blocking", "rate", "is", "higher", "and", "less", "LSP", "are", "established", "(", "effectively", "the", "unbroken", "ones", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "russian dolls model"}, {"tokens": ["al", "proposed", "a", "new", "hybrid", "approach", "using", "PSO", "for", "steganalysis", "named", "HYBRID", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["ECS", "-", "DBN", "has", "higher", "average", "values", "and", "lower", "variance", "for", "both", "G", "-", "mean", "and", "accuracy", "than", "other", "competing", "methods", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "Tables", "and", ",", "we", "show", "the", "speedup", "results", "comparing", "GPU", "RBP", "and", "RS", "to", "SRBP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["Furthermore", ",", "we", "develop", "a", "free", "adversarial", "training", "variant", "of", "ARD", "and", "demonstrate", "appreciably", "accelerated", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Information", "Botlleneck", "based", "SystemsThis", "section", "briefly", "describes", "the", "IB", "and", "TPIB", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["PSO", "is", "a", "nature", "-", "inspired", "meta", "-", "heuristic", "non", "-", "linear", "stochastic", "optimization", "technique", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Using", "instantaneous", "CSI", "and", "Eq", ":", "g_end_PureRS", ",", "rate", "-", "selective", "RS", "chooses", "between", "direct", "(", "non", "-", "relay", "assisted", ")", "and", "relay", "-", "assisted", "transmission", "based", "on", "the", "following", "criterionAs", "shown", "in", ",", "the", "MGF", "of", "can", "be", "obtained", "using", "the", "of", "pure", "RS", "aswhere", "is", "a", "RV", "with", "CDF", "given", "by", "which", "can", "be", "obtained", "using", "inverse", "sampling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random variable"}, {"tokens": ["As", "implied", "by", "the", "GDP", "guarantee", ",", "event", "holds", "with", "probability", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["After", "a", "certain", "value", "of", "the", "SI", ",", "this", "property", "of", "RS", "degrades", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "relay station"}, {"tokens": ["It", "is", "with", "clear", "advantage", "to", "employ", "a", "higher", "number", "of", "antennas", "at", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["The", "MGM", "GAN", "aligned", "the", "samples", "such", "that", "the", "significant", "instrument", "error", "in"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["The", "filterbank", "for", "LS", "and", "LM", "has", "a", "linear", "response", "(", "and", "lower", "resolution", ")", "for", "the", "lower", "frequencies", ",", "and", "a", "logarithmic", "response", "for", "the", "higher", "frequencies", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logarithmically spaced"}, {"tokens": ["The", "assigned", "scores", "demonstrate", "that", "our", "DisSim", "approach", "outperforms", "all", "other", "TS", "systems", "in", "the", "S", "dimension", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["The", "global", "loss", "is", "defined", "as", "the", "Euclidean", "distance", "between", "the", "codes", "generated", "from", "the", "synthesised", "and", "ground", "-", "truth", "HR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "high - resolution"}, {"tokens": ["Throughout", "this", "paper", "we", "use", "HR", "and", "LR", "to", "denote", "high", "and", "low", "resolutions", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["We", "set", "our", "focus", "on", "the", "PSI", "protocols", "that", "are", "OT", "-", "based", "so", "that", "we", "can", "employ", "our", "OT", "extension", "protocol", "in", "them", "to", "improve", "efficiency", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Thus", ",", "the", "formulations", "of", "the", "LB", "divergence", "for", "the", "unsupervised", "rank", "aggregation", "on", "score", "-", "based", "permutations", "as", "well", "as", "the", "related", "algorithms", "are", "still", "lacking", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["Work", "on", "QA", ",", "which", "uses", "the", "DBpedia", "knowledge", "on", "the", "other", "hand", ",", "use", "much", "more", "complex", "linguistically", "-", "based", "NLP", "techniques", "to", "generate", "an", "answer", "for", "a", "given", "question", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["AssumptionsThe", "network", "considered", "in", "this", "work", "mainly", "comprises", "of", "sensor", "nodes", ",", "CHs", ",", "RNs", ",", "and", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["[", "BSP", "-", "sttdev]samp", "/", "stddev.osm.bsp.epsfig", ":", "z"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["Functional", "splitting", "offers", "additional", "freedom", "in", "dividing", "the", "signal", "processing", "between", "the", "CC", "and", "cell", "sites", "with", "several", "possible", "split", "points", ",", "provided", "that", "a", "cell", "site", "server", "is", "made", "available", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["In", "addition", ",", "we", "also", "compare", "with", "some", "state", "-", "of", "-", "the", "-", "art", "online", "algorithms", ",", "RBP", ",", "Projectron", ",", "BPAS", ",", "BOGD", ",", "andNOGD", ",", "to", "verify", "the", "online", "performance", "of", "DDE", "-", "MGM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "markov geographic model"}, {"tokens": ["[", "CC", ",", "35", "runs", ",", "24", "clust", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "connected caveman"}, {"tokens": ["Figure", "7", "shows", "that", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "provides", "better", "SC", "than", "other", "schemes", "for", "different", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["[", "]", "Results", "for", "continual", "single", "-", "output", "GP", "regression", "over", "real", "-", "valued", "toy", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Our", "findings", "show", "that", "the", "SAR", "system", "successfully", "personalized", "its", "instruction", "and", "feedback", "to", "each", "participant", "over", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["But", ",", "if", "the", "SBM", "-", "acceptance", "probability", "led", "to", "a", "(", "provisional", ")", "'", "acceptance", "'", ",", "then", "there", "is", "one", "final", "step", "required", "to", "decide", "on", "rejection", "or", "acceptance", "of", "the", "move;we", "draw", "from", "the", "posterior", "of", ",", "drawing", "a", "new", "conditioning", "on", "the", "(", "proposed", ")", "new", "values", "of", "and", "in", "state", ";", "we", "fully", "accept", "the", "new", "state", "if", "and", "only", "if", "the", "satisfies", "the", "SCF", "validity", "constraint", "in", "Equation", "EQv", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Simulation", "results", "show", "that", "although", "the", "BS", "does", "not", "require", "the", "channel", "information", "of", "all", "users", ",", "by", "the", "proposed", "geometry", "-", "based", "user", "scheduling", "algorithm", "the", "sum", "-", "rate", "of", "the", "system", "is", "only", "slightly", "less", "than", "the", "well", "-", "known", "greedy", "weight", "clique", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["As", "an", "exact", "inference", "method", "we", "use", "the", "sampling", "approach", "of(To", "increase", "efficiency", ",", "the", "GP", "values", "are", "sampled", "by", "elliptical", "slice", "sampling", "murray2010elliptical", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Applications", "of", "the", "BQ", "in", "nonlinear", "filtering", "have", "appeared", "previously", "in", "with", "encouraging", "results", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian quadrature"}, {"tokens": ["While", "these", "two", "SAT", "resistant", "techniques", "are", "strong", "enough", "to", "withstand", "the", "power", "of", "oracle", "-", "guided", "attacks", ",", "they", "are", "vulnerable", "to", "Bypass", "attack", ",", "SPS", "attack", ",", "and", "AppSAT", "attack", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "signal probability skey"}, {"tokens": ["TTF", "is", "a", "static", "model", ",", "when", "teams", "develop", "familiarity", "with", "IS", "they", "are", "used", "differently", "to", "the", "designer", "'s", "intent", "-", "the", "Fit", "Appropriation", "Model"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["epiniere", ",", "ICM", ",", "Inserm", "U", "1127", ",", "CNRS", "UMR", "7225", ",", "Sorbonne", "Universite", ",", "F-75013", ",", "Paris", ",", "FranceMultiple", "sclerosis", "(", "MS", ")", "is", "a", "demyelinating", "disease", "of", "the", "central", "nervous", "system", "(", "CNS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "central nervous system"}, {"tokens": ["For", "2D", "CNN", "MTL", ",", "we", "convert", "all", "the", "3D", "convolutional", "/", "pooling", "layers", "of", "the", "proposed", "network", "to", "their", "2D", "versions", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multi - task learning"}, {"tokens": ["Note", "that", "the", "FL", "framework", "is", "simulated(not", "run", "on", "the", "real", "distributed", "environment", ")", ",", "hence", "the", "network", "latency", "issues", "are", "not", "considered", "in", "our", "experiment", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Many", "of", "the", "most", "successful", "CF", "techniques", "are", "based", "on", "matrix", "factorization", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["During", "training", ",", "we", "use", "a", "batch", "size", "of", "and", "for", "the", "LA", "and", "PA", "tasks", ",", "respectively", ",", "with", "an", "initial", "learning", "rate", "of", "that", "is", "halved", "on", "validation", "loss", "plateau", "with", "a", "patience", "of", "epochs", ",", "until", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["CORESETs", "are", "equivalent", "to", "the", "control", "region", "in", "LTE", "subframes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Zhang", "et", "al", "proposed", "a", "binary", "PSO", "with", "mutation", "operator", "to", "address", "CoD", "problem", "using", "feature", "selection", "techniques", "to", "solve", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["DL", "has", "addressed", "other", "issues", "in", "RS", ",", "like", "data", "fusion", "(", "see", "for", "a", "review", ")", "e.g.", "multimodal", "classification", ",", "pansharpening", ",", "and", "3D", "reconstruction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["decrease", "of", "costs", "over", "500", "epochs", "for", "the", "low", "-", "latency", "convolution", "and", "VAT", "models", ":", "a", "zoomed", "-", "out", "version", "of", "fig:10epcIn", "figures", "10", "and", "11"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["L", "&", "FA", "Post", "thalamic", "radiation", "L", "Set", "3", "&", "FA", "Corticospinal", "tract", "R", "&", "FA", "Superior", "O.F."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], "long_form": "fractional anisotropy"}, {"tokens": ["CST", "(", "R", ")", ","], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "corticospinal tract"}, {"tokens": ["As", "a", "result", ",", "the", "mean", "cross", "-", "validated", "CCC", "was", "substantially", "lower", "than", "the", "CCC", "for", "the", "best", "story", ",", "and", "the", "standard", "deviation", "tends", "to", "be", "almost", "as", "large", "as", ",", "if", "not", "larger", "than", ",", "the", "mean", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["ConclusionsIn", "this", "article", ",", "we", "present", "CroPark", "that", "is", "consisted", "of", "an", "ultrasonic", "ranger", "and", "a", "GPS", "receiver", "to", "determine", "the", "distance", "from", "the", "vehicle", "to", "roadside", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["We", "demonstrate", "the", "effectiveness", "of", "these", "two", "algorithms", "in", "terms", "of", "relevance", "(", "by", "NDCG", ")", "and", "diversity", "(", "by", "NCE", ")", "if", "applicable", "in", "the", "offline", "experiments", "using", "real", "customer", "data", "at", "Ancestry", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["The", "same", "happens", "if", "we", "consider", "an", "option", "in", "which", "a", "UE", "participates", "in", "the", "D2D", "communication", "depending", "on", "the", "remaining", "battery", "it", "has", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["These", "large", "steps", "will", "make", "the", "predicted", "AR", "slave", "-", "tool", "appear", "jumpy", "and", "therefore", "untrustworthy", "to", "operators", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["RA", "-", "based", "systems", "achieve", "scalable", "performance", "as", "they", "successfully", "decouple", "network", "usage", "from", "the", "number", "of", "workers", "in", "the", "system", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["Typically", ",", "landmark", "detection", "networks", "are", "trained", "with", "crops", "of", "HR", "images", "taken", "from", "AFLW", "and", "300W", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["In", "the", "GP", "literature", ",", "this", "marginal", "distribution", "is", "often", "rewritten", "as", "and", "in", "our", "case", ",", "we", "may", "express", "it", "also", "as", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["PSO", "is", "popular", "for", "its", "ability", "to", "optimize", "complex", "non", "-", "linear", "functions", "and", "for", "its", "simple", "implementation", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["All", "of", "our", "images", "are", "from", "the", "testing", "images", "of", "MS", "COCO", "dataset", ",", "the", "MQ", ",", "main", "questions", ",", "are", "from", "the", "testing", "questions", "of", "VQA", ",", "open", "-", "ended", ",", "dataset", ",", "the", "BQ", ",", "basic", "questions", ",", "are", "from", "the", "training", "and", "validation", "questions", "of", "VQA", ",", "open", "-", "ended", ",", "dataset", ",", "and"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["The", "BF", "multi", "-", "classifier", "takes", "the", "basic", "features", "from", "the", "user", "profiles", "and", "tweets", "as", "an", "input", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic feature"}, {"tokens": ["The", "forecasting", "tool", "is", "applied", "to", "Australian", "online", "job", "ads", "data", "to", "uncover", "growth", "trends", "of", "DSA", "jobs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["The", "dashed", "diagonal", "line", "represents", "the", "ROC", "curve", "of", "a", "random", "predictor", "as", "a", "baseline", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["A", "formalisation", "of", "the", "LTE", "process", "can", "be", "found", "in", "the", "Supplemental", "Material", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "language transmission engine"}, {"tokens": ["The", "density", "of", "is", "nowThey", "argued", "that", ",", "in", "the", "limit", "of", "a", "large", "sparse", "graph", "where", "the", "edge", "probability", "equals", "the", "expected", "number", "of", "edges", ",", "this", "version", "of", "the", "SBM", ",", "called", "the", "Poisson", "SBM", ",", "is", "asymptotically", "equivalent", "to", "the", "Bernoulli", "counterpart", "in", "eqn.graph_lik_hard", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "iteration", "is", "then", "terminated", "when", "no", "new", "constraint", "is", "violated", ",", "guaranteeing", "a", "solution", "of", "the", "full", "OPF", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["CF", "does", "tend", "to", "give", "results", "from", "other", "categories", "than", "the", "selected", "category", "(", "juice", "is", "recommended", "for", "milk", ",", "skirt", "for", "a", "fleece", "and", "a", "DVD", "for", "an", "accessory", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["We", "outline", "the", "methods", "used", "in", "the", "past", ",", "extend", "them", ",", "and", "provide", "and", "test", "means", "of", "validating", "QA", "relevance", "feedback", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Experiments", "and", "ResultsExample", "of", "sGVG", ",", "simulated", "deformations", ",", "rigid", "alignment", "and", "resulting", "GM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "graph matching"}, {"tokens": ["IEEEtranAdarsha", "Balaji", "Adarsha", "Balaji", "received", "a", "Bachelor", "\u2019s", "degree", "from", "\ufeffVisvesvaraya", "Technological", "University", ",", "India", ",", "in", "2012", "and", "a", "Master", "'s", "degree", "from", "Drexel", "University", ",", "Philadelphia", ",", "PA", ",", "in", "2017", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "philadelphia"}, {"tokens": ["Note", "that", "recognition", "accuracy", "is", "not", "the", "same", "as", "AP", ",", "since", "detection", "scores", "also", "matter", "in", "AP", "calculation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "performance", "improvement", "of", "ECS", "-", "DBN", "over", "DBN", "and", "CSDBN", "with", "randomly", "generated", "cost", "values", "on", "many", "performance", "metrics", "further", "illustrates", "the", "need", "for", "cost", "-", "sensitive", "learning", "and", "the", "effectiveness", "of", "optimization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["All", "DSA", "categories", "had", "higher", "trend", "growth", "rates", "than", "'", "All", "Australian", "Job", "Postings", "'", "during", "this", "period", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["In", "this", "section", ",", "the", "research", "papers", "are", "analyzed", "considering", "non", "-", "conventional", "sources", "along", "with", "conventional", "sources", ",", "to", "dispatch", "electric", "power", "economically", "using", "various", "PSO", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power system operations"}, {"tokens": ["UAVs", "can", "contribute", "to", "reduce", "the", "resources", "needed", "in", "support", "of", "more", "efficient", "SAR", "operations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "search and rescue"}, {"tokens": ["which", "makes", "an", "attempt", "to", "predict", "landmarks", "on", "LR", "images", "by", "super", "-", "resolution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["WhileAISTATS17_hanawal2017unsupervised", "andAISTATS19_verma2019online", "focus", "on", "UCB", "based", "algorithms", ",", "we", "also", "propose", "TS", "based", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["We", "define", "a", "vector", "to", "capture", "the", "parameters", "related", "to", "the", "global", "FL", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["Adaptive", "DE", "automatically", "updates", "the", "parameters", "according", "to", "the", "probability", "matching", ",", "that", "can", "be", "easily", "implemented", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Consider", "the", "fact", "that", "most", "of", "the", "results", "for", ">", "50", "are", "between", "0.5", "and", "1", ",", "irrespective", "of", "CF", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["GP", "Standard", "Form"], "acronym_pos": [1, 0, 0], "long_form": "geometric programming"}, {"tokens": ["In", "certain", "disastrous", "situations", "like", "poisonous", "gas", "infiltration", ",", "wildfires", ",", "avalanches", ",", "and", "search", "for", "missing", "persons", ",", "UAVs", "can", "be", "used", "to", "play", "a", "support", "role", "and", "speed", "up", "SAR", "operations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "search and rescue"}, {"tokens": ["Additionally", ",", "the", "chance", "of", "handling", "a", "new", "continual", "GP", "prior", "makes", "the", "current", "approach", "feasible", "to", "multi", "-", "output", "scenarios", "where", "otherwise", ",", "concatenating", "inducing", "points", "would", "not", "be", "possible", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["is", "fine", "-", "tuned", "with", "a", "subset", "of", "annotated", "SAR", "land", "cover", "dataset", "with", "12,000", "slices", "for", "classification", ",", "obtaining", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Aside", "from", "the", "probabilistic", "CER", "correction", ",", "no", "CTC", "alignment", "or", "CCA", "post", "correction", "was", "applied", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["In", "this", "paper", ",", "we", "diagnosed", "and", "analyzed", "the", "DCNN", "-", "DCF", "based", "tracking", "system", ",", "and", "found", "that", "the", "deep", "features", "extracted", "by", "image", "classification", "task", "pretrained", "model", "are", "consist", "of", "a", "large", "number", "of", "redundant", "and", "harmful", "information", "for", "the", "tracking", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["BTAS", "stand", "for", "bass", ",", "tenor", ",", "alto", ",", "soprano", ",", "and", "Q", "and", "CM", "are", "short", "for", "quartet", "and", "choir", "mix", ",", "meaning", "that", "the", "dispersion", "values", "belong", "to", "a", "4-singers", "and", "16-singers", "setting", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "choir mix"}, {"tokens": ["However", ",", "no", "quantitative", "evaluation", "of", "this", "approach", "was", "offered", "(", "only", "a", "few", "hand", "-", "picked", "examples", "based", "on", "the", "Italian", "texts", "from", "the", "Gutenberg", "Project", ")", ",", "and", "thus", "it", "is", "unclear", "whether", "TRI", "is", "any", "better", "than", "other", "distributional", "models", "for", "the", "task", "of", "semantic", "shift", "detection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal random indexing"}, {"tokens": ["A", "demonstrative", "visualization", "of", "the", "whole", "continual", "GP", "learning", "process", "for", "the", "solar", "sunspot", "signal", "can", "be", "found", "at", "https://www.youtube.com", "/", "watch?v", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "have", "also", "proposedpractical", "algorithms", "to", "tune", "the", "unlicensed", "-", "band", "channel", "time", "usagesfor", "IFWs", "and", "DBFs", ",", "which", "uses", "the", "WiFi", "and", "LTE", "air", "interfaces", "in", "theunlicensed", "band", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": [":", "OP_FSDF_Difm", ",", "substituting", "Eq", ":", "MGF_end_Final_Equalm", "to", "Eq", ":", "Inverse_Laplaca", ",", "a", "closed", "-", "form", "expression", "for", "of", "pure", "RS", "is", "given", "bywhere", ",", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["If", "the", "data", "is", "concentrated", "on", "a", "low", "dimensional", "submanifoldof", "the", "high", "-", "dimensional", "space", ",", "one", "could", "still", "try", "to", "combine", "our", "method", "with", "other", "density", "estimators", "providing", "a", "base", "measure", "that", "is", "adapted", "to", "this", "submanifold", ",", "to", "allow", "for", "tractable", "GP", "inference", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["An", "introduction", "to", "ROC", "analysis", "."], "acronym_pos": [0, 0, 0, 1, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["In", "contrast", ",", "the", "importance", "sampling", "weighting", "in", "the", "MGM", "GAN", "balances", "the", "densities", ",", "allowing", "the", "generator", "to", "converge", "to", "this", "alignment", "(", "Figure", "fig", ":", "artificialb", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["These", "are", "the", "desired", "centres", "of", "LV", ",", "RV", ",", "RA", "and", "LA", "cavities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["It", "can", "be", "seen", "from", "Figure", ",", "that", "the", "presented", "system", ",", "sssynth", "preforms", "better", "than", "DeepConvSep", "and", "FASST", "in", "terms", "of", "the", "SIR", "metric", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "source to interferences ratio"}, {"tokens": ["Although", "word", "embeddingsMikolov2013", "with", "CNNs", "are", "state", "-", "of", "-", "the", "-", "art", "in", "many", "text", "classification", "tasksKim2014", ",", "a", "traditional", "VSM", "approach", "is", "used", "instead", ",", "as", "it", "seems", "to", "perform", "better", "when", "dealing", "with", "large", "textsOramas2017", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vector space model"}, {"tokens": ["Ablation", "StudyHaving", "demonstrated", "a", "benefit", "to", "using", "an", "ISP", ",", "we", "aim", "to", "understand", "which", "components", "of", "the", "ISP", "contribute", "most", "to", "improved", "classification", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Related", "attacks", "are", "clickjacking", ",", "UI", "redressing", ",", "and", "mousejacking", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "user interface"}, {"tokens": ["As", "a", "future", "work", ",", "we", "plan", "to", "focus", "on", "the", "robustness", "of", "RS", "in", "different", "system", "models", "with", "altered", "CSIT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["Full", "skeleton", "with", "standard", "POS", ":"], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "part of speech"}, {"tokens": ["The", "first", "instance", "of", "Mobile", "AR", "can", "certainly", "be", "associated", "with", "the", "development", "of", "wearable", "AR", ",", "in", "a", "sense", "of", "experiencing", "AR", "during", "locomotion", "(", "mobile", "as", "a", "motion", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Using", "this", "information", ",", "the", "AP", "can", "identify", "the", "worst", "channel", "'s", "condition", "and", "then", "adjust", "the", "transmission", "rate", "and", "FEC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "forward error correction"}, {"tokens": ["h", "]", "Lifetime", "vs.", "Network", "load", "of", "ABC", ",", "GSA", "and", "DE", "[", "!"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Hence", ",", "these", "optimization", "problems", "can", "be", "solved", "at", "each", "iteration", "of", "the", "SCA", "as", "given", "in", "Algorithm", "where", "each", "GP", "in", "the", "iteration", "loop", "(", "line", "3", "-", "7", ")", "tries", "to", "improve", "the", "accuracy", "of", "the", "approximations", "to", "a", "particular", "minimum", "in", "the", "original", "feasible", "region", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Second", ",", "since", "FCA", "methods", "are", "used", "to", "discover", "regularity", "features", ",", "thus", "it", "does", "not", "consider", "forecasting", "exceptions", "(", "unexpected", "results", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "formal concept analysis"}, {"tokens": ["It", "is", "shown", "that", ",", "unlike", "and", ",", "the", "proposed", "algorithms", "guarantee", "locally", "optimal", "solutions", "with", "the", "perfect", "knowledge", "of", "channels", "at", "the", "AP", "and", "the", "RIS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["However", ",", "results", "obtained", "from", "the", "post", "experiment", "survey", "indicate", "that", "participants", "decidedly", "preferred", "the", "TDW", "experience", "over", "the", "SDD", ",", "even", "if", "their", "performance", "results", "did", "not", "show", "a", "marked", "difference", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["They", "aim", "to", "optimize", "the", "TS", "and", "PS", "ratios", "in", "order", "to", "maximize", "the", "throughput", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["*", "par(a)u", "-", "a", "-", "ka-", "MP", "pahlug", "'", "side", ",", "rib", "'", "NP", "pahlu", "'", "side'PIr", "*", "cau(a)r", "-", "cat-", "PSWIr", "*"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["However", ",", "no", "quantitative", "evaluation", "of", "this", "approach", "was", "offered", "(", "only", "a", "few", "hand", "-", "picked", "examples", "based", "on", "the", "Italian", "texts", "from", "the", "Gutenberg", "Project", ")", ",", "and", "thus", "it", "is", "unclear", "whether", "TRI", "is", "any", "better", "than", "other", "distributional", "models", "for", "the", "task", "of", "semantic", "shift", "detection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal random indexing"}, {"tokens": ["Since", "has", "been", "determined", ",", "the", "total", "LTE", "licensed", "band", "rate", "of", "the", "sDevice", ",", "is", "now", "a", "constant", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Studies", "were", "therefore", "analysed", "which", "defined", "taxonomies", "of", "constraints", "to", "successful", "implementation", "of", "IS", "Yeo2002", ",", "Al", "-", "ahmad2009", "-", "although", "what", "constitutes", "success", "Agarwal2006", ",", "Shaul2013", "was", "considered", "out", "of", "scope", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["In", "the", "SFM", ",", "pedestrian", "motion", "is", "driven", "by", "a", "superposition", "of", "forces", "called", "social", "forces", "that", ",", "according", "to", "the", "authors", ",", "represent", "a", "\"", "measure", "for", "the", "internal", "motivation", "of", "the", "individuals", "to", "perform", "certain", "actions", "(", "movement", ")", "\"", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "social force model"}, {"tokens": ["Our", "results", "suggest", "that", "performance", "metrics", "reported", "on", "the", "current", "PA", "dataset", "may", "be", "overestimating", "the", "actual", "performance", "of", "the", "models", ",", "which", "might", "become", "somewhat", "of", "a", "\"", "horse", "\"", "that", "trivially", "sidesteps", "the", "actual", "problem", ",", "thus", "raising", "concerns", "about", "model", "validity", "as", "well", "as", "performance", "results", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["Therefore", ",", "SAR", "acts", "are", "defined", "to", "be", "illocutions", "irrespective", "of", "communicative", "modality", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["*", "taxra-", "'", "bitter", "'", "Phl", "taxl", ",", "MMP", "tahr", "NP", "talx", ";", "Phl", "taxlih", "'", "bitterness", "'", "NP", "talxi", "(", "the", "latter", "change", "could", "be", "analogical)PIr"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["K40c", "(", "ECC", "on", ")", "]"], "acronym_pos": [0, 0, 1, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["So", ",", "the", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "provides", "comparatively", "lower", "SC", "w.r.t", "than", "the", "proposed", "scheme", "which", "is", "illustrated", "in", "Figure", "6", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["Since", "differs", "only", "slightly", "in", "the", "amplitude", "from", "the", "general", "pattern", ",", "these", "dictionaries", "seem", "insufficient", "to", "capture", "this", "fine", "dissimilarity", ":", "while", "Self", "and", "DI", "dictionaries", "simply", "do", "not", "contain", "enough", "elements", ",", "UI", "dictionary", "is", "to", "simple", "to", "capture", "this", "difference", "(", "it", "shares", "this", "feature", "with", "DI", "dictionary", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "dyadic indicator"}, {"tokens": ["The", "key", "hyper", "-", "parameters", "of", "our", "approach", "are", "and", "VAT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "virtual adversarial training"}, {"tokens": ["The", "UAV", "employs", "GPS", "module", "and", "wireless", "network", "module", "to", "navigate", "to", "the", "autonomous", "charging", "station", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["The", "SCCs", "of", "a", "PSP", "can", "be", "computed", "in", "linear", "time", "using", "e.g.", "Tarjan", "'s", "algorithm", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strongly connected components"}, {"tokens": ["This", "indicates", "that", "with", "semi", "-", "supervised", "learning", "generalizes", "well", "to", "real", "LR", "data", ",", "and", "hence", "also", "validates", "our", "hypothesis", "of", "training", ",", "and", "together", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["After", "convergence", ",", "the", "training", "data", "were", "then", "fed", "into", "network", "to", "yield", "pseudo", "-", "probabilty", "maps", "of", "WT", "at", "2", "mm", "resolution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "whole tumor"}, {"tokens": ["In", "FCA", ",", "association", "rules", "are", "implications", "between", "sets", "ofattributes", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "formal concept analysis"}, {"tokens": ["In", "this", "paper", ",", "we", "investigate", "HCI", "via", "a", "deep", "multi", "-", "facial", "patches", "aggregation", "network", "for", "Face", "Expression", "Recognition", "(", "FER", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["Any", "opinions", ",", "findings", ",", "conclusions", ",", "or", "recommendations", "expressed", "in", "this", "material", "are", "those", "of", "the", "authors", "and", "do", "not", "necessarily", "reflect", "the", "views", "of", "the", "NSF", ",", "the", "TRI", ",", "any", "other", "Toyota", "entity", ",", "or", "others", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "toyota research institute"}, {"tokens": ["In", "recent", "years", ",", "there", "has", "been", "a", "growing", "interest", "in", "the", "connections", "between", "the", "IB", "principle", "and", "deep", "neural", "networkspTishbyZ15", ",", "DVIB", ",", "Wieczorek", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Swedish", "Blog", "Sentences", "(", "SBS", ")", "is", "a", "corpus", "containing", "2.7", "billion", "tokens", ",", "from", "randomly", "rearranged", "sentences", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "swedish blog sentences"}, {"tokens": ["Similar", "conclusions", "could", "be", "drawn", "by", "looking", "at", "results", "obtained", "for", "the", "MDC", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["This", "is", "in", "part", "because", "the", "experiment", "deliberately", "spanned", "a", "range", "of", "difficulty", ",", "and", "thereby", "is", "inclusive", "of", "both", "the", "SDD", "and", "TDW", "advantages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["However", ",", "in", "our", "case", ",", "there", "is", "not", "a", "traditional", "PAP", ",", "because", "there", "is", "no", "central", "authority", "managing", "the", "policies", ",", "being", "each", "one", "of", "the", "document", "keepers", "managers", "of", "their", "own", "documents", ",", "working", "as", "a", "distributed", "PAP", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "policy administration point"}, {"tokens": ["Accuracy", "of", "the", "MNIST", "classifier", "on", "the", "sampled", "transferred", "by", "our", "DTN", "method", "from", "SHVN", "to", "MNIST", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "domain transfer network"}, {"tokens": ["To", "determine", "whether", "an", "AP", "is", "rogue", "or", "not", ",", "one", "can", "scan", "the", "white", "-", "list", "to", "see", "whether", "a", "similar", "fingerprint", "exists", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "received", "pilot", "signal", "at", "the", "BS", ",", ",", "is", "given", "bywhere", "denotes", "circularly", "symmetric", "complex", "Gaussian", "noise", ",", "and", "is", "the", "identity", "matrix", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["BPP", "deployed", "at", "a", "particular", "height", "above", "the", "ground", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binomial point process"}, {"tokens": ["Failure", "to", "this", "may", "be", "due", "to", "fairly", "small", "size", "of", "training", "samples", ",", "since", "training", "of", "BLSTM", "-", "CTC", "architecture", "needs", "huge", "amount", "of", "data", ",", "which", "we", "could", "not", "afford", "to", "produce", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["Hence", ",", "FEM", "is", "used", "to", "validate", "the", "predicted", "results", "of", "shock", "environment", "at", "component", "interface", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["Binary", "neural", "networks", "(", "BNN", ")", "help", "to", "alleviate", "the", "prohibitive", "resource", "requirements", "of", "DNN", ",", "where", "both", "activations", "and", "weights", "are", "limited", "to", "-bit", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary neural networks"}, {"tokens": ["The", "aim", "of", "given", "evolutionary", "algorithms", "for", "steganalysis", "It", "is", "worth", "mentioning", "that", "majority", "of", "researchers", "almost", "used", "SPAM", "and", "CC", "-", "PEV", "as", "their", "feature", "extractors", "according", "to", "fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subtractive pixel adjacency matrix"}, {"tokens": ["As", "mentioned", "before", ",", "we", "define", "the", "AP", "as", "the", "sensor", "node", "that", "can", "communicate", "with", "the", "outside", "information", "world", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Hence", ",", "RF", "and", "GBM", "are", "generally", "better", "then", "C4.5", "or", "Naive"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["Figure", "compares", "learning", "curves", "of", "the", "SC", "and", "baseline", "agents", "with", "oracle", "gating", "and", "using", "the", "full", "action", "set", ",", "respectively", ",", "in", "the", "simplest", "of", "levels", "(", "Level", "1", "and", "2", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "score contextualisation"}, {"tokens": ["Graphical", "representation", "of", "the", "IB", "curve", "in", "the", "information", "plane", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["If", "we", "test", "it", "with", "30", "D2D", "links", "and", "10", "UE", "links", "the", "BDI", "solutions", "has", "a", "rate", "of", "405", "b", "/", "s", "/"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["ANN", "is", "inspired", "of", "human", "nervous", "system", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["where", "are", "the", "mean", "values", "of", "the", "GMM", "modes", ",", "are", "the", "corresponding", "covariances", ",", "and", "are", "the", "mixing", "probabilities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "capaciti", "analysis", "and", "OMA", "based", "SWIPT", "-", "PS", "scheme", "are", "also", "presented", "in", "this", "section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Also", ",", "the", "experiment", "was", "clearly", "investigating", "the", "perceived", "value", "of", "TDWs", "compared", "to", "the", "SDD", ",", "and", "may", "have", "skewed", "participants", "'", "perception", "in", "favour", "of", "the", "more", "novel", "technology", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["The", "features", "in", "are", "good", "enough", "to", "transfer", "to", "the", "SAR", "targets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["To", "improve", "on", "these", "issues", ",", "the", "adaptive", "FEC", "-", "based", "mechanism", "with", "motion", "intensity", "awareness", "(", "MINT", "-", "FEC", ")", "was", "proposed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["where", "DUs", "are", "deployed", "at", "both", "the", "CC", "and", "the", "ECs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["(", "VQM", ")", "Network", "footprint", "analysisFigure", "shows", "the", "network", "overhead", "results", "of", "all", "PLRs", "using", "the", "four", "FEC", "schemes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "obtained", "results", "can", "be", "used", "as", "a", "comparison", "of", "the", "current", "LTE", "PTM", "solution", "and", "NR", "PTP", "including", "the", "physical", "layer", "changes", "specified", "in", "Rel-15", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Since", "the", "error", "of", "DTP", "(", "or", "target", "propagation", "algorithms", "in", "general", ")", "is", "represented", "as", "the", "change", "in", "activities", "of", "the", "same", "set", "of", "neurons", ",", "if", "any", "neural", "activity", "is", "unstable", ",", "the", "overall", "algorithm", "will", "fail", "to", "train", "the", "underlying", "model", "effectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "difference target propagation"}, {"tokens": ["Although", ",", "generation", "of", "LR", "images", "is", "an", "unpaired", "task", ",", "we", "use", "AFLW", "and", "300W", "images", "for", "training", ",", "as", "the", "generated", "LR", "images", "from", "these", "datasets", "are", "used", "for", "semi", "-", "supervised", "learning", "in", "the", "second", "step", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["PIN", "consistently", "performs", "better", "for", "Top", "3", "and", "Top", "5", "retrieval", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["ELD", "using", "modified", "/", "improved", "/", "enhanced", "version", "of", "PSO", "Park", "et", "al", ".", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["In", "this", "research", ",", "DSA", "skills", "refer", "to", "the", "use", "of", "scientific", "methods", ",", "processes", ",", "algorithms", ",", "and", "systems", "to", "extract", "knowledge", "and", "insights", "from", "structured", "and", "unstructured", "data", ",", "which", "can", "be", "used", "to", "make", "data", "-", "driven", "decisions", "and", "actions", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["We", "try", "to", "constrain", "AN", "'s", "attention", "just", "on", "each", "target", "character", "by", "introducing", "the", "focusing", "network", ",", "which", "is", "detailed", "in", "the", "following", "section", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["comparison_efficiency_clusters", "shows", "comparison", "of", "the", "parallel", "efficiency", "of", "the", "RMSD", "task", "between", "different", "test", "cases", "on", "SDSC", "Comet", ",", "PSC", "Bridges", ",", "and", "LSU", "SuperMIC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["The", "LS", "data", "term", "in", "(", ")", "can", "be", "replaced", "by", "other", "fit", "-", "to", "-", "data", "functional", ",", "for", "example", ",", "Poisson", "log-", "likelihood", "functional", ",", "which", "is", "better", "suited", "noise", "model", "for", "ET", "reconstruction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "emission tomography"}, {"tokens": ["The", "work", "described", "in", "this", "paper", "is", "complementary", "but", "different", "from", "past", "work", "in", "that", "it", "analyzes", "a", "long", "-", "term", "SAR", "intervention", "for", "abstract", "concept", "learning", ",", "specifically", "helping", "children", "with", "ASD", "learn", "mathematics", "skills", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["To", "further", "investigate", "the", "relationship", "between", "FA", "and", "BP", ",", "we", "also", "investigated", "the", "performance", "of", "models", "that", "were", "trained", "with", "BP", "but", "with", "either", "added", "noise", "(", "BP", "+", "Noise", ")", "or", "with", "weight", "matrices", "that", "were", "forced", "to", "align", "with", "arbitrary", "random", "matrices", "(", "BP", "+", "Alignment", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["Multi", "-", "objective", "versions", "of", "PSO", "have", "also", "been", "considered", "early", "on", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "channel", "estimation", "load", "vs.", "value", "of", "error", "of", "antennas", "at", "the", "receiver", "BS", "for", "different", "values", "of", "total", "number", "of", "users", "in", "the", "cell", "with", "m.[t", "!", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Given", "the", "practical", "importance", "of", "AQG", "and", "its", "potential", "to", "influence", "research", "in", "QA", "itself", ",", "it", "is", "quite", "natural", "to", "expect", "that", "there", "will", "soon", "be", "an", "explosive", "growth", "in", "the", "research", "in", "this", "area", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["In", "BC", "learning", ",", "two", "audio", "signals", "from", "different", "classes", "are", "mixed", "with", "each", "other", "with", "a", "random", "ratio", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "between class"}, {"tokens": ["We", "find", "that", "both", "CF", "and", "hybrid", "models", "consistently", "outperform", "the", "heuristic", "baseline", "model", "by", "significant", "margins", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "claim", "follows", "from", "the", "property", "of", "PS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "probabilistic serial"}, {"tokens": ["According", "to", ",", "GRASP", "-", "BGWO", "did", "excel", "all", "existing", "decent", "works", "like", "SRM", ",", "PSRM", "and", "SPAM", "even", "in", "low", "volume", "payload", "per", "pixel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subtractive pixel adjacency matrix"}, {"tokens": ["The", "MSR", "Action3D", "dataset", ":", "The", "most", "notable", "advantage", "of", "DDE", "-", "MGM", "over", "the", "other", "online", "algorithms", "is", "the", "robustness", "to", "random", "data", "length", "and", "misalignment", ",", "which", "is", "better", "demonstrated", "in", "the", "experiment", "on", "the", "MSR", "Action3D", "dataset", "as", "shown", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["In", "order", "to", "show", "the", "statistical", "significance", "of", "the", "performance", "of", "ECS", "-", "DBN", ",", "Wilcoxon", "paired", "signed", "-", "rank", "test", "has", "been", "implemented", "in", "this", "section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Results", "of", "retrievals", "with", "these", "new", "question", "are", "loaded", "into", "the", "FA", "database", "and", "a", "report", "describing", "any", "performance", "changes", "is", "generated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["Depending", "on", "the", "choice", "on", "the", "encryption", "approach", "in", "the", "MDC", ",", "as", "discussed", "above", ",", "there", "are", "two", "choices", ":", "(", "i", ")", "if", "the", "MDC", "encryption", "key", "was", "negotiated", "with", "the", "SCBR", ",", "SCBR", "would", "decrypt", "the", "data", "and", "this", "data", "would", "be", "disseminated", "unencrypted", ";", "(", "ii", ")", "if", "the", "encryption", "key", "is", "negotiated", "with", "the", "trusted", "parties", ",", "the", "sensitive", "information", "(", "e.g.", ",", "the", "measurements", "is", "kept", "encrypted", "even", "within", "the", "SCBR", "enclave", ")", ",", "this", "could", "be", "useful", "for", "connecting", "systems", "that", "store", "information", ",", "even", "if", "the", "systems", "themselves", "can", "not", "read", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "metering data collector"}, {"tokens": ["Table", "shows", "the", "comparative", "transaction", "payload", "analysis", "of", "Proposed", "IoT", "-", "BC", "and", "QUORAM", "-", "BC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0], "long_form": "blockchain"}, {"tokens": ["Even", "though", "the", "low", "-", "level", "features", "learnt", "from", "natural", "images", "that", "resemble", "Gabor", "filters", "are", "effective", "to", "represent", "SAR", "targets", ",", "the", "features", "from", "higher", "layers", "are", "more", "specific", "on", "natural", "images", "which", "indicates", "more", "distant", "the", "mid", "-", "level", "features", "of", "natural", "images", "and", "SAR", "targets", "present", ",", "much", "worse", "in", "high", "layers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Unfortunately", "AP", "also", "suffers", "from", "the", "following", "issues", ":", "it", "can", "only", "discover", "globular", "clusters", "which", "seriously", "limits", "it", "'s", "applicability", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["They", "were", "required", "to", "determine", "the", "best", "way", "to", "operate", "between", "themselves", "as", "part", "of", "the", "task", ",", "and", "in", "all", "cases", "settled", "the", "matter", "of", "who", "would", "operate", "the", "interface", "(", "in", "the", "case", "of", "the", "SDD", ")", "or", "how", "they", "would", "split", "the", "search", "area", "(", "in", "the", "case", "of", "the", "TDW", ")", ",", "with", "a", "very", "brief", "discussion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Mean", "scores", "for", "CD", "across", "the", "alignments", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0], "long_form": "cosine distance"}, {"tokens": ["Conclusion", "Future", "DirectionThe", "ANN", "has", "been", "applied", "as", "a", "function", "approximator", "for", "RL", "using", "hand", "-", "crafted", "features", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["This", "suggests", "the", "potential", "application", "of", "OT", "in", "various", "vision", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["The", "MP", "architecture", "improves", "performance", "especially", "when", "small", "metallic", "implants", "are", "dominated", "by", "the", "non", "-", "metal", "regions", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mask pyramid"}, {"tokens": ["In", "the", "case", "of", "perfect", "regression", "the", "size", "of", "the", "optimization", "problem", "is", "equal", "to", "the", "original", "OPF", "problem", "and", "the", "gain", "is", "determined", "by", "the", "convergence", "of", "dual", "variables", "that", "does", "not", "seem", "to", "depend", "on", "the", "size", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["GMM", "-", "UBM", "-", "I", "-", "vectors"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["In", "the", "case", "of", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", ",", "SC", "is", "lower", "than", "the", "proposed", "scheme", "because", "the", "capacities", "of", "CCU", "and", "CEU", "are", "comparatively", "lower", "than", "the", "proposed", "scheme", "(", "Which", "are", "shown", "in", "Figure", "3", "and", "Figure", "4", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["we", "can", "see", "that", "the", "performance", "of", "the", "proposed", "FL", "scheme", "outperforms", "the", "conventional", "TDMA", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Statistics", "of", "M", "-", "ARS", "corpus", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0], "long_form": "addressee and response selection"}, {"tokens": ["Computational", "complexity", "and", "training", "overheadAs", "mentioned", "above", ",", "the", "computational", "complexity", "of", "exhaustedly", "search", "in", "the", "codebook", "will", "increase", "linearly", "with", "at", "the", "BS", "in", "the", ",", "as", "well", "as", "the", "training", "overhead", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "this", "work", ",", "the", "main", "contributions", "are", ":", "(", "i", ")", "the", "objective", "function", "in", "has", "been", "reformulated", "using", "additional", "penalty", "term", "for", "optimal", "performance", ",", "(", "ii", ")", "two", "other", "evolutionary", "techniques", "(", "DE", "and", "GSA", ")", "have", "been", "used", "in", "the", "second", "phase", "to", "efficiently", "deploy", "the", "RNs", ",", "(", "iii", ")", "the", "effectiveness", "of", "the", "proposed", "algorithms", "is", "compared", "and", "contrasted", "with", "on", "the", "basis", "of", "network", "lifetime", "enhancement", "and", "speed", "of", "convergence", ",", "and", "lastly", "(", "iv", ")", "comprehensive", "experiments", "have", "been", "carried", "out", "to", "show", "the", "efficacy", "(", "faster", "convergence", "and", "better", "optimal", "solution", ")", "of", "using", "DE", "as", "opposed", "to", "ABC", "presented", "in", "to", "deploy", "backbone", "devices", "in", "WSNs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["The", "random", "SP", "offers", "the", "value", "of", "in", "between", "(", "max", ")", "and", "(", "min", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "shortest path"}, {"tokens": ["K", ")", "Magnitude", "of", "the", "correlation", "between", "trust", "and", "PI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "purchase intention"}, {"tokens": ["We", "observe", "that", "the", "reductions", "in", "abboud2014popularfrom", "-subgraph", "-", "connectivity", "to", "-reachability", "(", "Lemma", "6.1", ")", "and", "from", "-", "reachability", "to", "BP", "-", "Match", "(", "Lemma", "6.2", ")", "and", "SC", "(", "Lemma", "6.4)are", "sensitivity", "-", "preserving", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "strongly connected"}, {"tokens": ["To", "model", "the", "random", "tessellation", "of", "roads", ",", "we", "consider", "the", "so", "-", "called", "PLP", "which", "is", "mathematically", "derived", "from", "the", "spatial", "PPP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["The", "Department", "of", "Energy", "will", "provide", "public", "access", "to", "these", "results", "of", "federally", "sponsored", "research", "in", "accordance", "with", "the", "DOE", "Public", "Access", "Plan", "(", "http://energy.gov/downloads/doe-public-access-plan", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "department of energy"}, {"tokens": ["Results", "on", "the", "LA", "and", "PA", "evaluation", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["The", "low", "entropy", "of", "TI", "2", "(", ")", "indicates", "that", "two", "individuals", "have", "preferred", "interactive", "locations", ",", "and", "the", "predication", "of", "their", "future", "interactive", "location", "is", "possible", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["For", "the", "TS", "scheme", ",", "the", "transmitter", "divides", "the", "transmission", "block", "into", "two", "orthogonal", "time", "slots", ",", "one", "for", "transferring", "power", "and", "the", "other", "for", "transmitting", "data", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["We", "notice", "that", "the", "estimated", "C", "-", "rates", "are", "not", "constant", "during", "the", "CC", "phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "charging current"}, {"tokens": ["In", "this", "paper", ",", "we", "convert", "the", "RSSI", "to", "PRR", "for", "the", "by", "the", "experimental", "results", "of", "PRR", "-", "RSSI", "relationship", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "packet reception rate"}, {"tokens": ["Uber", "Inc", "adapted", "the", "baidu", "RA", "algorithm", "and", "in", "its", "Horovod", "which", "is", "a", "distributed", "training", "framework", "for", "TensorFlow", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["The", "cover", "complexity", "(", "CC", ")", "is", "The", "CD", "is", "defined", "as", "the", "difference", "between", "the", "mean", "of", "SC", "and", "the", "mean", "of", "MC", ",", "since", "each", "category", "occurs", "with", "the", "same", "probability", "(", ")", "in", "the", "data", "sets", "mostly", "used", "in", "practice", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "self cover"}, {"tokens": ["propose", "a", "general", "purpose", "a", "QA", "system", "using", "Wikipedia", "data", "as", "its", "knowledge", "source", ",", "which", "can", "answer", "wh", "-", "interrogated", "questions", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "random", "selection", "of", "pixels", "in", "the", "context", "points", "provides", "the", "desired", "stochasticity", "behavior", "in", "the", "NP", "framework", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "neural processes"}, {"tokens": ["BSP", ":"], "acronym_pos": [1, 0], "long_form": "binary space partitioning"}, {"tokens": ["At", "last", ",", "we", "demonstrate", "that", "our", "method", "offers", "better", "coding", "efficiency", "than", "several", "advanced", "MD", "image", "compression", "methods", ",", "when", "tested", "on", "commonly", "available", "datasets", ",", "especially", "at", "low", "bit", "rates", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["That", "is", ",", "FG", "is", "responsible", "for", "generating", "the", "integrated", "feature", "sequence", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "filter gate"}, {"tokens": ["System", "parametersWe", "assume", "a", "HetNet", "consisting", "of", "one", "macrocell", "BS", "with", "radius", "of", "one", "km", ",", "four", "MBSs", "(", ")", "with", "a", "coverage", "of", "250", "meters", ",", "and", "six", "identical", "drones", "(", ")", ",", "unless", "otherwise", "stated", ",", "that", "can", "potentially", "be", "placed", "in", "sixteen", "different", "locations", "(", ")", "in", "addition", "to", "the", "charging", "station", "location", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Let", "denotes", "the", "feature", "vector", "extracted", "by", "the", "-th", "layer", "from", "a", "DCNN", "backbone", ",", "which", "is", "a", "tensor", "of", "dimension", ",", "where", ",", "and", "are", "width", ",", "height", "and", "channel", "numbers", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["The", "solution", "in", "problem", "sys0eq3_1", "represents", "the", "difference", "between", "the", "global", "FL", "parameter", "and", "local", "FL", "parameter", "for", "user", ",", "i.e.", ",", "is", "the", "local", "FL", "parameter", "of", "user", "at", "iteration", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Since", "LibOPT", "implements", "the", "naive", "PSO", ",", "it", "does", "not", "employ", "adaptive", "inertia", "weight", "(", "they", "are", "used", "only", "for", "Particle", "Swarm", "Optimization", "with", "Adaptive", "Inertia", "Weight", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["to", "provide", "the", "GPS", "receiver", "with", "a", "clear", "view", "from", "satellites", ",", "while", "we", "led", "the", "ultrasonic", "rangefinder", "to", "the", "passenger", "door"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["The", "Expectation", "Maximization", "(", "EM", ")", "algorithmem", "-", "dempster-77", "can", "be", "used", "to", "estimate", "the", "parameters", "of", "the", "GMM", "(", "mean", "vector", ",", "covariance", "matrices", "and", "weights", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Robust", "validation", "accuracy", "of", "adversarially", "trained", "and", "free", "trained", "MobileNetV2", "and", "TRADES", "WRN", "ARD", "(", "and", "Fast", "-", "ARD", ")", "onto", "MobileNetV2", "on", "CIFAR-10", "under", "various", "attacks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["h]Augmented", "Reality", "camera", "exampleResearch", "Challenges", "in", "Augmented", "RealityDespite", "the", "growing", "interests", "and", "development", "in", "AR", ",", "following", "are", "the", "challenges", "that", "exists", "in", "the", "field", "which", "has", "very", "wide", "scope", "of", "research", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Most", "of", "the", "PSO", "based", "approach", "do", "not", "utilize", "this", "information", "about", "the", "subset", "cardinality", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "input", "to", "the", "DST", "module", "is", "the", "combined", "output", "of", "the", "ASR", "and", "the", "NLU", "model", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["[", "]", "[", "]", "Saturated", "throughput", "against", "In", "the", "non", "-", "saturated", "condition", ",", "we", "set", "the", "traffic", "load", "for", "each", "STA", "and", "the", "AP", "to", "Mbps", "and", "Mbps", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["where", "the", "OPF", "of", "the", "current", "trellis", "stage", "is", "initialized", "to", "that", "of", "the", "previous", "stage", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal pareto front"}, {"tokens": ["Next", ",", "we", "apply", "the", "same", "approximations", "given", "in", "Definition", "1", "to", "the", "inequality", "constraints", "to", "obtain", "posynomials", "that", "fit", "into", "the", "GP", "standard", "form", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": [")", "right", "Corticospinal", "tract", "-", "CST", "(", "R", ")", ",", "b", ")", "Corpus", "Callosum", "-", "CC", ",", "and", "c", ")"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "corticospinal tract"}, {"tokens": ["From", "this", "nonlinear", "transformation", "of", "both", "linear", "/", "pairwise", "signals", ",", "the", "PNN", "can", "effectively", "model", "high", "-", "order", "interactions", "between", "the", "user", "contexts", "and", "the", "previous", "item", ",", "obtaining", "a", "vector", "encoding", "the", "user", "-", "contextual", "preference", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Moreover", ",", "with", "an", "increased", "GMM", "distribution", ",", "the", "computational", "time", "for", "log", "-", "likelihood", "iterations", "also", "increases", "which", "is", "needed", "to", "achieve", "the", "ideal", "value", "for", "convergence", "for", "the", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Collaboration", "Coefficient", "(", "CC", ")", "is", "a", "simple", "statistical", "measure", "(", "non", "-", "network", "based", ")", "to", "assess", "the", "extent", "of", "multi", "-", "author", "papers", "and", "track", "its", "evolution", "(", "see", "Methods", "section", "for", "details", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaboration coefficient"}, {"tokens": ["Also", ",", ",", "introduced", "the", "economic", "scheduling", "of", "multi", "-", "micro", "-", "grids", "using", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "power system operations"}, {"tokens": ["The", "number", "of", "available", "antennas", "of", "the", "AP", "decreases", "by", "one", "each", "time", "an", "uplink", "RTS", "is", "successfully", "received", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "sum", "-fair", "utility", "maximization", "problem", "can", "be", "formulated", "aswhere", ",", ",", ",", ",", ",", "is", "the", "maximal", "instantaneous", "transmission", "power", "of", "the", "BS", ",", "and", "is", "the", "maximal", "average", "transmission", "power", "of", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["(", "GI", ":", "gradient", "initialization", ",", "SSS", ":", "staggered", "sample", "selection", ",", "SOM", ":", "standard", "SOM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "staggered sample selection"}, {"tokens": ["Tomita", "languages", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "and", "7", "are", "SL", ",", "SL", ",", "regular", ",", "SL", ",", "regular", ",", "regular", ",", "and", "SP", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["It", "outperforms", "LE", "and", "HP", "by", "nearly", "1.7", "times", "as", "well", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low energy"}, {"tokens": ["CS", "problem", "is", "another", "widely", "known", "issue", "for", "CF", "approach", ",", "which", "can", "occur", "on", "new", "users", "or", "items", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["In", "this", "section", ",", "we", "briefly", "explain", "the", "syntax", "and", "semantics", "of", "AML", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "actor modeling language"}, {"tokens": ["LR", "works", "well", "for", "predicting", "categorical", "outcomes", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Our", "method", "FCAVG", "consistently", "performs", "better", "than", "all", "other", "methods", ":", "IMSHARP", ",", "BF", ",", "WLS", ",", "and", "GF", "enhancement", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bilateral filtering"}, {"tokens": ["Also", "note", "that", "too", "small", "AR", "means", "a", "failure", "of", "tracking", "and", "leads", "to", "a", "termination", "of", "the", "current", "episode", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "accumulated reward"}, {"tokens": ["The", "accuracy", "of", "the", "GM", "is", "given", "by", "the", "percentage", "of", "correct", "correspondences", ",", "and", "differences", "of", "registration", "performances", "between", "sGVG", "and", "sGVT", "are", "evaluated", "with", "a", "paired", "Wilcoxon", "signed", "rank", "test", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph matching"}, {"tokens": ["IntroductionFormal", "Concept", "Analysis", "(", "FCA", ")", "is", "a", "mathematical", "theory", "for", "dataanalysis", "using", "formal", "contexts", "and", "concept", "lattices", "as", "key", "tools", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "formal concept analysis"}, {"tokens": ["The", "LTE", "-", "U", "BS", "operates", "at", "maximum", "power", "by", "enabling", "all", "its", "resource", "blocks", "with", "the", "highest", "modulation", "coding", "scheme", "(", "i.e.", ",", "64-QAM", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "terms", "of", "energy", "consumption", "GA", "-", "PSO", "approach", "achieved", "better", "results", "over", "both", "greedy", "strategy", "and", "OSFP", "approaches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["On", "average", ",", "over", "the", "splits", "of", "the", "training", "and", "test", "data", ",", "BMAA", "*", ",", "FAR", ",", "and", "WHCA"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "flow annotation replanning"}, {"tokens": ["There", "are", "40", "MTCDs", "uniformly", "distributed", "with", "a", "BS", "in", "the", "center", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["However", ",", "in", "recent", "years", "multiple", "IB", "relaxations", "for", "Gaussianpart", ":", "chechik", ":", "gib", "and", "meta", "-", "Gaussian", "variablespmgib", "have", "been", "proposed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Languages", "in", "the", "LTT", "and", "NC", "classes", "can", "be", "defined", "with", "first", "-", "order", "statements", "over", "relational", "structures", "representing", "sequences", "where", "the", "order", "relation", "is", "given", "as", "successor", "and", "precedence", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "locally threshold testable"}, {"tokens": ["The", "capture", "model", "seeks", "to", "\"", "undo", "\"", "the", "ISP", "processing", "that", "has", "already", "been", "applied", "to", "these", "images", "when", "they", "were", "originally", "captured", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["As", "there", "is", "no", "effective", "vaccine", "for", "ASF", ",", "we", "model", "hypothetical", "vaccines", "with", "80", "efficacy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "african swine fever"}, {"tokens": ["ET", "reconstructionTo", "simulate", "emission", "tomography", "reconstruction", "we", "designed", "a", "more", "realistic", "phantom", "from", "the", "high", "-", "quality", "X", "-", "ray", "scan", "of", "a", "mice", "bone", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "emission tomography"}, {"tokens": ["If", "the", "and", "are", "known", "or", "designed", "well", "in", "advance", ",", "then", "the", "above", "optimization", "degenerates", "towards", "the", "following", "simple", "PA", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power allocation"}, {"tokens": ["This", "dataset", "can", "be", "used", "to", "train", "natural", "language", "generation", "applications", "that", "perform", "a", "syntactic", "TS", ",", "simplifying", "sentences", "with", "a", "complex", "linguistic", "structure", "into", "a", "fine", "-", "grained", "representation", "of", "short", "sentences", "that", "present", "a", "simple", "and", "more", "regular", "structure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "target syntactic"}, {"tokens": ["On", "the", "other", "hand", ",", "excluding", "the", "TSGD", "has", "fewer", "failures", "than", "excluding", "the", "QA", ",", "even", "though", "it", "has", "the", "longest", "initial", "solution", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "quantum annealing"}, {"tokens": ["In", "this", "section", ",", "we", "propose", "a", "low", "-", "complexity", "algorithm", "to", "solve", "Problem", "when", "UEs", "have", "been", "selected", "by", "using", "the", "UE", "selection", "algorithms", "in", "Section", ",", "and", "denote", "the", "selected", "subset", "of", "UEs", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "this", "paper", ",", "we", "investigate", "LA", "and", "PA", "spoofing", "detection", "on", "the", "ASVspoof", "2019", "dataset", "using", "ensemble", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["to", "fit", "this", "channel", "access", "scheme", "with", "the", "periodic", "LTE", "subframe", "structure", ",", "we", "require", "both", "and", "should", "be", "integer", "multiples", "of", "LTE", "subframe", "duration", "which", "is", "1ms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["ROC", "curves", "for", "both", "schemes", "[", "h", "!", "]"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["DCNN", "ArchitecturesIn", "this", "section", ",", "we", "will", "present", "the", "most", "influential", "DCNN", "architectures", "that", "have", "shaped", "the", "current", "state", "-", "of", "-", "the", "-", "art", "in", "object", "recognition", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Based", "on", "the", "ET", "framework", ",", "the", "probability", "distributions", ",", "possible", "distributions", ",", "and", "intervals", "can", "be", "converted", "into", "DS", "structures", "with", "a", "finite", "number", "of", "closed", "intervals", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "evidence theory"}, {"tokens": ["It", "is", "worth", "noting", "that", "caching", "the", "content", "at", "the", "EC", "prevents", "us", "from", "functional", "splitting", "since", "the", "content", "is", "already", "at", "EC", "and", "it", "is", "not", "meaningful", "to", "centralize", "processing", "at", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "central cloud"}, {"tokens": ["We", "design", "a", "new", "FM", "module", ",", "which", "is", "flexible", "to", "plug", "in", "any", "modern", "DCNN", "architectures", ";", "iii", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["We", "also", "observe", "that", "BOA", "achieves", "a", "lower", "constant", "as", "compared", "to", "the", "DE", "and", "GA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["For", "our", "experiment", "on", "training", "a", "QA", "system", ",", "we", "extracted", "(", "see", "Section", ")", "the", "knowledge", "stored", "in", "Dbpedia", "Infobox", "Properties,(http://downloads.dbpedia.org/2016", "-", "04/core", "-", "i18n", "/", "en", "/", "infobox_properties_en.ttl.bz2", ")", "which", "with", "its", "n", "-", "triple", "structure", "represents", "answers", "to", "particular", "questions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["this", "work", ",", "we", "focus", "on", "explicit", "CF", "as", "well", "as", "CTR", "prediction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Though", ",", "AR", "can", "be", "looked", "from", "the", "point", "of", "view", "of", "enhancement", "to", "reality", ",", "it", "can", "be", "defined", "as", "AR", "is", "use", "of", "computers", "to", "enhance", "the", "richness", "of", "the", "real", "world", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Inspired", "by", "Net2Net", ",", "we", "can", "firstly", "train", "a", "part", "of", "PNN", "(", "e.g.", ",", "the", "FNN", "or", "FM", "part", ")", "as", "the", "initialization", ",", "and", "then", "start", "to", "let", "the", "back", "propagation", "go", "over", "the", "whole", "net", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Secondly", ",", "the", "need", "of", "tools", "that", "scale", "enough", "to", "the", "huge", "size", "of", "real", "-", "world", "RS", "images", "and", "datasets", ",", "raises", "as", "a", "major", "computing", "challenge", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["(", "ECC", "on", ")", "&", "Our", "Histogram", "&", "45.3", "&", "42.5", "&", "45.4", "&", "37.8", "&", "32.1", "&", "26.5", "&", "24.2", "&", "18.8", "&", "&", "CUB", "&", "13.7", "&", "14.9", "&", "16.9", "&", "19.1", "&", "21.4", "&", "21.8", "&", "20.8", "&", "19.5", "&", "&", "Speedup", "vs.", "CUB", "&", "3.30x", "&", "2.86x", "&", "2.69x", "&", "1.98x", "&", "1.50x", "&", "1.21x", "&", "1.16x", "&", "0.96x", "2", "-", "11", "&", "3*Tesla", "K40c", "(", "ECC", "off", ")", "&", "Our", "Histogram", "&", "53.0", "&", "47.2", "&", "48.1", "&", "38.3", "&", "32.3", "&", "26.5", "&", "24.0", "&", "18.7", "&", "&", "CUB", "&", "13.6", "&", "14.7", "&", "16.7", "&", "18.9", "&", "21.3", "&", "21.8", "&", "20.7", "&", "19.5", "&", "&", "Speedup", "vs.", "CUB", "&", "3.90x", "&", "3.20x", "&", "2.88x", "&", "2.03x", "&", "1.52x", "&", "1.21x", "&", "1.16x", "&", "0.96x", "2", "-", "11", "&", "3*GeForce", "GTX", "1080", "&", "Our", "Histogram", "&", "61.0", "&", "61.1", "&", "60.9", "&", "60.7", "&", "60.2", "&", "45.2", "&", "59.6", "&", "52.7", "&", "&", "CUB", "&", "60.5", "&", "60.7", "&", "60.5", "&", "60.7", "&", "61.1", "&", "60.6", "&", "60.3", "&", "60.9", "&", "&", "Speedup", "vs.", "CUB", "&", "1.01x", "&", "1.01x", "&", "1.01x", "&", "1.00x", "&", "0.98x", "&", "0.75x", "&", "0.99x", "&", "0.87x"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["GA", "and", "PSO", "algorithms", "were", "used", "separately", "to", "select", "the", "optimal", "set", "of", "inputs", "that", "maximizes", "the", "network", "efficiency", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["a", ")", "The", "series", "of", "two", "typical", "TIs", "TI", "1(up", ")", "and", "TI", "2(bottom", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["Furthermore", ",", "in", "the", "case", "of", "lower", "SI", ",", "RS", "behaves", "better", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["Training", "an", "entire", "DCNN", "with", "random", "initialization", "is", "highly", "computationally", "intensive", "and", "may", "not", "be", "practically", "feasible", "due", "to", "a", "limited", "dataset", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["AN", "beams", "toward", "the", "eavesdroppers", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Therefore", ",", "an", "accurate", "and", "independent", "measurement", "of", "VAT", "and", "SAT", "volumes", "(", "VAT", "-", "V", "and", "SAT", "-", "V", ")", "is", "of", "significant", "clinical", "and", "research", "interest", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Though", "the", "best", "feature", "combination", "tuned", "on", "development", "set", "gives", "better", "SER", "than", "the", "IB", "system", ",", "we", "observed", "that", "it", "may", "not", "always", "show", "improvement", "over", "LSF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Hyper", "-", "parameters", "in", "GP", "that", "control", "the", "degree", "of", "spatial", "smoothness", "and", "temporal", "variability", "are", "determined", "using", "the", "training", "data", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "general", ",", "GP", "in", "its", "standard", "form", "is", "a", "non", "-", "convex", "optimization", "problem", ",", "because", "posynomials", "and", "monomials", "functions", "are", "non", "-", "convex", "functions", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Overall", ",", "the", "proposed", "mechanism", "exceeds", "by", "48", "the", "without", "FEC", "scheme", "when", "it", "comes", "to", "video", "quality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Our", "protocol", "is", "built", "on", "the", "semi", "-", "honest", "secure", "extension", "protocol", "of", "Kolesnikov", "and", "Kumaresan", "of", "CRYPTO'13", "(", "referred", "as", "KK13", "protocol", "henceforth", ")", "which", "is", "the", "best", "known", "OT", "extension", "for", "short", "secrets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Image", "perturbations", "can", "be", "repeated", "multiple", "times", "and", "thus", "allows", "a", "more", "precise", "estimation", "of", "the", "ICC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["The", "average", "difference", "between", "NPMs", "of", "healthy", "subjects", "and", "patients", "for", "NP", "models", "with", "different", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["The", "first", "one", "attempts", "to", "complement", "the", "original", "pose", "-", "incomplete", "information", "carried", "by", "the", "sequences", "with", "synthetic", "GAN", "-", "generated", "images", ",", "and", "fuse", "their", "feature", "vectors", "into", "a", "more", "discriminative", "viewpoint", "-", "insensitive", "embedding", ",", "namely", "Weighted", "Fusion", "(", "WF", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "weighted fusion"}, {"tokens": ["FA", ":", "feature", "alignment", ";", "HGP", ":", "hierarchical", "Gaussian", "process", ";", "GPA", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process adaptation"}, {"tokens": ["The", "end", "-", "to", "-", "end", "OP", "of", "repetitive", "transmission", "is", "easily", "obtained", "using", "asSubstituting", "Eq", ":", "CDF_gEND_MRD_Distinct_C", "and", "Eq", ":", "CDF_gEND_MRD_Same_C", "to", "Eq", ":", "OP_Rep", ",", "closed", "-", "form", "expressions", "for", "the", "of", "repetitive", "transmission", "with", "MRD", "over", "INID", "Nakagami-", "fading", "channels", "with", "integer", "'s", "and", "distinct", "'s", "as", "well", "as", "with", "arbitrary", "'s", "and", ",", "respectively", ",", "are", "obtained", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal ratio diversity"}, {"tokens": ["To", "the", "best", "of", "our", "knowledge", ",", "there", "is", "no", "research", "work", "concerning", "how", "to", "design", "TAS", "methods", "for", "secure", "SM", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["AcknowledgementsThe", "original", "TLS", "scans", "of", "the", "trees", "used", "in", "this", "study", "are", "the", "property", "of", "Raisa", "Makipaa", ",", "raisa.makipaa@luke.fi", ",", "Natural", "Resources", "Institute", "Finland", ",", "Latokartanonkaari", "9", ",", "FI-00790", "Helsinki", ",", "FINLAND", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "terrestrial laser scanning"}, {"tokens": ["By", "using", "Fresnel", "-", "zone", "-", "plate", "lenses", "antenna", "at", "BS", ",", "this", "issue", "can", "be", "mitigated", "without", "affecting", "the", "helical", "phase", "profile", "of", "OAM", "beam", "[", "15", "-", "17].The", "normalized", "channel", "matrix", "can", "be", "expressed", "as", "follows", "[", "16", "]", "where", "is", "the", "index", "of", "the", "receiving", "antenna", "and", "is", "the", "total", "number", "of", "receiving", "antennas", "[", "16].", "Since", "one", "OAM", "beam", "is", "considered", "here", "to", "transmit", "by", "OAM", ",", "so", "there", "are", "no", "possibilities", "of", "intersymbol", "interference", "or", "intermodal", "interference", "among", "the", "OAM", "beams", "for", "LOS", "system", "[", "16].", "Relay", "TransmissionIn", "the", "second", "time", "slot", ",", "Link", "4", "is", "transmitted", "with", "total", "transmit", "power", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["the", "VGG13", ",", "CRNN", "and", "GCNN", "architectures", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["With", "the", "GMM", "method", ",", "we", "can", "adaptively", "adjust", "the", "decision", "surface", "for", "classification", ",", "which", "can", "better", "distinguish", "anomalies", "from", "normal", "activities", "in", "videos", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "main", "idea", "of", "GP", "-", "MI", "is", "to", "use", "simulators", "with", "tunable", "parameters", ",", "i.e.", ",", "mean", "functions", "of", "the", "form", "where", "each", "vector", "corresponds", "to", "a", "different", "prior", "model", "of", "the", "system", "(", "e.g.", ",", "different", "lengths", "of", "links", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Fully", "Automated", "Lung", "CT", "Cancer", "DiagnosisThe", "DeepLung", "system", "includes", "the", "nodule", "detection", "using", "the", "3D", "Faster", "R", "-", "CNN", ",", "and", "nodule", "classification", "using", "GBM", "with", "constructed", "feature", "(", "deep", "3D", "dual", "path", "features", ",", "nodule", "size", "and", "raw", "nodule", "CT", "pixels", ")", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["Then", ",", "maximizing", "and", "can", "obtain", "the", "same", "point", "in", "the", "IB", "curve", "if", ",", "where", "is", "the", "derivative", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "the", "second", "phase", "of", "our", "research", "we", "proposed", "a", "new", "wrapper", "-", "based", "Tabu", "Search", "-", "Random", "Forest", "(", "TS", "-", "RF", ")", "feature", "selection", "algorithm", "for", "IDS", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["Both", "the", "BS", "and", "the", "users", "have", "ULA", "antennas", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "performance", "of", "the", "LS", "and", "LMMSE", "estimators", "would", "significantly", "degrade", "when", "deployed", "in", "nonlinear", "systems", "since", "the", "biases", "between", "the", "estimated", "channels", "derived", "from", "the", "linear", "estimators", "and", "the", "target", "channels", "are", "in", "general", "large", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["Datasets", "and", "EnvironmentsIn", "this", "section", ",", "we", "describe", "a", "set", "of", "environments", "with", "incremental", "difficulty", ",", "designed", "to", "assess", "SRL", "algorithms", "for", "robotic", "control", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["3D", "Human", "Pose", "CAD", "ProgramWe", "can", "naturally", "define", "a", "compositional", "model", "over", "the", "parts", "parameterized", "by", "the", "GP", ",", "such", "as", "an", "infinite", "mixture", "of", "GP", "experts", "or", "a", "hierarchical", "GP", "mixture", "model", "to", "learn", "3D", "shapes", "such", "as", "human", "bodies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "expectation", "is", "computed", "with", "respect", "to", "the", "GP", "prior", "conditioned", "on", "the", "sparse", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["Number", "of", "appearance", "of", "a", "word", "in", "the", "entire", "corpus", "\u201d", "is", "defined", "to", "be", "the", "total", "number", "of", "occurrences", "of", "a", "word", "in", "the", "LSC", "when", "the", "corpus", "is", "considered", "as", "one", "large", "document", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["We", "name", "this", "algorithm", "class", "-", "dependent", "OLS", "(", "cdOLS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["In", "future", "work", ",", "we", "plan", "to", "evaluate", "the", "classification", "of", "the", "rhetorical", "relations", ",", "examine", "to", "what", "extent", "other", "NL", "Processing", "tasks", "such", "as", "QA", "systems", "may", "benefit", "from", "the", "results", "produced", "by", "our", "framework", "and", "investigate", "the", "creation", "of", "big", "knowledge", "graphs", "for", "QA", "by", "performing", "a", "large", "-", "scale", "Wikipedia", "extraction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["They", "indicate", "that", "both", "models", "can", "interpret", "the", "same", "string", "as", "either", "a", "coordinated", "noun", "phrase", ",", "or", "as", "an", "NP", "object", "and", "the", "start", "of", "a", "coordinated", "VP", "with", "the", "second", "NP", "as", "its", "subject", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "noun phrase"}, {"tokens": ["If", "we", "use", "Proposition", "on", "both", "Lagrangians", "we", "obtain", "the", "bijective", "mapping", "between", "their", "Lagrange", "multipliers", "and", "a", "certain", "level", "of", "compression", "in", "the", "classification", "setting", ":", "Power", "IB", "Lagrangian", ":", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["recognitionIntroductionConnected", "components", "labeling", "(", "CCL", ")", "is", "a", "task", "to", "give", "a", "unique", "ID", "to", "each", "connected", "region", "in", "a", "2D/3D", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "input data"}, {"tokens": ["Thus", ",", "mobile", "user", "is", "able", "to", "figure", "out", "the", "best", "RS", "subsequently", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "relay station"}, {"tokens": ["Per", "-", "user", "power", "constraints", ",", "backhaul", "capacity", "constraints", "and", "throughput", "requirements", "have", "been", "considered", "and", "an", "SCA", "has", "been", "exploited", "to", "convert", "the", "power", "allocation", "problem", "into", "a", "GP", "and", "efficiently", "solve", "the", "non", "-", "convex", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["As", "we", "are", "aware", "that", "heteroskedasticity", "is", "also", "a", "fair", "concern", "that", "clearly", "could", "affect", "these", "results", ",", "we", "also", "perform", "an", "OLS", "\u201c", "robust", "\u201d", "estimation", "following", "White", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "ordinary least square"}, {"tokens": ["Taking", "a", "similar", "approach", ",", "Ferres2016", "describe", "a", "linguistically", "-", "motivated", "rule", "-", "based", "TS", "approach", "called", "YATS", ",", "which", "relies", "on", "part", "-", "of", "-", "speech", "tags", "and", "syntactic", "dependency", "information", "to", "simplify", "a", "similar", "set", "of", "linguistic", "constructs", ",", "using", "a", "set", "of", "only", "76", "hand", "-", "crafted", "transformation", "patterns", "in", "total", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["VAT", "-", "V", "to", "SAT", "-", "V", "ratio", "is", "higher", "in", "overweight", "and", "obese", "participants", "compared", "to", "those", "with", "normal", "weight", "(", "p<0.001", ")", ",", "but", "there", "is", "no", "difference", "between", "overweight", "and", "obese", "(", "p=0.505", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Moreover", ",", "we", "find", "that", "the", "advantage", "of", "RL", "over", "RS", "is", "larger", "in", "this", "case", "(", "RL", "achieves", "1.54", "better", "validation", "accuracy", "than", "RS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random search"}, {"tokens": ["Moreover", ",", "we", "take", "the", "MQ", ",", "BQ", "and", "the", "given", "image", "as", "the", "input", "of", "Module", "2", ",", "the", "VQA", "module", "with", "co", "-", "attention", "mechanism", ",", "and", "then", "it", "can", "output", "the", "final", "answer", "of", "MQ", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["Substituting", "Equation", "(", ")", "into", "Equation", "(", ")", ",", "the", "packet", "error", "probability", "at", "the", "BS", "can", "be", "given", "by", "Therefore", ",", "the", "can", "be", "The", "data", "payload", "stored", "on", "each", "node", "is", "represented", "by", "and", "the", "fairness", "coefficients", "is", ",", "where", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["However", ",", "on", "the", "PA", "tasks", "our", "single", "model", "B", "outperforms", "ensemble", "models"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["This", "is", "especially", "true", "for", "the", "baseline", "because", "it", "does", "not", "use", "any", "type", "of", "FEC", "-", "based", "mechanism", "to", "secure", "the", "transmissions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Measured", "training", "throughput", "of", "RA", "."], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "ring allreduce"}, {"tokens": ["We", "demonstrated", "normative", "modeling", "as", "a", "possible", "target", "application", "for", "NP", "-", "based", "mixed", "-", "effect", "modeling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["In", "the", "experiments", ",", "we", "demonstrate", "that", "the", "performance", "of", "GPA", "outperforms", "the", "state", "-", "of", "-", "the", "-", "arts", "on", "various", "tasks", ",", "i.e.", ",", "link", "prediction", "and", "node", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["We", "adapt", "the", "IB", "for", "learning", "the", "outcome", "of", "a", "therapy", "when", "partial", "covariate", "information", "is", "available", "for", "at", "test", "time", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["workMcDaidSBM", "for", "a", "detailedanalysis", "of", "the", "accuracy", "of", "the", "collapsed", "SBM", "MCMC", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Each", "element", "of", "the", "RDM", "reflects", "the", "measure", "of", "dissimilarity", "(", "distance", ")", "among", "the", "neural", "activity", "patterns", "(", "i.e.", ",", "the", "object", "representations", ")", "associated", "with", "two", "different", "image", "stimuli", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "representational dissimilarity matrix"}, {"tokens": ["In", "Figure", ",", "we", "have", "shown", "that", "the", "length", "of", "the", "CC", "phase", "reduces", "as", "the", "capacity", "of", "the", "battery", "reduces", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["We", "discuss", "our", "view", "of", "what", "should", "be", "included", "in", "the", "\"", "IS", "logic", "toolbox", "\"", "in", "order", "for", "the", "students", "to", "be", "able", "to", "carry", "out", "activities", "for", "checking", "(", "by", "proof", ",", "analysis", "or", "testing", ")", "that", "a", "software", "system", "meets", "specifications", "and", "fulfills", "its", "intended", "purpose", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["At", "the", "end", "of", "the", "optimization", "process", ",", "the", "best", "individual", "is", "used", "as", "misclassification", "costs", "to", "form", "an", "ECS", "-", "DBN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["Also", ",", "we", "assume", "that", "a", "user", "is", "served", "by", "at", "most", "one", "BS", "(", "either", "a", "macrocell", "BS", ",", "MBS", ",", "or", "DBS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["To", "recall", ",", "in", "this", "setting", ",", "the", "three", "models", ",", "and", "(", "with", "and", "frozen", ")", "are", "trained", "jointly", "in", "a", "semi", "-", "supervised", "way", "and", "Tinyface", "training", "images", "are", "used", "as", "real", "LR", "data", "for", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["It", "can", "be", "observed", "that", "the", "local", "data", "is", "not", "accessed", "by", "the", "BS", ",", "so", "as", "to", "protect", "the", "privacy", "of", "users", ",", "as", "is", "required", "by", "FL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "federated learning"}, {"tokens": ["*", "arani-", "OP", "arasni-", "'", "cubit", "'", "MP", "aresn", "NP"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "new persian"}, {"tokens": ["We", "created", "such", "datasets", "for", "each", "kind", "of", "Question", "Answering", "task", ",", "and", "study", "the", "relation", "between", "the", "quality", "of", "the", "questions", "and", "performance", "on", "the", "QA", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["To", "achieve", "this", "we", "need", "to", "modify", "the", "cost", "function", "(", "consequently", "also", "the", "message", "passing", "phase", ")", "and", "the", "decision", "mechanism", "for", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "affinity propagation"}, {"tokens": ["A", "snapshot", "of", "a", "DD", "relay", "-", "assisted", "cellular", "network", "with", "BS", "and", "MSs", "in", "a", "slot", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["As", "one", "can", "see", ",", "the", "CSG", "(", "red", "dots", ")", "stays", "roughly", "unchanged", "for", "reduction", "ratios", "below", "but", "then", "increases", "sharply", "after", "that", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cumulative spectral gradient"}, {"tokens": ["Fraudulent", "Services", "(", "FS", ")", "Domains", "and", "IP", "addresses", "engaged", "in", "the", "distribution", "or", "provisioning", "of", "bogus", "or", "fraudulent", "services", "or", "applications", "such", "as", "the", "promotion", "of", "comments", ",", "likes", ",", "ratings", ",", "votes", "or", "any", "variations", "thereof", "de2014paying", ",", "Ikram:2017:MCD", ",", "farooqicharacterizing", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fraudulent services"}, {"tokens": ["Their", "work", "is", "positioned", "within", "the", "broader", "SP", "literature", ",", "where", "traditionally", "SMT", "and", "parsing", "methods", "are", "used", "to", "study", "the", "problem", "of", "translating", "text", "to", "formal", "meaning", "representations", ",", "usually", "centering", "around", "QA", "applications", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic parsing"}, {"tokens": ["On", "the", "practical", "front", ",", "OT", "has", "been", "pivotal", "in", "building", "several", "state", "-", "of", "-", "the", "-", "art", "practically", "efficient", "general", "MPC", "protocols", "and", "several", "protocols", "for", "special", "-", "purpose", "problems", "of", "interest", "such", "as", "private", "set", "intersection", "(", "PSI", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "PS", "incorporates", "gradients", "from", "all", "nodes", "and", "updates", "the", "stored", "model", "parameters", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["TD", "-", "LR", "approach", "has", "the", "worst", "performance", "because", "of", "the", "inconsistent", "nodes", "present", "in", "the", "original", "hierarchy", "that", "are", "negatively", "impacting", "the", "generalization", "capabilities", "of", "learned", "models", "at", "the", "higher", "levels", "(", "see", "Section", ")", ",", "which", "results", "in", "error", "propogation", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["fine", "-", "tuned", "the", "VGG-16", "model", "trained", "under", "natural", "images", "to", "detect", "ships", "in", "SAR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["The", "computations", "to", "determine", "all", "the", "outgoing", "messages", "from", "factor", "node", "still", "have", "overall", "computational", "complexity", ",", "same", "as", "the", "factor", "node", "in", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "affinity propagation"}, {"tokens": ["The", "channel", "between", "the", "BS", "and", "each", "user", "is", "assumed", "to", "be", "Rice", "model", "with", "paths", "totally", "and", "the", "Rician", "K", "-", "factor", "is", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Logistic", "Regression", "(", "LR", ")", "&", "A", "simple", "classification", "algorithm", "for", "predicting", "a", "binary", "discrete", "variable", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["For", "a", "specific", "channel", "realization", "and", "the", "th", "selected", "pattern", ",", "the", "transmission", "rates", "of", "desired", "and", "eavesdropping", "channels", "are", "respectively", "bounded", "aswhere", "and", "are", "given", "byThen", ",", "the", "corresponding", "SR", "is", "bounded", "asNotice", "that", "and", "are", "the", "functions", "of", ",", "thus", "we", "can", "carefully", "select", "a", "pattern", "for", "maximizing", ",", "which", "can", "be", "formulated", "asIn", "general", ",", "the", "optimal", "TAS", "pattern", "for", "(", ")", "is", "usually", "obtained", "by", "an", "exhaustive", "search", "approach", "due", "to", "the", "fact", "that", "the", "in", "(", ")", "is", "associated", "with", "the", "selected", "pattern", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["The", "main", "contribution", "of", "this", "paper", "is", "a", "novel", "energy", "efficient", "transmission", "and", "computation", "resource", "allocation", "scheme", "for", "FL", "over", "wireless", "communication", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["FEC", "-", "based", "schemes", "have", "been", "successfully", "used", "in", "real", "-", "time", "systems", "Nafaa2008", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Any", "powerful", "density", "estimator", "which", "fulfils", "this", "condition", "could", "provide", "a", "base", "measure", "which", "could", "then", "potentially", "be", "improved", "by", "the", "GP", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["tp", "-", "sequencefigureThe", "larger", "the", "number", "of", "clusters", "in", "use", ",", "the", "more", "often", "the", "TP", "sees", "an", "event", "(", "changes", ")", ",", "and", "the", "more", "frequently", "it", "learns", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["Our", "sentiment-", "and", "cluster", "-", "controlled", "systems", "outperform", "TS", "in", "max", "metric", "scores", "and", "BS", "in", "diversity", "(", "self", "-", "BLEU", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature - based sampling"}, {"tokens": ["AP", "calculation", "."], "acronym_pos": [1, 0, 0], "long_form": "average precision"}, {"tokens": ["wV(C)r-", "NP", "gV(C)r-:[noitemsep]PIr", "*", "uaraja-", "MP", "waraz", "NP", "guraz", "'", "boar'PIr", "*", "uart-", "'", "turn", "'", "OP"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["(", "ECC", "on", ")", "&", "5cGeForce", "GTX", "1080", "(", "r)2", "-", "6(l)7", "-", "11Graph", "Name", "&", "Near", "-", "Far", "&", "Bucketing", "&", "3cMultisplit", "-", "SSSP", "&", "Near", "-", "Far", "&", "Bucketing", "&", "3cMultisplit", "-", "SSSP", "(", "r)1", "-", "1", "(", "r)2", "-", "2", "(", "r)3", "-", "3", "(", "r)4", "-", "6", "(", "l)7", "-", "7", "(", "l)8", "-", "8", "(", "l)9"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["Moreover", ",", "in", "order", "to", "achieve", "a", "particular", "level", "of", "performance", "multiple", "optimizations", "with", "different", "Lagrange", "multipliers", "must", "be", "done", "to", "draw", "the", "IB", "curve", "and", "select", "the", "best", "traded", "-", "off", "representation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["GBM", "is", "best", "on", "3", "datasets", "but", "also", "struggled", "with", "the", "two", "Ozone", "datasets", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["We", "find", "that", "spoofed", "audio", "recordings", "for", "the", "PA", "task", "tend", "to", "have", "more", "silence", "at", "the", "end", "than", "bonafide", "recordings", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["Convergence", "curves", "for", "regression", "by", "DE", "(", "left", ")", "and", "CMA", "-", "ES", "(", "right", ")", "using", "the", "sinc2d", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Similarly", ",", "107", "example", "ruptures", "are", "correctly", "identified", "as", "TP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "true positives"}, {"tokens": ["The", "Formula", "shows", "how", "much", "bandwidth", "is", "dedicated", "for", "each", "worker", "node", "to", "communicate", "with", "the", "PS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "parameter server"}, {"tokens": ["For", "this", "purpose", ",", "we", "analysed", "the", "role", "of", "a", "sufficient", "covariate", "in", "the", "context", "of", "the", "IB", "framework", "to", "estimate", "the", "causal", "effect", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "Table", ",", "our", "proposed", "method", "yields", "the", "highest", "overall", "SAD", "score", "over", "ground", "truth", "materials", "and", "the", "quality", "of", "abundance", "estimates", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["Here", "we", "demonstrate", "the", "idea", "using", "deterministic", "UE", "and", "Logit", "/", "Probit", "-", "based", "SUE", "as", "the", "route", "choice", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equilibrium"}, {"tokens": ["w.r.t", "transmit", "SNR", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["At", "time", ",", "the", "outage", "probability", "at", "the", "node", "is", "given", "by", "where", "is", "the", "SNR", "threshold", "required", "for", "successful", "reception", "at", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Average", "Precision", "(", "AP", ")", "in", "for", "different", "distance", "thresholds", "of", "a", "predicted", "set", "element", "to", "be", "considered", "correct", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["We", "say", "that", "an", "algorithm", "fails", "on", "a", "benchmark", "with", "metric", "AUC", "(", "or", "AP", ")", "at", "significance", "level", "if", "the", "computed", "AUC", "(", "or", "AP", ")", "quantiles", "are", "less", "than", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["To", "enable", "downlink", "analysis", "of", "the", "SINR", "coverage", "probability", ",", "we", "first", "derive", "fairly", "accurate", "analytical", "expressions", "of", "the", "distance", "distribution", "of", "nearest", "LOS", "/", "NLOS", "BS", "to", "typical", "UE", "and", "association", "probability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["We", "show", "an", "interesting", "application", "of", "our", "proposed", "extension", "protocol", "in", "OT", "-", "based", "PSI", "protocols", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["In", "the", "case", "of", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", ",", "CCU", "capacity", "is", "degraded", "than", "the", "proposed", "scheme", "due", "to", "using", "a", "dedicated", "time", "slot", "for", "each", "separate", "transmission", "from", "BS", "to", "CCU", ",", "excluding", "OAM", "based", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "distance", "between", "the", "AP", "and", "the", "vehicles", "are", "set", "as", ":", "(", "m", ")", ",", "where", "denotes", "the", "vehicle", "index", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Similar", "to", "FA", "tools", "used", "for", "contactless", "probing", ";", "the", "tools", "required", "for", "contact", "-", "based", "probing", "can", "be", "rented", "almost", "at", "the", "same", "rate", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["According", "to", "this", "model", ",", "a", "LOS", "probability", "is", "defined", "as", "a", "deterministic", "non", "-", "increasing", "function", "of", "distance", "denoted", "as", ",", "where", "is", "the", "distance", "between", "BSs", "and", "the", "typical", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["FR", "and", "XGB", "denote"], "acronym_pos": [1, 0, 0, 0], "long_form": "faster r - cnn"}, {"tokens": ["While", "the", "results", "associated", "with", "the", "Velocity", "Verlet", "and", "BCSS", "integrators", "are", "still", "far", "from", "the", "target", "value", ",", "the", "averages", "produced", "with", "AIA", "are", ",", "regardless", "a", "choice", "of", "simulation", "parameters", ",", "always", "closer", "to", "0.94", "nm", "both", "in", "HMC", "and", "in", "MD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "molecular dynamics"}, {"tokens": ["DBN", "provides", "higher", "average", "values", "on", "all", "evaluation", "metrics", "than", "other", "methods", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["For", "Bayesian", "inference", "we", "define", "a", "GP", "prior", "measure", "with", "zero", "mean", "and", "covariance", "kernel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "last", "two", "convolution", "layers", "were", "not", "replaced", "by", "LR", "or", "MLconv", "layer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "low rank"}, {"tokens": ["Simulation", "Parameters", "for", "GA", ",", "DE", "and", "BOA", "ResultsThe", "code", "has", "been", "run", "for", "the", "same", "population", "size", "and", "the", "optimal", "objective", "function", "variation", "with", "respect", "to", "the", "the", "number", "of", "generations", "is", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Additionally", ",", "for", "given", ",", "the", "SL", "and", "SP", "classes", "are", "learnable", "in", "the", "limit", "from", "positive", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Energy", "EfficiencyEE", "shows", "the", "ratio", "of", "SC", "and", "total", "transmitted", "power", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["Develop", "a", "classification", "method", ",", "based", "on", "the", "CC", "properties", "and", "the", "overlap", "among", "the", "vertices", "in", "the", "innermost", "core", "across", "consecutive", "time", "steps", ",", "to", "distinguish", "between", "networks", "for", "which", "the", "high", "centrality", "vertices", "can", "be", "predicted", "with", "high", "accuracy", "and", "networks", "for", "which", "reliable", "prediction", "is", "not", "possible", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "core connected"}, {"tokens": ["DiscussionThe", "results", "show", "that", ",", "when", "optimising", "the", "BBOB", "2015", "objective", "function", "suite", ",", "the", "predictive", "methodology", "out", "performed", "using", "fixed", "and", "adaptive", "tuning", "parameters", "for", "DE", "with", "p", "-", "values0.0001", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Actively", "Secure", "OT", "Extension", "ProtocolKK13OTEXTmal", "Protocol", "for", "from", "[", "-", "]", "Input", "of", ":", "tuples", "of", "bit", "strings", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["the", "first", "mobile", "AR", "game", "with", "high", "quality", "content", "at", "the", "level", "of", "commercial", "gamesGT09", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["ID", "with", "clusters", "and", "disks", "per", "cluster", ",", "can", "have", "only", "one", "disk", "failure", "per", "cluster", "and", "any", "one", "of", "the", "disks", "in", "a", "cluster", "can", "fail", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["The", "PPC", "also", "sees", "an", "increase", "of", "percent", ",", "which", "means", "that", "platform", "efficiency", "also", "increases", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pay per click"}, {"tokens": ["DMD", "solves", "the", "left", ",", "but", "not", "the", "right", "example", ",", "EMD", "solves", "the", "right", ",", "but", "not", "the", "left", "one", ",", "and", "iterative", "improvement", "solves", "both", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "excessive mapping dissolution"}, {"tokens": ["Figure", "in", "Section", "shows", "the", "speedups", "of", "IAW", "on", "NPR", "and", "IA", "on", "GMB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "incremental approximation"}, {"tokens": ["Next", "we", "use", "the", "rank", "-", "based", "model", "to", "generate", "the", "training", "data", ",", "which", "is", "shown", "to", "be", "equivalent", "to", "RUM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "random utility modelwe"}, {"tokens": ["Hence", ",", "the", "average", "number", "of", "users", "served", "by", "an", "active", "BS", "during", "time", "slot", "is", "denoted", "by", "and", "is", "given", "by", ":", "where", "is", "the", "minimum", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["(", "Video", "-", "aware", "FEC", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["introduced", "a", "new", "approach", "to", "the", "PSO", "algorithm", "for", "solving", "ELD", "problems", "considering", "non", "-", "smooth", "objective", "functions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["PAP", "therapy", "is", "applied", "through", "the", "use", "of", "a", "specialised", "medical", "device", "which", "delivers", "a", "highly", "controlled", "wave", "of", "pressurised", "air", "to", "the", "upper", "airway", ",", "acting", "as", "a", "pneumatic", "splint", "and", "preventing", "the", "blockage", "of", "the", "pharynx", "that", "characterises", "OSA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "obstructive sleep apnoea"}, {"tokens": ["This", "led", "to", "a", "situation", "where", "although", "CSIS", "might", "have", "one", "value", ",", "a", "DT", "could", "amend", "this", "data", "on", "a", "Base", "Inventory", "System", "otherwise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "delivery teams"}, {"tokens": ["We", "consider", "that", "the", "user", "distribution", "during", "time", "slot", "over", "the", "macrocell", "BS", "area", "follow", "a", "certain", "probability", "density", "function", "(", "pdf", ")", "denoted", "by", ",", "where", "represents", "the", "geographical", "coordinates", "of", "a", "user", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Decreased", "Fractional", "Anisotropy", "(", "FA", ")", "in", "the", "SN", "is", "commonly", "observed", "in", "PD", "patients", "using", "DTIcochrane2013diffusion", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fractional anisotropy"}, {"tokens": ["Furthermore", ",", "different", "from", "the", "LS", "and", "LMMSE", "estimators", "that", "can", "be", "applied", "to", "the", "whole", "input", "space", ",", "the", "learned", "DL", "estimator", "can", "only", "make", "valid", "estimate", "for", "the", "inputs", "that", "are", "restricted", "to", "regions", "where", "training", "samples", "are", "not", "empty", "and", "would", "behaves", "randomly", "outside", "these", "regions", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["increase", "of", "training", "and", "validation", "accuracy", "over", "500", "epochs", "for", "the", "low", "-", "latency", "convolution", "and", "VAT", "models", ":", "a", "zoomed", "-", "out", "version", "of", "fig:10epaIn", "figure", "12", "we", "can", "see", "the", "behavior", "of", "loss", "function", "with", "respect", "to", "time", "for", "all", "the", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["l0", ",", "in", "this", "letter", ",", "we", "focus", "on", "the", "two", "greedy", "pursuit", "based", "approaches", "-", "OMP", "and", "OLS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "orthogonal least square"}, {"tokens": ["On", "the", "other", "hand", ",", "RV", "and", "AV", "strategies", "require", "a", "higher", "number", "of", "nodes", "to", "be", "vaccinated", "with", "70", "and", "40", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["However", ",", "for", "higher", ",", "the", "OP", "of", "at", "CEU", "increased", "linearly", "due", "to", "the", "channel", "condition", "between", "BS", "and", "CCU", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "designed", "mechanism", "is", "based", "on", "ECC", "and", "blockchain", ";", "which", "helps", "vehicles", "to", "seamlessly", "access", "VFS", "with", "the", "following", "features", ":", "cross", "-", "data", "center", "authentication", ",", "user", "anonymity", ",", "mutual", "authentication", ",", "lightweight", ",", "user", "privacy", "and", "confidentiality", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["PSO", "In", ",", "Maurice", "Clerc", "and", "James", "Kennedy", "introduced", "the", "concept", "of", "constriction", "factor", "to", "PSO", "to", "solve", "problems", "of", "multidimensional", "search", "space", "efficiently", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["The", "number", "of", "fair", "nodes", "of", "our", "algorithm", "is", "more", "than", "the", "ones", "of", "FCFS", ",", "LE", "and", "HP", "for", "200", ",", "180", ",", "155", "nodes", "when", "=", "50", "and", "N", "=", "300", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low energy"}, {"tokens": ["The", "interval", "graph", "gives", "a", "reduced", "picture", "of", "temporal", "interactions", ",", "where", "vertices", "are", "individuals", ",", "and", "each", "edge", "represents", "at", "least", "one", "TI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "temporal interactions"}, {"tokens": ["In", "the", "case", "of", "a", "large", "target", ",", "this", "was", "often", "more", "readily", "found", "on", "the", "SDD", "as", "it", "was", "quicker", "to", "obtain", "this", "overview", "and", "therefore", "ascertain", "the", "target", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["The", "number", "of", "antennas", "at", "the", "users", "is", "and", "the", "resolution", "of", "the", "phase", "shifters", "is", "at", "the", "BS", "and", "at", "the", "user", "side", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Each", "controller", "is", "responsible", "for", "a", "theoretical", "subset", "of", "SAR", "actions", ",", "henceforth", "referred", "to", "as", "SAR", "acts", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Among", "the", "non", "variational", "methods", ",", "the", "VCC", "theory", "constitutes", "a", "robust", "way", "to", "get", "precision", "out", "of", "small", "spaces", "with", "a", "computational", "cost", "sharply", "increasing", "with", "the", "level", "of", "excitations", "exponentially", "deployed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vibrational coupled cluster"}, {"tokens": ["The", "impact", "of", "changes", "in", "transmit", "SNR", ",", "allowed", "power", "splitting", "factor", ",", "distance", "between", "BS", "and", "on", "the", "performance", "of", "the", "considered", "system", "are", "discussed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "sparse", "approximation", "assumes", "a", "variational", "posterior", "of", "the", "formwhere", "is", "the", "GP", "evaluated", "at", "a", "finite", "set", "of", "inducing", "points", "and", "is", "the", "conditional", "prior", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["From", "the", "tables", ",", "reports", "that", "all", "top", "5", "classifiers", "performing", "well", "under", "the", "CC", ",", "LC", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "classifier chain"}, {"tokens": ["The", "locations", "of", "the", "BS", ",", "destination", "users", "and", "eavesdroppers", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["A", "transmit", "power", "vector", "is", "an", "-dimensional", "vector", "in", "which", "element", ",", ",", "for", ",", "denotes", "the", "power", "expended", "by", "MS", "to", "transmit", "packets", "to", "MS", "over", "the", "link", "and", "is", "the", "power", "expended", "by", "MS", "for", "transmitting", "directly", "to", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Their", "capability", "may", "also", "include", "netlist", "reverse", "engineering", "and", "access", "to", "FA", "lab", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "failure analysis"}, {"tokens": ["Most", "feature", "extractors", "used", "in", "the", "DCNN", "-", "DCF", "based", "tracking", "systems", "are", "pretrained", "on", "the", "large", "ImageNet", "classification", "dataset", ",", "which", "contains", "more", "than", "1", "million", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Moreover", ",", "if", "HEFT", "achieves", "the", "best", "absolute", "performance", "with", "respect", "to", "DADA", "on", "QR", ",", "while", "DADA", "hassimilar", "or", "better", "performances", "than", "HEFT", "on", "Cholesky", "and", "LU", "for", "large", "numbers", "of", "GPU", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["We", "assume", "a", "NOMA", "system", "with", "a", "BS", ",", "relay", "and", "two", "sets", "of", "users", "and", "use", "stochastic", "geometry", "to", "capture", "the", "impact", "of", "random", "locations", "of", "the", "users", "in", "a", "cooperative", "NOMA", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["-", "Step", "1", "-", "First", "pass", ":", "In", "the", "first", "pass", ",", "we", "perform", "IB", "based", "diarization", "that", "is", "followed", "by", "KL", "-", "HMM", "based", "realignment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "storage", "sub", "-", "system", "of", "OCFA", "used", "physical", "symbolic", "links", "to", "CarvFS", "CarvPaths", "inside", "of", "its", "primarily", "CAS", "based", "storage", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "content addressed storage"}, {"tokens": ["ROC", "curves", "for", "classification"], "acronym_pos": [1, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["POS", "Tagging", "and", "Dependency", "ParsingThe", "joint", "POS", "tagging", "and", "dependency", "parsing", "model", "in", "spaCy", "is", "an", "arc", "-", "eager", "transition", "-", "based", "parser", "trained", "with", "a", "dynamic", "oracle", ",", "similar", "to", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["When", "using", "the", "continual", "GP", "approach", ",", "this", "problem", "disappears", ",", "as", "one", "can", "augment", ",", "reduce", "or", "keep", "constant", "the", "number", "of", "inducing", "-", "inputs", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Neural", "ISP", "Algorithms", "."], "acronym_pos": [0, 1, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Thus", ",", "ARD", "is", "a", "natural", "analogue", "of", "adversarial", "training", "but", "in", "the", "context", "of", "distillation", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["We", "compare", "the", "final", "voltage", "of", "multiple", "devices", "of", "same", "model", "and", "find", "that", "38", "of", "the", "devices", "use", "CC", "-", "CV", "and", "59", "use", "DLC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant current"}, {"tokens": ["This", "is", "because", "a", "small", "number", "of", "devices", "apply", "the", "CV", "charging", "to", "charge", "the", "first", "10", "and", "then", "the", "CC", "charging", "begins", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "constant charging"}, {"tokens": ["Additionally", ",", "in", "order", "to", "prevent", "over", "-", "fitting", ",", "the", "popular", "L2", "regularization", "term", "is", "added", "to", "the", "loss", "function", "when", "training", "LR", "and", "FM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["The", "designed", "system", "used", "4", "number", "of", "entropy", "measurements", ",", "CEM", ",", "SEM", ",", "IEM", "and", "GEM", "of", "SODP", "in", "ECG", "time", "-", "series", ",", "as", "discriminative", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "squared entropy measurement"}, {"tokens": ["There", "are", "recordings", "(", "from", "SC", "subjects", "from", "ST", "subjects", ")", "in", "the", "training", "set", "and", "recordings", "(", "from", "SC", "subjects", "from", "ST", "subjects", ")", "in", "the", "test", "set", "of", "the", "RS", "-", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "random split"}, {"tokens": ["UAV", "-", "Based", "SAR", "SystemSAR", "operations", "using", "traditional", "aerial", "systems", "(", "e.g.", ",", "aircrafts", "and", "helicopters", ")", "are", "typically", "very", "costly", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["Then", "each", "is", "a", "concatenation", "of", "word", "-", "embedding", "vector", "(", "embedding", "representation", "of", "word", "and", "trained", "on", "PubMed", "abstracts", ")", ",", "POS", "-", "embedding", "vector", "(", "also", "trained", "on", "PubMed", "abstract", ")", ",", "and", "position", "-", "embedding", "vector", "(", "mapped", "each", "distance", "value", "to", "a", "10-dimensional", "vector", "initialized", "by", "normal", "random", "distribution", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "Kappa", "value", "of", "ECS", "-", "DBN", "is", "0.9156", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["We", "observe", "that", "ICA", "performs", "well", ",", "but", "not", "as", "well", "as", "DMF", "(", "or", "as", "quickly", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["The", "two", "-", "player", "game", "may", "be", "arranged", "as", "a", "clinician", "(", "first", "avatar/", "instructor", ")", "shows", "the", "movements", "of", "the", "patient", "(", "second", "avatar", ")", "in", "that", "the", "patient", "follows", "the", "actions", "of", "the", "clinician", "and", "accordingly", "the", "patient", "'s", "ROM", "is", "recorded", "by", "the", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "range of motion"}, {"tokens": ["The", "authors", "claim", "that", "the", "throughput", "increases", "nearly", "linearly", "with", "the", "number", "of", "antennas", "at", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access part"}, {"tokens": ["the", "lower", "the", "better", ",", "ACC", "the", "highest", "the", "better", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "accuracy"}, {"tokens": ["We", "find", "that", "ARD", "and", "Fast", "-", "ARD", "outperform", "adversarial", "training", "and", "free", "training", "respectively", "across", "all", "attacks", "we", "tried", "(", "see", "Table", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["When", "the", "network", "is", "sparse", ",", "the", "videos", "tend", "to", "have", "lower", "quality", ",", "especially", "without", "any", "FEC", "-", "based", "mechanism", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Constraint", "(", ")", "ensures", "that", ",", "if", "CP", "of", "cell", "is", "split", ",", "then", "all", "the", "CP", "and", "UP", "above", "the", "split", "point", "must", "be", "placed", "at", "CC", "processed", "by", "the", "same", "DU", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["The", "legacy", "CAS", "storageOCFA", "in", "its", "initial", "release", "came", "with", "a", "Content", "Addressed", "Storage", "system", "for", "storing", "data", "entities", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "content addressed storage"}, {"tokens": ["Evaluation", "procedure", "using", "this", "dataset", "is", "the", "same", "as", "for", "the", "RT", "dataset", ":", "one", "should", "calculate", "the", "average", "precision", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ruthes"}, {"tokens": ["Then", ",", "two", "high", "-", "performance", "TAS", "schemes", ":", "leakage", "-", "based", "and", "Max", "-", "SR", ",", "have", "been", "proposed", "to", "improve", "the", "SR", "performance", ",", "and", "the", "EDAS", "method", "has", "been", "generalized", "to", "provide", "a", "secure", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["All", "DE", "variants", "reach", "the", "same", "low", "-", "error", ",", "where", "DE", "-", "SB", "shows", "the", "fastest", "decrease", "in", "error", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["BAMs", "can", "effectively", "optimize", "resource", "allocation", "for", "the", "target", "networks", "by", "either", "reconfiguring", "its", "operational", "parameters", "or", "switching", "among", "BAM", "distinct", "models", "(", "MAM", ",", "RDM", "and", "ATCS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "russian dolls model"}, {"tokens": ["We", "can", "recover", "AP", "by", "setting", "(", "and", "subtracting", "the", "additional", "factor", "in", "eq", ":", "APEAPobjmain1", "to", "avoid", "the", "an", "ill", "-", "posed", "optimization", "problem", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["Although", "it", "is", "tempting", "to", "claim", "that", "semantic", "structure", "is", "learned", "using", "syntactic", "structure", "as", "natural", "scaffolding", ",", "it", "is", "possible", "that", "the", "simple", "predictive", "power", "of", "POS", "is", "acting", "as", "an", "attractor", "and", "starving", "semantic", "features", "that", "are", "rarer", "and", "more", "ambiguous", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Tracking", "AP", "on", "CVPR2013", "dataset", "after", "feature", "selection", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Intelligent", "Transportation", "System", "(", "ITS", ")", "is", "one", "of", "the", "key", "components", "in", "smart", "cities", ",", "due", "to", "its", "capability", "of", "supporting", "communications", "between", "vehicles", "to", "improve", "the", "driving", "experience", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intelligent transportation system"}, {"tokens": ["we", "briefly", "introduce", "the", "basic", "concept", "of", "SRC", "and", "illustrate", "the", "recovery", "performance", "of", "OMP", "and", "OLS", "using", "an", "illustrative", "case", "study", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["The", "localization", "and", "navigation", "problems", "may", "seem", "like", "simple", "problems", "due", "to", "the", "many", "GPS", "systems", "that", "already", "exist", ",", "but", "to", "make", "drone", "delivery", "practical", "in", "different", "operating", "conditions", ",", "the", "integration", "of", "low", "cost", "sensors", "and", "localization", "systems", "is", "required", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Suppose", "that", "in", "using", "the", "tools", "presented", "in", "this", "paper", ",", "we", "find", "that", "the", "GMM", "of", "the", "residual", "distribution", "is", "the", "combination", "of", "three", "distinct", "Gaussian", "modes", "(", "e.g.", ",", "see", "Fig", ".", ")", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["TP", "means", "true", "positives", "denoting", "the", "number", "of", "apps", "correctly", "classified", "as", "malicious", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["One", "other", "difference", "between", "two", "corpora", "is", "that", "NAWL", "contains", "oral", "academic", "discourse", "as", "well", "as", "written", "texts", "while", "LSC", "includes", "only", "written", "academic", "English", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["This", "section", "describes", "the", "ISP", "we", "model", ",", "our", "approach", "in", "generating", "images", "for", "training", "/", "evaluation", ",", "and", "the", "ML", "benchmarks", "we", "use", "for", "evaluation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["CE", ":", "context", "encoder", ",", "SI", ":", "semantic", "inpainting", ","], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "semantic inpainting"}, {"tokens": ["Space", "and", "time", "efficiency", "of", "student", "and", "teacher", "modelsWe", "perform", "our", "experiments", "for", "ARD", "with", "WideResNet", "(", "34", "-", "10", ")", "and", "ResNet18", "teacher", "models", "as", "well", "as", "a", "MobileNetV2", "student", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["The", "relative", "improvement", "in", "accuracy", "provided", "by", "a", "minimally", "-", "viable", "ISP", "(", "BL", "+", "WB", "+", "TM", ")", "far", "outweighs", "the", "additional", "algorithmic", "complexity", "associated", "with", "that", "ISP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "image signal processor"}, {"tokens": ["Secondly", ",", "the", "LR", "and", "distribution", "attack", "algorithms", "have", "lower", "values", "for", "AUC", "for", "all", "datasets", "compared", "with", "the", "JSMA", "algorithm", "and", "with", "respect", "to", "the", "FPR", "values", "presented", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Again", ",", "a", "hierarchical", "or", "nested", "structure", "can", "be", "incorporated", ",", "so", "that", "the", "groups", "are", "modelled", "by", "another", "SBM", ",", "and", "so", "on", ",", "if", "necessary", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Comparison_Efficiency_all_Bridges.pdf", "PSC", "Bridges", "fig", ":"], "acronym_pos": [0, 1, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["In", "cases", "where", "the", "excitation", "parameters", "(", "V", "/", "UV", ",", "F0", ",", "ContF0", ",", "or", "MVF", ")", "were", "predicted", "by", "the", "CNNs", "but", "the", "original", "MGC", "-", "LSP", "features", "were", "used", "during", "synthesis", ",", "the", "preference", "towards", "the", "proposed", "methods", "is", "visible", "(", "in", "absolute", "terms", ")", ":", "the", "variant", "'", "g", "'", "achieved", "43.45", "compared", "to", "the", "baseline", "system", "'d", "'", "of", "40.87", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["We", "see", "through", "our", "experiments", "in", "Table", "that", "ARD", "is", "able", "to", "create", "robust", "students", "from", "teachers", "whose", "robustness", "failed", "to", "transfer", "during", "knowledge", "distillation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["China", ",", "the", "largest", "pork", "producing", "country", "has", "an", "ongoing", "ASF", "outbreak", "and", "has", "reportedly", "culled", "1,170,000", "hogs", "as", "of", "3rd", "October", "2019", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "african swine fever"}, {"tokens": ["In", "a", "regression", "method", "based", "on", "the", "GP", "is", "proposed", "for", "prediction", "of", "wind", "power", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["SC", "analyses", "feature", "distributions", "of", "neighboring", "pixels", "that", "share", "the", "same", "labels", "and", "gives", "higher", "values", "for", "consistent", "annotations", "which", "have", "similar", "feature", "distributions", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "self consistency"}, {"tokens": ["In", "this", "literature", ",", "the", "process", "of", "mass", "detection", "is", "automated", "with", "the", "use", "of", "transfer", "learning", "techniques", "of", "Deep", "Convolutional", "Neural", "Networks", "(", "DCNN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Specifically", ",", "precise", "phase", "transition", "and", "fundamental", "limits", "exist", "for", "one", "of", "the", "central", "graph", "generation", "models", "to", "test", "community", "detection", "algorithms", ",", "the", "so", "-", "called", "Stochastic", "Block", "Model", "SBM", "(", ",", ",", ")", "and", "its", "symmetric", "variant", "Symmetric", "Stochastic", "Block", "Model", ",", "SSBM", "(", ",", ",", ",", ")", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Long", "Term", "Evolution", "(", "LTE", ")", "and", "WiFi", "represent", "the", "airinterfaces", "used", "in", "a", "band", ";", "blank", "box", "means", "the", "spectrum", "is", "not", "used", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "the", "two", "-", "dimensional", "input", "experiment", "for", "GP", "classification", ",", "we", "setup", "an", "initial", "grid", "of", "inducing", "-", "points", "with", "per", "side", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Strategy", ":", "It", "now", "suffices", "to", "define", "a", "player", "MD", "strategy", "so", "that", "we", "have", "for", "all", "and", "for", "all", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["The", "capacities", "of", "the", "users", "and", "the", "SC", "are", "given", "by"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["We", "just", "find", "a", "few", "studies", "in", "which", "transfer", "learning", "is", "applied", "to", "conquer", "the", "difficulty", "of", "lacking", "labeled", "SAR", "data", "to", "train", "a", "deep", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["[", ",", "STA", "Mbps", ",", "AP", "Mbps", "]"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "access point"}, {"tokens": ["SSIM", "drop", "from", "LR", "to", "HR", "light", "field", "image", "stems", "from", "the", "second", "residual", "addition", "which", "causes", "slight", "blur", "in", "the", "erroneous", "region", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["We", "challenged", "the", "closed", "-", "set", "classification", "assumption", "and", "discussed", "the", "limitations", "of", "standard", "machine", "learning", "techniques", "in", "dealing", "with", "the", "open", "set", "AA", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["LTE", "transmissions", "areorganized", "in", "periodic", "subframes", "in", "time", ",", "and", "can", "start", "only", "at", "thebeginning", "of", "subframes", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Activation", "FunctionWhen", "autoencoder", "is", "used", "for", "DE", "we", "should", "avoid", "using", "activation", "function", "just", "before", "the", "innermost", "hidden", "layer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["LSC", "is", "a", "corpus", "of", "abstracts", "of", "academic", "articles", "and", "proceeding", "papers", ",", "where", "all", "papers", "are", "indexed", "by", "WoS", "and", "published", "in", "2014", "in", "English", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["An", "integral", "expression", "for", "the", "network", "coverage", "probability", "is", "derived", "in", "considering", "SBS", "cooperation", "in", "downlink", "heterogeneous", "cellular", "networks", ",", "which", "has", "shown", "that", "SBS", "cooperation", "is", "more", "beneficial", "for", "the", "worst", "-", "performing", "user", "compared", "to", "the", "general", "population", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["Therefore", ",", "we", "removed", "the", "examples", "which", "can", "not", "fulfill", "the", "requirement", "of", "extraction", "-", "based", "QA", "after", "translation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Based", "on", "and", ",", "for", "both", "transmission", "strategies", "the", "elements", "of", "are", "obtained", "aswhere", "is", "'s", "transmit", "rate", "and", "for", "repetitive", "transmission", ",", "whereas", "for", "RS", "-", "based", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Similarly", ",", "we", "used", "the", "Chamfer", "distance", "to", "train", "our", "encoder", "whereas", "EMD", "distance", "might", "work", "better", "pointset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "earth mover 's distance"}, {"tokens": ["Another", "important", "observation", "in", "NP", "models", "is", "the", "ascending", "trend", "of", "the", "detection", "performance", "as", "the", "number", "of", "samples", "from", "the", "fixed", "-", "effect", "(", ")", "increases", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["This", "section", "presents", "the", "DE", "of", "the", "user", "rate", "during", "the", "data", "transmission", "with", "RS", "in", "the", "second", "link", ",", "which", "takes", "place", "for", "time", "slots", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deterministic equivalent"}, {"tokens": ["One", "advantage", "of", "MAD", "in", "selecting", "neuron", "activations", "among", "feature", "maps", "is", "that", "it", "considers", "the", "context", "of", "input", "-", "the", "weight", "vector", "is", "computed", "on", "the", "fly", "for", "each", "training", "or", "test", "sample", ",", "which", "shares", "a", "big", "distinction", "in", "previous", "work", "where", "weights", "in", "the", "learned", "combination", "kernel", "are", "fixed", "(", "see", "Section", "sec", ":"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["examplepropositionFor", "an", "formula", ",", "is", "an", "formula", ",", "and", "is", "a", "conjunction", "of", "formulae", "of", "the", "form", "which", "contain", "only", "variables", "from", ",", "a", "PA", "can", "be", "constructed", "effectively", "such", "that", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "presburger arithmetic"}, {"tokens": ["Robustness", "analysisFeature", "robustness", "was", "assessed", "using", "the", "intraclass", "correlation", "coefficient", "(", "1,1", ")", "(", "ICC", ")", ",", "based", "on", "the", "assumption", "that", "test", "-", "retest", "images", ",", "as", "well", "as", "perturbations", ",", "possess", "no", "consistent", "bias", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["In", "this", "work", ",", "we", "explore", "the", "obstacles", "that", "hinder", "the", "performance", "of", "FA", "in", "deeper", "networks", "and", "present", "modifications", "that", "allow", "these", "methods", "to", "remain", "competitive", "with", "BP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["So", ",", "the", "ANN", "can", "be", "summarised", "as", "follows:(1", ")", "Initialize", "randomly", "the", "weights", "and", "biases", "in", "ANN", "in", "order", "to", "avoid", "a", "local", "minimum", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Tagging", ":", "POS", "Tagging", "is", "the", "process", "of", "assigning", "parts", "of", "speech", "(", "verb", ",", "adverb", ",", "adjective", ",", "noun", ")", "to", "each", "word", ",", "which", "are", "referred", "to", "as", "tokens", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Experiments", "on", "Hyperspectral", "Classification", "DatasetsIn", "this", "section", ",", "we", "analyze", "SAD", "and", "the", "qualitative", "performance", "of", "the", "baseline", "methods", "on", "the", "University", "of", "Pavia", "and", "Mississippi", "Gulfport", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["There", "are", "approaches", "based", "on", "LDA", "to", "deal", "with", "this", "problem", "that", "some", "of", "the", "methods", "are", "combined", "with", "CF", "methods", ",", "for", "example", ",", "Lin", "et", "al", ",", "investigated", "the", "cold", "-", "start", "issue", "with", "use", "the", "social", "information", "for", "app", "recommendation", "in", "Twitter", "and", "used", "a", "LDA", "model", "to", "discovering", "latent", "group", "from", "'", "Twitter", "personalities", "'", "to", "recommendations", "discovery", "and", "shown", "that", "their", "approach", "overcomes", "the", "difficulty", "of", "cold", "-", "start", "app", "recommendation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["In", "the", "SBS", "cooperation", "strategy", "with", "a", "distance", "constraint", ",", "selecting", "cooperative", "SBSs", "is", "based", "on", "the", "distances", "between", "the", "UE", "and", "SBSs", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["The", "sample", "size", "of", "the", "training", "data", "is", "critical", "for", "both", "RF", "and", "ANN", "models", "to", "achieve", "good", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["One", "of", "the", "main", "issues", "of", "neural", "network", "is", "determining", "proper", "values", "for", "weights", "and", "biases", "which", "in", "this", "paper", ",", "we", "use", "ICA", "for", "prognosticating", "earthquake", "intensity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "imperialist competitive algorithm"}, {"tokens": ["We", "consider", "six", "high", "dimensional", "real", "datasets", "from", "the", "UCI", "library", "(", "see", "for", "details", ")", "and", "compute", "the", "AUC", "and", "AP", "scores", "for", "each", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Schematic", "description", "of", "the", "coupling", "between", "a", "BEM", "and", "a", "FEM", "discretization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "finite element method"}, {"tokens": ["Although", "the", "CTC", "algorithm", "takes", "care", "of", "the", "alignment", "of", "input", "with", "the", "output", "labels", ",", "it", "can", "be", "finicky", "to", "train", "and", "increases", "compute", "complexity", "during", "inference", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["The", "outage", "statistics", "for", "the", "same", "set", "of", "users", "in", "SC", "mode", "is", "also", "presented", "for", "comparison", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "single connectivity"}, {"tokens": ["In", "the", "legacy", "LTE", "architecture", ",", "the", "number", "of", "control", "signaling", "exchanges", "for", "the", "addition", "of", "SeNB", "between", "MeNB", "and", "SeNB", "is", "3", "(", "SeNB", "addition", "request", ",", "SeNB", "addition", "request", "acknowledge", "and", "SeNB", "reconfiguration", "complete", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "resulting", "structure", "is", "the", "same", "of", "ClumpFind", "(", "i.e.", ",", "CAA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "clump assignment array"}, {"tokens": ["This", "is", "due", "to", "that", "GPA", "exploits", "several", "effective", "strategies", "that", "overcome", "the", "shortage", "of", "HARP", "and", "lead", "to", "a", "better", "initialization", "for", "the", "network", "embedding", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["Each", "document", "in", "LSC", "is", "assigned", "to", "at", "least", "1", "and", "at", "most", "6", "categories", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Related", "WorkThe", "coexistence", "of", "LTE", "and", "Wi", "-", "Fi", "in", "the", "unlicensed", "spectrum", "gives", "rise", "to", "several", "challenges", "in", "terms", "of", "Wi", "-", "Fi", "client", "association", ",", "interference", "management", ",", "scheduling", "/", "resource", "allocation", ",", "fair", "coexistence", ",", "imperfect", "carrier", "sensing", ",", "etc", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["SC", "with", "respect", "to", ",", ",", ",", ",", ","], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["We", "demonstrated", "on", "four", "NP", "-", "hard", "problems", "that", ",", "by", "adopting", "a", "simple", "imitation", "learning", "scheme", ",", "the", "policies", "learned", "by", "a", "GCNN", "were", "outperforming", "previously", "proposed", "machine", "learning", "approaches", "for", "branching", ",", "and", "could", "also", "outperform", "the", "default", "branching", "strategy", "of", "SCIP", ",", "a", "modern", "open", "-", "source", "solver", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["Numerical", "ExamplesReduced", "Basis", "for", "a", "Fibrous", "MicrostructureThe", "applicability", "of", "the", "proposed", "RB", "method", "in", "combination", "with", "the", "sampling", "scheme", "is", "now", "numerically", "studied", "for", "a", "fibrous", "microstructure", "roughly", "resembling", "polymers", "with", "woven", "reinforcements", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["CEIB", "makes", "state", "-", "of", "-", "the", "-", "art", "predictions", "of", "the", "ACE", "that", "are", "robust", "against", "confoundingAcross", "the", "IHDP", "dataset", ",", "we", "see", "that", "predictions", "of", "the", "ACE", "are", "more", "accurate", "than", "existing", "approaches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "average causal effect"}, {"tokens": ["For", "this", "purpose", ",", "we", "made", "a", "critical", "set", "of", "modifications", "in", "the", "objective", "function", "related", "to", "this", "domain", "and", "a", "novel", "objective", "function", "is", "reformulated", "as", ":", "where", "is", "the", "normalized", "SAD", "score", "between", "the", "original", "and", "reconstructed", "version", "as", "in", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["However", ",", "in", "most", "of", "the", "cases", "GMM", "is", "the", "fastest", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["Compared", "with", "the", "methods", "of", "MP", "or", "SP", ",", "the", "major", "challenge", "in", "the", "periodic", "decomposition", "is", "how", "to", "select", "the", "dominant", "periodic", "component", "in", "each", "iteration", ",", "due", "to", "the", "definition", "of", "the", "dominant", "periodic", "component", "in", "a", "signal", "is", "not", "clear", "yet", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subspace pursuit"}, {"tokens": ["Given", "that", "the", "typical", "UE", "observes", "at", "least", "one", "BS", "in", "tier", ",", "the", "conditional", "PDF", "of", "distance", "to", "the", "nearest", "BS", "in", "tier", "is", "where", "is", "the", "probability", "that", "the", "typical", "UE", "observes", "at", "least", "one", "BS", "in", "tier", "and", "is", "the", "equivalent", "density", "of", "PHP", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["We", "use", "the", "GBM", "and", "construct", "features", "to", "conduct", "diagnosis", "for", "the", "detected", "nodules", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["O.", "Khan", ",", "R.", "Burns", ",", "J.", "S.", "Plank", ",", "W.", "Pierce", "and", "C.", "Huang", ",", "\"", "Rethinking", "Erasure", "Codes", "for", "Cloud", "File", "Systems", ":", "Minimizing", "I", "/", "O", "for", "Recovery", "and", "Degraded", "Reads", ",", "\"", "FAST", "2012", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "file and storage technologies"}, {"tokens": ["We", "define", "a", "new", "sensor", "deployment", ",", "which", "is", "a", "subset", "of", "the", "all", "sensor", "locations", ",", "as", "the", "vector", "of", "sensor", "locations", "for", "the", "sensor", "nodes", "connected", "to", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["At", "the", "highest", "level", ",", "the", "quality", "of", "a", "SAR", "intervention", "can", "be", "assessed", "relative", "to", "some", "goal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "GP", "model", "increases", "the", "number", "of", "inducing", "-", "inputs", "(", "black", "crosses", ")", "as", "long", "as", "new", "observations", "come", "in", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "believe", "this", "is", "due", "to", "our", "method", "representing", "the", "LiDAR", "data", "using", "a", "RV", "where", "the", "previous", "work", "uses", "a", "BEV", "representation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "range view"}, {"tokens": ["In", "the", "experiment", ",", "two", "groups", "of", "algorithms", "are", "cited", "to", "compare", "with", "the", "propose", "DDE", "-", "MGM", ":", "1", ")", "offline", "algorithms", "that", "can", "achieve", "the", "state", "-", "of", "-", "the", "-", "art", "classification", "accuracy", "but", "time", "-", "consuming", "or", "assuming", "the", "input", "data", "are", "of", "the", "same", "length", "and", "well", "aligned", ",", "and", "2", ")", "online", "algorithms", "that", "learn", "models", "efficiently", "in", "an", "online", "fashion", "-", "the", "model", "is", "updated", "and", "applied", "to", "testing", "alternately", "for", "each", "sample", "in", "the", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["The", "following", "three", "rules", "can", "be", "resulting", "in", "the", "study", "of", "according", "to", ":", "If", "the", "number", "of", "hidden", "units", "in", "the", "top", "level", "of", "the", "network", "crosses", "a", "predefined", "threshold", ";", "the", "performance", "of", "DBN", "essentially", "flattens", "at", "around", "certain", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["tab", ":", "litreviewtabularl", "l", "l", "l", "l", "l", "l", "lReference", "&", "Year", "&", "Knowledge-", "&", "Experience-", "&", "Data-", "&", "Model-", "&", "Hybrid", "&", "Other", "methods", "&", "&", "based", "&", "based", "&", "Driven", "&", "based", "&", "&", "luo2003model", "&", "2003", "&", "&", "&", "&", "&", "&", "schwabacher2005survey", "&", "2005", "&", "&", "&", "&", "&", "&", "jardine2006review", "&", "2006", "&", "&", "&", "&", "&", "&", "AI", "lee2006intelligent", "&", "2006", "&", "&", "&", "&", "&", "&", "goh2006review", "&", "2006", "&", "&", "&", "&", "&", "&", "kothamasu2009system", "&", "2006", "&", "&", "&", "&", "&", "&", "Reliability", ",", "Stochasticcoble2008prognostic", "&", "2008", "&", "&", "&", "&", "&", "&", "Stress", "and", "effects", "-", "based", "heng2009rotating", "&", "2009", "&", "&", "&", "&", "&", "&", "sikorska2011prognostic", "&", "2011", "&", "&", "&", "&", "&", "&", "Life", "Expectancy", ",", "ANN", "si2011remaining", "&", "2011", "&", "&", "&", "&", "&", "&", "ahmadzadeh2014remaining", "&", "2014", "&", "&", "&", "&", "&", "&", "tsui2015prognostics", "&", "2014", "&", "&", "&", "&", "&", "&", "SA", ",", "Stochastic", ",", "ANNtsui2015prognostics", "&", "2015", "&", "&", "&", "&", "&", "&", "tabulartabletable[htbp", "!", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["In", "OT", "extension", ",", "the", "th", "row", "of", "the", "transferred", "matrix", "allows", "the", "sender", "to", "create", "two", "pads", "for", "the", "two", "messages", "in", "the", "th", "extended", "OT", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "oblivious transfer"}, {"tokens": ["As", "it", "shows", ",", "the", "2Ch", "view", "bisects", "both", "the", "LV", "and", "RV", ",", "whereas", "the", "4Ch", "view", "bisects", "the", "LV", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["In", "order", "to", "calculate", "the", "energy", "consumed", "by", "the", "algorithms(AE", "-", "OCC", ",", "B", "-", "OCC", ",", "B", "-", "OCC+NG", ")", ",", "we", "measure", "the", "execution", "time", "of", "the", "algorithms", "employing", "INA", "and", "the", "power", "drawn", "by", "the", "uP", "to", "execute", "these", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "one class classifier"}, {"tokens": ["The", "main", "novelty", "of", "our", "work", "is", "on", "the", "recursive", "construction", "of", "the", "GP", "prior", "conditioned", "to", "the", "fitted", "variational", "posterior", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["(", "b", ")", "Multiple", "pairs", "of", "projection", "units", "(", "DBPN", "-", "MR", ")", "utilizes", "multiple", "up-", "and", "down", "-", "projection", "units", "as", "shown", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "middle resolution"}, {"tokens": ["In", "our", "framework", "for", "adaptive", "quantum", "error", "correction", ",", "we", "consider", "a", "PS", "agent", "that", "interacts", "with", "a", "specific", ",", "simulated", "environment", "-", "the", "surface", "code", "quantum", "memory", "subject", "to", "noise", "and", "its", "classical", "control", "managing", "the", "QEC", "procedure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "projective simulation"}, {"tokens": ["This", "behavior", "of", "MP", "outperforming", "CF", "can", "only", "be", "observed", "in", "this", "use", "case", ",", "which", "shows", "that", "personalized", "approaches", "are", "not", "always", "necessary", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["In", "addition", ",", "we", "provide", "the", "precoder", "design", "for", "the", "common", "message", ",", "implemented", "to", "be", "used", "under", "the", "RS", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "relay station"}, {"tokens": ["We", "investigate", "both", "uni-", "and", "bi", "-", "directional", "RNN", "models", "and", "propose", "a", "method", "to", "include", "external", "information", "(", "for", "instance", "low", "level", "information", "from", "POS", ")", "in", "the", "RNN", "to", "train", "higher", "level", "taggers", "(", "for", "instance", ",", "super", "sense", "taggers", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["RB", ":", "coefficients", "is", "the", "Newton", "-", "Raphson", "scheme", ",", "which", "necessitates", "the", "Jacobian", "with", "the", "componentsThen", ",", "the", "th", "iteration", "to", "the", "solution"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["NCE", "makes", "it", "possible", "to", "compare", "diversity", "for", "ranking", "lists", "with", "different", "length", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["In", "order", "to", "improve", "spatial", "context", "and", "prevent", "misclassification", "of", "the", "arms", ",", "the", "dataset", "was", "complemented", "by", "a", "synthetic", "class", "defined", "as", "\"", "other", "tissue", "\"", "that", "was", "composed", "of", "any", "soft", "tissue", "inside", "the", "abdomen", "cavity", "that", "is", "not", "VAT", "or", "SAT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["As", "a", "result", ",", "a", "larger", "network", "trained", "with", "a", "large", "-", "scale", "dataset", "and", "a", "source", "task", "similar", "to", "SAR", "target", "recognition", "are", "both", "required", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Another", "exciting", "aspect", "of", "the", "ANN", "model", "is", "that", "it", "consistently", "finds", "the", "same", "hidden", "data", "patterns", "despite", "the", "various", "weight", "initializations", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Finally", ",", "the", "RB", "is", "constructed", "aswhere", "the", "factor", "accounts", "for", "normalization", "of", "the", "base", "elements", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["Such", "possibility", "of", "empty", "groups", "ensure", "the", "joint", "posterior", "of", "and", ",", "with", "other", "parameters", "integrated", "out", "in", "their", "Poisson", "SBM", ",", "to", "be", "computed", "correctly", ":", "Now", ",", "applying", "an", "MCMC", "algorithm", "with", "as", "the", "target", "density", "will", "give", "a", "(", "marginal", ")", "posterior", "of", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["We", "use", "an", "utterance", "-", "level", "mean", "-", "variance", "normalized", "log", "spectrogram(Power", "-", "spectrogram", "for", "the", "LA", "task", "and", "Mel", "-", "spectrogram", "with", "80", "mel", "bands", "(", "for", "computational", "reasons", ")", "for", "the", "PA", "task", ".", ")", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["The", "nature", "of", "multi", "-", "turn", "QA", "systems", "makes", "quite", "hard", "to", "design", "accurate", "evaluation", "frameworks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Crowd", "workers", "were", "asked", "to", "select", "a", "checkbox", "for", "added", "information", "if", "the", "output", "contained", "information", "not", "present", "in", "the", "given", "MR", ",", "or", "a", "checkbox", "for", "missed", "information", "if", "the", "output", "missed", "some", "information", "from", "the", "MR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "meaning representation"}, {"tokens": ["Extensions", "of", "the", "SBM", "regarding", "the", "type", "of", "graph", "are", "reviewed", "in", "Section", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["This", "is", "also", "reflected", "in", "the", "recommendation", "accuracy", "results", "presented", "in", "Table", "as", "the", "unpersonalized", "MP", "approach", "provides", "better", "results", "than", "the", "personalized", "CF", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "most popular"}, {"tokens": ["We", "can", "see", "that", "in", "the", "absence", "of", "DC", "DF", "for", "round", "-", "shaped", "droplets", "decreases", "while", "it", "increases", "for", "the", "square", "-", "shaped", "ones", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dominating frequencies"}, {"tokens": ["accurate", "cameras", "and", "smart", "devices", ",", "it", "is", "bound", "that", "more", "and", "more", "AR", "based", "devices", "and", "applications", "are", "going", "to", "capture", "its", "market", "share", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Data", "packets", "collected", "by", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Mirrored", "disks", "such", "as", "ID", ",", "GRD", ",", "and", "CD", "are", "referred", "to", "as", "semistructured", "and", "shown", "to", "outperform", "BM", "as", "far", "as", "seek", "distances", "are", "concerned", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group rotate declustering"}, {"tokens": ["The", "larger", "and", "deeper", "network", "size", "of", "DBN", ",", "the", "more", "computing", "is", "required", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Recently", ",", "by", "the", "basic", "idea", "of", "IA", "with", "some", "constraints", "shows", "that", "one", "can", "achieve", "DoF", "for", "the", "fast", "fade", "interference", "channel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interference alignment"}, {"tokens": ["Both", "performance", "and", "data", "transfersof", "the", "policies", "introduced", "above", ":", "HEFT", ",", "DADA", "(", ")", ",", "DADA", "(", ")", "and", "DADA()+CP", "are", "studied", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["In", "this", "architecture", ",", "the", "Core", "Network", "can", "consist", "of", "LTE", "Core", "or", "5", "G", "Core", "(", "5GC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["[", "CC", ",", "100", "runs", ",", "24", "clust", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "connected caveman"}, {"tokens": ["This", "value", "is", "always", "higher", "for", "the", "LR", ",", "Distribution", "and", "KNN", "attack", "algorithms", "than", "for", "the", "JSMA", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["The", "benefit", "of", "adopting", "BC", "in", "our", "research", "is", "three", "-", "fold", ":", "Decentralised", "or", "distributed", ",", "Permission", "-", "based", "and", "all", "-", "secure", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["GPS", "methods", "consist", "a", "subset", "of", "the", "aforementioned", "algorithms", "which", "do", "not", "require", "the", "explicit", "computation", "of", "the", "gradient", "in", "each", "iteration", "-", "step", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["Besides", ",", "we", "find", "the", "standard", "IB", "outperforms", "SIB", ",", "which", "seems", "contradictory", "to", "our", "standpoint", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["the", "SAD", "scores", "vary", "between", "and", "zero", "value", "means", "that", "two", "samples", "are", "identical", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["The", "MGM", "GAN", "importance", "sampling", "compensates", "for", "the", "differing", "densities", ",", "and", "allows", "the", "identity", "function", "to", "be", "a", "possible", "local", "optima", "for", "the", "GAN", "loss", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["The", "decoding", "order", "at", "the", "BS", "is", "denoted", "by", "a", "permutation", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "other", "words", ",", "in", "this", "approach", ",", "we", "consider", "the", "nearest", "holes", "that", "are", "associated", "with", "the", "interferer", "MBSs", ",", "i.e.", "the", "MBSs", "who", "are", "not", "serving", "the", "typical", "UE", ",", "and", "therefore", ",", "the", "effect", "of", "the", "serving", "hole", "has", "not", "taken", "into", "account", "in", "this", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["As", "SAR", "continues", "to", "substantiate", "itself", "as", "an", "effective", "enhancement", "to", "human", "intervention", ",", "researchers", "have", "sought", "to", "study", "its", "longitudinal", "impacts", "in", "real", "-", "world", "environments", ",", "including", "the", "home", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["along", "with", "the", "value", "of", "the", "area", "under", "the", "macro", "-", "average", "ROC", "curve", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["the", "learning", "algorithms", ",", "we", "found", "that", "the", "retrained", "and", "incremental", "modeling", "have", "similar", "effect", "on", "LR", "and", "DT", ",", "but", "they", "lead", "to", "considerably", "diverse", "result", "while", "working", "on", "SVM", "and", "MLP", ":", "overall", ",", "the", "retrained", "modeling", "is", "clearly", "better", "in", "accuracy", "on", "SVM", "while", "the", "incremental", "one", "yields", "much", "better", "results", "on", "MLP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["NP"], "acronym_pos": [1], "long_form": "new persian"}, {"tokens": ["With", "the", "AC", "-", "OPF", "formulation", ",", "the", "gain", "of", "the", "perfect", "regression", "did", "not", "show", "a", "correlation", "with", "the", "system", "size", ",", "and", "for", "some", "cases", "we", "observed", "even", "negative", "gain", "with", "the", "warm", "-", "start", "OPF", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "optimal power flow"}, {"tokens": ["We", "also", "show", "that", "while", "expanding", "retrieval", "set", "(", "from", "to", ",", "where", ")", "has", "no", "gain", "for", "the", "decoding", "based", "on", "standard", "beam", "decoding", "(", "BS", ")", "and", "heuristic", "-", "based", "decoding", "(", "BS++", ")", ",", "the", "performance", "of", "the", "proposed", "decoding", "method", "significantly", "increases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard beam search"}, {"tokens": ["PAF", "is", "an", "extension", "of", "BF", ",", "with", "the", "expense", "of", "a", "higher", "control", "overhead", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "provider - aware forwarding"}, {"tokens": ["However", ",", "the", "index", "values", "for", "sk", "-", "means", "clusters", "are", "mainly", "lower", "than", "those", "for", "OEC", "clusters", "showing", "that", "sk", "-", "means", "clustering", "creates", "relatively", "better", "clusters", "in", "terms", "of", "cohesion", "and", "separation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["Betweenness", "centrality", "(", "BC", ")", "is", "another", "important", "measure", "which", "is", "used", "to", "find", "the", "extent", "to", "which", "a", "node", "lies", "on", "the", "shortest", "paths", "between", "another", "pair", "of", "nodes", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["Table", "shows", "that", "of", "the", "rank", "1", "accuracy", "improvement", "(", "for", "the", "mAP", ")", "is", "due", "to", "the", "WF", "method", ",", "while", "the", "remaining", "(", "for", "mAP", ")", "to", "the", "WPR", "viewpoint", "-", "based", "alignment", "technique", ",", "which", "highlights", "the", "effectiveness", "of", "our", "two", "schemes", "and", "demonstrates", "that", "they", "are", "complementary", "to", "some", "extent", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "weighted fusion"}, {"tokens": ["It", "is", "found", "that", "RV", "strategy", "requires", "to", "vaccinate", "70", "of", "nodes", "to", "achieve", "such", "preventive", "efficiency", "in", "both", "the", "DDT", "and", "GDT", "networks", "(", "see", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["We", "also", "add", "professor", ",", "which", "does", "not", "have", "a", "clear", "definition", "as", "per", "CPS", "but", "has", "been", "known", "to", "have", "different", "gender", "splits", "at", "senior", "and", "junior", "levels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "current population survey"}, {"tokens": ["While", "our", "sub", "-", "linear", "convergence", "rates", "for", "MP", "and", "FW", "only", "depend", "on", "bounded", "norm", "of", "the", "iterates", "and", "on", "the", "diameter", "of", "the", "atom", "set", ",", "the", "linear", "rates", "also", "depend", "on", "our", "notion", "of", "minimal", "intrinsic", "directional", "width", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["The", "artificial", "neural", "networks", "(", "ANN", ")", "are", "multilayer", "perceptrons", "with", "a", "single", "hidden", "layer", ",", "but", "a", "different", "number", "of", "neurons", "in", "it", ";", "the", "first", "referred", "to", "as", "ANN6", "has", "six", "neurons", ",", "while", "the", "second", ",", "ANN10", ",", "has", "ten", "neurons", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["We", "first", "annotate", "each", "of", "the", "sentences", "from", "a", "change", "request", "using", "Stanford", "POS", "tagger", ",", "and", "organize", "the", "annotated", "words", "into", "various", "ranks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["This", "is", "because", "using", "the", "nonlinear", "-", "IB", ",", "as", "stated", "by", ",", "does", "not", "guarantee", "that", "we", "find", "optimal", "representations", "due", "to", "factors", "like", ":", "(", "i", ")", "inaccurate", "estimation", "of", ",", "(", "ii", ")", "restrictions", "on", "the", "structure", "of", ",", "(", "iii", ")", "use", "of", "an", "estimation", "of", "the", "decoder", "instead", "of", "the", "real", "one", "and", "(", "iv", ")", "the", "typical", "non", "-", "convex", "optimization", "issues", "that", "arise", "with", "gradient", "-", "based", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "this", "work", "we", "follow", "the", "PASCAL", "VOC", "definition", "of", "the", "AP", "which", "uses", "all", "points", "for", "an", "interpolation", "and", "estimation", "of", "the", "AUC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "impact", "of", "normalized", "transmission", "distance", "between", "BS", "to", "CCU", "on", "SC", "is", "illustrates", "in", "Figure", "7", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["This", "is", "because", ",", "in", "RA", "the", "available", "network", "bandwidth", "is", "constant", "between", "worker", "nodes", "whereas", "for", "the", "PS", "or", "P2P", "systems", ",", "the", "bandwidth", "is", "a", "shared", "resources", "among", "all", "worker", "nodes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["SAD", "is", "differentiable", "to", "optimize", "necessary", "parameters", "with", "the", "backpropagation", "algorithm", "by", "minimizing", "the", "loss", "function", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["we", "analyze", "the", "connectivity", "design", "in", "the", "encapsulated", "module", "and", "the", "many", "choices", "in", "the", "OT", "divergence", "unit", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Our", "prior", "study", "collected", "data", "from", "31", "typically", "developing", "preschool", "children", "who", "interacted", "with", "a", "SAR", "tutor", "in", "a", "single", "session", "at", "their", "child", "development", "center", "preschool", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["To", "obtain", "HR", "light", "field", "we", "run", "the", "network", "twice", "sequentially", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["first", "step", "of", "our", "new", "method", "is", "to", "train", "a", "NN", "-", "based", "classifier", "using", "grid", "parameters", "as", "features", ",", "to", "predict", "the", "binding", "status", "of", "the", "constraints", "of", "the", "full", "OPF", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["In", "this", "paper", ",", "we", "employ", "and", "evaluate", "the", "power", "of", "DNNs", "including", "DBN", ",", "CNN", "and", "CNN", "with", "dropout", "on", "HBDR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Note", "that", "the", "ID", "organization", "implicitly", "utilizes", "two", "strip", "sizes", ",", "where", "secondary", "strips", "are", "times", "smaller", "than", "primary", "strips", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["The", "system", "comprises", "a", "BS", "with", "transmit", "antennas", ",", "(", ")", "single", "-", "antenna", "destination", "users", "(", ")", ",", "and", "single", "-", "antenna", "eavesdroppers", "(", ")", ",", "wishing", "to", "wiretap", "the", "confidential", "information", "sent", "from", "the", "BS", "to", "the", "destination", "users", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "introduce", "a", "particular", "case", "of", "the", "convex", "IB", "Lagrangians", ":", "the", "shifted", "exponential", "IB", "Lagrangian", ",", "which", "allow", "us", "to", "approximately", "obtain", "a", "specific", "compression", "level", "in", "any", "scenario", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["&", "Up", "to", "2.5", "kg", "Kg", "/", "LAP", "/12", "-", "20", "min", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "low altitude platform"}, {"tokens": ["Equation", "describes", "the", "CER", "computation"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "character error rate"}, {"tokens": ["The", "additional", "cost", "to", "the", "overall", "model", "parameters", "is", "also", "from", "the", "OT", "module", "for", "each", "level", ";", "however", ",", "we", "find", "using", "just", "one", "conv", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["The", "predicted", "facial", "image", "is", "matched", "with", "the", "actual", "facial", "image", "at", "27", "year", "of", "the", "subject", ";", "the", "matched", "images", "'", "differences", "are", "provided", "as", "feedback", "into", "the", "model", "again", ",", "this", "whole", "process", "is", "part", "of", "the", "ANN", "back", "-", "propagation", "learning", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["CM", "is", "a", "diagonal", "matrix", "in", "ideal", "case", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "confusion matrix"}, {"tokens": ["Still", ",", "comparison", "of", "the", "two", "plots", "in", "plot", ":", "IACFequil", "reveals", "the", "clear", "superiority", "in", "sampling", "efficiency", "of", "HMC", "over", "MD", "for", "the", "tested", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["We", "can", "infer", "that", "all", "the", "rewiring", "strategies", "give", "a", "higher", "value", "of", "and", "lower", "value", "of", "maximum", "BC", ",", "than", "the", "original", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["The", "majority", "of", "past", "work", "with", "SAR", "for", "ASD", "has", "been", "related", "to", "social", "skills", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["However", ",", "we", "find", "that", "the", "hybrid", "model", "performs", "even", "better", "than", "the", "CF", "model", "using", "ICD-9", "code", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Going", "along", "the", "same", "line", ",", "KK13", "OT", "extension", "allows", "the", "sender", "to", "create", "pads", "for", "the", "messages", "in", "the", "th", "extended", "OT", "using", "the", "th", "row", "of", "the", "transferred", "matrix", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Herein", ",", "\"", "hybrid", "\"", "means", "that", "during", "the", "data", "exchange", ",", "the", "eavesdropper", "not", "only", "overhears", "to", "extract", "confidential", "information", "but", "also", "propagates", "AN", "to", "degrade", "the", "PHY", "layer", "security", "of", "the", "legitimate", "sub", "-", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["The", "greedy", "policy", "shows", "very", "little", "improvement", "for", ",", "which", "significantly", "outperforms", ",", "this", "is", "because", "VSM", "processes", "rebuild", "requests", "at", "a", "lower", "priority", "than", "external", "requests", ",", "while", "PCM", "processes", "them", "at", "the", "same", "priority", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "permanent customer model"}, {"tokens": ["i.e.", ",", "it", "is", "preferred", "to", "affect", "slightly", "-", "active", "users", "more", "than", "highly", "-", "active", "users", "or", "vice", "versa)*[ht", "]", "HR@10", "for", "small", "-", "size", "and", "large", "-", "size", "attacks", "with", "respect", "to", "the", "class", "of", "user", ",", "slightly", "-", "active", "and", "highly", "-", "active", ",", "and", "the", "CF", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Given", "such", "values", "of", "and", "functions", ",", ",", "the", "gain", "assures", "the", "robust", ",", "finite", "-", "time", "stability", "of", "the", "origin", "of", "the", "STA", "STA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["However", ",", "it", "must", "be", "noted", "that", "our", "approach", "can", "only", "be", "applied", "to", "a", "subset", "of", "SC", "tasks", ":", "those", "that", "can", "be", "done", "on", "a", "street", "-", "view", "image", "of", "the", "space", ",", "and", "is", "limited", "by", "how", "up", "-", "to", "-", "date", "images", "are", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial crowdsourcing"}, {"tokens": ["Viewing", "the", "casters", "'", "behaviors", "through", "the", "dual", "lens", "of", "PEAS", "+", "IFT", "has", "implications", "for", "not", "only", "the", "kinds", "of", "patches", "that", "an", "explanation", "system", "would", "need", "to", "provide", ",", "but", "also", "the", "cost", "to", "users", "of", "not", "providing", "these", "patches", "in", "a", "readily", "accessible", "format", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information foraging theory"}, {"tokens": ["We", "can", "see", "a", "reduction", "in", "the", "accuracy", "of", "in", "the", "-stage", "SC", "-", "task", "compared", "to", "the", "paper", "reported", "metric", ",", "which", "can", "be", "due", "to", "an", "increased", "number", "of", "data", "epochs", "and", "patient", "independent", "splitting", "during", "evaluation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sleep cassette"}, {"tokens": ["To", "cope", "with", "these", "problems", ",", "we", "proposed", "a", "new", "approach", "of", "implementing", "IoT", "Application", "on", "Fabric", "-", "BC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "blockchain"}, {"tokens": ["uavFEC", "OverviewThe", "uavFEC", "mechanism", "uses", "motion", "vectors", "details", ",", "FEC", ",", "and", "Fuzzy", "logic", "to", "improve", "the", "resilience", "of", "UAV", "video", "transmission", "with", "both", "UEP", "and", "QoE", "-", "awareness", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["When", "assigning", "VAT", "labels", "there", "is", "also", "a", "tendency", "towards", "undersegmenting", "some", "of", "the", "outer", "areas", "of", "the", "depots", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Mode", "Selection", "How", "to", "select", "mode", "(", "inband", "/", "outband", "D2D", ")", "and", "transport", "mode", "(", "D2D", "relay", "/", "D2D", "relay", "hop", "/", "D2D", "cluster):The", "D2D", "candidate", "can", "conclude", "mode", "selection", "by", "searching", "(", "CPICH", "/", "PBCH", ")", "for", "the", "nearest", "and", "the", "best", "D2D", "relay", "nodes", "(", "BDI", "agents", ")", "and", "comparing", "sum", "rates", "(", "from", "UE", "to", "gateway", ")", "with", "the", "current", "data", "rate", "of", "connection", "to", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Here", "and", "respectively", "stand", "for", "the", "time", "-", "varying", "radio", "path", "distance", "for", "the", "BS", "-", "MS", "and", "the", "BS", "-", "IO", "-", "MS", "links", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "the", "following", ",", "we", "compare", "the", "GP", "density", "model", "and", "its", "two", "inference", "algorithms", "with", "two", "alternative", "density", "estimation", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["GMM", "being", "a", "baseline", "clustering", "algorithm", "and", "Wasserstein", "distance", "being", "a", "widely", "used", "symmetric", "distance", "measure", "between", "two", "clusters", "are", "the", "reasons", "for", "using", "them", "in", "our", "experiments", "though", "we", "would", "expect", "more", "complex", "alternatives", "to", "also", "work", "with", "our", "framework", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["However", ",", "the", "trade", "of", "between", "an", "increase", "of", "the", "number", "of", "channel", "uses", "and", "the", "gained", "robustness", "towards", "SPAM", "errors", "remains", "unclear", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "state preparation and measurement errors"}, {"tokens": ["Based", "on", "the", "proposals", "generated", "from", "the", "zoom", "network", ",", "we", "conduct", "a", "RoI", "-", "pooling", "on", "each", "level", "after", "the", "MAD", "unit", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "map attention decision"}, {"tokens": ["Moreover", ",", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "other", "two", "conventional", "schemes", "such", "as", "CNOMA", "-", "SWIPT", "-", "PS", "and", "CNOMA", "-", "SWIPT", "-", "TS", "are", "also", "compared", "with", "the", "proposed", "scheme", "for", "a", "fair", "comparison", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["Therefore", ",", "judgements", "turn", "out", "to", "be", "equivalent", "to", "standard", "subtype", "assertions", ",", "following", "the", "style", "of", "FJ", "where", "explicit", "subsumption", "is", "replaced", "by", "algorithmic", "subtype", "statements", "in", "the", "typing", "rules", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "featherweight java"}, {"tokens": ["Simulations", "and", "numerical", "studies", "are", "conducted", "to", "validate", "the", "accuracy", "and", "efficiency", "of", "the", "proposed", "SSAUA", "approach", "and", "SPS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "surcharge pricing scheme"}, {"tokens": ["Understanding", "QuestionsData", "challengesIndexing", "Heterogeneous", "DatasetsA", "typical", "QA", "system", "is", "empirically", "only", "as", "good", "as", "the", "performance", "of", "its", "indexing", "module", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["So", ",", "there", "is", "a", "clear", "gap", "between", "LDP", "and", "CDP", "approach", ",", "which", "is", "definitely", "a", "great", "research", "area", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["Since", "SC", "is", "higher", "for", "better", "agreement", "with", "labels", ",", "the", "corresponding", "penalty", "cost", "for", "is", "equation", "D(L_x=1)^r=1-SC_x^r", ",", "equation", "where", "is", "the", "label", "of", "voxel", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "self consistency"}, {"tokens": ["A", "MD", "tem", "aplica\u00e7\u00f5es", "nas", "mais", "variadas", "esferas", "de", "conhecimento", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "massa de dados"}, {"tokens": ["The", "OEC", "algorithm", "uses", "two", "other", "parameters", "that", "we", "need", "to", "set", "during", "the", "experiments", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["This", "pattern", "has", "significant", "overlap", "to", "canonical", "closed", "-", "cell", "MCC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "mesoscale cellular convection"}, {"tokens": ["Conclusion", "and", "future", "workIn", "this", "paper", ",", "we", "present", "a", "design", "of", "a", "Dengue", "monitoring", "and", "tracking", "system", "based", "on", "GPS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "global positioning system"}, {"tokens": ["External", "EavesdropperThis", "section", "reviews", "the", "applications", "of", "economic", "and", "pricing", "models", "for", "the", "FJ", "power", "allocation", "between", "the", "friendly", "jammer", "and", "the", "source", "-", "destination", "pairs", "to", "maximize", "the", "secrecy", "capacity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["The", "dictionaries", "LScD", "and", "LScDC", "are", "scientific", "dictionaries", "where", "words", "are", "extracted", "from", "the", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Receiver", "Operating", "Characteristic", ",", "ROC", "."], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["As", "such", ",", "our", "regret", "guarantee", "applies", "to", "the", "Con", "-", "TS", "-", "RTP", "algorithm", "with", "constraints", "as", "formulated", "in", "Constraint", "Set"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["The", "authors", "in", "considered", "the", "sum", "learning", "and", "transmission", "energy", "minimization", "problem", "for", "FL", ",", "for", "a", "case", "in", "which", "all", "users", "transmit", "learning", "results", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["tabularllll", "&", "Task", "-", "oriented", "DS", "&", "Conversational", "Agents", "&", "Interactive", "QA", "Task", "&", "Yes", "-", "clear", "defined", "&", "No", "&", "Yes", "-", "answer", "questions", "Dial", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Another", "important", "advance", "of", "the", "MINT", "-", "FEC", "over", "the", "uavFEC", "was", "the", "network", "overhead", "reduction", "beyond", "1200", "m", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["None", "&", "5.00", "&", "19.15", "&", "21.10", "&", "21.35", "Denoise", "&", "3.35", "&", "17.85", "&", "20.95", "&", "22.80", "BL", "+", "TM", "&", "9.23", "&", "20.10", "&", "21.90", "&", "26.05", "BL", "+", "WB", "+", "TM", "&", "10.54", "&", "24.01", "&", "22.50", "&", "27.20", "ISP", "w/o", "denoise", "&", "10.40", "&", "23.60", "&", "20.65", "&", "26.15"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["The", "utility", "function", "for", "the", "ET", "at", "position", ",", "that", "takes", "the", "average", "charging", "and", "fairness", "of", "energy", "distribution", "in", "consideration", ",", "is", "formulated", "as", "follow", ":", "Here", ",", "is", "the", "trade", "-", "off", "factor", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy transmitters"}, {"tokens": ["Inspired", "by", "recent", "work", "in", "predicting", "active", "constraint", "sets", ",", "the", "main", "contribution", "of", "this", "paper", "is", "to", "combine", "the", "classifier", "approach", "with", "meta", "-", "optimization", ",", "to", "obtain", "a", "reduced", "OPF", "model", "where", "the", "computational", "cost", "of", "the", "iterative", "feasibility", "test", "is", "minimized", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["given", "input", "Chinese", "(", "English", ")", "word", "embedding", "sequenceGiven", "English", "sentence", "as", "input", ",", "the", "and", "are", "added", "as", "the", "input", "of", "the", "following", "layers", "of", "the", "QA", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "decoding", "steps", "of", "the", "Reed", "-", "Solomon", "code", "involve", "the", "computation", "of", "the", "sub", "-", "matrix", "of", "the", "GM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "generator matrix"}, {"tokens": ["For", "the", "\"", "with", "CF", "\"", "users", ",", "violin", "plots", "for", "the", "original", "response", "values", "(", "from", "-1", "to", "1", ")", "can", "be", "seen", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["This", "FL", "approach", "uses", "a", "threshold", "-", "based", "homomorphic", "cryptosystem", "that", "allows", "for", "a", "trusted", "parameter", "that", "specifies", "the", "number", "of", "participants", "that", "are", "trusted", "not", "to", "collude", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["The", "results", "also", "show", "that", "a", "higher", "system", "capacity", "can", "be", "achieved", "by", "employing", "more", "antennas", "at", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access point"}, {"tokens": ["C2", "makes", "sure", "that", "the", "EB", "level", "is", "always", "above", "or", "equal", "to", "a", "preset", "threshold", ",", "to", "guarantee", "energy", "self", "-", "sustainability", "over", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy buffer"}, {"tokens": ["The", "learning", "approach", "employed", "in", "most", "of", "the", "PSO", "based", "feature", "selection", "methods", "can", "be", "classified", "into", "three", "categories", ":", "(", "1", ")", "euclidean", "distance", "based", "(", "2", ")", "probabilistic", "and", "(", "3", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Despite", "this", "the", "change", "is", "not", "a", "multiple", "of", "the", "path", "length", "(", "non", "-", "linear", ")", "and", "this", "suggests", "that", "MR", "interface", "designers", "should", "not", "extend", "the", "line", "too", "far", "into", "the", "future", "of", "the", "robot", "'s", "planned", "path", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mixed reality"}, {"tokens": ["Notice", "that", "upper", "bound", "for", "AP", ",", "AP", "and", "AP", "are", "all", "the", "same", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Resolution", "of", "phase", "shiftersReferring", "to", ",", "to", "guarantee", "the", "analog", "beamforming", "performance", ",", "the", "analog", "beamforming", "codebook", "at", "the", "BS", "should", "contain", "candidate", "vectors", "at", "least", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Performance", "of", "TRADES", "WideResNet", "distilled", "onto", "MobileNetV2", "using", "ARD", "with", "adversaries", "generated", "using", "different", "numbers", "of", "attack", "steps", "on", "CIFAR-10", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["[", "Downlink", "-", "dominant", ":", "STA", "Mbps", ",", "AP", "Mbps][PP", "Scenario", ":", "STA", "Mbps", ",", "AP", "Mbps]Throughput", "against", "Figure", "shows", "the", "throughput", "against", "in", "the", "down", "/", "up", "-", "link", "balanced", "traffic", "scenario", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["For", "each", ",", "the", "past", "temporal", "profiles", "(", "i.e.", ",", "earlier", "than", "the", "venue", "creation", "time", ")", "are", "used", "as", "features", "for", "a", "GP", "and", "the", "outputs", "of", "the", "GP", "are", "the", "prediction", "of", "the", "characteristic", "temporal", "profile", "of", "the", "new", "venue", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["PS", "proceeds", "in", "multiple", "rounds", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["The", "Global", "Positioning", "System", "(", "GPS", ")", "is", "a", "satellite", "-", "based", "navigational", "system", "that", "was", "developed", "by", "the", "United", "States", "Department", "of", "Defence", "in", "the", "early", "1980s", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["For", "the", "correlating", "transform", "-", "based", "MDC", "framework", ",", "good", "performance", "can", "be", "achieved", "for", "multiple", "description", "coding", "when", "adding", "a", "small", "amount", "of", "redundancy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["Besides", ",", "the", "optimal", "PS", "strategies", "in", "SISO", "/", "SIMO", "fading", "channels", "are", "derived", "in", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["It", "can", "be", "seen", "from", "Figure", ",", "that", "the", "presented", "system", ",", "sssynth", "preforms", "better", "than", "DeepConvSep", "and", "FASST", "in", "terms", "of", "the", "SIR", "metric", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "source to interferences ratio"}, {"tokens": ["The", "energy", "harvested", "by", "power", "receiver", "of", "user", "between", "user", "'s", "UL", "information", "transmission", "in", "epoch", "and", "user", "'s", "UL", "information", "transmission", "in", "epoch", "is", "given", "byfor", "all", ",", "where", "is", "the", "channel", "gain", "between", "user", "and", "user", "in", "epoch", ",", "for", "all", ",", "is", "the", "conversion", "efficiency", "of", "the", "energy", "harvested", "from", "the", "BS", ",", "and", "represents", "the", "conversion", "efficiency", "of", "the", "energy", "harvested", "from", "the", "other", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["As", "described", "in", "step", "in", "Algorithm", "1", ",", "the", "algorithm", "starts", "by", "calculating", "the", "summation", "over", "all", "cluster", "powers", ",", "i.e.", ",", "and", "selects", "the", "user", "with", "the", "strongest", "received", "power", "at", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["In", "order", "to", "provide", "a", "quantitative", "evaluation", "of", "1PS", ",", "2PS", ",", "4PS", ",", "RA", "(", "Horovod", ")", ",", "and", "P2P", "Systems", ",", "we", "evaluated", "the", "performance", "of", "these", "system", "architectures", "with", "the", "same", "basic", "classification", "ML", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["Prior", "work", "has", "addressed", "a", "similar", "issue", "of", "silence", "on", "the", "ASVspoof", "2017", "PA", "dataset", ",", "which", "calls", "for", "careful", "design", "and", "validation", "of", "the", "2019", "PA", "spoofing", "dataset(We", "have", "reported", "the", "\"", "silence", "\"", "issue", "to", "the", "challenge", "organisers", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["SAR", "Specific", "Model"], "acronym_pos": [1, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Although", "\"", "Ours", "-", "mr", "\"", "is", "trained", "with", "MR", "-", "SSIM", "instead", "of", "MS", "-", "SSIM", ",", "both", "the", "MR", "-", "SSIM", "and", "MS", "-", "SSIM", "results", "of", "several", "comparative", "MDC", "approaches", "are", "provided", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["Approximately", "and", "improvements", "are", "introduced", "for", "SAD", "and", "RMSE", "metrics", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["Also", "in", "case", "of", "CDP", "there", "is", "ESA", "architecture", "and", "its", "PROCHLO", "implementation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["Estimated", "epoch", "time", "for", "RA", "."], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "ring allreduce"}, {"tokens": ["Afterwards", ",", "the", "TTP", "returns", "the", "results", "to", "all", "data", "parties", "and", "the", "raw", "data", "of", "Alice"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "trusted third party"}, {"tokens": ["The", "fact", "that", "ECS", "-", "DBN", "outperforms", "DBN", "validates", "the", "need", "for", "cost", "-", "sensitive", "learning", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "next", "step", "consists", "on", "identifying", "the", "query", "subject", "among", "the", "group", "of", "training", "samples", "with", "the", "same", "pose", "using", "Canonical", "Discriminant", "Analysis", "(", "CDA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "canonical discriminant analysis"}, {"tokens": ["As", "VGI", ",", "SC", "faces", "challenges", "regarding", "availability", "of", "workers", "in", "areas", "where", "they", "are", "needed", ",", "plus", "specific", "challenges", "like", "optimal", "task", "assignment", "according", "to", "workers", "'", "current", "positions", "and", "available", "budget", ",", "and", "how", "to", "preserve", "their", "privacy", "kandappu_obfuscation_2018,tong_flexible_2017", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "special case"}, {"tokens": ["The", "main", "practical", "objective", "in", "teaching", "logic", "to", "IS", "practitioners", "is", "to", "give", "them", "the", "ability", "to", "apply", "formal", "methods", "in", "industry", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["The", "AP", "of", "deep", "learning", "features", "are", "higher", "than", "or", "equal", "to", "the", "AP", "of", "hand", "-", "crafted", "features", "for", "the", "majority", "of", "attributes", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["The", "classification", "is", "mainly", "implemented", "by", "the", "shallow", "learning", "models", "such", "as", "ANN", "and", "SVM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "gain", "in", "the", "sum", "-", "rate", "of", "the", "second", "link", ",", "achieved", "by", "the", "RS", "strategy", "with", "comparison", "to", "the", "NoRS", "transmission", ",", "is", "given", "by", "the", "difference"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["[", "cloud", ",", "below", "of", "=", "gc", ",", "node", "distance", "=", "2", "cm", "]", "(", "m", ")", "Race", "Classification", ";", "[", "cloud", ",", "below", "of", "=", "init", ",", "node", "distance", "=", "2", "cm", "]", "(", "f", ")", "Race", "Classification", ";", "[", "block3", ",", "below", "left", "of", "=", "m", ",", "node", "distance", "=", "1.5", "cm", "]", "(", "of", ")", "BM", "Age", "Estimator", ";"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "black males"}, {"tokens": ["By", "the", "same", "token", "as", "CF", "prediction", ",", "we", "leverage", "factorisation", "machine", "and", "the", "model", "parameter", "thus", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "FCA", "resources", "are", "replaced", "by", "NGCC", "located", "at", "the", "Hub", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward capacity auctions"}, {"tokens": ["Affine", "Invariant", "Generalized", "Matching", "PursuitTo", "design", "an", "affine", "invariant", "MP", "algorithm", "we", "will", "rely", "on", "the", "following", "slight", "variation", "of", "(", "defined", "in", "def", ":", "Cf", ")", "using", "instead", "of", ",", "i.e.,Throughout", "this", "section", ",", "we", "again", "assume", "availability", "of", "a", "finite", "constant", "as", "an", "upper", "bound", "of", "the", "atomic", "norms", "of", "the", "optimum", ",", "as", "well", "as", "the", "iterate", "sequence", "up", "to", "the", "current", "iteration", ",", "as", "defined", "in", "eq", ":", "rho", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["the", "DCM", "is", "outside", "the", "scope", "of", "RUM", "and", "the", "regularity", "is", "violated", ",", "the", "Markov", "chain", "and", "MNL", "model", "may", "fail", "to", "specify", "the", "choice", "behavior", "correctly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random utility modelwe"}, {"tokens": ["From", "the", "simulation", "results", ",", "the", "proposed", "ECS", "-", "DBN", "exhibits", "superior", "overall", "performance", ",", "especially", "in", "terms", "of", "G", "-", "mean", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Ende", "des", "Vergleichs\u00ad-essays", "von", "RB", "geaussert", "wird", ",", "mischt", "von", "der", "Redehaltung", "her"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rosi braidotti"}, {"tokens": ["Goodput", "and", "lossfigure*Random", "mobilityIn", "the", "scenario", "where", "nodes", "move", "at", "random", "and", "consumers", "do", "not", "always", "have", "a", "path", "to", "the", "content", "producer", ",", "intermediate", "nodes", "should", "take", "a", "store", "and", "forward", "approach", ",", "which", "is", "naturally", "done", "in", "NDN", "and", "in", "TCP", "/", "IP", "this", "is", "implemented", "via", "delay", "-", "tolerant", "network", "(", "DTN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "delay tolerant networks"}, {"tokens": ["Since", "training", "with", "noisy", "data", "and", "different", "speakers", "will", "make", "QA", "model", "more", "robust", "during", "testing", ",", "the", "number", "of", "speakers", "is", "large", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "algorithmically", "extracted", "BPM", "information", "also", "is", "imperfect", ",", "and", "likely", "contains", "octave", "errors", ",", "in", "which", "BPM", "is", "under-", "or", "overestimated", "by", "a", "factor", "of", "2", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "beat per minute"}, {"tokens": ["On", "the", "other", "hand", ",", "HAP", "operates", "at", "very", "high", "altitude", "above", "km", ",", "and", "vehicles", "utilizing", "this", "platform", "are", "able", "to", "stay", "for", "a", "long", "time", "in", "the", "upper", "layers", "of", "the", "stratosphere", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high altitude platform"}, {"tokens": ["Tests", "for", "Evaluating", "Imbalance", "LearningStatistical", "tests", "provide", "evidence", "to", "ascertain", "the", "claim", "that", "the", "ECS", "-", "DBN", "outperforms", "other", "competitive", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["HOG", "is", "calculated", "by", "dividing", "the", "input", "image", "into", "small", "spatial", "regions", "called", "cells", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "histogram of oriented gradient"}, {"tokens": ["In", "this", "paper", ",", "we", "use", "both", "SC", "and", "SCL", "techniques", "for", "decoding", "BIPCM", "and", "MLPC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "successive cancellation"}, {"tokens": ["Network", "TrainingWe", "integrate", "the", "BCNN", ",", "AON", ",", "FG", "and", "attention", "decoder", "into", "one", "network", ",", "as", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "filter gate"}, {"tokens": ["Then", ",", "we", "construct", "the", "following", "auxiliary", "signal", "transmission", "model", "for", "UE", "where", "can", "be", "regarded", "as", "the", "number", "of", "interfering", "sources", "from", "UE", ",", "can", "be", "treated", "as", "the", "CSI", "from", "the", "th", "interfering", "source", "of", "UE", "to", "UE", ",", "is", "the", "corresponding", "transmission", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Temperature", "RMSD", "with", "respect", "to", "the", "target", "temperature", "observed", "in", "HMC", "simulations", "of", "the", "toxin", "with", "different", "lengths", "of", "trajectories", ",", "time", "steps", "and", "integrating", "schemes", "(", "left", ")", "and", "average", "temperature", "in", "MD", "simulations", "of", "the", "toxin", "using", "various", "time", "steps", "and", "integrators", "(", "right", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["DBNs", "can", "be", "used", "as", "a", "feature", "extraction", "method", "for", "dimensionality", "reduction", "where", "the", "class", "labels", "is", "not", "required", "with", "BP", "in", "the", "DBN", "architecture", "(", "unsupervised", "training", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["BSP", "is", "an", "iterative", "computation", "model", "where", "a", "superstep", "(", "iteration", ")", "consists", "of", "a", "user", "-", "specified", "function", "(", "compute", "(", ")", ")", "run", "in", "parallel", "by", "workers", "on", "different", "parts", "of", "the", "graph", ",", "with", "the", "functions", "optionally", "generating", "messages", "to", "other", "parts", "of", "the", "graph", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bulk synchronous parallel"}, {"tokens": ["After", "feature", "transformation", ",", "softmax", "layer", "serves", "as", "the", "output", "layer", "of", "DBN", "to", "perform", "classification", "predictions", "as", "parameterized", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["As", "a", "consequence", ",", "for", "each", "one", "of", "the", "-th", "non", "-", "linear", "functions", ",", "we", "will", "set", "a", "continual", "GP", "prior", "of", "the", "form", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["this", "section", "we", "formulate", "a", "fully", "discrete", "approximation", "to", "eq", ":", "PVI", "using", "backward", "Euler", "scheme", "in", "time", "and", "piecewise", "linear", "finite", "element", "method", "in", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parabolic variational inequality"}, {"tokens": ["One", "result", "is", "that", "the", "MGE", "preconditioner", "does", "nothelp", "PI", ";", "when", "we", "add", "it", ",", "the", "calculation", "slows", "down", "enough", "that", "it", "did", "notfinish", "within", "available", "wall", "time", "limits", ",", "although", "convergence", "does", "occureventually", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["MC", ",", "as", "a", "novel", "feature", "to", "enhance", "reliability", "and", "reduce", "the", "packet", "failure", "probability", "(", "by", "transmitting", "data", "packets", "to", "the", "UE", "from", "multiple", "cells", "independently", ")", ",", "is", "considered", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "this", "regard", ",", "the", "optimisation", "algorithm", "that", "is", "introduced", "in", "next", "section", "to", "solve", "the", "generalised", "GCP", "is", "only", "provided", "for", "the", "discrete", "case", ",", "for", "simplicity", "reasons", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph compression problem"}, {"tokens": ["Conclusion", "and", "Future", "WorkWe", "proposed", "and", "studied", "and", "as", "extensions", "of", "RP", "and", "PS", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["The", "communication", "complexity", "of", "KK13", "OT", "extension", "producing", "is", "bits", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["hbt]The", "association", "between", "age", "and", "SAT", "-", "Volume", "and", "VAT", "-", "Volume", "in", "men", "and", "women", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Furthermore", ",", "LR", "is", "prone", "to", "the", "problem", "of", "over", "-", "fitting", "as", "it", "focuses", "on", "maximizing", "the", "likelihood", ",", "while", "SVM", "can", "generate", "linear", "hyperplanes", "by", "mapping", "the", "data", "into", "high", "-", "dimensional", "spaces", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Note", "that", "MP", "does", "not", "require", "to", "maintain", "the", "active", "set", "as", "the", "update", "only", "relies", "on", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["While", "LSTM", "and", "GRU", "-", "D", "can", "process", "time", "series", "input", "directly", "to", "make", "a", "binary", "prediction", "for", "each", "ICU", "stay", ",", "both", "LR", "and", "RF", "make", "predictions", "using", "a", "flattened", "vector", "of", "the", "24-hour", "time", "-", "series", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["This", "example", "indicates", "the", "proposed", "ECS", "-", "DBN", "can", "obtain", "better", "performance", "by", "finding", "suitable", "misclassification", "costs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Finally", ",", "we", "note", "that", "bpsk_upper1", "can", "be", "used", "under", "different", "path", "loss", "models", "and", "generalizes", "the", "SEP", "derivations", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "symbol error probability"}, {"tokens": ["FEC", "SSIM", "&", "0,876", "&", "0,785", "&", "0,734", "&", "0,709", "&", "0,591", "VQM", "&", "2,266", "&", "3,264", "&", "3,783", "&", "3,935", "&", "6,425", "Overhead", "&", "18,777", "&", "31,888", "&", "45,342", "&", "63,102", "&", "-", "tabular", "tab", ":", "corv", ":"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "TP", "runs", "only", "if", "the", "winning", "cluster", "in", "the", "SP", "changes", "which", "results", "in", "an", "event", "-", "driven", "architecture", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["As", "suggested", "in", ",", "most", "of", "the", "DCNN", "architectures", "we", "inspected", "follow", "a", "clear", "two", "-", "part", "design", "pattern", ":", "In", "the", "first", "part", "(", "at", "the", "beginning", "of", "the", "network", ")", "multiple", "convolution", "and", "pooling", "layers", "are", "stacked", "on", "top", "of", "each", "other", "to", "produce", "abstract", "data", "representations", "and", "in", "the", "second", "part", "(", "at", "the", "end", "of", "the", "network", ")", "additional", "fully", "connected", "layers", "are", "used", "to", "forward", "these", "abstractions", "to", "the", "output", "layer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Based", "on", "the", "channel", "measurements", ",", "the", "MgNB", "can", "set", "up", "MC", "by", "requesting", "the", "SgNB", "to", "allocate", "resources", "for", "a", "specific", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["Matching", ":", "we", "refer", "to", "a", "0", "-", "1", "matrix", "which", "is", "the", "solution", "of", "a", "particular", "LAP", "as", "a", "\"", "matching", "\"", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "linear assignment problem"}, {"tokens": ["Resilient", "Vector", ":", "Properties", "and", "Generation", "Since", "RV", "is", "a", "core", "element", "of", "our", "construction", ",", "we", "here", "provide", "details", "discussion", "on", "its", "properties", "and", "how", "it", "can", "be", "generated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["This", "stems", "from", "the", "fact", "that", "the", "SCM", "representation", "space", "can", "be", "more", "discriminative", "than", "the", "DSCN", "for", "this", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial compositional model"}, {"tokens": ["The", "prior", "of", "the", "GP", "then", "becomes", ":", "where", "is", "a", "covariance", "function", "(", "or", "kernel", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["It", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "accuracy", "of", "84.8", "that", "is", "a", "bit", "lower", "than", "DDE", "-", "MGM", ",", "but", "its", "run", "time", "is", "drastically", "longer", "than", "the", "proposed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["RESULTSThe", "overall", "testing", "performance", "of", "the", "LMEM", ",", "RF", ",", "and", "ANN", "models", "are", "summarized", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Since", "does", "not", "have", "value", "-", "decreasing", "transitions", ",", "we", "can", "invoke", "Lemma", "lem", ":", "reach", "-", "opt", "-", "uniform", "to", "obtain", "a", "player", "MD", "strategy", "with", "for", "all", "and", "for", "all", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["In", "this", "paper", ",", "we", "present", "an", "approach", "to", "DST", "that", "pretrains", "a", "model", "on", "a", "source", "domain", "for", "which", "turn", "-", "level", "annotations", "exist", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["ABEP", ",", ",", "of", "DBPSK", "for", "RS", "versus", "the", "average", "relay", "SNR", "per", "bit", ",", ",", "and", "for", "dB", "over", "INID"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["The", "SAR", "system", "offered", "ten", "different", "types", "of", "games", "based", "on", "five", "different", "levels", "of", "challenge", "(", "LoC", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["for", "a", "GP", "instance", "that", "work", "well", ",", "i.e.", ",", "solve", "a", "given", "problem", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Although", "there", "are", "several", "other", "BC", "technologies", ",", "BC", "such", "as", "that", "adopted", "by", "Bitcoin", ",", "but", "Fabric", "reduces", "computation", "cycles", "and", "provides", "scalability", ",", "identity", "management", ",", "and", "privacy", ",", "which", "is", "of", "the", "utmost", "importance", "in", "the", "IoT", "paradigm", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["Box", "plot", "summarizing", "mean", "predicted", "difficulty", "values", "of", "control", "algorithms", "(", "JC", ",", "SC", ",", "CC", "and", "CFB", ")", "in", "needle", "steering", "using", "physiological", "response", "(", "left", ")", "and", "kinematic", "features", "(", "right", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "steering control"}, {"tokens": ["From", "amongst", "these", "CM", ",", "the", "polyhedral", "CMuRN", "scored", "the", "highest", "in", "terms", "of", "average", ",", "and", "although", "this", "method", "did", "not", "outperform", "the", "more", "intricate", "supervised", "machine", "learning", "methods", ",", "the", "performance", "is", "nevertheless", "exceptional", "for", "its", "interpretability", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "centroid methods"}, {"tokens": ["figuretabularcccF", "-", "score", "&", "Domain", "1", "&", "Domain", "2", "MGM", "GAN", "&", "0.96", "&", "0.91", "GAN", "&", "0.26", "&", "0.90", "Cycle", "GAN", "&", "0.92", "&", "0.71", "Random", "weights", "&", "0.76", "&", "0.23", "tabularF", "-", "scores", "for", "CD25", "+", "cells", "in", "the", "two", "samples", "in", "the", "mouse", "thymus", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["for", "both", "repetitive", "and", "RS", "-", "based", "transmission", ",", "degrades", "with", "decreasing", "and/or", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["DiscussionFigure", "compares", "synthesis", "results", "of", "the", "non", "-", "parametric", "OT", "5", ",", "BS", "2", "methods", "and", "the", "statistical", "random", "convolution", "method", "in", "Algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["All", "notebooks", "are", "released", "under", "a", "Creative", "Commons", "Attribution", "4.0", "International", "(", "CC", "BY", "4.0", ")", "License", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "creative commons"}, {"tokens": ["SettingIn", "this", "paper", ",", "we", "performed", "all", "the", "experiments", "on", "two", "deep", "learning", "models", ",", "such", "as", "CNN", "and", "LSTM", ",", "and", "three", "machine", "learning", "algorithms", ",", "such", "as", "RF", ",", "GBR", ",", "and", "LR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "linear regression"}, {"tokens": ["Finally", ",", "we", "perform", "similar", "analyses", "and", "assess", "the", "error", "in", "estimating", "the", "ACE", "when", "varying", "the", "number", "of", "mixture", "components", "in", "Figure", "fig", ":", "ATE", "-", "error", "-", "cluster", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average causal effect"}, {"tokens": ["E.g.", "for", "a", "typical", "ring", "all", "-", "reduce", "algorithm", ",", "working", "on", "16", "processes", ",", "4", "MB", "data", "size", "and", "1Gbps", "Ethernet", "network", "we", "can", "measure", "45.7ms", "and", "18.2ms", ",", "thus", "using", "PAP", "optimized", "algorithm", "can", "save", "at", "most", "27.5ms", "of", "average", "elapsed", "time", ",", "no", "matter", "how", "slow", "the", "delayed", "process", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["For", "similar", "optimization", "stability", "reasons", ",", "for", "AC", "-", "OPF", "the", "binding", "status", "of", "lower", "and", "upper", "bound", "limits", "of", "voltage", "magnitudes", "were", "not", "predicted", "either", ",", "and", "always", "set", "to", "binding", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["For", "instance", ",", "the", "convex", "IB", "Lagrangian", "is", "related", "with", "the", "concave", "IB", "Lagrangian", "as", "defined", "by", "Propositon", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "this", "paper", ",", "we", "first", "present", "quickly", "the", "reinforcement", "learning", "framework", "and", "the", "main", "state", "representation", "learning", "approaches", "that", "are", "implemented", ",", "before", "presenting", "the", "SRL", "Toolbox", "environments", "and", "datasets", ",", "the", "qualitative", "and", "quantitative", "evaluation", "methods", ",", "and", "a", "set", "of", "experiments", "illustrating", "the", "performances", "of", "the", "implemented", "approaches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["In", "general", ",", "PNN", "uses", "product", "layers", "to", "explore", "feature", "interactions", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["On", "the", "other", "hand", ",", "features", "in", "and", "show", "more", "robust", "on", "generalization", "to", "SAR", "targets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Despite", "many", "studies", "on", "imbalanced", "learning", ",", "the", "potential", "benefits", "through", "DBN", "with", "imbalanced", "learning", "have", "not", "been", "fully", "explored", "yet", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Here", ",", "the", "distributed", "ledger", "of", "blockchain", "is", "used", "for", "maintaining", "the", "network", "information", "while", "the", "highly", "secure", "ECC", "is", "employed", "for", "mutual", "authentication", "between", "vehicles", "and", "road", "side", "units", "(", "RSUs", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["Specifically", ",", "we", "show", "that", "common", "English", "words", "are", "sufficient", "to", "a", "greater", "extent", "in", "distinguishing", "among", "writings", "of", "most", "renowned", "authors", ",", "especially", "when", "AA", "is", "performed", "in", "the", "closed", "-", "set", "setup", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["Scores", "are", "reported", "in", "Table", "tab", ":", "mnistfscore", ",", "where", "we", "see", "as", "expected", ",", "the", "MGM", "significantly", "outperforms", "the", "traditional", "GANs", "in", "both", "domains", "with", "scores", "of", "and", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["Conclusions", "and", "Future", "WorkThis", "study", "focuses", "on", "several", "algorithms", "for", "unsupervised", "submodular", "rank", "aggregation", "on", "score", "-", "based", "permutations", "based", "on", "the", "LB", "divergence", "in", "both", "linear", "and", "nested", "structured", "frameworks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["c", ")", ":", "Wireless", "AR", "setup", "concept", "by", "Fruend", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Basic", "Question", "ConcatenationIn", "this", "section", ",", "we", "propose", "a", "criterion", "to", "use", "these", "BQ", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "basic question"}, {"tokens": ["QA", "systems", "have", "been", "evolving", "since", "the", "early", "1960s", "with", "the", "efforts", "in", "the", "database", "community", "to", "support", "natural", "language", "queries", "by", "translating", "them", "into", "structured", "queries", "[", "see", ",", "e.g."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["DE", "requires", "both", "sparsity", "and", "consistency", ",", "which", "is", "shown", "in", "figure", "and", "figure", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["However", ",", "the", "following", "question", "is", "open", ":", "if", "a", "state", "is", "almost", "-", "surely", "winning", "forplayer", "in", "a", "co", "-", "Buchi", "game", ",", "does", "player", "also", "have", "a", "winning", "MD", "strategy", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["Although", "most", "of", "the", "GM", "algorithms", "considered", "in", "this", "work", "are", "used", "for", "2D", "applications", "in", "computer", "vision", ",", "their", "general", "formulation", "allows", "the", "alignment", "of", "any", "generic", "network", ",", "regardless", "the", "dimensional", "embedding", ",", "and", "offer", "a", "rich", "ground", "for", "ad", "-", "hoc", "methodological", "developments", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph matching"}, {"tokens": ["For", "very", "low", "-values", ",", "the", "ICC", "distribution", "for", "NSCLC", "may", "be", "less", "stable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["(", "a", ")", "RGB", "(", "b", ")", "IMSHARP", "(", "c", ")", "BF", "(", "d", ")", "GF", "(", "e", ")", "WLS", "(", "f", ")", "BFWLSAVG", "(", "g", ")", "FCMAX", "(", "ours", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bilateral filtering"}, {"tokens": ["Separate", "linear", "regression", "analyses", "are", "performed", "to", "explore", "the", "effect", "of", "age", "on", "SAT", "-", "V", "and", "VAT", "-", "V", "in", "men", "and", "women", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["However", ",", "when", "provided", "with", "high", "-", "dimensional", "random", "variables", "such", "as", "images", ",", "these", "algorithms", "do", "not", "scale", "well", "and", "deep", "learning", "based", "techniques", ",", "where", "the", "IB", "Lagrangian", "is", "used", "as", "the", "objective", "function", ",", "prevailed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["For", "the", "AD", "-", "level", "evaluation", ",", "we", "compare", "the", "performance", "of", "GMV", ",", "ROI", ",", "CVR", ",", "and", "PPC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "pay per click"}, {"tokens": ["Denmark", "is", "stronger", "in", "the", "AA", "category", ",", "compared", "to", "the", "PSS", "category", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "astronomy and astrophysics"}, {"tokens": ["The", "active", "power", "flow", "of", "the", "distribution", "network", "is", "monitored", "by", "sensing", "the", "consumption", "at", "the", "GCP", "with", "a", "PMU", "-", "based", "metering", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "grid connection point"}, {"tokens": ["LF", "-", "RCNNLate", "fusion", "encoder", "with", "concatenated", "history", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "late fusion"}, {"tokens": ["The", "cover", "complexity", "(", "CC", ")", "is", "The", "CD", "is", "defined", "as", "the", "difference", "between", "the", "mean", "of", "SC", "and", "the", "mean", "of", "MC", ",", "since", "each", "category", "occurs", "with", "the", "same", "probability", "(", ")", "in", "the", "data", "sets", "mostly", "used", "in", "practice", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cover complexity"}, {"tokens": ["The", "users", "feed", "back", "the", "estimated", "AOD", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Consequently", ",", "we", "are", "able", "to", "recommend", "over", "80", "of", "patients", "with", "relevant", "primary", "care", "doctors", "by", "presenting", "them", "with", "a", "list", "of", "10", "recommendations", "(", "compared", "to", "just", "37", "using", "the", "heuristic", "baseline", "or", "69", "using", "CF", "without", "the", "trust", "measure", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Figure", "f.samples_kernel_expcos", "shows", "two", "functions", "sampled", "from", "a", "GP", "with", "covariance", "function", "e.kernel_expcos", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Suppose", "the", "solutions", "are", "allocated", "in", "a", "balanced", "manner", "in", "the", "BSP", "tree", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["We", "start", "with", "the", "most", "basic", "version", "of", "NBC", "which", "was", "developed", "by", "using", "TF", "(", "bag", "-", "of", "-", "word", ")", ",", "a", "feature", "extraction", "technique", "which", "counts", "the", "number", "of", "words", "in", "documents", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "naive bayes classifier"}, {"tokens": ["The", "dataset", "that", "we", "have", "compiled", "can", "be", "enriched", "with", "additional", "essays", "from", "Victorian", "periodicals", "to", "become", "a", "challenging", "benchmark", "dataset", "and", "an", "invaluable", "resource", "for", "evaluating", "future", "computational", "AA", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["As", "described", "in", "Figure", ",", "the", "ANN", "has", "3", "inputs", "(", "collectivity", "of", "person", ",", "mean", "Euclidean", "distance", "from", "a", "person", "to", "others", "and", "the", "number", "of", "people", "in", "the", "Social", "Space(Social", "space", "is", "related", "to", "meters", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Mean", "Precision", "(", "MP", ")", "averages", "such", "measures", "for", "all", "requests", "from", "the", "dataset", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean precision"}, {"tokens": ["ht][][]Class", "wise", "ROC", "curves", "for", "lesion", "segmentation", "using", "the", "proposed", "DSNet", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "downlink", "throughput", "of", "Uni", "-", "MUMAC", "can", "achieve", "higher", "gains", "when", "the", "network", "is", "not", "saturated", ",", "which", "is", "because", "the", "proposed", "-nd", "round", "transmission", "increases", "the", "uplink", "transmission", "efficiency", ",", "and", "therefore", "decreases", "the", "number", "of", "AP", "'s", "channel", "contenders", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["DE", "of", "digit", "0", "increases", "with", "width", "and", "then", "plateaus", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["The", "DT", "hyperparameters", "are", "dynamically", "set", "for", "each", "dataset", ",", "using", "the", "Gini", "criterion", "to", "find", "the", "best", "splits", ",", "and", "using", "as", "seed", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["An", "example", "of", "a", "successful", "uplink", "transmission", "is", "shown", "in", "Figure", ",", "in", "which", "illustrating", "case", ",", "the", "AP", "has", "antennas", ",", "STA", "picks", "and", "STA", "picks", "from", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "FCA", "main", "goal", "is", "the", "computation", "of", "the", "concept", "lattice", "associated", "to", "thecontext", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "formal concept analysis"}, {"tokens": ["Furthermore", ",", "among", "the", "interesting", "outcomes", "of", "this", "paper", ",", "it", "was", "extracted", "that", "by", "increasing", "the", "number", "of", "relay", "antennas", "or", "by", "decreasing", "the", "severity", "of", "SI", ",", "RS", "appears", "to", "be", "more", "robust", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["Global", "Positioning", "System", "(", "GPS", ")", "is", "also", "discussed", "as", "it", "is", "a", "key", "feature", "used", "in", "the", "mobile", "application", "to", "determine", "the", "location", "of", "the", "user", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Performance", "evaluation", "of", "efficiency", "of", "supervised", "PIN", "on", "Referit", "Game*[h]Qualitative", "results", "on", "the", "test", "sets", "of", "Flickr30", "K", "Entities", "(", "top", "row", ")", "and", "ReferIT", "Game", "(", "middle", "row", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "proposal indexing network"}, {"tokens": ["This", "means", "that", "we", "have", "the", "same", "mechanism", "used", "to", "build", "continual", "GP", "priors", ",", "that", "now", "works", "similarly", "but", "in", "the", "latent", "function", "layer", "rather", "than", "in", "the", "output", "function", "one", "obtained", "after", "mixing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["A", "first", "simple", "classification", "can", "be", "made", "based", "on", "if", "the", "AP", "governs", "both", "downlink", "and", "uplink", "communication", ",", "or", "the", "random", "access", "is", "still", "considered", "to", "initiate", "transmissions", "from", "STAs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["In", "the", "following", ",", "we", "compare", "the", "proposed", "systematic", "Exact", "-", "MBR", "codes", "with", "the", ",", "in", "terms", "of", "the", "range", "of", "and", "the", "encoding", "complexity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Compared", "with", "the", "large", "-", "scale", "annotated", "dataset", "in", "natural", "images", ",", "the", "lack", "of", "labeled", "data", "in", "remote", "sensing", "becomes", "an", "obstacle", "to", "train", "a", "deep", "network", "very", "well", ",", "especially", "in", "SAR", "image", "interpretation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Simulation", "and", "DiscussionTo", "assess", "the", "SR", "performance", "gain", "of", "the", "proposed", "Max", "-", "SR", "PA", "strategy", ",", "simulation", "results", "and", "analysis", "are", "presented", "in", "the", "following", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["Starting", "with", "an", "initial", "lifted", "belief", "state", ",", "in", "the", "framework", "of", "BF", "(", "sequential", ")", ",", "we", "need", "to", "perform", "consecutively[(1", ")", "]", "updating", "the", "belief", "state", "according", "to", "the", "observations", "(", "update", ")", ",", "answering", "of", "application", "specific", "questions", ",", "and", "predicting", "the", "next", "lifted", "belief", "state", "by", "applying", "the", "compound", "actions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian filtering"}, {"tokens": ["Our", "target", "from", "the", "beginning", "is", "to", "build", "an", "analysis", "technique", "which", "will", "follow", "the", "CDP", ",", "as", "well", "as", "easy", "to", "understand", ",", "robust", ",", "fast", "and", "cheap", "in", "implement", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["As", "seen", "from", "plot", ":", "IACFequil", ",", "for", "all", "combinations", "of", "and", ",", "both", "HMC", "and", "MD", "simulations", "using", "the", "AIA", "integrators", "decorrelated", "faster", "than", "the", "corresponding", "simulations", "that", "used", "the", "velocity", "Verlet", "integrator", ",", "BCSS", "or", "the", "method", "of", "Predescu", "et", "al", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["At", "the", "beginning", "of", "each", "time", "slot", ",", "the", "BS", "observes", "current", "AoS", "of", "each", "source", "and", "computes", "the", "Whittle", "'s", "index", "for", "each", "user", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["(", "ICC", "VAT", "0.999", "and", "SAT", "0.999", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Section", "describes", "the", "multi", "-", "armed", "bandit", "formulation", "for", "the", "electricity", "pricing", "problem", ",", "presents", "the", "modified", "TS", "heuristic", ",", "and", "discusses", "its", "performance", "and", "reliability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["errorIn", "this", "experiment", ",", "we", "are", "particularly", "interested", "in", "the", "demonstration", "of", "the", "effect", "that", "the", "continual", "GP", "prior", "reconstruction", "has", "on", "the", "whole", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Therefore", ",", "it", "is", "sometimes", "taken", "into", "account", "in", "the", "modelling", "in", "the", "assortative", "or", "affinity", "SBM", "by", ",", "for", "example", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Notice", "that", "the", "is", "the", "available", "bandwidth", "between", "every", "client", "and", "PS", ",", "represents", "the", "total", "bandwidth", "available", "for", "all", "clients", ",", "and", "indicates", "all", "active", "workers", "who", "communicate", "with", "PS", ".", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "parameter server"}, {"tokens": ["The", "images", "shown", "from", "ImageNet", "have", "been", "processed", "using", "our", "capture", "model", "and", "ISP", "model", ",", "whereas", "the", "images", "shown", "from", "our", "lab", "-", "captured", "dataset", "have", "only", "been", "processed", "using", "our", "ISP", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Two", "-", "layered", "clip", "network", "of", "a", "PS", "agent", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "projective simulation"}, {"tokens": ["The", "BQ", "utilization", "process", "can", "be", "explained", "as", "Table", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["When", "the", "sources", "employ", "the", "FJ", "powers", "from", "the", "friendly", "jammer", "to", "improve", "their", "secrecy", "capacities", ",", "a", "certain", "cost", "is", "incurred", "to", "the", "friendly", "jammer", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["(", "1.7", "x", ")", "8*turn90K40c", "(", "ECC", "off)turn", "&", "4*turn90key", "-", "onlyturn", "&", "DMS", "&", "8.99", "(", "5.2", "x", ")", "&", "8.52", "(", "4.9", "x", ")", "&", "6.98", "(", "4.0", "x", ")", "&", "4.94", "(", "2.9", "x", ")", "&", "3.26", "(", "1.9", "x", ")", "&", "-", "&", "-", "&", "-", "&", "&", "WMS", "&", "14.15", "(", "8.2", "x", ")", "&", "11.74", "(", "6.8", "x", ")", "&", "11.65", "(", "6.7", "x", ")", "&", "8.68", "(", "5.0", "x", ")", "&", "7.57", "(", "4.4", "x", ")", "&", "-", "&", "-", "&", "-", "&", "&", "BMS", "&", "8.74", "(", "5.1", "x", ")", "&", "8.59", "(", "5.0", "x", ")", "&", "8.07", "(", "4.7", "x", ")", "&", "7.69", "(", "4.4", "x", ")", "&", "6.47", "(", "3.7", "x", ")", "&", "5.10", "(", "2.9", "x", ")", "&", "3.59", "(", "2.1", "x", ")", "&", "2.48", "(", "1.4", "x", ")", "&", "&", "RB", "-", "sort", "&", "6.42", "(", "3.7", "x", ")", "&", "6.40", "(", "3.7", "x", ")", "&", "6.37", "(", "3.7", "x", ")", "&", "6.30", "(", "3.6", "x", ")", "&", "5.70", "(", "3.3", "x", ")", "&", "3.72", "(", "2.2", "x", ")", "&", "3.72", "(", "2.1", "x", ")", "&", "3.69", "(", "2.1", "x", ")", "2", "-", "11", "&", "4*turn90key", "-", "valueturn", "&", "DMS", "&", "8.99", "(", "7.7", "x", ")", "&", "7.05", "(", "6.0", "x", ")", "&", "5.71", "(", "4.9", "x", ")", "&", "3.98", "(", "3.4", "x", ")", "&", "1.96", "(", "1.7", "x", ")", "&", "-", "&", "-", "&", "-", "&", "&", "WMS", "&", "9.58", "(", "8.2", "x", ")", "&", "8.90", "(", "7.6", "x", ")", "&", "7.55", "(", "6.5", "x", ")", "&", "6.78", "(", "5.8", "x", ")", "&", "4.57", "(", "3.9", "x", ")", "&", "-", "&", "-", "&", "-", "&", "&", "BMS", "&", "7.23", "(", "6.2", "x", ")", "&", "6.99", "(", "6.0", "x", ")", "&", "6.28", "(", "5.4", "x", ")", "&", "5.66", "(", "4.8", "x", ")", "&", "5.13", "(", "4.4", "x", ")", "&", "4.59", "(", "3.9", "x", ")", "&", "3.06", "(", "2.6", "x", ")", "&", "1.81", "(", "1.5", "x", ")", "&", "&", "RB", "-", "sort", "&", "2.98", "(", "2.6", "x", ")", "&", "2.98", "(", "2.5", "x", ")", "&", "2.78", "(", "2.4", "x", ")", "&", "2.63", "(", "2.2", "x", ")", "&", "2.67", "(", "2.3", "x", ")", "&", "1.92", "(", "1.6", "x", ")", "&", "1.84", "(", "1.6", "x", ")", "&", "1.76", "(", "1.5", "x", ")", "8*turn90GTX", "1080", "turn", "&", "4*turn90key", "-", "onlyturn", "&", "DMS", "&", "17.67", "(", "5.2", "x", ")", "&", "14.38", "(", "4.2", "x", ")", "&", "11.00", "(", "3.2", "x", ")", "&", "7.73", "(", "2.3", "x", ")", "&", "5.54", "(", "1.6", "x", ")", "&", "-", "&", "-", "&", "-", "&", "&", "WMS", "&", "18.93", "(", "5.6", "x", ")", "&", "17.54", "(", "5.2", "x", ")", "&", "17.98", "(", "5.3", "x", ")", "&", "16.18", "(", "4.8", "x", ")", "&", "12.20", "(", "3.6", "x", ")", "&", "-", "&", "-", "&", "-", "&", "&", "BMS", "&", "18.42", "(", "5.4", "x", ")", "&", "17.84", "(", "5.2", "x", ")", "&", "17.79", "(", "5.2", "x", ")", "&", "18.01", "(", "5.3", "x", ")", "&", "16.64", "(", "4.9", "x", ")", "&", "14.14", "(", "4.2", "x", ")", "&", "11.43", "(", "3.4", "x", ")", "&", "7.05", "(", "2.1", "x", ")", "&", "&", "RB", "-", "sort", "&", "8.13", "(", "2.4", "x", ")", "&", "8.13", "(", "2.4", "x", ")", "&", "8.09", "(", "2.4", "x", ")", "&", "8.06", "(", "2.4", "x", ")", "&", "7.91", "(", "2.3", "x", ")", "&", "7.51", "(", "2.2", "x", ")", "&", "6.43", "(", "1.9", "x", ")", "&", "4.51", "(", "1.3", "x", ")", "2", "-", "11", "&", "4*turn90key", "-", "valueturn", "&", "DMS", "&", "11.17", "(", "5.9", "x", ")", "&", "9.75", "(", "5.1", "x", ")", "&", "7.07", "(", "3.7", "x", ")", "&", "4.95", "(", "2.6", "x", ")", "&", "3.51", "(", "1.8", "x", ")", "&", "-", "&", "-", "&", "-", "&", "&", "WMS", "&", "11.38", "(", "6.0", "x", ")", "&", "11.21", "(", "5.9", "x", ")", "&", "10.81", "(", "5.7", "x", ")", "&", "10.37", "(", "5.5", "x", ")", "&", "8.04", "(", "4.2", "x", ")", "&", "-", "&", "-", "&", "-", "&", "&", "BMS", "&", "11.67", "(", "6.1", "x", ")", "&", "11.62", "(", "6.1", "x", ")", "&", "11.57", "(", "6.1", "x", ")", "&", "11.40", "(", "6.0", "x", ")", "&", "11.04", "(", "5.8", "x", ")", "&", "10.64", "(", "5.6", "x", ")", "&", "9.78", "(", "5.1", "x", ")", "&", "5.85", "(", "3.1", "x", ")", "&", "&", "RB", "-", "sort", "&", "3.44", "(", "1.8", "x", ")", "&", "3.44", "(", "1.8", "x", ")", "&", "3.42", "(", "1.8", "x", ")", "&", "3.40", "(", "1.8", "x", ")", "&", "3.34", "(", "1.8", "x", ")", "&", "3.19", "(", "1.7", "x", ")", "&", "2.83", "(", "1.5", "x", ")", "&", "2.31", "(", "1.2", "x", ")", "tabular", "Multisplit", "with", "delta", "-", "buckets", "and", "random", "keys", "uniformly", "distributed", "among", "buckets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["Ageing", "coupled", "with", "RLS", "and", "SBM", "can", "reach", "the", "optimum", "by", "local", "moves", ",", "which", "respectively", "yields", "upper", "bounds", "of", "and", "for", "arbitrarily", "small", "constant", "on", "their", "runtimes", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard bit mutations"}, {"tokens": ["The", "v", "-", "rescale", "thermostat", "was", "applied", "in", "MD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "molecular dynamics"}, {"tokens": ["Spectral", "angle", "distance", "(", "SAD", ")", "measures", "the", "spectral", "angle", "between", "two", "input", "samples", "and", "the", "score", "closer", "to", "zero", "implies", "higher", "correlation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["NoduleNet", "outperformed", "previous", "state", "-", "of", "-", "the", "-", "art", "deep", "learning", "based", "method", "by", "0.95", "on", "DSC", ",", "without", "the", "need", "to", "train", "a", "separate", "and", "dedicated", "3D", "DCNN", "for", "nodule", "segmentation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["arrows", ",", "positioning", ",", "patterns", "multi", "-", "objective", "net", "-", "works", "C", "-", "MAPSS", "classification", "hyper", "-", "parameters", "pre", "-", "process", "pre", "-", "processing", "ada", "-", "boost", "G", "-", "mean", "Cost", "-", "sensitive", "ECS", "-", "DBN", "Evolutionary", "Algorithm", "A", "Cost", "-", "Sensitive", "Deep", "Belief", "Network", "for", "Imbalanced", "ClassificationChong", "Zhang", ",", "Kay", "Chen", "Tan", ",", "Fellow", ",", "IEEE", ",", "Haizhou", "Li", ",", "Fellow", ",", "IEEE", ",", "and", "Geok", "Soon", "Hong", "C.", "Zhang", "and", "H.", "Li", "are", "with", "the", "Department", "of", "Electrical", "and", "Computer", "Engineering", ",", "G.", "S.", "Hong", "is", "with", "the", "Department", "of", "Mechanical", "Engineering", ",", "National", "University", "of", "Singapore", ",", "4", "Engineering", "Drive", "3", ",", "117583", ",", "Singapore", "(", "e", "-", "mail", ":", "zhangchong@u.nus.edu", ";", "haizhou.li@nus.edu.sg", ";"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Due", "to", "its", "simplicity", "on", "dealing", "issues", "that", "arise", "with", "rendering", "terrains", "with", "TS", ",", "is", "going", "to", "be", "the", "default", "way", "to", "manage", "LOD", "and", "tessellation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tessellation shader"}, {"tokens": ["Consequently", ",", "the", "research", "of", "sampling", "-", "based", "MDC", "methods", "should", "be", "further", "developed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["This", "has", "two", "consequences", "for", "our", "search", "over", ":", "First", ",", "the", "size", "of", "LAP", "problems", "which", "must", "be", "solved", "at", "each", "step", "decreases", "over", "time", "(", "as", "we", "find", "-optima", "for", "a", "denser", "and", "denser", "set", "of", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear assignment problem"}, {"tokens": ["After", "obtaining", "the", "attention", "maps", "from", "MAD", ",", "we", "further", "feed", "them", "into", "a", "subsequent", "convolution", "layer", "and", "conduct", "the", "anchor", "detection", "in", "the", "final", "RPN", "layer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["The", "intuition", "behind", "this", "design", "is", "that", "if", "where", "is", "indistinguishable", "from", "where", ",", "the", "shared", "encoder", "will", "learn", "to", "extract", "features", "and", "structures", "across", "different", "language", "domains", ",", "and", "thus", "make", "the", "following", "layers", "of", "QA", "models", "easier", "to", "learn", "language", "-", "independent", "general", "knowledge", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Table", "reports", "the", "performance", "achieved", "on", "speaker", "identification", "and", "verification", "tasks", "(", "Classification", "Error", "Rates", "-", "CER", "for", "speaker", "-", "i", "d", "task", "and", "Equal", "Error", "Rate", "-", "EER", "for", "speaker", "verification", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classification error rate"}, {"tokens": ["AML", "has", "omitted", "some", "features", "of", "Rebeca", "for", "simplicity", "and", "is", "used", "for", "studying", "various", "aspects", "of", "actor", "systems", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["Now", "we", "can", "utilize", "to", "warmstart", "an", "initial", "GP", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "test", "the", "continual", "GP", "model", "under", "the", "same", "toy", "experiment", "included", "in", "for", "GP", "classification", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["All", "the", "QA", "models", "were", "trained", "on", "DRCD", "then", "test", "on", "DRCD", "dev", "set", "and", "ODSQA", "testing", "set", "respectively", "to", "compare", "the", "performance", "between", "text", "documents", "and", "spoken", "documents", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Black", "-", "DROPS", "with", "GP", "-", "MI", "was", "able", "to", "robustly", "learn", "controllers", "for", "a", "pendubot", "swing", "-", "up", "task", "even", "when", "the", "priors", "were", "misleading", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["This", "experiment", "shows", "that", "LiMa", "can", "efficiently", "perform", "BF", "in", "situations", "with", "mixed", "anonymous", "and", "identifying", "observations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian filtering"}, {"tokens": ["When", "such", "distribution", "is", "unknown", ",", "we", "may", "easily", "replace", "it", "by", "the", "empirical", "distributions", "from", "the", "data", "sample.(For", "instance", ",", "in", "CF", "for", "practical", "purposes", "we", "can", "approximate", "as", "number", "of", "samples", "pertaining", "to", "i", "-", "th", "user", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["While", "Terrain", "with", "TS", "is", "well", "suit", "for", "global", "visualization", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "tessellation shader"}, {"tokens": ["This", "did", "not", "substantially", "reduce", "performance", "(", "Table", ")", ",", "indicating", "that", "the", "reduction", "in", "performance", "for", "FA", "can", "not", "be", "accounted", "for", "by", "gradient", "noise", "that", "is", "centered", "on", "the", "BP", "gradient", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["For", "lightly", "loaded", "networks", ",", "the", "optimizer", "may", "decide", "to", "use", "drones", "instead", "of", "micro", "cell", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["The", "GLBPSO", "algorithm", "improves", "the", "standard", "PSO", "by", "having", "global", "and", "local", "best", "PSO", "simultaneously", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "euclidean", "distance", "based", "learning", "has", "been", "used", "for", "the", "PSO", "based", "wrappers", "in", ";", "where", "a", "threshold", "was", "used", "to", "decide", "whether", "or", "not", "to", "include", "the", "feature", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["We", "wish", "to", "clarify", "that", "we", "do", "not", "use", "the", "argument", "structure", "from", "the", "SRL", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["Our", "OT", "extension", "protocol", "relies", "on", "the", "following", "well", "-", "known", "property", "of", "WH", "codes", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["So", ",", "the", "achievable", "capacity", "of", "is", "obtained", "as", "below", "by", "(", "4", ")", "and", "(", "11),Capacity", "of", "Using", "(", "5", ")", ",", "(", "6", ")", ",", "(", "8)", "and", "(", "12", ")", "the", "achievable", "capacity", "of", "for", "and", "can", "be", "achieved", "by", "following", "equation", ",", "Sum", "CapacitySo", ",", "the", "SC", "can", "be", "achieved", "by", "following", "equation", "[", "27]Whereas", ",", "and", "are", "the", "capacity", "of", "and", "for", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "technique", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "factor", "appears", "in", "the", "above", "expression", "as", "a", "complete", "transmission", "from", "BS", "to", "users", "takes", "two", "time", "slots", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["A", "fine", "-", "grained", "analysis", "of", "the", "impact", "of", "attacks", "on", "user", "classes", "by", "looking", "into", "the", "CF", "models", "and", "attack", "types", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["We", "can", "see", "that", "quickly", "drops", "when", "the", "network", "is", "trained", "without", "IB", ",", "indicating", "overpowers", "substantially", "and", "learns", "to", "differentiate", "between", "features", "of", "the", "two", "domains", "accurately", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["A", "variety", "of", "automated", "and", "semi", "-", "automated", "methods", "for", "VAT", "and", "SAT", "segmentation", "have", "been", "developed", "for", "images", "derived", "from", "both", "CT", "and", "MRI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["The", "different", "types", "of", "PSO", "algorithms", "have", "been", "used", "in", "solving", "the", "formulated", "problems", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["The", "ASA", "includes", "a", "Gaussian", "Mixture", "(", "GMM", ")", ",", "morphological", "operations", ",", "Voronoi", "diagrams", ",", "and", "watershed", "segmentation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["figure[!t", "]", "images", "/", "semanticAverage", "ACC", ":", "class", "labels", "vs.", "attributes", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "accuracy"}, {"tokens": ["If", "player", "does", "not", "have", "value", "-", "increasing", "transitions", "then", "Lemma", "lem", ":", "pre", "-", "reach", "-", "unreach", "-", "geq", "-", "MD", "supplies", "either", "player", "or", "player", "with", "an", "MD", "winning", "strategy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["Linear", "MP", "ratesthm", ":"], "acronym_pos": [0, 1, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["Neural", "Transition", "ModelIn", "a", "SSM", ",", "the", "temporal", "evolution", "of", "latent", "states", "is", "determined", "by", "the", "transition", "matrix", "as", "in", "Equation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state space model"}, {"tokens": ["Learning", "in", "GP", "regression", "corresponds", "to", "computing", "the", "posterior", "distribution", "over", "the", "function", "conditioned", "on", "the", "observed", "data", "Sarkka2011,Roberts12", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["table", "Ablation", "study", "on", "MAD", "unit", "and", "training", "strategies", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["To", "address", "the", "problem", ",", "proposes", "a", "harvest", "-", "then", "-", "transmit", "protocol", "in", "a", "WPCN", "with", "a", "single", "-", "antenna", "HAP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "hybrid access point"}, {"tokens": ["The", "results", "show", "the", "advantage", "of", "the", "proposed", "GP", "-", "PF", "method", "over", "the", "other", "methods", "when", "applied", "to", "the", "ground", "truth", "contour", "evidences", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["No", "macrocell", "(", "only", "one", "fBS", ",", "one", "WiFi", "AP", ",", "one", "sDevice", "and", "one", "wDevice", ")", ",", "LTE", "Licensed", "Bandwidth", "1.4MHz", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "the", "case", "of", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", ",", "CEU", "capacity", "is", "degraded", "than", "the", "proposed", "scheme", "due", "to", "using", "a", "dedicated", "time", "slot", "for", "each", "separate", "transmission", "from", "BS", "to", "CEU", "like", "as", "CCU", ",", "excluding", "OAM", "based", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "what", "follows", ",", "we", "use", "the", "IB", "to", "learn", "a", "sufficient", "covariate", "that", "allows", "us", "to", "approximate", "this", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["What", "is", "then", "the", "role", "of", "NS", "in", "the", "light", "of", "the", "platforms", "'", "profiling", "practices", "carried", "out", "in", "order", "to", "detect", "users", "'", "preferences", "and", "to", "nudge", "them", "to", "consumption", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "network science"}, {"tokens": ["We", "further", "demonstrate", "the", "effectiveness", "of", "our", "method", "by", "comparing", "it", "with", "another", "baseline", "(", "PAT", ")", "where", "we", "first", "perform", "bayesian", "pruning", ",", "freeze", "the", "dropout", "mask", "and", "then", "perform", "adversarial", "training", "(", "see", "Figure", "fig", ":", "final_results", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "perform adversarial training"}, {"tokens": ["The", "implementation", "of", "is", "not", "available", "in", "the", "same", "platform", "as", "the", "other", "OT", "extensions", "given", "in", "the", "table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["In", ",", "a", "structured", "bit", "-", "error", "resilient", "mapping", "is", "leveraged", "to", "make", "MD", "lattice", "vector", "quantizers", "resilient", "to", "the", "transmission", "bit", "error", "by", "exploiting", "intrinsic", "structural", "characteristic", "of", "the", "lattice", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["5,000", "QA", "pairs", "are", "randomly", "selected", "from", "the", "original", "training", "set", "as", "our", "validation", "set", ",", "and", "the", "remaining", "QA", "pairs", "are", "taken", "as", "our", "new", "training", "set", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Our", "intervention", "experiments", "in", "Section", "suggests", "that", "many", "models", "trained", "on", "the", "PA", "dataset", "can", "become", "somewhat", "of", "a", "\"", "horse", "\"", ",", "where", "solving", "the", "actual", "problem", "is", "unintentionally", "avoided", "by", "exploiting", "silence", "as", "trivial", "cues", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["Therefore", ",", "we", "approximate", "as", "following", ",", "which", "incorporates", "the", "serving", "hole", "and", "ignores", "other", "holeswhere", "was", "defined", "in", "Definition", "and", "is", "the", "distance", "between", "the", "serving", "MBS", "and", "the", "typical", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["MGF_g_end_PureRS", ",", "a", "closed", "-", "form", "expression", "for", "of", "pure", "RS", "for", "INID", "Nakagami-", "fading", "with", "integer", "'s", "and", "distinct", "'s", "is", "given", "byFor", "IID", "Nakagami-", "fading", "channels", "with", "integer", ",", "substituting", "Eq", ":", "MGF_gbest_EqualC", "to", "Eq", ":", "MGF_g_end_PureRS", "a", "closed", "-", "form", "expression", "for", "of", "pure", "RS", "is", "given", "byTo", "obtain", "of", "pure", "RS", "for", "INID", "Nakagami-", "fading", "with", "integer", "'s", "and", "distinct", "'s", ",", "we", "substitute", "Eq", ":", "MGF_end_Final", "to", "Eq", ":", "Inverse_Laplaca", "and", "after", "some", "algebraic", "manipulations", "yields", "the", "following", "closed", "-", "form", "expressionwhere", ",", "with", "being", "positive", "real", ",", "andfor", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["We", "note", "that", "the", "resampling", "methods", "are", "a", "little", "bit", "faster", "than", "ECS", "-", "DBN", "due", "to", "the", "small", "data", "size", "of", "KEEL", "benchmark", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Therefore", ",", "caution", "should", "be", "taken", "whenever", "an", "assortative", "SBM", "is", "used", ",", "although", "the", "stochastic", "gradient", "method", "by", "should", "be", "easily", "generalisable", "to", "a", "non", "-", "assortative", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["It", "is", "remarked", "that", "this", "effect", "depends", "on", "how", "close", "a", "RN", "is", "to", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Multilingual", "POS", "Tagging"], "acronym_pos": [0, 1, 0], "long_form": "part of speech"}, {"tokens": ["Hence", ",", "the", "learned", "latent", "factors", "are", "less", "representative", "in", "FM", "and", "PolyNet", ",", "compared", "with", "the", "proposed", "SFM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "structural factorization machine"}, {"tokens": ["Prob", "denotes", "and", "RB", "is", "our", "rank", "-", "based", "method", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "rank - based"}, {"tokens": ["(", "ICE", ")", "plotsgoldstein2015peeking", "are", "very", "similar", "to", "PDP", "(", "but", "yield", "one", "curve", "for", "each", "data", "point", ")", ",", "and", "suffer", "from", "the", "same", "independence", "assumption", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial dependence plots"}, {"tokens": ["The", "data", "analysed", "by", "contained", "individual", "attributes", "that", "allowed", "them", "to", "divide", "the", "nodes", "into", "groups", ",", "and", "their", "focus", "was", "on", "showing", "that", "their", "dynamic", "SBM", "obtained", "results", "closer", "to", "the", "ground", "truth", "than", "the", "static", "counterpart", "did", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Moreover", ",", "the", "presented", "application", "of", "NP", "for", "deep", "normative", "modeling", "of", "clinical", "neuroimaging", "data", "brings", "the", "advantages", "of", "deep", "neural", "networks", "in", "representation", "learning", "to", "the", "applications", "in", "precision", "psychiatry", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["Hence", "in", "AP", ",", "initially", "each", "data", "point", "is", "treated", "as", "a", "potential", "exemplar", "and", ",", "therefore", ",", "initialization", "issues", "are", "circumvented", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["Denote", "if", "the", "BS", "choose", "to", "be", "idle", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "PPC", ",", "installed", "solar", "PV", "capacity", ",", "and", "the", "monthly", "totals", "of", "each", "prosumer", "for", "June", "2019", "are", "presented", "in", "Table", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "peak power contract"}, {"tokens": ["In", "other", "words", ",", "the", "problems", "are", "solved", "for", "continuous", "solutions", "of", "in", "where", "the", "GP", "is", "executed", "to", "determine", "the", "optimum", "solution", "with", "non", "-", "binary", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Discussion", "on", "Regret", "Performance", "of", "Con", "-", "TS", "-", "RTPThe", "regret", "analysis", "of", "Con", "-", "TS", "-", "RTP", "is", "inspired", "by", "the", "results", "in", "for", "TS", "with", "nonlinear", "cost", "functions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["In", "addition", "to", "generated", "and", "groundtruth", "heatmaps", ",", "the", "discriminator", "also", "receives", "predicted", "heatmaps", "for", "real", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["Branch", "-", "and", "-", "Bound", "MethodThe", "performance", "of", "the", "proposed", "BPSO", "method", "will", "be", "compared", "to", "that", "of", "the", "BB", "algorithm", ",", "that", "will", "be", "also", "jointly", "applied", "with", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "geometric programming"}, {"tokens": ["To", "emphasize", "the", "difference", ",", "we", "call", "our", "model", "the", "Manifold", "Geometry", "Matching", "GAN", ",", "or", "MGM", "GAN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["To", "be", "able", "to", "calculate", "the", "epistemic", "uncertainty", "in", "our", "NP", "model", ",", "we", "keep", "the", "dropout", "layers", "active", "at", "test", "time", "gal2016dropout", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["Flexibility", "in", "setting", "up", "an", "SRBIn", "legacy", "LTE", "architecture", ",", "the", "SRB", "is", "usually", "served", "by", "macro", "eNB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "the", "literature", ",", "the", "performance", "of", "LTE", "control", "channels", "with", "fixed", "receivers", "and", "perfect", "channel", "estimators", "has", "been", "studied", "in", ",", "and", "a", "potential", "power", "-", "based", "optimization", "for", "the", "control", "information", "transmission", "based", "on", "LTE", "has", "been", "discussed", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": [",", "Israelelovici@bgu.ac.il", "AbstractThis", "article", "presents", "a", "proof", "-", "of", "-", "concept", "illustrating", "the", "feasibility", "of", "creating", "a", "covert", "channel", "between", "a", "CC", "server", "and", "a", "malware", "installed", "in", "an", "organization", "by", "exploiting", "an", "organization", "'s", "scanner", "and", "using", "it", "as", "a", "means", "of", "interaction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "covert channels"}, {"tokens": [":", "We", "plug", "the", "passage", "ranker", "into", "the", "QA", "pipeline", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "mean", "RSS", "value", "prediction", "using", "GP", "for", "one", "APThe", "mean", "predicted", "RSS", "value", "and", "training", "data", "of", "one", "APRequired", "time", "for", "site", "surveyThe", "total", "time", "for", "site", "survey", "can", "be", "broken", "down", "into", "i", ")", "setup", "time", ",", "during", "which", "markers", ",", "starting", "and", "ending", "points", "of", "paths", "are", "decided", "and", "measured", ",", "and", "ii", ")", "data", "collection", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Unlike", "in", "AP", ",", "this", "penalty", "is", "now", "limited", "by", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["The", "two", "-", "steps", "registration", "pipeline", "is", "described", "also", "listing", "the", "considered", "GM", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "graph matching"}, {"tokens": ["Here", ",", "the", "eNodeB", "receives", "feedback", "from", "every", "UE", "about", "CSI", "for", "each", "individual", "RB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "typical", "UE", "is", "associated", "with", "a", "BS", "in", "tier", "if", "and", "only", "if", "it", "has", "a", "BS", "in", "that", "tier", ",", "and", "its", "nearest", "BS", "in", "tier", "has", "smaller", "average", "power", "than", "that", "of", "the", "nearest", "BS", "in", "tier", "and", "the", "nearest", "BS", "in", "tier", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Therefore", ",", "the", "minimum", "entropy", "loss", "from", "the", "sketch", "reduced", "to", "the", "maximum", "correlation", "measured", "in", "between", "the", "RV", "pair", ",", "conditioned", "on", "their", "inputs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["and", "proposed", "latent", "feature", "models", "(", "Section", ")", "that", "deviate", "from", "the", "SBM", ",", "while", "proposed", "an", "edge", "partition", "model", "(", "Section", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["L", ")", "Magnitude", "of", "the", "correlation", "between", "trust", "and", "sales", ",", "(", "M", ")", "Magnitude", "of", "the", "correlation", "between", "trust", "and", "price", ",", "(", "N", ")", "Magnitude", "of", "the", "correlation", "between", "trust", "and", "history", ",", "(", "O", ")", "Magnitude", "of", "the", "correlation", "between", "PI", "and", "sales", ",", "(", "P", ")", "Magnitude", "of", "the", "correlation", "between", "price", "and", "PI", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "purchase intention"}, {"tokens": ["However", ",", "connections", "between", "ANN", "and", "the", "brain", "are", "in", "fact", "rather", "slim", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["We", "have", "studied", "Simple", "and", "Bidirectional", "RNN", "architectures", "on", "multilingual", "POS", "and", "SST", "tagging", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["'", "greater", ",", "oftener'PIr", "*", "kaciah-", "MP", "keh", "'", "smaller", "'", "NP", "kih", "'", "small'PIr", "*", "maciah-", "MP", "mahy", "(", "MMP", "<", "mhy", ">", ")", "'", "bigger", "'", "NP", "mih", "'", "big'Variation", "of", "this", "sort", "led", "to", "argue", "that", "was", "an", "optional", "pronunciation", "of", "s", "in", "Old", "Persian", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["For", "the", "scenario", "of", "multi", "-", "user", "uplink", "transmission", ",", "the", "performance", "of", "the", "over", "-", "the", "-", "air", "computation", "scheme", ",", "in", "which", "the", "AP", "computes", "a", "target", "function", "of", "the", "aggregated", "data", "from", "all", "users", ",", "is", "investigated", "in", "by", "exploiting", "RISs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "ROC", "curves", "obtained", "using", "the", "proposed", "DSNet", "for", "different", "lesion", "classes", "of", "both", "datasets", "are", "presented", "in", "Fig", ".", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Step", "3", ":", "The", "application", "encrypts", "the", "signature", "'s", "recording", "(", "using", "TTP", "'s", "public", "-", "key", ")", "and", "sends", "the", "ciphertext", "to", "TTP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "trusted third party"}, {"tokens": ["The", "MR", "approach", "assumes", "that", "robots", "broadcast", "their", "future", "trajectories", "and", "state", "etc", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mixed reality"}, {"tokens": ["During", "the", "DL", "phase", "in", "epoch", ",", "the", "transmission", "power", "of", "the", "BS", "for", "user", "is", "denoted", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "notice", "that", "the", "CD", "increases", "with", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "contact distance"}, {"tokens": ["We", "can", "see", "that", "in", "the", "absence", "of", "DC", "DF", "for", "round", "-", "shaped", "droplets", "decreases", "while", "it", "increases", "for", "the", "square", "-", "shaped", "ones", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dominating frequencies"}, {"tokens": ["For", "RS", ",", "we", "lock(Exploration", "of", "different", "splash", "depths", "could", "be", "interesting", ",", "though", "we", "change", "our", "focus", "to", "randomized", "updates", ",", "and", "thus", "do", "not", "pursue", "this", "further", ".", ")"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["As", "an", "alternative", "to", "the", "Monte", "Carlo", "integration", "in", "our", "approach", "we", "could", "avoid", "the", "infinite", "dimensionality", "of", "the", "latent", "GP", "from", "the", "beginning", "by", "working", "with", "a", "binning", "scheme", "for", "the", "Poisson", "observations", "as", "in", "hensman2015mcmc", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["A", "cropland", "classification", "based", "on", "EO", "data", "should", "have", "at", "least", "an", "overall", "accuracy", "of", "83", "to", "provide", "estimation", "of", "production", "more", "accurate", "than", "the", "historical", "average", "and", "trend", "(", ")", "for", "all", "crops", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "earth observation"}, {"tokens": ["The", "predicted", "controllability", "curves", "become", "rugged", "for", "the", "two", "homogeneous", "random", "graphs", ",", "ER", "and", "SW", ",", "in", "the", "initial", "stage", "of", "RA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "random attack"}, {"tokens": ["The", "relation", "between", "FCC", "and", "the", "length", "of", "CC", "phase", "is", "our", "ongoing", "research", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["Perfect", "AMR", "Core", "Roles", "(", "SRL", ")", "&", "77.1", "&", "47.0", "&", "58.4", "&", "19.7", "&", "16.9", "&", "18.2"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["This", "proves", "that", "the", "zoom", "-", "out", "-", "and", "-", "in", "structure", "with", "a", "MAD", "unit", "is", "effective", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["POS", "achieves", "this", "by", "using", "DVFS", "techniques", "shekar2010energy", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial optimal slacking"}, {"tokens": ["OT", "metric", "maps", "the", "comparison", "of", "two", "distributions", "on", "high", "-", "dimensional", "feature", "space", "onto", "a", "lower", "dimension", "space", "so", "that", "it", "is", "more", "sensible", "to", "measure", "the", "similarity", "between", "two", "distributions", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["=", "r+r_Hence", ",", "CD", "distribution", "is", "given", "asFor", "the", "2-", "(", ")", "case"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "contact distance"}, {"tokens": ["We", "explore", "the", "influence", "of", "different", "source", "data", "and", "tasks", ",", "including", "optical", "images", ",", "SAR", "scene", "images", ",", "and", "SAR", "target", "dataset", ",", "as", "well", "as", "classification", "and", "reconstruction", ",", "and", "different", "architectures", "to", "show", "what", "network", "together", "with", "datasets", "should", "be", "transferred", "to", "SAR", "target", "recognition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Even", "though", "the", "energy", "benefit", "of", "neurons", "generation", "is", "not", "visible", "here", ",", "it", "requires", "less", "flash", "memory", "to", "implement", "base", "learners", "than", "B", "-", "OCC", ",", "since", ",", "in", "B", "-", "OCC", "method", ",", "random", "weights", "and", "biases", "are", "used", "as", "an", "immediate", "operand", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "one class classifier"}, {"tokens": ["The", "influence", "of", "age", "and", "sex", "on", "VAT", "-", "V", "and", "SAT", "-", "V", "follows", "different", "patterns", "(", "as", "illustrated", "in", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["The", "CP", "architecture", "can", "also", "be", "formed", "using", "the", "nodes", "which", "are", "part", "of", "-core", "and", "having", "maximum", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "closeness centrality"}, {"tokens": ["We", "assume", "that", "keypoint", "locations", "in", "a", "generated", "LR", "image", "stay", "relatively", "same", "as", "its", "downsampled", "version", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["In", "this", "first", "phase", ",", "the", "node", "in", "BC", "signs", "and", "send", "the", "transaction", "-", "proposal", "for", "execution", "to", "endorser(s", ")", "(", "designated", "peers", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["We", "found", "that", "processing", "images", "with", "an", "ISP", "improves", "accuracy", "by", "an", "average", "of", "7.0", "for", "a", "chosen", "set", "of", "MobileNets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["SST", "Systems", "EvaluatedThe", "goals", "of", "our", "SST", "experiments", "are", "twofold", ":", "first", ",", "to", "investigate", "the", "effectiveness", "of", "using", "POS", "information", "to", "build", "multilingual", "super", "sense", "tagger", ",", "secondly", "to", "measure", "the", "impact", "of", "the", "parallel", "corpus", "quality", "(", "manual", "or", "automatic", "translation", ")", "on", "our", "RNN", "models", "(", "SRNN", ",", "BRNN", "and", "our", "proposed", "variants", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["In", "explicit", "CF", "user", "ratings", "for", "particular", "items", "are", "directly", "observed", "and", "therefore", "it", "can", "be", "formally", "framed", "as", "a", "matrix", "completion", "problem", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["ConclusionIn", "this", "paper", ",", "we", "elaborately", "explore", "what", "network", "and", "source", "tasks", "are", "better", "to", "transfer", ",", "in", "which", "layer", "the", "features", "are", "more", "generic", "to", "transfer", "and", "how", "to", "effectively", "transfer", "in", "SAR", "target", "recognition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "LTE", "turbo", "and", "the", "WiMAX", "LDPC", "offer", "a", "gain", "of", "0.5", "dB", "and", "0.7", "dB", "compared", "with", "SC", "-", "decoded", "BIPCM", "system", ",", "respectively", ",", "but", "at", "a", "cost", "of", "much", "more", "decoding", "complexity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "successive cancellation"}, {"tokens": ["However", ",", "the", "complicated", "form", "of", "the", "solution", ",", "led", "us", "to", "follow", "a", "suboptimal", "power", "allocationmethod", "similar", "to", ",", "where", "RS", "outperforms", "the", "conventional", "broadcasting", "schemes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["For", "example", ",", "the", "latent", "feature", "model", "deviated", "from", "the", "hard", "clustering", "SBM", "in", "a", "different", "way", "than", "MMSBM", "did", ",", "and", "therefore", "made", "comparison", "with", "the", "latter", "in", "terms", "of", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["To", "solve", "this", "problem", ",", "we", "implement", "four", "different", "models", "(", "SVM", ",", "LR", ",", "Bi", "-", "LSTM", ",", "and", "GRU", ")", "to", "compare", "and", "find", "the", "most", "suitable", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["NP", "nal(idan", ")", "'", "lament'PIr"], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["To", "explore", "whether", "the", "SC", "and", "ST", "subsets", "in", "the", "Sleep", "-", "EDF", "database", "exhibit", "heterogeneous", "properties", "or", "not", ",", "we", "perform", "one", "-", "way", "ANOVA", "on", "two", "time", "-", "domain", "features", "(", "MMD", "EnergySis", ")", "and", "two", "spectral", "features", "(", "Spectral", "Rolloff", "Spectral", "Spread", ")", "extracted", "from", "frequency", "bands", "(", ")", "of", "the", "Fpz", "-", "Cz", "channel", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subset compared"}, {"tokens": ["The", "effect", "of", "SC", "is", "also", "highlighted", "through", "experiments", "on", "synthetic", "images", "(", "Section", "expt", ":", "synth", ")"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "self consistency"}, {"tokens": ["From", "left", "to", "right", ":", "The", "posterior", "mean", "inferred", "by", "Gibbs", "sampler", "and", "VB", "algorithm", ",", "followed", "by", "density", "estimation", "using", "KDE", "and", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "SP", "is", "chosen", "through", "red", ",", "blue", "and", "green", "color", "dotted", "line", "for", "User2", "gives", "the", "value", "of", "as", "and", "respectively", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "shortest path"}, {"tokens": ["is", "known", "as", "the", "constriction", "factor", "of", "PSO", ",", "and", "is", "defined", "as", "follows", ";", "where", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Importantly", ",", "we", "recursively", "perform", "one", "-", "sample", "updates", "of", "the", "model", ",", "to", "adapt", "the", "continual", "GP", "for", "a", "most", "similar", "scenario", "to", "the", "one", "presented", "in", "the", "IHGP", "toy", "experiment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "results", "of", "the", "experiments", "on", "IFD", "and", "ORL", "face", "database", "has", "been", "shown", "in", "next", "figures", "5", "to", "8", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "indian face database"}, {"tokens": ["Our", "SC", "-", "task", "uses", "data", "from", "multiple", "patients", "(", "Fig", ")", "during", "test", ",", "which", "is", "more", "challenging", "compared", "to", "LOO", "-", "CV", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sleep cassette"}, {"tokens": ["Since", "PNN", "context", "encoders", "can", "handle", "arbitrary", "user", "-", "side", "contextual", "information", "and", "build", "upon", "an", "existing", "pretrained", "RNN", "session", "model", ",", "we", "believe", "that", "deploying", "our", "model", "for", "real", "-", "world", "systems", "would", "be", "a", "handy", "solution", "that", "can", "improve", "the", "recommendation", "quality", "of", "a", "system", "without", "considerable", "effort", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Two", "channels", "are", "jointly", "model", "using", "the", "continual", "learning", "approach", "aforementioned", "for", "multi", "-", "output", "GP", "regression", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["MP", "is", "a", "non", "-", "personalized", "algorithm", "and", "is", "especially", "useful", "for", "new", "entities", "in", "a", "data", "market", "without", "any", "interactions", "so", "far", ",", "commonly", "referred", "as", "cold", "-", "start", "entities", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "most popular"}, {"tokens": ["To", "solve", "P1", ",", "we", "leverage", "the", "use", "of", "LLC", ",", "GP", ",", "and", "heuristics", ",", "obtaining", "the", "feasible", "system", "control", "inputs", ",", "that", "yield", "the", "best", "system", "behavior", "within", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Therefore", ",", "we", "propose", "a", "new", "h", "-", "NSF", "model", "with", "time", "-", "variant", "and", "trainable", "MVF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "maximum voice frequency"}, {"tokens": ["The", "3D", "surface", "of", "the", "residual", "GMM", "probability", "density", "function", "(", "shaded", "to", "reveal", "height", "mapping", ")", "constructed", "from", "Gaussian", "modes", "with", "means", "denoted", "by", "blue", "dots", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Minimum", "Read", "ESQ", "(", "MR", "-", "ESQ", ")", ":"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "minimum read"}, {"tokens": ["SMAPE", ",", "first", "proposed", "by", "Armstrong", "Scott_Armstrong1985-tt", "and", "then", "by", "Makridakis", "makridakis1993accuracy", ",", "DSA", "Skills", "Listtab", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["According", "to", ",", "they", "are", "formulated", "as", "followsandwhere", ",", "and", "are", "given", "byandwhere", "is", "the", "AWGN", "vector", ",", "and", "is", "the", "covariance", "matrix", "of", "interference", "plus", "noise", "at", "EveFinally", ",", "our", "objective", "is", "to", "maximize", "the", "SR", "by", "TAS", "scheme", ",", "which", "is", "written", "as", "the", "following", "optimization", "problemwhich", "is", "an", "integer", "or", "binary", "optimization", "problem", "and", "is", "NP", "-", "hard", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["MAD_extend", "to", "be", "4", "best", "fits", "the", "task", ",", "which", "is", "noted", "as", "'", "ZIP", "MAD", "E", "'", "in", "the", "table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["This", "approach", "enables", "us", "to", "efficiently", "explore", "the", "impact", "of", "the", "ISP", "design", "space", "on", "CNN", "classification", "performance", ",", "without", "the", "huge", "expense", "of", "manually", "capturing", "and", "labelling", "a", "sufficiently", "large", "image", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Moreover", ",", "random", "dropping", "of", "the", "ANN", "units", "during", "training", "of", "the", "network", "simulates", "the", "situation", "of", "sensor", "failure", "in", "the", "real", "world", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Terrain", "rendering", "techniques", "which", "use", "TS", "are", "more", "applicable", "in", "the", "context", "of", "this", "proposal", ",", "they", "are", "fair", "better", "at", "generating", "global", "features", "for", "a", "terrain", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tessellation shader"}, {"tokens": ["Therefore", ",", "there", "exists", "a", "unique", "Stackelberg", "equilibrium", "which", "is", "the", "pair", "of", "the", "optimal", "FJ", "power", "and", "price", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["The", "GP", "-", "based", "optimization", "approach", "jointly", "implemented", "with", "BPSO", "and", "BB", "is", "proposed", "in", "Section", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["The", "other", "image", "sets", "are", "generated", "by", "processing", "raw", "images", "with", "a", "number", "of", "ISP", "stages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Explicitly", ",", "its", "order", "can", "be", "formally", "expressed", "as", "follows", ":", "where", "corresponds", "to", "the", "fraction", "of", "the", "OPF", "identified", "by", "the", "first", "trellis", "stages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal pareto front"}, {"tokens": ["In", "our", "case", ",", "however", ",", "the", "categories", "of", "SAR", "targets", "to", "be", "recognized", "are", "usually", "never", "seen", "before", "so", "the", "classifier", "should", "be", "retrained", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["SC", "with", "respect", "to", "transmit", "SNR", ",", ",", ",", ",", ",", ",", "and", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["[", "]", "Results", "for", "single", "-", "output", "regression", "on", "solar", "physics", "data", "with", "one", "-", "sample", "updates", "of", "the", "continual", "sparse", "GP", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["O.", "Khan", ",", "R.", "Burns", ",", "J.", "S.", "Plank", ",", "W.", "Pierce", "and", "C.", "Huang", ",", "\"", "Rethinking", "Erasure", "Codes", "for", "Cloud", "File", "Systems", ":", "Minimizing", "I", "/", "O", "for", "Recovery", "and", "Degraded", "Reads", ",", "\"", "FAST", "2012", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "file and storage technologies"}, {"tokens": ["The", "proposed", "GP", "-", "PF", "method", "estimates", "the", "objects", "boundaries", "more", "precisely", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Only", "in", "DE", "-", "SB", ",", "we", "apply", "an", "additional", "step", "by", "increasing", "the", "error", "yield", "of", "some", "solution", "candidates", "which", "are", "not", "in", "the", "same", "partition", "as", "the", "selected", "partition", "holding", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["In", "this", "letter", ",", "a", "global", "dataset", "of", "multi", "-", "level", "annotated", "HR", "SAR", "images", "has", "been", "experimented", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["If", "the", "confidence", "threshold", "is", "low", ",", "chances", "are", "high", "for", "over", "-", "prediction", ",", "i.e.", "high", "TP", "but", "also", "high", "FP", "rates", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["Although", "the", "AN", "is", "used", "to", "interfere", "the", "eavesdroppers", ",", "since", "the", "BS", "has", "only", "6", "transmit", "antennas", ",", "the", "BS", "can", "not", "generate", "enough", "AN", "beams", "to", "interfere", "the", "additional", "eavesdroppers", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Experiment", "ScenarioThe", "purpose", "of", "the", "experiment", "is", "to", "understand", "whether", "multi", "-", "task", "learning", "and", "active", "learning", "help", "to", "improve", "SRL", "model", "performance", "compared", "to", "the", "baseline", "model", "(", "SRL", "with", "no", "AL", "scenario", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["For", "more", "difficult", "tasks", "on", "TVV", "and", "TAS", "retrieval", ",", "since", "SIFT", "feature", "can", "not", "fully", "capture", "the", "characteristics", "in", "TAS", ",", "the", "fusion", "of", "STIP", "and", "SIFT", "does", "not", "gain", "significant", "improvement", "where", "CCA", "even", "suffers", "great", "loss", "from", "SIFT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transverse abdominal section"}, {"tokens": ["The", "principal", "contribution", "of", "this", "paper", "is", "given", "below", ":", "PS", "based", "CNOMA", "-", "SWIPT", "-", "PS", "is", "considered", "over", "the", "Rician", "fading", "channel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["always", "outperform", "the", "others", "significantly", ",", "in", "terms", "of", "both", "ACC", "and", "NMI", ",", "on", "all", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "accuracy"}, {"tokens": ["To", "this", "end", ",", "the", "state", "space", "of", "the", "system", ",", "i.e.", ",", "and", "the", "interface", "of", ",", "is", "generated", "in", "the", "same", "way", "of", "the", "AML", "semantics", "while", "we", "follow", "with", "each", "action", "as", "long", "as", "the", "error", "state", "has", "not", "been", "visited", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["If", "a", "node", "lies", "in", "the", "shortest", "path", "with", "high", "BC", "then", "it", "may", "be", "congested", "early", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["For", "the", "hero", "data", ",", "WrapperSubsetEval", "using", "BestFirstSearch", "coupled", "with", "LR", "and", "RF", "achieved", "higher", "accuracy", "than", "when", "LR", "and", "RF", "are", "run", "using", "the", "features", "selected", "by", "CfsSubsetEval", "with", "BestFirstSearch", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["We", "summarize", "our", "key", "contributions", "as", "follows", ":", "We", "propose", "HybridAlpha", ",", "an", "efficient", "privacy", "-", "preserving", "FL", "approach", "that", "employs", "a", "differential", "privacy", "mechanism", "and", "defines", "a", "SMC", "protocol", "from", "a", "multi", "-", "input", "functional", "encryption", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["The", "concepts", "of", "updating", "the", "velocity", "vector", "using", "PSO", "provides", "enough", "exploration", "whereas", "the", "GSA", "provides", "enough", "exploitation", "to", "each", "particle", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["The", "worker", "nodes", "use", "key", "-", "value", "store", "API", "to", "pull", "the", "recent", "parameters", "from", "the", "PS"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "parameter server"}, {"tokens": ["LSC", ",", "LScD", "and", "LScDC", "are", "available", "online", "in", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["In", "the", "proposed", "algorithm", ",", "PSO", "parameters", "are", "adjusted", "dynamically", "using", "fuzzy", "rules", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Interestingly", ",", "the", "content", "-", "only", "method", "outperforms", "our", "joint", "method", "in", "the", "offline", "simulation", ",", "and", "is", "only", "outperformed", "by", "the", "CF", "-", "based", "recommendations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Simulations", "are", "also", "run", "by", "increasing", "for", "RV", "strategy", "until", "the", "preventive", "efficiency", "reaches", "the", "stage"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["Similar", "to", "previous", "works", ",", "assuming", "the", "knowledge", "of", "CSI", "and", "RIS", "phases", "at", "the", "BS", ",", "precoding", "can", "be", "performed", ",", "and", "the", "ergodic", "capacity", "of", "the", "system", "is", "maximized", "through", "the", "optimization", "of", "the", "RIS", "phases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Let", "denote", "the", "event", "of", "passing", "the", "consistency", "check", "for", "a", "corrupt", "who", "commits", "a", "non", "-", "codeword", "matrix", "in", "the", "seed", "OT", "phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["are", "selected", "to", "evaluate", "the", "influence", "of", "the", "number", "of", "GMM", "components", "that", "utilized", "in", "the", "training", "process", "of", "motion", "primitive", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["It", "is", "also", "interesting", "that", "even", "though", "and", "are", "closely", "related", "problems", ",", "the", "MB", "-", "enumerating", "algorithms", "are", "often", "an", "order", "of", "magnitude", "faster", "than", "their", "MIB", "-", "enumerating", "counterparts", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["Thus", ",", "the", "partial", "downloading", "schemes", "are", "also", "developed", "on", "the", "proposed", "repair", "-", "by", "-", "transfer", "codes", "and", "Exact", "-", "MBR", "codes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["BS", ":", "batch", "size", "."], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "batch size"}, {"tokens": ["It", "is", "clear", "that", "the", "proposed", "ECS", "-", "DBN", "benefits", "from", "the", "well", "optimized", "misclassification", "costs", "to", "achieve", "better", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Influence", "of", "HardwareWe", "ran", "the", "same", "benchmarks", "on", "multiple", "HPC", "systems", "that", "were", "equipped", "with", "a", "Lustre", "parallel", "file", "system", "[", "XSEDE", "'s", "PSC", "Bridges", "(", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["tab", ":", "suprestabularllllllllll2", "*", "&", "3cRBWH", "&", "3cRCH", "&", "3cGCH", "&", "P", "&", "R", "&", "F1", "&", "P", "&", "R", "&", "F1", "&", "P", "&", "R", "&", "F1", "SVM", "&", "0.8539", "&", "0.8122", "&", "0.8325", "&", "0.9366", "&", "0.8811", "&", "0.9080", "&", "0.9347", "&", "0.8810", "&", "0.9071", "SGD", "&", "0.8575", "&", "0.7329", "&", "0.7903", "&", "0.9104", "&", "0.8276", "&", "0.8670", "&", "0.8713", "&", "0.7951", "&", "0.8315", "NB", "&", "0.9353", "&", "0.7102", "&", "0.8074", "&", "0.8409", "&", "0.9048", "&", "0.8717", "&", "0.8049", "&", "0.9281", "&", "0.8621", "RF", "&", "0.8508", "&", "0.7524", "&", "0.7986", "&", "0.9182", "&", "0.7552", "&", "0.8288", "&", "0.8654", "&", "0.8210", "&", "0.8426", "LR", "&", "0.8872", "&", "0.6912", "&", "0.7770", "&", "0.7003", "&", "0.0725", "&", "0.1314", "&", "0.9751", "&", "0.5043", "&", "0.6648", "CNN", "&", "0.9159", "&", "0.9028", "&"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["NCE", "trains", "a", "binary", "classifier", "to", "distinguish", "between", "node", "samples", "coming", "from", "the", "empirical", "similarity", "distribution", "and", "those", "generated", "by", "a", "noise", "distribution", "over", "the", "nodes", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "noise contrastive estimation"}, {"tokens": ["Strategy", "1", ":", "Threshold", "initialization", "(", "TI", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "threshold initialization"}, {"tokens": ["Li", "and", "Jiang", ",", "proposed", "PSO", "algorithm", "-", "based", "model", "to", "evaluate", "and", "lower", "the", "risk", "arises", "due", "to", "high", "wind", "power", "penetration", "and", "its", "variability", "into", "the", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Following", "the", "same", "reasoning", "as", "we", "did", "in", "the", "proof", "of", "Theorem", ",", "we", "can", "ensure", "the", "IB", "curve", "can", "be", "explored", "if", ":", "We", "minimize", "the", "concave", "IB", "Lagrangian", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["A", "Low", "-", "complexity", "UE", "Selection", "AlgorithmIn", "this", "section", ",", "we", "propose", "a", "low", "-", "complexity", "UE", "selection", "algorithms", "to", "deal", "with", "Problem", ":"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["ANN", "AlgorithmIn", "summary", ",", "the", "number", "of", "hidden", "layers", ",", "the", "length", "of", "epoch", "and", "the", "learning", "rate", "define", "the", "ANN", "architecture", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["DC", "between", "LTE", "MN", "and", "WLAN", "SN", "is", "characterized", "in", "as", "LTE", "WLAN", "Aggregation", "(", "LWA", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Currently", ",", "ER", ",", "SBM", ",", "DCER", ",", "DCSBM", ",", "and", "RDPG", "are", "supported", "for", "model", "estimation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["However", ",", "there", "is", "a", "clear", "difference", "in", "the", "DOA", "metrics", ":", "in", "our", "method", ",", "DOA", "error", "is", "reduced", "by", "a", "factor", "of", "2.6", ",", "but", "FR", "is", "points", "worst", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "frame recall"}, {"tokens": ["We", "justify", "this", "value", "by", "the", "fact", "that", "both", "CF", "models", "exploit", "the", "item", "-", "item", "similarity", "computation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["This", "uncovers", "306,577", "DSA", "job", "ads", "across", "23", "occupational", "classes", "from", "2012", "-", "2019", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["As", "a", "benchmark", ",", "the", "user", "capacities", "and", "SC", "of", "OMA", "with", "OAM", "-", "MDMA", "(", "OMA", "-", "OAM", "-", "MDMA", ")", "are", "also", "compared", "with", "the", "capacities", "of", "the", "proposed", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["We", "introduce", "the", "loss", "function", ",", "that", "captures", "the", "FL", "performance", "over", "input", "vector", "and", "output", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["For", "this", "dataset", ",", "DDE", "-", "MGM", "significantly", "outperforms", "the", "other", "algorithms", "in", "both", "off-", "and", "on", "-", "line", "testing", "because", "the", "raw", "data", "is", "not", "well", "aligned", "and", "varies", "in", "length", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Without", "using", "a", "FEC", "-", "based", "scheme", "to", "protect", "the", "transmission", ",", "the", "average", "MOS", "was", "2.05", ",", "which", "is", "considered", "poor", "video", "quality", "with", "annoying", "impairments", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Note", "that", "our", "ultimate", "goal", "of", "applying", "OT", "loss", "is", "to", "make", "feature", "learning", "in", "the", "mainstream", "(", "blue", "blocks", ")", "better", "aligned", "across", "capsules", "in", "the", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["The", "cumulative", "probability", "distribution", "of", "inter", "-", "event", "times", "of", "TI", "1(orange", "square", ")", "and", "TI", "2(green", "triangle", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["When", "all", "contents", "are", "placed", "at", "CC", ",", "the", "least", "power", "is", "consumed", ",", "however", ",", "in", "this", "case", "some", "of", "users", "are", "dropped", "due", "to", "the", "latency", "constraint", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Spatio", "-", "temporal", "traces", "are", "then", "converted", "into", "spatio", "-", "temporal", "Boolean", "or", "quantitative", "signals", "in", "the", "following", "way", ":", "similarly", "to", "the", "case", "of", "STL", ",", "each", "atomic", "predicate", "is", "of", "the", "form", ",", "for", "some", "function", ",", "where", "are", "the", "primary", "signals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "signal temporal logic"}, {"tokens": ["In", "the", "uplink", ",", "the", "AP", "can", "easily", "extract", "the", "uplink", "CSI", "from", "the", "PHY", "preambles", "of", "received", "frames", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Comparison", "of", "predicted", "shock", "by", "LPSRS", "method", "and", "numerically", "measured", "shock", "by", "FEM"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "finite element method"}, {"tokens": ["Both", "algorithms", "rely", "on", "the", "sparse", "GP", "approximation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["SEM", "employs", "sem", ":", "hasActor", "to", "establish", "connection", "between", "sem", ":", "Event", "and", "sem", ":", "Actor", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simple event model"}, {"tokens": ["Another", "version", "of", "RS", "utilizes", "the", "best", "relay", "only", "in", "the", "case", "that", "it", "results", "in", "capacity", "gains", "over", "the", "direct", "source", "to", "destination", "transmission", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["In", "addition", ",", "the", "algorithm", "reduces", "the", "communication", "overhead", "as", "it", "aggregates", "feedback", "until", "a", "predefined", "FP", "and", "TP", "goal", "is", "reached", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["The", "analytical", "result", "is", "justified", "by", "simulation", "results", "which", "demonstrate", "that", "the", "proposed", "CNOMA", "-", "OAM", "provides", "higher", "SC", "compared", "to", "other", "schemes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["Due", "to", "the", "requirement", "of", "long", "timescale", "consideration", "without", "increasing", "the", "dimensions", "of", "GMM", ",", "the", "regrouped", "training", "data", "of", "motion", "primitives", "are", "based", "on", "the", "previous", ",", "current", "and", "future", "cluster", "labels", "of", "path", "primitives", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["ParkNet", "consists", "of", "a", "GPS", "receiver", "and", "an", "ultrasonic", "rangefinder", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Input", "Sample", "GenerationIn", "order", "to", "explore", "a", "variety", "of", "distinct", "active", "sets", "of", "constraints", "for", "the", "synthetic", "cases", "and", "mimic", "the", "time", "-", "varying", "behavior", "of", "the", "OPF", "input", "parameters", ",", "grid", "parameter", "samples", "with", "feasible", "OPF", "solutions", "were", "generated", "by", "varying", "the", "original", "values", "in", "the", "grid", "data", "-", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["In", "training", ",", "however", ",", "LR", "images", "are", "synthetically", "generated", "from", "clinical", "HR", "data", "using", "the", "MR", "acquisition", "model", "discussed", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["Algorithm", "presents", "a", "pseudo", "code", "for", "a", "standard", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "particle swarm optimization"}, {"tokens": ["We", "do", "not", "suggest", "to", "use", "natural", "images", "pre", "-", "trained", "model", "straightforwardly", "to", "SAR", "targets", "due", "to", "the", "large", "difference", "between", "them", "which", "may", "result", "in", "much", "specific", "features", "in", "higher", "layers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["In", "the", "TTF", "context", "this", "refers", "to", "IS", ";", "which", "cover", "policies", ",", "training", ",", "etc", ",", "as", "well", "as", "the", "IT", "itself", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["The", "MGM", "GAN", "'s", "importance", "sampling", "upweights", "these", "points", "in", "the", "low", "-", "density", "region", "and", "downweights", "the", "points", "in", "the", "high", "-", "density", "region", ",", "allowing", "it", "to", "generate", "evenly", "over", "the", "geometry", "of", "the", "data", "(", "Figure", "fig", ":", "artificial2c", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["Our", "proposed", "developments", "are", "based", "on", "the", "observation", "that", "OLS", "is", "generally", "better", "suited", "for", "sparse", "coefficient", "recovery", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["Let", "be", "a", "convex", "IB", "Lagrangian", ",", "then", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["They", "are", "associated", "with", "scheduling", "strategiesthat", "are", "based", "on", "task", "completion", "time", "such", "as", "HEFT", "and", "DADA", "with", "and", "without", "affinity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["Here", "the", "GMM", "is", "composed", "of", "three", "Gaussian", "modes", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Further", ",", "Platypus", "is", "a", "QA", "system", "on", "Wikidata", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["In", "this", "case", ",", "BS", "transmits", "information", "signal", "for", "CCU", "and", "CEU", "independently", "in", "different", "time", "slots", "with", "total", "transmit", "power", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "employ", "this", "strategy", "by", "first", "fitting", "a", "GMM", "to", "the", "problem", "and", "then", "utilising", "the", "fit", "as", "base", "measure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["In", "order", "to", "decrease", "the", "discrepancy", "between", "source", "and", "target", "domain", "in", "very", "high", "layer", ",", "the", "proposed", "MK", "-", "MMD", "based", "transfer", "method", "to", "separately", "train", "the", "adaptation", "layer", "and", "slightly", "update", "the", "off", "-", "the", "-", "shelf", "layers", "is", "recommended", "which", "improves", "the", "performance", "than", "simply", "fine", "-", "tuning", "all", "layers", "in", "SAR", "target", "recognition", "transferring", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Valued", "graphsThe", "Bernoulli", "SBM", "can", "be", "easily", "generalised", "or", "modified", "for", "valued", "graphs", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["In", "this", "scenario", ",", "the", "initial", "(", "horizontal", ")", "distances", "between", "the", "BS", "and", "the", "MS", ",", "the", "MS", "and", "IO", "1", ",", "and", "the", "MS", "and", "IO", "2", "are", "shown", "by", ",", ",", "and", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "note", "that", ":", "RoBERTa", "-", "Large", "with", "ASNQ", "TREC", "-", "QA", "again", "establishes", "an", "impressive", "performance", "of", "0.943", "in", "MAP", "and", "0.974", "in", "MRR", ",", "outperforming", "the", "previous", "state", "of", "the", "art", "by", "Yoon", "et", "al", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["We", "compared", "the", "returned", "names", "of", "the", "three", "systems", "(", "CSSeer", ",", "ArnetMiner", ",", "andMicrosoft", "Academic", "Search", ")", "and", "GS", "*", ",", "a", "system", "we", "built", "to", "simulate", "GoogleScholar", "'s", "ranking", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "google scholar 's"}, {"tokens": ["IEEEtranAdarsha", "Balaji", "Adarsha", "Balaji", "received", "a", "Bachelor", "\u2019s", "degree", "from", "\ufeffVisvesvaraya", "Technological", "University", ",", "India", ",", "in", "2012", "and", "a", "Master", "'s", "degree", "from", "Drexel", "University", ",", "Philadelphia", ",", "PA", ",", "in", "2017", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "philadelphia"}, {"tokens": ["It", "can", "be", "observed", "that", "the", "sum", "secrecy", "rate", "grows", "with", "the", "increase", "of", "the", "transmit", "power", "at", "the", "BS", "for", "all", "four", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["denotes", "the", "path", "loss", "between", "UE", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "user equipment"}, {"tokens": ["[", "]", "The", "performance", "of", "the", "proposed", "GP", "-", "PF", "method", "with", "different", "covariance", "functions", "on", "the", "obtained", "contour", "evidences", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["It", "is", "also", "important", "to", "note", "that", "only", "one", "single", "SRNN", "and", "BRNN", "tagger", "applies", "to", "German", ",", "Greek", "and", "Spanish", ";", "so", "this", "is", "a", "truly", "multilingual", "POS", "tagger", "!"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "scheme", "without", "FEC", "averaged", "a", "value", "of", "0,806", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["GP", "Squared", "-", "Exp", "is", "a", "GP", "model", "with", "a", "squared", "-", "exponential", "ARD", "kernel", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Finally", ",", "as", "for", "several", "other", "NLP", "tasks", "such", "as", "language", "modelling", "or", "machine", "translation", "(", "where", "standard", "and", "NN", "-", "based", "models", "are", "generally", "combined", "in", "order", "to", "obtain", "optimal", "results", ")", ",", "the", "combination", "of", "standard", "and", "RNN", "-", "based", "approaches", "(", "Projection+", ")", "seems", "necessary", "to", "further", "optimize", "POS", "tagging", "accuracies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Furthermore", ",", "GP", "enables", "the", "achievement", "of", "better", "solutions", "than", "the", "dual", "problem", "-", "based", "optimization", "ones", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["In", "the", "proposed", "method", ",", "the", "first", "stream", "is", "a", "DCNN", "trained", "to", "extract", "discriminative", "global", "appearance", "features", "for", "each", "vehicle", "identity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["Wi", "-", "Fi", "BSSs", "for", "LTE", "-", "U", "CSATVanlin", "Sathya", ",", "Adam", "Dziedzic", ",", "Monisha", "Ghosh", ",", "and", "Sanjay", "KrishnanUniversity", "of", "Chicago", ",", "Illinois", ",", "USA", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["MRC", "is", "considered", "at", "CEU", "to", "combine", "direct", "and", "relay", "link", "and", "perform", "ID", "effectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information decoding"}, {"tokens": ["For", "Mixed", "-", "Hero", "data", ",", "LR", "is", "0.5", "better", "but", "for", "Pro", "-", "Hero", "data"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["This", "scheme", "was", "mainly", "meant", "for", "the", "Q", "-", "based", "and", "CF", "-", "based", "recommendations", ",", "but", "for", "the", "sake", "of", "a", "fair", "comparison", ",", "we", "also", "used", "it", "for", "View", "-", "pop", "and", "Edit", "-", "pop", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "ibAbI", "dataset", "mentioned", "before", "it", "has", "been", "created", "based", "on", "bAbI", "to", "cover", "several", "representative", "multi", "-", "turn", "QA", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["For", "\"", "no", "CF", "\"", "users", ",", "three", "of", "the", "remaining", "six", "were", "View", "-", "pop", "and", "the", "other", "three", "Edit", "-", "pop", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Coelho", "and", "Lee", ",", "suggested", "a", "combination", "of", "chaotic", "sequences", "and", "Gaussian", "probability", "distribution", "functions", "with", "PSO", "in", "solving", "ELD", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["From", "the", "GP", "perspective", ",", "we", "consider", "that", "every", "output", "sample", "is", "generated", "as", ",", "where", "is", "a", "non", "-", "linear", "function", "evaluation", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["MotivationAs", "far", "as", "we", "know", ",", "all", "previous", "work", "on", "GP", "-", "SSM", "assume", "the", "emission", "function", "to", "be", "a", "linear", "mapping", "between", "latent", "state", "and", "the", "mean", "of", "observation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["A", "smaller", "allows", "DE", "to", "have", "better", "exploitation", "ability", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["The", "analysis", "of", "IS", "and", "FID", "leads", "to", "similar", "conclusions", ":"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["ECS", "-", "DBN", "shows", "better", "performance", "in", "terms", "of", "G", "-", "mean", ",", "AUC", "and", "precision", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Each", "RB", "(", "Fig", ".", ")"], "acronym_pos": [0, 1, 0, 0, 0, 0], "long_form": "resource blocks"}, {"tokens": ["We", "see", "similar", "impacts", "in", "this", "work", "where", "lower", "capacity", "models", "(", "RF", ",", "LR", ")", "are", "preferred", "on", "both", "our", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["The", "advantage", "of", "ID", "over", "BM", "is", "that", "the", "read", "load", "of", "primary", "data", "on", "a", "failed", "disk", "is", "distributed", "over", "disks", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["To", "the", "best", "knowledge", "of", "the", "author", "there", "are", "no", "PAP", "optimized", "all", "-", "reduce", "algorithms", "described", "in", "the", "literature", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["For", "example", ",", "in", "a", "chatbot", "-", "based", "train", "reservation", "system", ",", "DST", "amounts", "to", "understanding", "key", "information", "provided", "by", "the", "user", "as", "slot", "-", "value", "pairs", ",", "such", "as", "the", "desired", "departure", "and", "arrival", "stations", ",", "the", "day", "and", "time", "of", "travel", ",", "among", "others", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["This", "way", ",", "while", "the", "MSE", "provides", "an", "initial", "indication", "of", "the", "model", "'s", "performance", ",", "the", "CCC", "shows", "the", "capability", "of", "the", "model", "to", "describe", "the", "expressions", "in", "a", "video", "as", "a", "whole", ",", "taking", "into", "consideration", "the", "contextual", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "congruence coefficient correlation"}, {"tokens": ["The", "expectation", "is", "that", "the", "future", "generation", "of", "QA", "systems", "(", "or", "search", "engines", ")", "rely", "on", "computational", "explainable", "models", "and", "interact", "with", "the", "end", "-", "user", "via", "the", "explainable", "user", "interface", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["However", "it", "assumed", "that", "each", "UE", "transmits", "at", "the", "same", "power", "and", "femtocell", "users", "are", "uniformly", "distributed", "in", "an", "infinitesimally", "thin", "ring", "around", "the", "femtocell", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "objects", "in", "SDD", "are", "very", "small", "as", "the", "dataset", "contains", "aerial", "view", "of", "objects", "from", "high", "altitude", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stanford drone dataset"}, {"tokens": ["In", "this", "paper", ",", "we", "apply", "a", "BC", "technology", "known", "as", "Hyperledgder", "Fabric", ",", "to", "an", "IoT", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["Similarly", ",", "RB", "-", "sort", "achieve", "up", "to", "1.15x", "faster", "on", "Tesla", "K40c", "(", "ECC", "off", ")", "with", "the", "binomial", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["Let", "us", "now", "proceed", "by", "characterizing", "the", "complexity", "imposded", "by", "the", "CDP", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "classical dynamic programming"}, {"tokens": ["In", "scenarios", "with", "dynamic", "RA", ",", "it", "is", "easy", "to", "make", "an", "upper", "-", "triangular", "matrix", "during", "the", "RA", "phase", "by", "relabelling", "the", "REs", "and", "users", ",", "provided", "that", "there", "exists", "orthogonal", "users(On", "the", "occasion", "that", "there", "are", "not", "orthogonal", "active", "users", "in", "the", "system", ",", "we", "can", "relabel", "the", "layers", "rather", "than", "the", "users", "and", "some", "minor", "modifications", "to", "the", "SD", "algorithm", "will", "be", "needed", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resource allocation"}, {"tokens": ["The", "BS", "directly", "communicates", "with", "the", "CCU", "called", "and", "CEU", "called", "as", "well", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["ConclusionIn", "this", "paper", ",", "the", "NOMA", "-", "OAM", "-", "MDMA", "scheme", "has", "been", "proposed", "to", "enhance", "the", "user", "capacities", "and", "SC", "of", "NOMA", "downlink", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "sum capacities"}, {"tokens": ["These", "places", "are", "called", "information", "\"", "patches", "\"", "in", "IFT", "terminology", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information foraging theory"}, {"tokens": ["Systematic", "Exact", "-", "MBR", "coding", "algorithmBased", "on", "the", "framework", "of", "Exact", "-", "MBR", "codes", "in", "Sec", ".", ","], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["While", "transfer", "learning", "has", "begun", "to", "attract", "attention", "in", "optical", "remote", "sensing", "application", "recently", ",", "relevant", "study", "in", "SAR", "images", "has", "not", "caught", "up", "with", "yet", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["An", "ANN", "structure", "has", "been", "used", "for", "learning", "word", "embeddings", "which", "encode", "many", "linguistics", "regularities", "and", "patterns", "explicitly", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "MAD", "gives", "an", "indication", "of", "the", "absolute", "differences", "that", "we", "can", "expect", "when", "switching", "from", "peer", "review", "to", "metrics", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "median absolute difference"}, {"tokens": ["The", "activation", "requirement", "is", ",", "which", "is", "the", "same", "with", "the", "coverage", "requirement", "in", "the", "PSC", "instance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "partial set cover"}, {"tokens": ["One", "particular", "finding", "of", "us", "is", ",", "that", "in", "cases", "having", "a", "limited", "set", "of", "candidate", "entities", "available", "like", "in", "UC1", ",", "popularity", "-", "based", "methods", "such", "as", "MP", "provide", "good", "results", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "most popular"}, {"tokens": ["We", "used", "separate", "speaker", "-", "dependent", "convolutional", "neural", "networks", "to", "predict", "the", "ContF0", ",", "MVF", "and", "MGC", "-", "LSP", "parameters", "from", "Ultrasound", "Tongue", "Image", "input", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["In", "the", "particular", "case", "of", "standard", "GP", "regression", ",", "the", "set", "corresponds", "to", "the", "mean", "parameter", ",", "which", "is", "assumed", "to", "be", "a", "non", "-", "linear", "function", "drawn", "from", "a", "GP", "prior", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Importantly", ",", "we", "always", "use", "a", "single", "-", "output", "latent", "function", "for", "modeling", "likelihood", "parameters", ",", "that", "is", ",", "we", "avoid", "solutions", "similar", "to", "the", "chained", "GP", ",", "which", "could", "be", "also", "applied", "to", "the", "current", "experiment", "with", "continual", "GPs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["ECS", "-", "DBN", "ranks", "first", "over", "other", "competing", "methods", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["This", "observation", "contrasts", "with", "the", "main", "argument", "from", ",", "where", "the", "authors", "argue", "that", "TS", ",", "their", "best", "-", "performing", "method", ",", "worked", "better", "than", "complex", "models", "because", "the", "calibration", "space", "is", "inherently", "simple", ",", "and", "complex", "models", "tend", "to", "over", "-", "fit", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature scaling"}, {"tokens": ["There", "are", "two", "predictions", "tasks", "for", "understanding", "the", "users", ":", "Web", "Browsing", "Prediction", "(", "CF", "Task", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "DE", "-", "SB", "method", "is", "described", "in", "Algorithm", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["We", "also", "thank", "Rufus", "Pollock", "for", "distributing", "a", "list", "of", "the", "tickers", "of", "the", "SP", "500", "companies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "standards poors"}, {"tokens": ["In", "addition", ",", "nodes", "in", "cellular", "networks", "are", "synchronized", ",", "and", "all", "communications", "are", "single", "-", "hop", "(", "from", "UE", "to", "BS", "or", "BS", "to", "UE", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "user equipment"}, {"tokens": ["Proposal", "Ranking", "Network(PRN)For", "visual", "stream", ",", "the", "visual", "features", "from", "PIN", "are", "augmented", "with", "contrastive", "visual", "features", "and", "5D", "relative", "location", "features", ";", "generating", "an", "augmented", "feature", "vector", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "proposal indexing network"}, {"tokens": ["Therefore", ",", "DDE", "-", "MGM", "is", "still", "competitive", "to", "those", "algorithms", "specifically", "designed", "for", "this", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Case", "2", "(", "Separate", "Femto+WLAN", ")", ":", "Each", "small", "cell", "(", "femtocell", ")", "operates", "onlyin", "licensed", "bands", "with", "the", "LTE", "air", "interface", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["While", "RS", "images", "processing", "software", "have", "internal", "mechanisms", "to", "deal", "with", "the", "large", "stacks", "of", "images", ",", "this", "problematic", "is", "out", "of", "DL", "frameworks", "scope", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "remote sensing"}, {"tokens": ["An", "NFA", "is", "GFG", "if", "and", "only", "if", "it", "is", "DBP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "determinisable by pruning"}, {"tokens": ["2001Joseph", "Newman", "present", "the", "BatPortal", ",", "a", "PDA", "-", "based", ",", "wireless", "AR", "system", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["In", "water", "-", "fat", "MRI", ",", "further", "strategies", "have", "been", "proposed", "such", "as", "the", "transfer", "of", "segmentations", "between", "volumes", ",", "clustering", "techniques", "for", "masking", "and", "fitting", "of", "three", "-", "dimensional", "surfaces", "or", "morphological", "operators", "that", "allow", "the", "identification", "of", "VAT", "and", "SAT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Spectral", "clustering", "(", "SC", ")", ",", "and", "SN", "that", "is", "also", "based", "on", "a", "spectral", "-", "clustering", "motivated", "objective", ",", "perform", "equally", "well", "as", "KNet", "on", "discovering", "non", "-", "convex", "clusters", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral clustering"}, {"tokens": ["Four", "solutions", "have", "been", "evaluated", "and", "inserted", "in", "the", "BSP", "tree", ",", "where", "becomes", "a", "virtual", "node", "of", ";", "and", "becomes", "a", "virtual", "node", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["The", "unnormalised", "maximum", "log", "-", "likelihood", "that", "a", "given", "partition", "in", "groups", "of", "the", "network", "is", "reproduced", "by", "the", "standard", "SBM", "reads", "where", "is", "the", "number", "of", "edges", "running", "from", "group", "to", "group", ",", "(", ")", "the", "number", "of", "vertices", "in", "(", ")", "and", "the", "sum", "runs", "overall", "pairs", "of", "groups", "(", "including", "when", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["SetupIn", "order", "to", "prove", "our", "claim", "that", "BQ", "can", "help", "accuracy", "and", "compare", "with", "the", "state", "-", "of", "-", "the", "-", "art", "VQA", "method", ",", "so"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["Ex", ":", "if", "'", "Jamshedpur", "'", "(", "a", "city", "in", "India", ")", "is", "recognised", "as", "'", "game", "shed", "poor", "'", "(", "articulation", "style", "and", "duration", "of", "utterance", "is", "the", "key", "difference", ")", ",", "then", "the", "whole", "QA", "process", "is", "altered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Its", "transpose", "(", "adjoint", ")", "isgivingThis", "implies", "that", "if", "the", "differential", "operator", "has", "a", "known", "Green", "'s", "function", ",", "then", "the", "covariance", "function", "of", "the", "GP", "can", "be", "calculated", "by", "transforming", "the", "covariance", "function", "of", "the", "noisy", "input", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Next", ",", "the", "height", "normalized", "line", "image", "is", "presented", "to", "the", "BLSTM", "-", "CTC", "based", "OCR", "system", "for", "training", "and", "validation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["Latent", "features", "are", "extracted", "from", "the", "penultimate", "layer", "of", "the", "trained", "ANN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "last", "version", "of", "the", "toy", "single", "-", "output", "GP", "regression", "experiment", "shows", "relevant", "properties", "of", "the", "model", "itself", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "have", "considered", "two", "spatial", "random", "distributions", "in", "order", "to", "distinguish", "between", "outdoor", "users", "distributed", "along", "a", "random", "system", "of", "roads", "in", "a", "typical", "cell", "coverage", "area", "(", "Cox", "Point", "Process", "driven", "by", "PLP", ")", "and", "indoor", "users", "distributed", "in", "buildings", "according", "to", "the", "widely", "used", "spatial", "PPP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["The", "AT", "model", "and", "the", "ARD", "model", "were", "trained", "with", "a", "-step", "PGD", "attack", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["As", "for", "the", "setup", "of", "the", "LB", "divergence", "-", "based", "methods", ",", "there", "were", "permutations", "and", "candidates", "associated", "with", "each", "query", "in", "total", ",", "and", "the", "number", "of", "units", "in", "the", "hidden", "layer", "for", "the", "nested", "structure", "is", "set", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["[", "85.6", "]", "2cTask", "&", "9lEC", ":", "resting", "state", "with", "eyes", "closed", ",", "EO", ":", "resting", "state", "with", "eyes", "open", ",", "MI", ":", "motor", "imagery", ",", "ERP", ":", "event", "related", "potential", "2c2*Classifier", "&", "9lANN", ":", "artificial", "neural", "networks", ",", "FDA", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "eyes open"}, {"tokens": ["Parameters", "for", "LR", "and", "RF", "are", "analyzed", "by", "comparing", "the", "results", "on", "the", "training", "data", "set", "and", "then", "used", "to", "predict", "the", "test", "data", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["In", "these", "networks", ",", "it", "was", "observed", "that", "as", "training", "progresses", ",", "the", "angle", "between", "the", "BP", "gradient", "and", "the", "FA", "error", "signal", "converges", "from", "approximately", "orthogonal", "to", "roughly", ",", "meaning", "that", "the", "FA", "weight", "updates", "are", "correlated", "with", "but", "not", "identical", "to", "those", "in", "BP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["1lPayload", "Size", "(", "KB", ")", "&", "Proposed", "BC", "&", "1lQuoram", "BC", "1", "&", "0.225", "&", "0.325", "10", "&", "0.280", "&", "0.383", "20", "&", "0.320", "&", "0.384", "30", "&", "0.330", "&", "0.407", "Conclusion", "and", "Future", "Work", "Security", "and", "privacy", "in", "IoT", "is", "extremely", "important", "these", "days", "and", "gain", "a", "considerable", "attention", "from", "research", "and", "industry", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["\"", ",", "_", "PSO", "_", ")", ";", "InitializeSearchSpace(s", ",", "_", "PSO", "_", ")", ";", "if(CheckSearchSpace(s", ",", "_", "PSO", "_", ")", ")"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Most", "of", "the", "solutions", "to", "RV", "segmentation", "problem", "till", "date", "are", "conventional", "approaches", "that", "although", "performed", "well", "but", "have", "not", "been", "able", "to", "reach", "human", "-", "level", "accuracy", "(", "0.90", "Dice", "score", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["There", "are", "domains", "that", "traditional", "QA", "does", "not", "hurt", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["However", ",", "the", "average", "delay", "of", "the", "AP", "(", ")", "increases", "sharply", "as", "the", "downlink", "traffic", "approaches", "saturation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["EMDlei2007fault", ",", "Bispectrumyang2002third", ",", "AR", "Frequency", "Spectrawang2008fault", ",", "NNwang2001fault", ",", "yam2001intelligent", ",", "huang2007residual", ",", "HMMocak2007online", ",", "zhang2010hidden", ",", "Fuzzy", "logicsatish2005fuzzy", ",", "GAfeng2009ga", ",", "ARMAgalati2006application", ",", "Stochastic", "Modelli2000stochastic", ",", "wang2002model", ",", "PCAzhang2005integratedGear", "&", "Manufacturing", "error", ",", "tooth", "missing", ",", "tooth", "pitting", "/", "spall", ",", "gear", "crack", ",", "gear", "fatigue", "/", "wear", "&", "High", "noise", ";", "high", "dynamics", ";", "signal", "modulated", "with", "other", "factors", ";", "gear", "specs", "need", "to", "be", "known", "&", "Vibration", ",", "oil", "debris", ",", "acoustic", "emission", "&", "Time", "domain", "statistical", "features", ",", "vibration", "signature", "frequencies", ",", "oil", "debris", "quantity", "and", "chemical", "analysis", "&", "FTchoy1996analysis", ",", "STFTkar2006technical", ",", "bartelmus2009vibration", ",", "WTpeng2004application", ",", "suh1999machinery", ",", "EMDloutridis2004damage", ",", "wang2007gearbox", ",", "liu2006gearbox", ","], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "auto - regression"}, {"tokens": ["In", "Section", ",", "it", "has", "been", "shown", "that", "using", "the", "SLR", "instead", "of", "the", "original", "LR", "strengthens", "the", "formulation", "while", "only", "marginally", "increasing", "computing", "times", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lp relaxation"}, {"tokens": ["Any", "opinions", ",", "findings", ",", "conclusions", ",", "or", "recommendations", "expressed", "in", "this", "material", "are", "those", "of", "the", "authors", "and", "do", "not", "necessarily", "reflect", "the", "views", "of", "the", "NSF", ",", "the", "TRI", ",", "any", "other", "Toyota", "entity", ",", "or", "others", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "toyota research institute"}, {"tokens": ["In", "this", "section", "we", "investigate", "the", "application", "of", "FA", "to", "steganalysis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "firefly algorithm"}, {"tokens": ["Recently", "GP", "has", "been", "proposed", "as", "a", "general", "feature", "engineering", "wrapper", "(", "FEW)(http://lacava.github.io", "/", "few", ")", "in", "order", "to", "harness", "its", "feature", "learning", "capability", "to", "improve", "scikit", "-", "learn", "estimators", ",", "both", "for", "regression", "and", "classification", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Indeed", ",", "the", "automaton", "is", "DBP", ",", "and", "can", "be", "pruned", "to", "keep", "only", "states", "(", "so", "getting", "rid", "of", "states", "such", "as", ")", "while", "still", "recognizing", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["ConclusionsIn", "this", "paper", ",", "we", "proposed", "a", "novel", "method", ",", "DDE", "-", "MGM", ",", "to", "model", "and", "classify", "time", "series", "in", "an", "online", "manner", ",", "where", "common", "but", "unrealistic", "assumptions", "like", "the", "same", "data", "length", "and", "well", "alignment", "are", "completely", "removed", ",", "facilitating", "the", "deployment", "of", "the", "method", "to", "real", "-", "world", "problem", "solving", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Overall", ",", "these", "results", "show", "clear", "evidence", "that", "including", "an", "ISP", "significantly", "improves", "the", "cost", "/", "accuracy", "pareto", "trade", "-", "off", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["For", "each", "experiment", "stage", ",", "there", "are", "three", "datasets", ":", "CF", "dataset", "(", ")", ",", "CTR", "dataset", "(", ")", "and", "Joint", "dataset", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["More", "accurate", "localization", "and", "mapping", "systems", "and", "algorithms", "are", "required", "in", "support", "of", "SAR", "operations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "search and rescue"}, {"tokens": ["For", "specific", "GP", "kernel", "operators", ",", "which", "are", "the", "inverses", "of", "differential", "operators", ",", "a", "solution", "in", "terms", "of", "linear", "partial", "differential", "equations", "would", "be", "possible", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Linge", "J", ",", "Borga", "M", ",", "West", "J", ",", "Tuthill", "T", ",", "Miller", "MR", ",", "Dumitriu", "A", ",", "et", "al", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["The", "state", "-", "of", "-", "the", "-", "art", "approach", "for", "CDA", "recognition", "on", "the", "MSDialog", "-", "Intent", "datasetqu2019user", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concurrent dialogue acts"}, {"tokens": ["In", "this", "work", "we", "extend", "the", "latent", "force", "framework", "to", "allow", "for", "multiplicative", "interactions", "between", "the", "GP", "and", "the", "latent", "states", "leading", "to", "more", "control", "over", "the", "geometry", "of", "the", "trajectories", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "PS", "system", "was", "built", "to", "solve", "distributed", "ML", "elastic", "scalability", ",", "communication", ",", "and", "flexible", "consistency", "problems", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["Neither", "the", "HKL", "nor", "the", "additive", "model", "dominate", "one", "another", "in", "terms", "of", "flexibility", ",", "however", "the", "GP", "-", "GAM", "and", "the", "SE", "-", "GP", "are", "special", "cases", "of", "additive", "GPs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Currently", ",", "the", "DAS", "team", "is", "working", "with", "data", "users", "to", "redesign", "the", "publication", "tables", ",", "with", "the", "hope", "of", "lowering", "their", "sensitivity", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "disclosure avoidance system"}, {"tokens": ["LR", "is", "a", "linear", "classifier", "with", "decision", "boundary", "of", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["The", "diagonal", "line", "denotes", "the", "FP", "vs", "TP", "akin", "to", "guessing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["This", "agrees", "with", "the", "fact", "that", "Haidian", "takes", "the", "second", "place", "of", "the", "GDP", "ranking", "of", "Beijing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gross domestic product"}, {"tokens": ["For", "instance", ",", "if", "we", "consider", "a", "deterministic", "scenario", "like", "the", "MNIST", "dataset", "with", ",", "for", "and", "the", "range", "of", "the", "Lagrange", "multipliers", "that", "allow", "the", "exploration", "of", "the", "IB", "curve", ",", "according", "to", "Corollary", ",", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "change", "in", "cosine", "similarity", "for", "CC", "from", "degrees", "(", "using", "varifolds", ")", "to", "degrees", "(", "using", "functional", "varifolds", ")", "while", "for", "CST", "(", "R", ")", "from", "degrees", "to", "degrees", ",", "reflect", "more", "drop", "in", "cosine", "similarity", "if", "along", "tract", "signal", "profiles", "are", "not", "similar", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "corticospinal tract"}, {"tokens": ["As", "a", "byproduct", "of", "GMM", "modeling", ",", "we", "present", "useful", "insights", "on", "characterizing", "the", "data", "generating", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["It", "can", "be", "seen", "that", ",", "from", "all", "the", "state", "-", "of", "-", "the", "-", "art", "methods", ",", "the", "iterative", "algorithm", "RV", "outperforms", "all", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "random voting"}, {"tokens": ["Corporate", "Messaging", "(", "CM", ")"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "corporate messaging"}, {"tokens": ["As", "expected", ",", "fine", "-", "tuning", "to", "each", "listener", "improved", "upon", "the", "generalized", "models", ",", "with", "the", "ATV", "model", "improving", "from", "a", "CCC", "of", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["Note", "that", "each", "of", "the", "mixture", "components", "of", "this", "GMM", "corresonds", "to", "an", "unseen", "class", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Hence", ",", "a", "for", "a", "UE", "is", "selected", "as", ":", "where", "is", "a", "fixed", "RSRQ", "threshold", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["We", "assume", "that", "this", "is", "due", "to", "the", "fact", "that", "raters", "see", "the", "MR", "in", "both", "cases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "meaning representation"}, {"tokens": ["Given", "a", "score", "-", "based", "permutation", "and", "a", "concave", "function", ",", "the", "LB", "divergence", "defined", "as", "(", ")", "provides", "a", "constant", "upper", "bound", "to", "the", "NDCG", "loss", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["We", "modify", "the", "nonlinear", "-", "IB", "method", ",", "which", "is", "a", "neural", "network", "that", "minimizes", "the", "cross", "-", "entropy", "while", "also", "minimizing", "a", "differentiable", "kernel", "-", "based", "estimate", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Self", "Consistency", "of", "Experts", "sec", ":", "SC", "Since", "the", "annotator", "is", "guided", "by", "visual", "features", ",", "such", "as", "intensity", ",", "in", "distinguishing", "between", "different", "regions", ",", "it", "is", "expected", "that", "for", "reliable", "annotations", "the", "region", "with", "a", "particular", "label", "would", "have", "consistent", "feature", "distributions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "self consistency"}, {"tokens": ["Note", "that", "each", "class", "maintains", "a", "separate", "MGM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "markov geographic model"}, {"tokens": ["Experimental", "SetupTo", "compare", "the", "performance", "of", "our", "TS", "approach", "with", "state", "-", "of", "-", "the", "-", "art", "syntactic", "simplification", "systems", ",", "we", "evaluated", "DisSim", "with", "respect", "to", "the", "sentence", "splitting", "task", "(", "subtask", "1", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["SSIM", "measure", "assesses", "the", "correlation", "of", "local", "structures", "and", "is", "less", "sensitive", "to", "image", "noise", "than", "PSNR", "which", "is", "not", "used", "in", "our", "experiments", "since", "small", "misalignments", "between", "LR", "-", "HR", "image", "pairs", "could", "introduce", "large", "errors", "in", "the", "evaluation", "due", "to", "pixel", "by", "pixel", "comparisons", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["e.g.", ",", "Judeo", "-", "Isfahani", "kelews", "'", "celery", "'", "NP", "karafs", "Arabic", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Chikara", "and", "Kumari", "in", "proposed", "another", "version", "of", "PSO", "for", "steganalysis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Initially", ",", "we", "presented", "the", "RS", "method", "and", "the", "FD", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["Convergence", "curves", "for", "regression", "by", "DE", "(", "left", ")", "and", "CMA", "-", "ES", "(", "right", ")", "using", "the", "inc", "-", "sinc", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["To", "our", "best", "knowledge", ",", "there", "are", "no", "reports", "on", "the", "impact", "of", "the", "ANN", "-", "symmetries", "regarding", "the", "performance", "of", "the", "DE", "and", "CMA", "-", "ES", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["In", "OR", ",", "only", "a", "single", "relay", "with", "the", "most", "reliable", "signal", "path", "to", "the", "destination", "forwards", "a", "packet", "per", "hop", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "opportunistic relaying"}, {"tokens": ["Furthermore", ",", "we", "show", "that", "the", "AIR", "of", "HDD", "with", "bit", "-", "wise", "metric", "is", "higher", "than", "that", "of", "the", "CM", "scheme", "with", "symbol", "-", "wise", "metric", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "coded modulation"}, {"tokens": ["We", "also", "assume", "a", "trusted", "third", "party", "(", "e.g.", ",", "a", "bank", ")", ",", "TTP", ",", "that", "has", "deployed", "our", "verification", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "trusted third party"}, {"tokens": ["workers", "should", "not", "have", "less", "than", "the", "number", "of", "PS", "nodes", "in", "order", "to", "divide", "the", "bandwidth", "evenly", "among", "workers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["In", "this", "work", ",", "we", "build", "an", "open", "-", "domain", "QA", "system", "with", "sequence", "-", "to", "-", "sequence", "neural", "network", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["(", "ICC", "VAT", "0.998", "and", "SAT", "0.996", ")", "and", "manual", "re", "-", "editing"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["It", "is", "shown", "that", "the", "implemented", "GAN", "models", "can", "synthesize", "visually", "realistic", "MR", "images", "(", "incorrectly", "labeled", "as", "real", "by", "a", "human", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["network(CNN)-based", "JPEG", "-", "compliant", "MDC", "framework", "has", "been", "used", "to", "sample", "an", "input", "image", "to", "adaptively", "create", "multiple", "description", "images", ",", "but", "its", "coding", "efficiency", "is", "not", "very", "high", "because", "the", "usage", "of", "the", "standard", "JPEG", "limits", "the", "performance", "of", "this", "framework", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["The", "earliest", "valve", "-", "heart", "coupling", "model", "that", "includes", "FSI", "is", "credited", "to", "Peskin", "and", "McQueen", "'s", "pioneering", "work", "in", "the", "1970s", "using", "the", "classical", "IB", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "immersed boundary"}, {"tokens": ["To", "express", "this", "in", "the", "weighted", "cross", "-", "entropy", "expression", "we", "used", "and", "performed", "DC", "-", "OPF", "experiments", "as", "before", "using", "k", "samples", "(", "using", "the", "same", "setup", "for", "meta", "-", "optimization", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["The", "improvements", "in", "short", "-", "range", "prediction", "errors", "relative", "to", "the", "No", "-", "ANN", "model", "were", "smaller", "than", "found", "above", ",", "by", "a", "median", "of", "18", "for", "one", "-", "timestep", "tendency", "errors", "across", "ANNs", "with", "the", "same", "structures", "as", "those", "considered", "above", "and", "by", "about", "40", "for", "the", "ACC", "and", "RMSE", "at", "a", "lead", "time", "of", "1MTU", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "anomaly correlation coefficient"}, {"tokens": ["The", "CD", "organization", "was", "proposed", "in", "conjunction", "with", "the", "Gamma", "database", "machine", "project", ",", "which", "was", "inspired", "by", "the", "Teradata", "DBC/1012", "database", "computer", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["Despite", "their", "differences", ",", "it", "has", "been", "shown", "that", "there", "are", "several", "close", "connections", "between", "the", "VAE", "framework", "and", "the", "IB", "principle.tDVIB", "introduce", "the", "Deep", "Information", "Bottleneck", "(", "DIB", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "particular", ",", "the", "conditional", "GP", "prior", "in", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Towards", "the", "design", "of", "MINT", "-", "FECThe", "design", "process", "of", "MINT", "-", "FEC", "starts", "with", "the", "definition", "of", "the", "fuzzy", "components", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["These", "requirements", "are", "made", "according", "to", "(", "i", ")", "the", "inter", "-", "annual", "variability", "and", "the", "trend", "of", "historical", "data", ",", "(", "ii", ")", "the", "calendar", "of", "official", "statistics", "data", "collection", ",", "and", "(", "iii", ")", "the", "time", "at", "which", "early", "estimations", "of", "cropland", "area", ",", "crop", "area", "and", "crop", "yield", "can", "theoretically", "be", "available", "(", "based", "on", "EO", "data", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "earth observation"}, {"tokens": ["The", "RF", "and", "ANN", "models", "had", "relatively", "stable", "performance", "across", "all", "current", "levels", "in", "terms", "of", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["PathEarlier", "works", "have", "explored", "visualising", "the", "path", "of", "the", "robot", ",", "yet", "these", "designs", "extend", "lines", "far", "into", "the", "future", "and", "this", "means", "that", "in", "an", "MR", "setting", "where", "all", "the", "robots", "in", "the", "vincinity", "broadcast", "their", "paths", "the", "visual", "field", "would", "quickly", "become", "cluttered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mixed reality"}, {"tokens": ["Moreover", "it", "must", "be", "open", "such", "that", "it", "can", "be", "used", "in", "future", "QA", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "resulting", "structure", "is", "the", "same", "of", "ClumpFind", "(", "i.e.", ",", "CAA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "clump assignment array"}, {"tokens": ["Using", "the", "MGF", "approach", "and", "following", "the", "same", "steps", "as", "in", "Section", "II", "with", "(", "8)", ",", "upper", "bounded", "SEP", "for", "BPSK", "can", "be", "obtained", "asWe", "can", "generalize", "this", "simultaneous", "transmission", "scenario", "with", "two", "RISs", "to", "the", "general", "case", "of", "independent", "RISs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "symbol error probability"}, {"tokens": ["Exponential", "IB", "Lagrangian", ":", "and", "."], "acronym_pos": [0, 1, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Comparison", "of", "platform", "amplitude", "differences", "read", "from", "predicted", "LPSRS", "and", "FEM", "-", "measured", "LPSRS"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["First", ",", "we", "compute", "the'DSA", "skill", "intensity", "'", "for", "each", "standardised", "BGT", "occupation", ",", "defined", "as", "percentage", "of", "DSA", "skills", "relative", "to", "the", "total", "skill", "count", "for", "the", "job", "ads", "related", "to", "an", "occupation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["Both", "networks", "perform", "worse", "on", "the", "test", "data", "than", "in", "cross", "-", "validation", "and", "have", "a", "tendency", "to", "undersegment", "both", "VAT", "and", "SAT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["To", "produce", "an", "initial", "low", "resolution", "estimate", "of", "WT", ",", "the", "preprocessed", "training", "data", "were", "downsampled", "to", "2", "mm", "isotropic", "voxels", "and", "used", "to", "train", "a", "U", "-", "Net", "with", "four", "input", "channels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "whole tumor"}, {"tokens": ["When", "number", "of", "corrupted", "bits", "is", "greater", "than", "the", "correction", "capability", "of", "the", "FEC", "codes", ",", "transmitter", "needs", "to", "retransmit", "the", "corrupted", "data", "packet", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["For", "this", "reason", ",", "after", "designing", "the", "primarily", "neural", "network", "with", "two", "hidden", "layers", ",", "the", "number", "of", "neurons", "of", "each", "layer", "and", "the", "kind", "of", "training", "functions", "has", "been", "changed", "to", "determine", "the", "effects", "of", "those", "parameters", "by", "using", "which", "ICA", "algorithms", "we", "allocate", "weights", "and", "biases", "values", "of", "the", "network", "and", "it", "has", "been", "compared", "with", "a", "neural", "network", "trained", "by", "GA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imperialist competitive algorithm"}, {"tokens": ["For", "example", ",", "our", "measurements", "show", "that", "Samsung", "Galaxy", "S4", "draws", "1.56", "A", "current", "at", "5", "V", "from", "the", "charger", "during", "the", "CC", "phase", "of", "charging", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["Overview", "of", "Multi", "-", "Connectivity", "in", "3GPPMC", "in", "5", "G", "NR", "is", "inherited", "from", "the", "DC", "concept", "in", "LTE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "long term evolution"}, {"tokens": ["The", "results", "of", "the", "comparative", "investigation", "including", "the", "time", "-", "complexity", "analysis", "with", "GA", ",", "ACO", "and", "five", "other", "PSO", "variants", "illustrate", "that", "the", "proposed", "2D", "learning", "approach", "gives", "feature", "subset", "with", "relatively", "smaller", "cardinality", "and", "better", "classification", "performance", "withshorter", "run", "times", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["For", "AC", "-", "OPF", ",", "k", "samples", "were", "generated", "for", "the", "studied", "synthetic", "grids", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["For", "example", ",", "in", "a", "case", "that", "the", "AP", "employs", "antennas", ",", "the", "-nd", "contention", "round", "finishes", "as", "soon", "as", "a", "STA", "successfully", "wins", "the", "still", "-", "available", "antenna", "of", "the", "AP", ";", "while", "in", "a", "case", "that", "the", "AP", "employs", "more", "than", "antennas", ",", "the", "-nd", "contention", "round", "continues", ",", "therefore", "increasing", "the", "-nd", "round", "collision", "probability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["MP", "stands", "for", "Max", "Pooling", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "max pooling"}, {"tokens": ["Our", "i", "-", "vector", "feature", "fusion", "approach", "(", "model", "I", ")", "shows", "impressive", "performance", "on", "the", "LA", "task", "but", "relatively", "poor", "performance", "on", "the", "PA", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "physical access"}, {"tokens": ["These", "models", "generalise", "the", "flexible", "prediction", "system", "of", "GP", "approaches", "to", "the", "vector", "-", "valued", "random", "field", "setup", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["@X", "rrrrrrrrrr", "@", "&", "PC", "0", "&", "PC", "1", "&", "PC", "2", "&", "PC", "3", "&", "PC", "4", "&", "PC", "5", "&", "PC", "6", "&", "PC", "7", "&", "PC", "8", "&", "PC", "9", "CNS", "&", "0.40", "&", "0.18", "&", "0.10", "&", "0.07", "&", "0.07", "&", "0.06", "&", "0.04", "&", "0.03", "&", "0.03", "&", "0.02", "MDC", "&", "0.39", "&", "0.19", "&", "0.12", "&", "0.10", "&", "0.06", "&", "0.05", "&", "0.05", "&", "0.03", "&", "0.02", "&", "0.01", "T=30", ",", "Variance", "explained", "by", "principal", "components", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["These", "alternative", "signals", "are", "particularly", "relevant", "to", "SAR", "because", "robots", "have", "inherently", "expressive", "embodiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["present", "Archeoguide", ",", "a", "mobile", "AR", "system", "for", "cultural", "heritage", "sites", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Traditional", "Ascending", "Clock", "Auction", "(", "ACA", "-", "T", ")", "and", "Alternative", "Ascending", "Clock", "Auction", "(", "ACA", "-", "A)Different", "distributed", "auctions", "can", "be", "found", "in", "for", "the", "FJ", "power", "allocation", ",", "that", "are", "ACA", "-", "T", "and", "ACA", "-", "A."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["For", "future", "work", "we", "will", "focus", "on", "the", "utilization", "of", "more", "AI", "approaches", "under", "our", "BDIx", "framework", "and", "we", "will", "implement", "a", "dynamic", "approach", "by", "taking", "under", "consideration", "the", "speed", "and", "mobility", "of", "a", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["In", "more", "detail", ",", "the", "main", "contribution", "of", "this", "work", "is", "the", "proposal", "of", "an", "adversary", "-", "aware", "white", "-", "box", "AML", "mechanism", "against", "poison", "attacks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "adversarial machine learning"}, {"tokens": ["A", "straightforward", "BSP", "implementation", "of", "an", "operation", "on", "a", "frontier", "treats", "each", "element", "in", "the", "frontier", "equally", ",", "i.e.", ",", "with", "the", "same", "priority", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bulk synchronous parallel"}, {"tokens": ["Experiments", "and", "ResultsAblation", "ExperimentsWe", "experimentally", "demonstrated", "in", "Section", "(", "Figure", ")", "that", "networks", "trained", "on", "HR", "images", "perform", "poorly", "on", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["In", "Figure", ",", "some", "successful", "examples", "of", "SEM", "segmentation", "using", "FCNN", "networks", ",", "trained", "with", "balanced", "and", "augmented", "training", "data", "are", "shown", "next", "to", "some", "failure", "cases", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["If", "the", "battery", "is", "less", "than", "a", "specified", "threshold", "(", "user", "can", "setup", "this", "threshold", ")", "the", "UE", "acts", "as", "a", "regular", "UE", "device", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], "long_form": "user equipment"}, {"tokens": ["is", "the", "main", "technique", "of", "memorization", ",", "thus", "providing", "a", "significant", "complexity", "reduction", "by", "remembering", "and", "propagating", "the", "OPF", "identified", "across", "the", "previous", "trellis", "stages", "to", "the", "next", "ones", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal pareto front"}, {"tokens": ["We", "can", "clearly", "see", "that", "the", "proposed", "FL", "scheme", "achieves", "the", "best", "performance", "among", "all", "schemes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Affinity", "DADA", "builds", "a", "compromise", "taking", "into", "account", "both", "raw", "performance", "and", "transfers", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["Each", "of", "two", "mirrored", "virtual", "disks", "consists", "of", "disks", "and", ",", "so", "that", ":", "In", "the", "case", "of", "ID", "we", "use", "the", "expression", "for", "given", "by", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["Influence", "of", "age", "and", "sex", "on", "VAT", "-", "V", "and", "SAT", "-", "V", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Again", ",", "DE", "-", "SB", "and", "CMA", "-", "ES", "-", "SB", "are", "the", "fastest", "methods", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["By", "deducting", "and", ",", "the", "probability", "that", "the", "channel", "observes", "a", "collision", "slot", ",", ",", "is", "obtained", ":", "In", "the", "saturated", "condition", ",", "a", "successful", "downlink", "transmission", "always", "contains", "(", "the", "number", "of", "AP", "antennas", ")", "data", "streams", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Nguyen:2014:EFB:2566486.2568012", "have", "studied", "the", "effect", "of", "RS", "on", "Content", "Diversity", ",", "and", "demonstrated", "that", "recommendation", "-", "following", "users", "on", "the", "MovieLens", "platform", "were", "exposed", "to", "slightly", "more", "diverse", "content", "than", "non", "-", "recommendation", "-", "following", "users", ",", "therefore", "\"", "taking", "recommendations", "lessened", "the", "risk", "of", "a", "filter", "bubble", "\"", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["The", "fusion", "happens", "at", "the", "score", "level", ":", "the", "two", "score", "vector", "produced", "by", "WF", "and", "WPR", "(", "using", "the", "cosine", "distance", ")", "are", "summed", "up", "element", "-", "wise", "and", "ranked", "by", "decreasing", "overall", "score", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "weighted fusion"}, {"tokens": ["If", "it", "is", "below", "a", "threshold", ",", "it", "will", "be", "judged", "as", "an", "abnormal", ":", "where", "is", "the", "feature", "fed", "into", "the", "classifiers", ",", "and", "is", "the", "score", "given", "by", "the", "GMM", "Classifiers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Compared", "to", "the", "MVM", "method", ",", "which", "models", "the", "full", "-", "order", "interactions", "among", "all", "the", "modes", ",", "our", "proposed", "SFM", "leads", "to", "an", "average", "improvement", "of", "5.87", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "structural factorization machine"}, {"tokens": ["CCC", "is", "defined", "as", ":", "where", "is", "the", "Pearson", "'s", "correlation", "coefficient", ",", "and", ",", "and", "and", "are", "the", "standard", "deviations", "and", "means", "of", "the", "predicted", "score", "and", "the", "ground", "truth", "label", ",", "respectively", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["Lastly", ",", "we", "use", "the", "previously", "constructed", "features", "with", "the", "GBM", "classifier", "to", "achieve", "the", "best", "diagnosing", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["A", "bias", "as", "shown", "in", "Figure", "fig", ":", "ANN1", ",", "helps", "ANN", "to", "shift", "its", "output", "from", "to", "or", "vice", "-", "versa", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Fairness", "value", "vs.", "maximal", "transmission", "power", "of", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["thought", "that", "initialization", "with", "the", "weights", "learned", "from", "optical", "images", "has", "little", "effect", "on", "classification", "of", "SAR", "data", ",", "simply", "because", "the", "distributions", "of", "optical", "images", "and", "SAR", "data", "are", "probably", "too", "different", "from", "each", "other", "to", "transfer", "even", "in", "low", "layers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Because", "is", "transmitted", "directly", "from", "BS", "to", "CEU", "with", "full", "power", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Phl", "w't", ",", "MMP", "w'd", "NP", "bad", "'", "wind'PIr", "*", "uicati-", "Phl", "/", "MMP", "wyst", "/wi"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["System", "Model", "and", "Problem", "FormulationConsider", "a", "single", "cell", "uplink", "network", "with", "one", "BS", "serving", "a", "set", "of", "users", "using", "RSMA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["DTP", "'s", "struggle", "might", "be", "the", "result", "of", "losing", "too", "much", "of", "its", "layerwise", "target", "information", "too", "soon", "-", "the", "inverse", "mapping", "(", "or", "decoder", "of", "the", "layerwise", "auto", "-", "associative", "structure", ")", "requires", "a", "strong", "signal", "at", "each", "iteration", "to", "learn", "and", "if", "the", "signal", "is", "too", "weak", "or", "lost", ",", "the", "target", "produced", "for", "reconstruction", "becomes", "rather", "useless", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "difference target propagation"}, {"tokens": ["The", "MSEs", "of", "the", "LMMSE", "estimator", "with", "accurate", "channel", "statistics", "and", "the", "LS", "estimator", "are", "served", "as", "the", "benchmarks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["Hence", ",", "we", "believe", "that", "the", "ML", "approach", "is", "the", "preferred", "method", "for", "a", "LTE", "-", "U", "BS", "to", "detect", "the", "number", "of", "Wi", "-", "Fi", "APs", "and", "scale", "back", "the", "duty", "cycle", "efficiently", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Given", "this", "bound", ",", "as", "long", "as", ",", "KK13", "OT", "extension", "gives", "better", "communication", "complexity", "than", "IKNP", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Results", "are", "shown", "for", "the", "CNS", "and", "MDC", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["We", "also", "observe", "that", "the", "introduction", "of", "IB", "/", "SIB", "into", "the", "adversarial", "network", "can", "significantly", "constrain", "the", "performance", "of", ",", "thus", "stabilizing", "the", "adversarial", "training", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["We", "start", "by", "reviewing", "the", "MP", ",", "the", "OMP", ",", "and", "the", "FW", "algorithm", "in", "Hilbert", "spaces", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["CF", "-", "trust", ":", "CF", "model", "with", "the", "elements", "of", "the", "interaction", "matrix", "replaced", "with", "the", "proposed", "trust", "measure", "."], "acronym_pos": [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["When", "the", "energy", "receiver", "is", "unable", "to", "estimate", "CSI", ",", "proposes", "an", "EB", "design", "method", "where", "the", "transmitter", "adjusts", "its", "energy", "beamforming", "vector", "based", "on", "only", "one", "-", "bit", "feedback", "sent", "by", "the", "energy", "receiver(s", ")", ",", "indicating", "the", "increase", "or", "decrease", "of", "the", "harvested", "energy", "in", "the", "current", "iteration", "compared", "to", "the", "last", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "energy beam"}, {"tokens": ["LTSs", "are", "used", "as", "the", "formal", "framework", "to", "define", "the", "semantics", "of", "AML", "models", "and", "our", "generated", "assumptions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["=", "scriptsize", ",", "labelfont", "=", "bf", "results", "/", "compareAlgos.png", "UCB", "and", "TS", "based", "Algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["The", "accuracy", "in", "this", "experience", "is", "equal", "to", "97.96", ",", "It", "has", "been", "increased", "by", "8.25", "comparing", "to", "the", "baseline", "framework", "of", "MFP", "-", "CNN", "in", "the", "first", "experience", "and", "it", "confirms", "the", "impact", "of", "augmenting", "pre", "-", "training", "data", "sets", "in", "this", "framework", "of", "FER", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "facial expression recognition"}, {"tokens": ["For", "example", ",", "denotes", "an", "ANN", "model", "with", "a", "dropout", "of", "20", "nodes", "in", "the", "input", "layer", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "node", "communicates", "with", "the", "BS", "using", "CC2420", "radio", "in", "2.4", "GHz", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Considering", "the", "particularity", "of", "SAR", "images", ",", "especially", "the", "different", "imaging", "mechanisms", "between", "optical", "and", "SAR", "sensors", ",", "it", "\u2019s", "not", "easy", "to", "transfer", "the", "features", "immediately", "from", "those", "successfully", "models", "which", "are", "often", "trained", "with", "natural", "image", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["The", "proposed", "ACNN", "-", "Seg", "method", "is", "compared", "against", ":", "the", "current", "state", "-", "of", "-", "the", "-", "art", "cine", "MR", "2D", "slice", "by", "slice", "segmentation", "method", "(", "2D", "-", "FCN", ")", ",", "3D", "-", "UNet", "model", ",", "cascaded", "3D", "-", "UNet", "and", "convolutional", "AE", "model", "(", "AE", "-", "Seg", ")", ",", "sub", "-", "pixel", "3D", "-", "CNN", "segmentation", "model", "(", "3D", "-", "Seg", ")", "proposed", "in", "Sec", ".", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["First", ",", "the", "AP", "is", "playing", "a", "central", "role", "in", "collecting", "CSI", "from", "all", "STAs", "for", "downlink", "MU", "-", "MIMO", "transmissions", "in", "802.11ac", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["By", "using", "simulation", "and", "analysis", ",", "the", "performance", "improvement", "of", "the", "proposed", "EHS", "protocol", "with", "considered", "SISO", "based", "CNOMA", "DL", "transmission", "(", "EHS", "-", "CNOMA", ")", "over", "existing", "HS", "protocol", "with", "SISO", "based", "CNOMA", "DL", "transmission", "with", "SC", "(", "HS", "-", "CNOMA", ")", "are", "analyzed", "explicitly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "selection combining"}, {"tokens": ["ADEPOS", "enables", "X", "average", "energy", "saving", "over", "B", "-", "OCC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "one class classifier"}, {"tokens": ["We", "introduce", "AML", "as", "the", "formal", "foundation", "of", "our", "work", "to", "model", "asynchronous", "systems", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["[", "AP", "property", "]"], "acronym_pos": [0, 1, 0, 0], "long_form": "asymptotic preserving"}, {"tokens": ["Inspired", "byKumar_2018_CVPR", ",", "bulat2016human", "we", "employ", "a", "two", "-", "stage", "model", "to", "predict", "the", "vehicle", "'s", "orientation", "and", "landmarks", "in", "a", "coarse", "to", "fine", "manner", ";", "the", "coarse", "heatmaps", "predicted", "by", "a", "DCNN", "are", "refined", "using", "a", "shallower", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["With", "more", "than", "90", "of", "parameters", "in", "fully", "-", "connected", "layers", ",", "we", "only", "use", "the", "convolution", "layers", "of", "AlexNet", "due", "to", "the", "data", "scale", "in", "SAR", "targets", ",", "denoted", "as", "AlexNetConv", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["For", "that", "we", "will", "use", "the", "duality", "of", "the", "IB", "curve", "(", "Lemma", "10", "of", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["To", "serve", "as", "a", "reference", ",", "the", "corresponding", "clinical", "LR", "and", "HR", "images", "are", "displayed", "together", "with", "the", "upsampled", "images", "that", "are", "anonymised", "for", "a", "fair", "comparison", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["We", "use", "GP", "to", "represent", "the", "belief", "over", "time", "(", ",", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": [",", "MINT", "-", "FEC", "presented", "a", "slightly", "better", "video", "quality", "until", "1200", "m", ",", "which", "was", "between", "0.59", "and", "2.01", ",", "and", "between", "0.69", "and", "1.63", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["For", "MD", "video", "coding", ",", "motion", "information", "from", "temporal", "domain", "is", "often", "estimated", "in", "the", "encoder", "as", "a", "redundancy", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["Equation", "represents", "the", "total", "computational", "complexity", "of", "the", "encoding", "per", "element", ",", "where", "represents", "the", "rows", "and", "represents", "the", "columns", "of", "the", "GM", "matrix", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "generator matrix"}, {"tokens": ["The", "recent", "development", "in", "RT", "allows", "more", "distributions", "to", "be", "used", "in", "VAEs", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reparameterization trick"}, {"tokens": ["We", "experiment", "on", "four", "open", "-", "domain", "QA", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["Scheduling", "in", "the", "DownlinkCompared", "to", "the", "uplink", ",", "the", "AP", "plays", "a", "more", "direct", "role", "in", "the", "downlink", "scheduling", ",", "which", "can", "be", "classified", "into", "the", "packet", "based", "scheduling", "and", "the", "STA", "based", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": [":", "RB", ":"], "acronym_pos": [0, 1, 0], "long_form": "reduced basis"}, {"tokens": ["As", "the", "results", "show", ",", "using", "SEM", "images", ",", "fine", "tuned", "networks", "and", "augmented", "data", ",", "the", "best", "performance", "can", "be", "achieved", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Therefore", ",", "it", "is", "urgent", "to", "diagnose", "this", "dangerous", "diseases", "accurately", "in", "the", "critical", "early", "phase", "of", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "acute pancreatitis"}, {"tokens": ["As", "soon", "as", "the", "AP", "receives", "all", "successful", "CTSs", ",", "it", "precodes", "the", "outgoing", "frames", "based", "on", "the", "feedback", "CSI", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Compared", "with", "the", "methods", "of", "MP", "or", "SP", ",", "the", "major", "challenge", "in", "the", "periodic", "decomposition", "is", "how", "to", "select", "the", "dominant", "periodic", "component", "in", "each", "iteration", ",", "due", "to", "the", "definition", "of", "the", "dominant", "periodic", "component", "in", "a", "signal", "is", "not", "clear", "yet", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subspace pursuit"}, {"tokens": ["Our", "simulation", "of", "eq", ":", "PVI", "confirms", "that", "once", "the", "constraint", "is", "active", "and", "the", "set", "is", "growing", ",", "the", "growth", "ceases", "to", "be", "exponential", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parabolic variational inequality"}, {"tokens": ["SSR", "is", "NP", "-", "complete", "by", "easy", "reduction", "from", "Subset", "Sum", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "natural problem"}, {"tokens": ["For", "networks", "that", "are", "core", "connected", ",", "the", "CC", "strength", "of", "a", "network", "can", "be", "computed", "as", "the", "number", "of", "paths", "that", "pass", "through", "the", "core", "to", "the", "total", "number", "of", "paths", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "core connected"}, {"tokens": ["Condition", "(", "b", ")", "states", "that", "the", "sum", "of", "average", "service", "rate", "for", "the", "packets", "in", "the", "own", "queue", "of", "each", "MS", "to", "the", "BS", "and", "to", "every", "other", "MS", "is", "greater", "than", "the", "average", "exogenous", "arrival", "rate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "this", "experiment", ",", "we", "evaluate", "the", "performance", "of", "HybridAlpha", "with", "respect", "to", "multiple", "techniques", "to", "perform", "FL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "federated learning"}, {"tokens": ["app1", "Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs", "where", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["MSE", "for", "DAC", "is", "generally", "lower", "than", "MSE", "for", "PDP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "partial dependence plots"}, {"tokens": ["The", "main", "differences", "between", "the", "Reuters", "corpus", "and", "the", "LSC", "is", "genre", "of", "texts", ":", "Reuters", "corpus", "contains", "texts", "of", "news", "while", "LSC", "contains", "abstracts", "of", "scientific", "publications", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["This", "step", "invokes", "the", "BBHT", "-", "QSA", "once", ";", "however", ",", "since", "the", "quantum", "circuits", "of", "the", "original", "NDQIO", "algorithm", "are", "utilized", ",", "each", "activation", "of", "the", "quantum", "oracle", ",", "namely", "the", "operator", "in", ",", "compares", "each", "of", "the", "generated", "routes", "to", "all", "the", "routes", "comprising", "the", "OPF", "identified", "so", "far", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "optimal pareto front"}, {"tokens": ["System", "ModelConsider", "a", "network", "with", "a", "BS", "and", "two", "groups", "of", "randomly", "deployed", "users", ":", "near", "and", "far", "users", "as", "shown", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Suppose", "is", "the", "welfare", "-", "minimizing", "SSS", "inducing", "the", "partitions", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "stochastically stable states"}, {"tokens": ["Quantum", "tunneling", "used", "in", "QA", "modifies", "some", "of", "jointtrajectory", "with", "other", "valid", "alternatives", "of", "configurations", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "quantum annealing"}, {"tokens": ["The", "list", "of", "DI", "scores", "is", "then", "sorted", "to", "find", "the", "maximum", "value", "amongst", "all", "news", "articles", "in", "the", "person", "'s", "document", "list", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "document index"}, {"tokens": ["The", "Discrete", "Base", "Problem", "(", "DBP", ")", "and", "Approximate", "Factorization", "Problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "discrete base problem"}, {"tokens": ["From", "the", "perspective", "of", "this", "work", ",", "pure", "MF", "model", "for", "CF", "tasks", "is", "important", "because", "it", "offers", "the", "most", "distilled", ",", "simplest", "setting", "for", "which", "we", "can", "investigate", "the", "effects", "of", "mixed", "dimension", "embeddings", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "main", "contributions", "of", "this", "article", "are", ":", "We", "introduce", "a", "general", "family", "of", "Lagrangians", "(", "the", "convex", "IB", "Lagrangians", ")", "which", "are", "able", "to", "explore", "the", "IB", "curve", "in", "any", "scenario", "for", "which", "the", "squared", "IB", "Lagrangian", "is", "a", "particular", "case", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Some", "interesting", "theoretical", "questions", "on", "OT", "extension", "are", "addressed", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Following", "similar", "lines", "as", "in", "the", "derivation", "of", "eq", ":", "out", ":", "u1:def3", ",", "for", "can", "be", "written", "as-0.5emwhere", "is", "the", "pdf", "of", "the", "shortest", "distance", "from", "to", "the", "BS", "which", "is", "given", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Consequently", ",", "if", "it", "is", "possible", "to", "obtain", "a", "large", "-", "scale", "annotated", "SAR", "image", "dataset", ",", "the", "pre", "-", "trained", "model", "will", "be", "very", "useful", "for", "SAR", "target", "recognition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["The", "figure", "also", "highlights", "that", "although", "the", "charging", "rate", "from", "the", "wall", "charger", "is", "almost", "constant", "during", "the", "CC", "phase", "irrespective", "of", "the", "battery", "capacity", ",", "the", "C", "-", "rates", "of", "the", "older", "batteries", "are", "higher", "than", "the", "new", "batteries", "as", "derived", "earlier", "through", "measurements", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["In", "this", "work", ",", "we", "propose", "a", "model", "which", "alleviates", "the", "need", "for", "such", "disambiguators", "by", "jointly", "learning", "NER", "and", "MD", "taggers", "in", "languages", "for", "which", "one", "can", "provide", "a", "list", "of", "candidate", "morphological", "analyses", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "morphological disambiguation"}, {"tokens": ["[", "]", "[", "]", "Learning", "curves", "comparing", "MVE", "with", "learned", "dynamics", "(", "purple", ")", ",", "MVE", "without", "the", "TD-", "trick", "(", "orange", ")", ",", "IB", "(", "blue", ")", ",", "and", "DDPG", "(", "black", ")", "on", "(", "a", ")", "cheetah", ",", "(", "b", ")", "swimmer", ",", "and", "(", "b", ")", "walker", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "imaginary batches"}, {"tokens": ["illustrated", "that", "the", "DC", "-", "SBM", "managed", "to", "discover", "the", "known", "factions", "in", "a", "karate", "club", "network", ",", "while", "the", "original", "counterpart", "failed", "to", "do", "so", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Plain", "bars", "show", "results", "for", "the", "CNS", "dataset", ",", "dashed", "bars", "for", "the", "MDC", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["The", "DBN", "representation", "of", "the", "multivariate", "HMM", "used", "in", "the", "presented", "method", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic bayesian network"}, {"tokens": ["Synthesis", "results", "are", "present", "in", "Figure", ",", "alongside", "the", "BS", "matching", "heuristic", "and", "synthesis", "with", "a", "random", "convolutional", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bidirectional similarity"}, {"tokens": ["lemmaproofIn", "order", "to", "construct", "the", "claimed", "MD", "strategy", ",", "we", "define", "a", "sequence", "of", "modified", "games", "in", "which", "the", "strategyof", "player", "is", "already", "fixed", "on", "a", "finite", "subset", "of", "the", "state", "space", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["Design", "and", "hardware", "complexity", "can", "be", "reduced", "by", "using", "NPR", "instead", "of", "PR", "FB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "near perfect reconstruction"}, {"tokens": ["Whereas", ",", ",", ",", "and", "are", "the", "average", "power", "of", "BS", "to", ",", "BS", "to", ",", "and", "to", "relay", "link", "respectively", ",", "where", "[", "25]."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "explore", "applying", "a", "GP", "model", "and", "variograms", "for", "image", "registration", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["4.35", "V.", "The", "corresponding", "charging", "rates", "are", "0.143", ",", "0.45", ",", "and", "0.77", "C", "respectively", "at", "the", "end", "of", "the", "CC", "phases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "charging current"}, {"tokens": ["If", "a", "GPS", "method", "is", "formulated", "as", "described", "in", "Section", ",", ",", "the", "columns", "of", "the", "generating", "matrices", "are", "bounded", "by", "norm", "and", "Hyp", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["Similar", "TS", "and", "PS", "methods", "could", "then", "be", "applied", "to", "separate", "the", "DC", "current", "to", "perform", "EH", "and", "ID", ",", "respectively", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["u", "clicks", "on", "the", "ad", "at", "position", "iConsidering", "that", "in", "GSP", ",", "both", "the", "ranking", "and", "pricing", "rules", "are", "determined", "once", "the", "quality", "score", "is", "given", ",", "we", "will", "also", "refer", "to", "as", "the", "auction", "mechanism", "if", "there", "is", "no", "confusion", "in", "the", "context", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized second price"}, {"tokens": ["When", "increases", "to", "5", "or", "10", ",", "SSL+MultiTask", "outperforms", "U", "-", "net", "-", "scratch", "at", "details", ",", "for", "example", ",", "without", "RV", "under", "-", "segmentation", "errors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["Improving", "Gaussian", "Process", "State", "Space", "ModelGaussian", "Process", "State", "Space", "Models", "(", "GP", "-", "SSM", ")", "are", "a", "popular", "class", "of", "stochastic", "SSMs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["GA", "-", "SCP", "solves", "the", "SCP", "central", "plant", "problem", "given", "in", "(", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["ROC", "curve", "plots", "TPR", "against", "FPR", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["We", "use", "the", "SCA", "scheme", "proposed", "in", "to", "approximate", "Problem", "(", ")", "into", "a", "standard", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "geometric programming"}, {"tokens": ["We", "train", "an", "adversarial", "landmark", "localization", "network", "on", "the", "generated", "LR", "images", "and", "hence", ",", "switching", "the", "roles", "of", "generated", "and", "real", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["The", "path", "loss", "of", "the", "sensor", "-", "BS", "channel", "can", "be", "approximated", "as", "free", "-", "space", "path", "loss", "and", "is", "given", "by", ",", "where", "indicates", "the", "path", "loss", "component", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["MethodsDataMR", "imaging", "acquisition", "MR", "image", "acquisition", "was", "performed", "at", "two", "different", "sites", "both", "with", "identical", "3", "T", "Siemens", "MAGNETOM", "Prisma", "MR", "scanners", "(", "Siemens", "Healthcare", ",", "Erlangen", ",", "Germany", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["This", "approach", "enables", "us", "to", "study", "the", "impact", "of", "each", "stage", "of", "the", "ISP", "on", "prediction", "accuracy", "on", "a", "large", "dataset", "(", "like", "ImageNet", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["However", ",", "in", "practice", ",", "considering", "diverse", "individual", "needs", "and", "the", "noise", "of", "real", "-", "world", "environments", ",", "and", "the", "scale", "of", "need", "in", "ASD", ",", "non", "-", "autonomous", "personalization", "of", "SAR", "is", "infeasible", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "performance", "achieved", "by", "our", "proposed", "method", "in", "the", "SC", "-", "task", "is", "comparable", "with", "the", "accuracy", "acquired", "by", "state", "-", "of", "-", "the", "-", "art", "methods", "on", "the", "SC", "subset", "of", "the", "Physionet", "Sleep", "-", "EDF", "database", ",", "surpassing", "most", "except", "for", "in", "patient", "independent", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subset compared"}, {"tokens": ["According", "to", "the", "main", "idea", ",", "the", "allocation", "of", "the", "fraction", "results", "by", "setting", "thetotal", "transmit", "power", "of", "the", "private", "messages", "of", "RS", ",", "in", "order", "to", "achieve", "approximately", "the", "same", "sum", "rate", "as", "the", "conventional", "multi", "-", "user", "BC", "with", "full", "power", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["t]ABEP", ",", ",", "of", "square", "-QAM", "versus", "the", "number", "of", "relay", "nodes", ",", ",", "for", "average", "transmit", "SNR", "dB", "and", "dB", "over", "IID", "Nakagami-", "fading", "channels", "with", "different", "values", "of", ":", "(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["The", "History", "of", "Mobile", "Augmented", "Reality", "Developments", "in", "Mobile", "AR", "over", "the", "last", "almost", "50", "years", "Graz", "Technical", "Report", ",", "Mobile", "Augmented", "Reality", ",", "History", "["], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["GS", "function", "scores", "an", "appearance", "of", "a", "word", "as", "the", "sum", "of", "the", "scores", "of", "all", "its", "following", "appearances", "as", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric sequence"}, {"tokens": ["Extending", "OT", "divergence", "to", "image", "classification", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["Since", "the", "LS", "estimator", "requires", "no", "prior", "knowledge", "of", "channel", "statistics", ",", "it", "is", "easy", "to", "implement", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["tab", ":", "table1", "shows", "the", "23", "occupational", "classes", "that", "satisfy", "these", "DSA", "threshold", "requirements", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["The", "fraction", "of", "variance", "explained", "by", "each", "principal", "component", "for", "the", "CNS", "and", "MDC", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["Using", "a", "combination", "of", "a", "mean", "-", "field", "variational", "approximation", "together", "with", "sparse", "GP", "approximations", "we", "obtain", "explicit", "analytical", "variational", "updates", "leading", "to", "fast", "inference", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "propose", "to", "divide", "the", "original", "max", "-", "min", "problem", "into", "two", "sub", "-", "problems", "which", "can", "be", "iteratively", "solved", "by", "exploiting", "generalized", "eigenvalue", "problem", "and", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "geometric programming"}, {"tokens": ["A", "PyTorch", "implementation", "of", "ARD", "can", "be", "found", "at", ":", "https://github.com/goldblum/AdversariallyRobustDistillationAcknowledgmentsThis", "research", "was", "generously", "supported", "by", "DARPA", ",", "including", "the", "GARD", "program", ",", "QED", "for", "RML", ",", "and", "the", "Young", "Faculty", "Award", "program", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["The", "cardiac", "MR", "dataset", ",", "described", "in", "Sec", ".", ","], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["Average", "radii", "of", "gyration", "in", "HMC", "simulations", "of", "villin", "with", "different", "time", "steps", ",", "lengths", "of", "trajectories", "and", "integrating", "schemes", "(", "left", ")", "and", "in", "MD", "simulations", "of", "villin", "using", "various", "step", "sizes", "and", "integrators", "(", "right", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["The", "temporal", "information", "(", "TI", ")", "here", "is", "defined", "as", "the", "average", "absolute", "frame", "difference", "between", "luma", "pixels", "in", "the", "current", "frame", "and", "its", "neighbouring", "ones", "(", "one", "frame", "before", "and", "another", "after", "if", "available", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal information"}, {"tokens": ["Results", "for", "the", "power", "IB", "Lagrangian", "in", "the", "MNIST", "dataset", "with", ",", "from", "top", "to", "bottom", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["After", "the", "transformation", ",", "we", "used", "top", "5", "tree", "based", "(", "single", "label", ")", "classifiers", "for", "the", "predictions", "of", "multilabel", "methods", "(", "CC", ",", "LC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "classifier chain"}, {"tokens": ["When", ",", "the", "MSE", "of", "the", "LMMSE", "estimator", "with", "inaccurate", "channel", "statistics", "is", "significantly", "larger", "than", "those", "of", "the", "LS", "and", "LMMSE", "estimators", "with", "accurate", "channel", "statistics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["Interestingly", "the", "CM", "of", "the", "RF", "model", "is", "essentially", "the", "same", "as", "that", "of", "the", "ANN", "model", ",", "with", "two", "additional", "cases", "correctly", "predicted", "relative", "to", "the", "RF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["System", "ModelA", "two", "-", "phase", "CNOMA", "-", "SWIPT", "-", "PS", "network", "with", "a", "BS", "which", "is", "considered", "as", "a", "source", "and", "two", "users", "(", "a", "CCU", "and", "a", "CEU", ")", "is", "considered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["YAv", "xsafniia-", ",", ")", ";", "Kashani", "ciltuk", "'", "unhulled", "rice", "'", "NP", "saltok", ";", "Kashani", "cepun", "'", "herdsman", "'", ",", "Kurdish", "cuwan", "(", "copan", "'", "butcher", "'", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["The", "reason", "why", "both", "WHCA", "*", "and", "FAR", "are", "slower", "despite", "the", "agents", "traveling", "smaller", "distances", "than", "BMAA", "*", "is", "that", "many", "of", "the", "agents", "end", "up", "waiting", "for", "other", "agents", "due", "to", "their", "use", "of", "reservation", "tables", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "flow annotation replanning"}, {"tokens": ["This", "motivates", "us", "to", "develop", "some", "mechanism", "to", "focus", "AN", "'s", "attention", "back", "on", "the", "right", "regions", "of", "the", "target", "characters", "in", "the", "input", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["Confusion", "matrix", "of", "DDE", "-", "MGM", "on", "the", "MSR", "Action3D", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["At", "the", "same", "time", ",", "in", "the", "FEC", "-", "based", "schemes", ",", "such", "as", "Video", "-", "aware", "FEC", ",", "uavFEC", ",", "CLM", "-", "UEP", "and", ",", "MINT", "-", "FEC", ",", "the", "video", "quality", "was", "good", "for", "a", "long", "distance", ",", "until", "1200", "m", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["MGF_end_Def_Rep", ",", "the", "MGF", "of", "of", "pure", "RS", "can", "be", "obtained", "as", "the", "following", "product", ":", "where", "is", "given", "by", "Eq", ":", "MGF_gbest", "for", "INID", "Nakagami-", "with", "integer", "'s", "and", "distinct", "'s", ",", "whereas", "by", "Eq", ":", "MGF_gbest_EqualC", "for", "IID", "Nakagami-", "with", "integer", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Similar", "claims", "of", "better", "performance", "over", "SBM", "were", "made", "by", "in", "their", "dynamic", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["It", "was", "demonstrated", "that", "the", "firing", "of", "MTL", "cells", "was", "sparse", "because", "most", "of", "them", "did", "not", "respond", "to", "the", "great", "majority", "of", "images", "used", "in", "the", "experiment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "medial temporal lobe"}, {"tokens": ["We", "evaluated", "the", "method", "and", "shown", "it", "can", "detect", "community", "structure", "where", "the", "SBM", "can", "not", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Context", "QA", ":"], "acronym_pos": [0, 1, 0], "long_form": "question answering"}, {"tokens": ["Severe", "Sepsis", ",", "SK", "="], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "septic shock"}, {"tokens": ["The", "SBM", ",", "when", "told", "to", "find", "two", "clusters", ",", "divides", "the", "nodes", "according", "to", "degree", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Reference", "ArchitecturesIn", "this", "study", ",", "we", "refer", "to", "the", "link", "between", "the", "CC", "and", "the", "EC", "as", "the", "x", "-", "haul", "link", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Then", "in", "Section", ",", "we", "review", "several", "optimization", "problems", "that", "are", "related", "to", "the", "manifold", "learning", "task", "and", "we", "present", "the", "GPS", "framework", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "general pattern search"}, {"tokens": ["Thus", ",", "a", "new", "trial", "point", "of", "GPS", "algorithm", "towards", "this", "step", "would", "be", "where", "we", "evaluate", "the", "value", "of", "the", "function", "to", "minimize", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["Then", "based", "on", "real", "-", "world", "dataset", ",", "we", "show", "that", "HSMC", "can", "better", "learn", "GP", "-", "SSM", "when", "emission", "function", "is", "nonlinear", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "this", "section", "we", "will", "make", "a", "link", "between", "sentence", "composition", "functions", "and", "SRL", "scoring", "functions", ",", "and", "propose", "new", "scoring", "functions", "drawing", "inspiration", "from", "SRL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "statistical relational learning"}, {"tokens": ["Experiments", "on", "Standard", "BenchmarksWe", "provide", "empirical", "evidence", "on", "the", "benefits", "of", "using", "on", "two", "commonly", "used", "benchmarks", "for", "AS2", ":", "WikiQA", "and", "TREC", "-", "QA", ",", "which", "enable", "a", "direct", "comparison", "with", "previous", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["TP", "and", "TN", "are", "the", "examples", "where", "the", "rupture", "propagates", "or", "arrests", ",", "respectively", ",", "and", "the", "models", "predict", "them", "correctly", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["Comparison", "of", "Ideal", "Throughput", "with", "Actual", "System", "Throughput", "for", "RA", ",", "P2P", ",", "and", "PS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["Since", "differs", "only", "slightly", "in", "the", "amplitude", "from", "the", "general", "pattern", ",", "these", "dictionaries", "seem", "insufficient", "to", "capture", "this", "fine", "dissimilarity", ":", "while", "Self", "and", "DI", "dictionaries", "simply", "do", "not", "contain", "enough", "elements", ",", "UI", "dictionary", "is", "to", "simple", "to", "capture", "this", "difference", "(", "it", "shares", "this", "feature", "with", "DI", "dictionary", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "dyadic indicator"}, {"tokens": ["Further", "CommentSL", ",", "SP", ",", "LT", ",", "PT", ",", "and", "LTT", "classes", "form", "infinite", "hierarchies", "of", "language", "classes", "based", "on", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "locally threshold testable"}, {"tokens": ["Since", "OLS", "produces", "lower", "signal", "reconstruction", "error", "than", "OMP", "under", "similar", "conditions", ",", "we", "hypothesize", "that", "more", "accurate", "signal", "estimation", "will", "further", "improve", "the", "classification", "performance", "of", "classifiers", "that", "exploiting", "the", "sparsity", "of", "data", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["As", "a", "pillar", "to", "that", ",", "the", "core", "component", "of", "AR", "i.e.", "Feature", "Extraction", "is", "going", "to", "be", "technologically", "challenging", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["The", "parameters", "and", "jointly", "adjust", "for", "the", "SINR", "implementation", "efficiency", "of", "LTE", "MCSs", "and", "receiver", "algorithms", "(", "e.g.", ",", "linear", ",", "non", "-", "linear", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["lossVideoRules", "algorithmMINT", "-", "FEC", "utilises", "the", "same", "core", "structure", "of", "uavFEC", ",", "so", "once", "all", "the", "fuzzy", "rules", "and", "sets", "are", "defined", ",", "they", "are", "employed", "in", "real", "-", "time", "in", "the", "fuzzy", "logic", "controller", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "IB", "in", "supervised", "learningIn", "this", "section", ",", "we", "will", "first", "give", "an", "overview", "of", "supervised", "learning", "in", "order", "to", "later", "motivate", "the", "usage", "of", "the", "information", "bottleneck", "in", "this", "setting", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["To", "further", "improve", "the", "performance", "of", "MD", "vector", "quantization", "at", "the", "cost", "of", "a", "slight", "complexity", "increase", ",", "the", "fine", "lattice", "codebook", "is", "replaced", "by", "a", "non", "-", "lattice", "codebook", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["First", "we", "review", "the", "results", "for", "the", "DC", "-", "OPF", "formulation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Define", "for", "each", "as", "the", "set", "of", "nodes", "that", "play", "in", "the", "SSS", "in", "and", "play", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "stochastically stable states"}, {"tokens": ["Before", "looking", "at", "SBMs", "with", "topic", "modelling", "for", "graph", "and", "textual", "data", ",", "it", "is", "useful", "to", "look", "at", "a", "recently", "proposed", "SBM", "for", "textual", "data", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["In", "addition", ",", "there", "does", "not", "exist", "the", "dependence", "between", "TI", "'s", "active", "durations", "and", "inter", "-", "event", "durations", "as", "shown", "in", "Figure", "S3", ",", "which", "are", "uncorrelated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["Randomized", "Voting", "-", "Finally", ",", "this", "stage", "utilizes", "a", "moderate", "version", "of", "RV", "in", "order", "to", "label", "features", "that", "had", "not", "yet", "been", "joined", "to", "atoms", "marked", "in", "black", "in", "Figure", "(", "a)-(e", ")", ",", "and", "were", "not", "segmented", "to", "any", "independent", "moving", "object", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random voting"}, {"tokens": ["Interestingly", ",", "increasing", "the", "number", "of", "users", ",", "the", "efficiency", "of", "RS", "worsens", "and", "its", "implementation", "becomes", "less", "favorable", "under", "these", "conditions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["It", "is", "shown", "that", "RS", "is", "robust", "in", "both", "multipair", "HD", "and", "FD", "settings", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["ConclusionsIn", "this", "paper", ",", "we", "studied", "a", "secure", "vehicle", "communication", "system", "URLLC", "requirement", "under", "short", "packet", "transmission", ",", "where", "the", "AP", "transmits", "safety", "-", "critical", "messages", "to", "the", "vehicles", "and", "there", "exists", "an", "eavesdropper", "that", "attempts", "to", "eavesdrop", "this", "critical", "message", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["As", "in", "the", "case", "of", "articlebased", "recommendations", ",", "we", "factorize", "the", "matrix", "with", "alternating", "least", "squares", ",", "but", "for", "this", "problem", "we", "modeled", "the", "CF", "ratings", "(", "relevance", "of", "a", "section", ")", "as", "implicit", "feedback", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "SSIM", "average", "of", "the", "non", "-", "adaptive", "Video", "-", "aware", "FEC", "and", "ViewFEC", "mechanism", "was", "0.88", ",", "and", "the", "VQM", "values", "were", "1.81", "and", "1.77", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "each", "row", ",", "from", "left", "to", "right", "it", "is", "shown", "(", "i", ")", "the", "information", "plane", ",", "where", "the", "region", "of", "possible", "solutions", "of", "the", "IB", "problem", "is", "shadowed", "in", "light", "orange", "and", "the", "information", "-", "theoretic", "limits", "are", "the", "dashed", "orange", "line", ";", "(", "ii", ")", "as", "a", "function", "of", ";", "and", "(", "iii", ")", "the", "compression", "as", "a", "function", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["the", "feature", "maps", "of", "HOF", ",", "MHOF", "and", "HMOFAnomaly", "ClassifierThe", "GMM", "is", "a", "weighed", "sum", "of", "multivariate", "Gaussian", "probability", "densities", "given", "by", ":", "where", "is", "the", "parameter", "of", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["From", "areaunder", "the", "ROC", "curve", "to", "reclassification", "and", "beyond", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["In", "Algorithm", "1", ",", "the", "iterative", "method", "involvesa", "number", "of", "global", "iterations", "(", "i.e.", ",", "the", "value", "of", "in", "Algorithm", "1", ")", "to", "achieve", "a", "global", "accuracy", "for", "the", "global", "FL", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["FIM", "is", "always", "faster", "as", "it", "only", "needs", "one", "iteration", "trough", "the", "narrow", "band", ",", "while", "GMM", "always", "performs", "two", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["We", "finally", "show", "results", "on", "BraTS", "2017", "Training", "and", "Validation", "sets", ",", "showing", "that", "while", "the", "results", "obtained", "for", "the", "WT", "segmentation", "are", "competitive", "with", "other", "participants", "'", "algorithms", ",", "we", "are", "not", "able", "to", "properly", "capture", "the", "less", "common", "regions", "(", "TC", "or", "ET", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "whole tumor"}, {"tokens": ["It", "is", "worth", "noting", "that", "ECS", "-", "DBN", "outperforms", "on", "52", "out", "of", "58", "benchmark", "datasets", "in", "terms", "of", "G", "-", "mean", "as", "shown", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "a", "VSM", ",", "every", "document", "is", "represented", "by", "a", "vector", "whose", "size", "is", "the", "vocabulary", "size", "of", "the", "corpus", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vector space model"}, {"tokens": ["The", "first", "is", "without", "FEC", ",", "serving", "as", "a", "baseline", "to", "compare", "with", "the", "others", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "balancing", "between", "these", "techniques", "is", "controlled", "by", "the", "parameters", "of", "loudness", "and", "pulse", "emission", "rate", "[", "87].", "Yang", "[", "86", "]", "showed", "that", "the", "BA", "is", "able", "to", "outperform", "PSO", "and", "GA", "in", "terms", "of", "enhanced", "local", "optima", "avoidance", "and", "convergence", "speed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Once", "set", "up", ",", "it", "enables", "more", "efficient", "evaluations", "of", "the", "homogenized", "material", "response", "as", "compared", "to", "the", "Finite", "Element", "Method", "(", "FEM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "finite element method"}, {"tokens": ["During", "testing", ",", "the", "CTC", "acts", "as", "the", "classifier", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["Hence", ",", "the", "EQPO", "imposes", "a", "lower", "sequential", "complexity", "than", "the", "CDP", "method", ",", "as", "long", "as", "we", "have", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "classical dynamic programming"}, {"tokens": ["3tab", ":", "nodclstpfp", "tabularcccc", "Method", "&", "TP", "Set", "&", "FP", "Set", "&", "Doctors"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["For", "instance", ",", "in", ",", "the", "authors", "studied", "the", "achievable", "EH", "TS", "throughput", "using", "AF", "relay", "without", "optimizing", "the", "total", "EH", "output", "for", "TWR", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["We", "call", "the", "convex", "IB", "Lagrangian", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["In", "this", "paper", ",", "we", "collect", "the", "Wi", "-", "Fi", "AP", "energy", "values", "during", "LTE", "-", "U", "OFF", "duration", "and", "use", "the", "data", "to", "train", "different", "ML", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["RecoBundles", "oversegmented", "the", "CST", "to", "neighbouring", "gyri", "and", "selected", "many", "streamlines", "ending", "prematurely", "instead", "of", "reaching", "the", "correct", "start", "and", "end", "regions", "of", "the", "tract", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "corticospinal tract"}, {"tokens": ["To", "evaluate", "our", "results", "quantitatively", ",", "we", "computed", "both", "the", "Inception", "Score", "(", "IS", ",", "larger", "is", "better", ")", ",", "which", "tries", "to", "evaluate", "how", "recognizable", "and", "diverse", "objects", "within", "images", "are", ",", "as", "well", "as", "the", "Frechet", "Inception", "Distance", "(", "FID", ",", "smaller", "is", "better", ")", ",", "which", "compares", "the", "statistics", "of", "generated", "images", "with", "real", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["Zeng", "and", "Sun", ",", "proposed", "an", "improved", "PSO", "algorithm", "for", "solving", "the", "CHP", "-", "DED", "problems", "with", "various", "systems", "constraints", "of", "power", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["FCC", "estimate", "from", "Charging", "SOC", "C", "-", "RateNow", "from", "the", "C", "-", "rate", "curves", "presented", "earlier", "we", "need", "to", "select", "a", "rate", "within", "the", "CC", "phase", "SOC", "boundary", ",", "which", "would", "reflect", "the", "of", "the", "battery", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "constant current"}, {"tokens": ["Next", ",", "OLS", "calculates", "the", "residual", "norms", "of", "and", "obtained", "by", "projecting", "onto", "-plane", "and", "-plane", "respectively", ",", "and", "selects", ",", "since", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["Aiming", "for", "a", "specific", "compression", "levelLet", "denote", "the", "domain", "of", "Lagrange", "multipliers", "for", "which", "we", "can", "find", "solutions", "in", "the", "IB", "curve", "with", "the", "convex", "IB", "Lagrangian", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Their", "current", "locations", "are", "known", "through", "the", "LS", "API", ",", "within", "the", "MEC", "platform", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "location service"}, {"tokens": ["(", "c", ")", "Success", "plots", "obtained", "by", "the", "proposed", "MSC", "-", "trackers", "(", "MSC", "-", "CCO", "and", "MSC", "-", "DCF", ")", "and", "the", "top", "-", "performing", "deep", "feature", "-", "based", "CF", "trackers", "on", "(", "a", ")", "OTB-50", ",", "(", "b", ")", "OTB-2013", "and", "(", "c", ")", "OTB-2015", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correlation filter"}, {"tokens": ["*", "uaciah-", "MP", "wes", "'", "more", "'", "NP", "bes", "'", "more", "'", ";", "cf", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Our", "model", "extends", "PNN", "with", "the", "ability", "to", "use", "helpful", "modules", "selectively", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "progressive neural networks"}, {"tokens": ["In", "Exact", "-", "MBR", "codes", ",", "the", "presents", "the", "Exact", "-", "MBR", "codes", "with", "no", "arithmetic", "operations", "in", "node", "regeneration", "process", ",", "and", "the", "presents", "the", "constructions", "for", "all", "feasible", "Exact", "-", "MBR", "codes", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["em", "determinado", "curso", "atrav\u00e9s", "de", "algoritmos", "de", "MD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "massa de dados"}, {"tokens": ["The", "search", "variables", "of", "GA", "-", "SCP", "are", "the", "coefficients", "of", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["The", "layer", "-", "wise", "gradient", "ratios", "between", "FA", "and", "BP", "for", "a", "naive", "initialization", "(", "a", ")", "and", "using", "a", "variance", "-", "preserving", "initialization", "such", "as", "the", "one", "devised", "by", "(", "b", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["Indeed", ",", "because", "of", "these", "resource", "constraints", ",", "it", "is", "necessary", "to", "optimize", "the", "energy", "efficiency", "for", "FL", "implementation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["As", "stated", "before", ",", "we", "have", "been", "using", "Max", "Min", "scaling", "on", "the", "NP", "features", ",", "however", "vo_2015", "did", "not", "mention", "scaling", "in", "their", "paper", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural pooling"}, {"tokens": ["LI", ":", "liver", ",", "ST", ":", "stomach", ",", "DU", ":", "duodenum", ",", "LK", ":", "left", "kidney", ",", "and", "RK", ":", "right", "kidney", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "right kidney"}, {"tokens": ["This", "probability", "mass", "function", "is", "essentially", "identical", "to", "the", "SBM", "except", "that", "we", "have", "setthe", "density", "to", "zero", "where", "the", "constraint", "on", "is", "not", "satisfied", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Note", "the", "IB", "Lagrangian", "optimization", "yields", "a", "representation", "with", "a", "given", "performance", "(", ")", "for", "a", "given", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Flow", "of", "online", "modeling", "and", "classification", "based", "on", "DDE", "-", "MGM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "markov geographic model"}, {"tokens": ["AS", "reduces", "the", "hardware", "complexity", "of", "PS", "as", "it", "does", "not", "need", "a", "power", "splitter", "for", "each", "antenna", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["LTE", "DC", "and", "LWA", "Architectures", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["It", "is", "also", "true", "that", "LTT", "LTT", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 1, 0], "long_form": "locally threshold testable"}, {"tokens": ["The", "performance", "comparison", "between", "AP", "and", "EAP", "is", "presented", "in", "Table", "for", "all", "four", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["From", "these", "results", "it", "appears", "that", "topFiberM", "outperforms", "other", "methods", "in", "DBP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "discrete base problem"}, {"tokens": ["We", "limit", "the", "vocabulary", "with", "the", "most", "common", "thousand", "words", "to", "avoid", "introducing", "topic", "or", "genre", "specific", "bias", "into", "AA", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "authorship attribution"}, {"tokens": ["We", "observe", "that", "the", "segmentation", "results", "produced", "by", "the", "images", "from", "our", "Recon", "-", "GLGAN", "model", "are", "similar", "to", "FS", "images", "in", "comparison", "with", "the", "ZF", "and", "GAN", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fully sampled"}, {"tokens": ["The", "goal", "of", "OPF", "is", "to", "dispatch", "generation", "in", "order", "to", "meet", "demand", "at", "minimal", "cost", ",", "while", "respecting", "reliability", "and", "security", "constraints", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["Efficient", "set", "operations", "are", "already", "supported", "in", "standard", "libraries", "(", "e.g.", ",", "in", "C++", "through", "the", "Standard", "Template", "Library", "or", "STL", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "standard template library"}, {"tokens": ["We", "provided", "the", "logic", "with", "a", "Boolean", "and", "a", "quantitative", "semantics", "in", "the", "style", "of", "STL", "Donze2010", ",", "and", "defined", "novel", "monitoring", "algorithms", "to", "evaluate", "such", "semantics", "on", "spatio", "-", "temporal", "trajectories", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "signal temporal logic"}, {"tokens": ["This", "provides", "three", "advantages", ":", "i", ")", "like", "GPR", ",", "NP", "provides", "the", "necessary", "estimates", "of", "predictive", "uncertainty", "at", "test", "time", ";", "ii", ")", "similar", "to", "MT", "-", "GPR", ",", "it", "provides", "the", "possibility", "of", "learning", "structured", "variation", ";", "and", "iii", ")", "unlike", "alternatives", ",", "it", "is", "computationally", "scalable", "without", "restrictive", "assumptions", "on", "the", "orthogonality", "of", "lower", "dimensional", "representations", "of", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process regression"}, {"tokens": ["For", "example", ",", "the", "least", "recently", "used", "solutions", "in", "cNrGA", "-", "LRU", "are", "found", "amongst", "the", "shallow", "solutions", "in", "the", "BSP", "tree", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["We", "considered", "a", "constraint", "binding", "if", "either", "it", "was", "violated", "or", "the", "absolute", "value", "of", "the", "difference", "between", "the", "two", "sides", "was", "less", "than", "a", "fixed", "threshold", "value", "set", "at", "Meta", "-", "optimizationDuring", "meta", "-", "optimization", ",", "the", "NN", "weights", "obtained", "from", "conventional", "optimization", "were", "further", "varied", "to", "optimize", "the", "meta", "-", "loss", "objective", ",", "defined", "as", "the", "total", "computational", "time", "to", "solve", "each", "OPF", "problem", "in", "the", "meta", "-", "training", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["The", "user", "location", "context", "is", "provided", "by", "the", "LS", "API", ",", "which", "is", "a", "service", "that", "supports", "the", "mobile", "device", "location", "retrieval", "mechanism", "and", "then", "passes", "the", "information", "to", "authorized", "applications", ",", "within", "the", "MEC", "platform", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "location service"}, {"tokens": ["We", "use", "Apache", "Lucene", "for", "VSM", "development", "and", "for", "textual", "similarity", "matching", "between", "the", "API", "classes", "and", "each", "of", "the", "queries", "from", "our", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vector space model"}, {"tokens": ["They", "can", "correspond", "to", ",", "for", "example", ",", "the", "Bernoulli", "and", "the", "Poisson", "SBM", ",", "for", "modelling", "the", "edge", "existence", "and", "edge", "weight", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["This", "in", "turn", "requires", "the", "grid", "operators", "to", "have", "the", "computational", "capacity", "of", "running", "consecutive", "instances", "of", "OPF", "problems", "with", "fast", "convergence", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["The", "Critical", "Difference", "(", "CD", ")", "for", "Nemenyi", "test", "depends", "upon", "the", "given", "confidence", "level", "(", "which", "is", "0.05", "in", "our", "case", ")", "for", "average", "ranks", "and", "number", "of", "test", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "critical difference"}, {"tokens": ["http://dx.doi.org/10.3233/IDA-2002-6504CrossRef]Bradley", ",", "A.P.The", "use", "of", "the", "area", "under", "the", "ROC", "curve", "in", "the", "evaluation", "of", "machinelearning", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Putting", "this", "value", "in", "the", "expression", "of", "the", "PDF", "of", "CD", ",", "we", "get", "the", "simplified", "expression", "as", ":", "[", "ht", "!", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "contact distance"}, {"tokens": ["Almost", "-", "sure", "reachability", "games", "and", "even", "almost", "-", "sure", "Buchi", "games", "are", "strongly", "MD", "-", "determined", "(", "Theorems", "thm", ":", "reachability", "and", "thm", ":", "Buchi", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["Our", "dual", "stream", "architecture", "along", "with", "blank", "space", "symbol", "alignment", "eliminates", "the", "need", "of", "complex", "character", "alignment", "methods", "such", "as", "CTC", "in", "recurrent", "based", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["table[t]tabularccccc3", "-", "52c", "&", "3cHuman", "Preference1csystem", "1", "&", "system", "2", "&", "1", "&", "2", "&", "neither", "BS", "&", "TS", "&", "43", "&", "16", "&", "29", "BS", "&", "reranking", "&", "18", "&", "30", "&", "15", "BS", "&", "predicted", "&", "38", "&", "29", "&", "19", "TS", "&", "reranking", "&", "18", "&", "38", "&", "16TS", "&", "predicted", "&", "18", "&", "27", "&", "34reranking", "&", "predicted", "&", "27", "&", "24", "&", "21tabularHuman", "preferences", "when", "given", "three", "continuations", "from", "each", "pair", "of", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature - based sampling"}, {"tokens": ["The", "small", "target", "search", "proved", "too", "difficult", "to", "complete", "in", "the", "SDD", "environment", "due", "to", "a", "\"", "too", "-", "restrictive", "\"", "time", "limit", "of", "two", "minutes", ",", "and", "too", "few", "participants", "were", "available", "to", "complete", "the", "multiple", "image", "inspection", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Experimentally", ",", "we", "observed", "when", "the", "growth", "of", "our", "function", "is", "small", "in", "the", "domain", "of", "interest", "the", "convex", "IB", "Lagrangian", "does", "not", "perform", "well", "(", "see", "first", "row", "of", "Figures", "and", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["There", "is", "an", "exact", "mapping", "between", "the", "values", "of", "BIC", "and", "the", "Bayes", "factor", "(", "BF", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "bayes factor"}, {"tokens": ["MVF", "predicted", "from", "sinc1-h", "-", "NSF", "is", "in", "general", "consistent", "with", "the", "spectrogram", ",", "i.e.", ",", "high", "MVF", "in", "voiced", "regions", "and", "low", "MVF", "in", "unvoiced", "regions", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["The", "proposed", "scheme", "of", "OAM", "with", "CNOMA", "-", "SWIPT", "-", "PS", "is", "mentioned", "as", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "in", "this", "paper", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "meta", "-", "loss", "is", "computed", "within", "the", "iterative", "feasibility", "test", ",", "where", "denotes", "the", "full", "set", "of", "constraints", "of", "the", "original", "OPF", "problem", ",", "is", "the", "actual", "set", "used", "in", "the", "reduced", "problem", "and", "is", "the", "set", "of", "violated", "constraints", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["(", "c", ")", ":", "Wikitude", "AR", "Browser", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "augmented reality"}, {"tokens": ["This", "addition", "LSC", ",", "eases", "the", "flow", "of", "information", "across", "groups", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long skip connections"}, {"tokens": ["These", "networks", "are", "trained", "on", "the", "FS", "images", "and", ",", "testing", "the", "network", "with", "ZF", "images", "will", "result", "in", "an", "unsatisfactory", "segmentation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fully sampled"}, {"tokens": ["PCM", "and", "VSM", "rebuild", "in", "ordered", "and", "greedy", "order", "in", "mirrored", "disks", "are", "compared", "inGreedy", "rebuild", "is", "intended", "to", "reduce", "rebuild", "time", "by", "out", "-", "of", "-", "order", "processing", "of", "track", "reads", ","], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vacationing server model"}, {"tokens": ["tableAverage", "inference", "time", "(", "Inf", "-", "T", ")", "of", "the", "SR", "models", "per", "input", "LR", "image", "(", "120x120x12", ")", "using", "a", "GPU", "(", "GTX-1080", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["We", "see", "that", "edema", "(", "ED", "-", "label", "2", ")", "is", "overrepresented", "in", "our", "segmentation", "in", "detriment", "of", "smaller", "classes", ":", "GD", "-", "enhancing", "tumor", "(", "ET", "-", "label", "4", ")", "and", "the", "necrotic", "and", "non", "-", "enhancing", "tumor", "(", "NCR", "/", "NET", "-", "label", "1", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["BA", "provides", "improvements", "to", "the", "HS", "framework", "by", "introducing", "robust", "quadratic", "error", "formulation", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "black and anandan"}, {"tokens": ["Secondly", ",", "the", "-values", "from", "the", "Holm", "post", "-", "hoc", "test", "suggest", "that", "ECS", "-", "DBN", "achieves", "a", "statistically", "significant", "improvement", "over", "other", "competing", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["*", "GH", "GH", "GI", "or", "G", "and", "H", "have", "a", "Hamiltonian", "cycle", "equation"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph isomorphism"}, {"tokens": ["Their", "work", "also", "showed", "that", "such", "DAS", "statements", "can", "very", "quickly", "be", "made", "commonplace", "by", "a", "change", "in", "journal", "policy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data availability statement"}, {"tokens": ["NP", "surun", "'", "buttocks'PIr"], "acronym_pos": [1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Recently", ",", "the", "authors", "of", "focused", "on", "the", "problem", "of", "stronger", "eavesdropping", "channel", "and", "maximized", "the", "secrecy", "rate", "ofthe", "legitimate", "user", "by", "jointly", "designing", "the", "AP", "'s", "transmit", "beamformer", "and", "the", "RIS", "phases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["As", "will", "be", "explained", "in", "more", "detail", "in", "sec", ":", "subreg", ",", "SL", "and", "SP", "languages", "are", "simple", "regular", "languages", "which", "only", "encode", "local", "and", "certain", "types", "of", "long", "-", "term", "dependencies", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["The", "second", "case", "is", "a", "non", "-", "adaptive", "video", "-", "aware", "FEC", "-", "based", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Apart", "from", "sampling", "principals", "and", "the", "size", "of", "corpus", ",", "one", "other", "difference", "of", "SciCorp", "from", "the", "LSC", "lies", "in", "the", "type", "of", "texts", ":", "full", "-", "text", "in", "SciCorp", "and", "abstracts", "of", "scientific", "papers", "in", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["At", "last", ",", "visual", "comparisons", "of", "different", "MDC", "methods", "are", "provided", "to", "observe", "the", "image", "quality", "because", "human", "eyes", "are", "the", "ultimate", "recipients", "of", "the", "compressed", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["Following", "this", ",", "the", "TTP", "calculates", "the", "value", "of", "variable", "using", ",", "concatenation", ",", "and", "ECC", "point", "addition", "operations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["Integrals", "over", "The", "sparse", "GP", "approximation", "and", "the", "posterior", "over", "in", "Eq", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Another", "major", "drawback", "of", "the", "structural", "TS", "approaches", "described", "so", "far", "is", "that", "they", "do", "not", "preserve", "the", "semantic", "links", "between", "the", "individual", "split", "components", ",", "resulting", "in", "a", "set", "of", "incoherent", "utterances", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["Thus", ",", "in", "this", "paper", "we", "employ", "a", "combination", "of", "ECC", "and", "blockchain", "for", "secure", "and", "anonymous", "energy", "trading", "in", "V2", "G", "setups", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["We", "assume", "that", "each", "GP", "in", "e.general_f", "is", "stationary", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["It", "is", "found", "that", "the", "number", "of", "nodes", "vaccinated", "is", "stabilised", "at", "about", "6000", "nodes", "in", "the", "DDT", "network", "and", "10000", "nodes", "in", "the", "GDT", "network", "regardless", "of", "in", "RV", "strategy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random vaccination"}, {"tokens": ["Prediction", "runtime", "comparison", "(", "in", "mins", ")", "between", "Global", "-", "INF", "and", "LR", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "logistic regression"}, {"tokens": ["is", "the", "SCP", "central", "plant", "with", "and", "as", "its", "maximum", "gap", "metric", "and", "generalized", "stability", "margin", ",", "respectively", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["Note", "that", ",", "interestingly", ",", "BPSO", "outperformed", "not", "only", "GA", "and", "ACO", "but", "all", "the", "compared", "PSO", "variants", ",", "i.e."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["FEC", "-", "based", "schemes", "have", "been", "successfully", "used", "in", "real", "-", "time", "systems", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Similarly", ",", "in", "the", "work", "in", ",", "RN", "and", "MB", "are", "added", "to", "the", "synthetic", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "motion blurring"}, {"tokens": ["It", "is", "noteworthy", "that", "the", "online", "time", "of", "the", "RB", "method", "is", "strongly", "dominated", "by", "the", "assembly", "of", "the", "Jacobian", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["QA", "systems", "can", "be", "broadly", "categorized", "into", "three", "categoriesbernardi10from", ":"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Related", "Work*[htbp", "]", "Structure", "of", "DADA", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "dual adversarial domain adaptation"}, {"tokens": ["[", "-", "]", "LE", "as", "a", "conventional", "pixel", "-", "based", "label", "equivalence", "solution", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "label equivalence"}, {"tokens": ["We", "use", "the", "following", "scheme", ":", "First", ",", "make", "a", "proposal", "such", "as", "those", "used", "in", "the", "collapsed", "SBM", "algorithmMcDaidSBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["These", "altered", "dynamics", "also", "affect", "GRF", "measurements", "in", "similar", "to", "those", "described", "above", "for", "the", "ankle", "joint", ",", "specifically", "observable", "during", "IC", "due", "to", "a", "possible", "flattened", "foot", "position", "and", "in", "TS", "caused", "by", "a", "reduced", "forward", "propulsion", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "terminal stance"}, {"tokens": ["Then", "we", "have", "the", "attention", "maps", ",", "which", "is", "an", "outcome", "of", "the", "concatenated", "maps", "multiplied", "by", "the", "MAD", "vector", ":", "gathery_j^(m", ")", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["The", "PS", "extends", "the", "single", "server", "to", "more", "than", "one", "to", "solve", "load", "balance", ",", "and", "to", "reduce", "communication", "bottlenecks", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["In", ",", "adaptive", "temporal", "-", "spatial", "error", "concealment", "is", "applied", "for", "MD", "video", "coding", ",", "in", "which", "multiple", "descriptions", "are", "obtained", "by", "spatial", "subsampling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["[", "]", "Tabu", "Search", "algorithm", "parameters", "Gain", "Ratio", "and", "Pearson", "Correlation", "based", "methods", "calculate", "the", "importance", "of", "each", "feature", "in", "terms", "of", "\"", "Rank", "or", "weight", "\"", "ranging", "between", "[", "0", ",", "1].", "For", "Chi", "Square", "method", "we", "normalized", "the", "output", "between", "[", "0", ",", "1].", "Table", "present", "attributes", "and", "their", "corresponding", "weights", "for", "all", "three", "filter", "based", "feature", "selection", "technique", "and", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "tabu search"}, {"tokens": ["In", "the", "continual", "GP", "classification", "experiment", "with", "real", "-", "world", "data", ",", "we", "consider", "the", "case", "of", "a", "non", "-", "Gaussian", "likelihood", "model", "with", "an", "input", "dimensionality", "greater", "than", "one", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Here", "we", "show", "that", "the", "proposed", "method", "can", "improve", "the", "learning", "performance", "of", "GP", "to", "be", "comparable", "as", "neural", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Such", "a", "phenomenon", "could", "result", "from", "an", "improper", "update", "of", "critic", "and", "generator", "inside", "the", "OT", "module", ",", "since", "the", "gradient", "flow", "would", "be", "iterated", "twice", "more", "for", "the", "last", "two", "terms", "above", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["AP", "only", "requires", "all", "attributes", "to", "be", "correct", ",", "regardless", "of", "3d", "position", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["From", "the", "FEM", "explicit", "integration", "scheme", ",", "the", "numerical", "stability", "is", "ensured", "by", "the", "verification", "of", "Courant", "condition", ",", "i.e.where", "is", "the", "minimum", "element", "size", ";", "is", "the", "speed", "of", "control", "wave", ";", "and", "is", "the", "maximum", "time", "step", "in", "simulation", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["of", "noisy", "input", "image", ",", "the", "best", "suitable", "Gaussian", "component", "is", "selected", "from", "this", "group", "-", "based", "GMM", "learning", "stage", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Comparing", "with", "the", "outputs", "of", "AN", ",", "FAN", "obviously", "rectify", "the", "attention", "drift", "problem", "and", "correctly", "recognize", "more", "characters", "in", "the", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["Mean", "Recall", "(", "MR", ")", "averages", "such", "measures", "for", "all", "requests", "from", "the", "dataset", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean recall"}, {"tokens": ["Here", ",", "we", "discuss", "in", "detail", "the", "algorithms", "to", "check", "the", "new", "spatial", "operators", ":", "the", "somewhere", "and", "surrounded", "operators", ";", "the", "procedures", "for", "the", "other", "Boolean", "and", "temporal", "operators", "are", "similar", "to", "STL", "and", "will", "be", "just", "briefly", "recalled", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "signal temporal logic"}, {"tokens": ["PCM", "-", "Permanent", "Customer", "Model", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "permanent customer model"}, {"tokens": ["For", "the", "DE", "-", "family", ",", "the", "Kruskal", "-", "Wallis", "test", "showed", "no", "significant", "difference", "in", "means", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["hdf5-SuperMIC", "subfigure", "Examples", "of", "timing", "per", "MPI", "rank", "for", "the", "RMSD", "task", "with", "MPI", "-", "based", "parallel", "HDF5", "on", "(", "a", ")", "PSC", "Bridges", "and", "(", "b", ")", "LSU", "SuperMIC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["Our", "algorithm", "greatly", "reduces", "both", "the", "count", "and", "size", "of", "calls", "to", "the", "external", "LAP", "solver", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "linear assignment problem"}, {"tokens": ["Remembering", "that", "JPEGs", "are", "coded", "as", "integers", "in", "[", "0,255", "]", "the", "RMSE", "is", "typically", "1", "or", "less", "(", "for", "RB", "compared", "to", "Prob", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "rank - based"}, {"tokens": ["We", "may", "attribute", "this", "to", "the", "fact", "that", "ECS", "-", "DBN", "has", "been", "optimized", "using", "evolutionary", "algorithm", "with", "maximized", "G", "-", "mean", "objective", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Samples", "in", "the", "less", "reliable", "set", "are", "better", "aligned", "with", "aid", "of", "OT", "metric", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal transport"}, {"tokens": ["At", "a", "high", "-", "level", "what", "GDP", "says", "is", "that", "there", "exists", "a", "set", "of", "\"", "bad", "\"", "data", "sets", "where", "-differential", "privacy", "condition", "does", "not", "hold", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["The", "ANN", "model", "gets", "better", "at", "speaker", "discrimination", "over", "time", "even", "with", "a", "small", "number", "of", "fine", "-", "tuning", "epochs", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "layer", "-", "wise", "angular", "alignment", "between", "the", "gradient", "computed", "with", "BP", "and", "with", "(", "a", ")", "FA", ",", "(", "b", ")", "FA", "with", "uSF", ",", "and", "(", "c", ")", "BP", "with", "an", "alignment", "constraint", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["A", "GMM", "is", "a", "mixture", "of", "K", "Gaussian", "distributions", ",", "with", "variable", "mixture", "coefficients", ",", "means", ",", "and", "variances", "for", "the", "Gaussian", "distributions", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["We", "distinguish", "between", "the", "spatial", "random", "distribution", "of", "indoor", "users", ",", "modeled", "by", "a", "spatial", "Poisson", "Point", "Process", "(", "spatial", "PPP", ")", "in", "a", "typical", "area", "covered", "by", "a", "5", "G", "cell", ",", "and", "the", "distribution", "of", "outdoor", "users", "modeled", "by", "a", "linear", "PPP", "generated", "in", "a", "random", "system", "of", "roads", "modeled", "according", "to", "a", "Poisson", "Line", "Process", "(", "PLP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "poisson line process"}, {"tokens": ["In", "the", "case", "of", "ID", "with", "disks", "we", "assume", "the", "read", "load", "is", "evenly", "distributed", "between", "primary", "and", "secondary", "data", "blocks", ",", "so", "so", "that", "the", "normalized", "load", "at", "each", "disk", "is", "normal", "mode", "is", "one", ",", "since", ":", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["We", "subsampled", "the", "set", "of", "\"", "no", "CF", "\"", "users", "to", "also", "contain", "26,000", "users", ",", "and", "also", "generated", "participation", "tokens", "for", "them", ",", "for", "the", "sake", "of", "homogeneity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Hz", "can", "be", "obtained", "by", ":", "If", "the", "is", "the", "result", "of", "a", "FEM", "simulation", ",", "the", "bounds", "of", "are", ":", "[", "(", "iii", ")", "]"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["IntroductionOblivious", "Transfer", "(", "OT", ")", "is", "perhaps", "the", "most", "fundamental", "primitive", "in", "cryptographic", "protocol", "theory", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Cardiac", "MR", "Image", "EnhancementThe", "proposed", "ACNN", "model", "is", "also", "applied", "to", "the", "image", "SR", "problem", "and", "compared", "against", "the", "state", "-", "of", "-", "the", "-", "art", "CNN", "model", "used", "in", "medical", "imaging", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["The", "final", "HR", "light", "field", "is", "the", "result", "of", "adding", "multi", "-", "stage", "residual", "images", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["In", "a", "comparative", "analysis", ",", "we", "demonstrated", "that", "our", "TS", "approach", "achieves", "the", "highest", "scores", "on", "all", "three", "simplification", "corpora", "with", "regard", "to", "SAMSA", "(", "0.67", ",", "0.57", ",", "0.54", ")", ",", "and", "comes", "no", "later", "than", "a", "close", "second", "in", "terms", "of", "SAMSAabl", "(", "0.84", ",", "0.84", ",", "0.84", ")", ",", "two", "recently", "proposed", "metrics", "targeted", "at", "automatically", "measuring", "the", "syntactic", "complexity", "of", "sentences", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["One", "of", "our", "major", "goals", "was", "to", "overcome", "the", "conservatism", "exhibited", "by", "state", "-", "of", "-", "the", "-", "art", "syntactic", "TS", "approaches", ",", "i.e.", "their", "tendency", "to", "retain", "the", "input", "sentence", "rather", "than", "transforming", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["The", "text", "from", "each", "data", "point", "is", "first", "tokenized", "and", "then", "each", "token", "is", "assigned", "a", "POS", "label", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "part of speech"}, {"tokens": ["IMV", "&", "Individual", "movement", "based", "vaccination", "strategy", "IMVE", "&", "Individual", "movement", "based", "vaccination", "strategy", "with", "exact", "information", "IMVT", "&", "Individual", "movement", "based", "vaccination", "strategy", "with", "temporal", "information", "LST", "&", "SPDT", "network", "with", "the", "same", "number", "of", "links", "that", "of", "DDT", "network", "LST", "&", "SPST", "network", "with", "the", "same", "number", "of", "links", "that", "of", "DST", "network", "MLE", "&", "Maximum", "likelihood", "estimator", "OSN", "&", "Online", "social", "network", "PFU", "&", "Plaque", "-", "forming", "unit", "RV", "&", "Random", "vaccination", "DV", "&", "Degree"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["According", "to", "our", "results", ",", "for", "DTP", ",", "the", "inverse", "mapping", "used", "to", "reconstruct", "the", "underlying", "layerwise", "targets", "does", "not", "work", "all", "that", "well", "when", "weights", "are", "initialized", "from", "a", "purely", "random", "Gaussian", ",", "especially", "with", "a", "low", "standard", "deviation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "difference target propagation"}, {"tokens": ["shows", "the", "flowchart", "of", "the", "PSO", "algorithm", "discussed", "above", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["On", "the", "other", "hand", ",", "there", "are", "also", "fields", "for", "which", "the", "MAD", "is", "quite", "large", "(", "see", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "median absolute difference"}, {"tokens": ["It", "has", "been", "shown", "that", "the", "layers", "in", "an", "DCNN", "from", "bottom", "to", "top", "take", "increasingly", "larger", "receptive", "fields", "and", "extract", "different", "levels", "of", "features", "from", "the", "input", "signal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["The", "output", "layer", "returns", "the", "ANN", "\u2019s", "predictions", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "SAR", "system", "adapted", "to", "the", "participants", "in", "both", "cases", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["of", "each", "stage", "in", "the", "ISP", "pipeline", "in", "reverse", "order", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Tests", "are", "between", "Global", "-", "INF", "and", "best", "flat", ",", "LR", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "logistic regression"}, {"tokens": ["We", "use", "CTC", "Beam", "search", "decoder", "for", "getting", "the", "output", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["Moreover", ",", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "provides", "higher", "EE", "than", "other", "schemes", "due", "to", "higher", "SC", "can", "be", "achieved", "by", "different", "OAM", "mode", "based", "transmission", "from", "BS", "to", "the", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", ",", "MD", "distortion", "-", "rate", "performance", "is", "derived", "for", "certain", "randomly", "generated", "quantizers", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["Delay", "incurred", "due", "to", "cache", "processing", "at", "CC", "and", "EC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Comparison", "of", "DMD", ",", "EMD", ",", "and", "iterative", "improvement", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deficient mapping dissolution"}, {"tokens": ["A", "similar", "trend", "can", "be", "observed", "aslo", "for", "the", "results", "on", "TREC", "-", "QA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "question answering"}, {"tokens": ["The", "developed", "algorithm", "is", "named", "hybrid", "quantum", "inspired", "PSO", "(", "HQPSO", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Finding", "7", ":", "Even", "for", "the", "same", "learning", "algorithm", ",", "the", "decision", "of", "using", "incremental", "or", "retrained", "modeling", "can", "be", "a", "trade", "-", "off", ",", "see", "for", "example", "the", "DT", "on", "throughput", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["We", "construct", "an", "NCA", ",", "where", "is", "the", "set", "of", "accepting", "states", ",", "such", "that", "is", "DBP"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "determinisable by pruning"}, {"tokens": ["-", "7(r)8", "-", "10(r)11", "-", "1314", "-", "15Metric", "/", "Model", "&", "COR", "&", "QRFA", "&", "GS", "&", "COR", "&", "QRFA", "&", "GS", "&", "COR", "&", "QRFA", "&", "GS", "&", "COR", "&", "QRFA", "&", "GS", "&", "COR", "&", "QRFA", "Average", "/", "case", "&", "0.58", "&", "0.89", "&", "&", "0.74", "&", "1", "&", "&", "0.66", "&", "0.96", "&", "&", "0.7", "&", "0.99", "&", "&", "0.67", "&", "0.96", "Max", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gold standard"}, {"tokens": ["Further", ",", "employing", "Resnet", "architecture", "for", "PIN", "gives", "an", "additional", "1.67", "improvement", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "proposal indexing network"}, {"tokens": ["Contrastive", "divergence", "(", "CD", ")", "is", "a", "training", "technique", "used", "for", "RBMs", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "contrastive divergence"}, {"tokens": ["Theorem", "1", "can", "be", "used", "to", "derive", "the", "total", "time", "for", "performing", "the", "entire", "FL", "algorithm", "and", "transmission", "energy", "of", "all", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["ii", ")", "the", "majority", "of", "students", "felt", "the", "part", "related", "to", "formal", "specification", "is", "relevant", "for", "their", "IS", "practice(Examples", ":", "\"", "I", "think", "Z", "language", "is", "the", "most", "useful", "part", ",", "because", "it", "is", "applied", "in", "industry", "\"", ",", "\"", "If", "I", "encounter", "any", "other", "formal", "notation", "in", "industry", ",", "it", "will", "take", "me", "less", "time", "to", "get", "familiar", "with", "the", "subject", "\"", ".", ")", ";"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["The", "gap", "between", "the", "best", "model", "AP", "and", "UAP", "is", "above", "30", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["MINT", "-", "FEC", "."], "acronym_pos": [0, 0, 1, 0], "long_form": "forward error correction"}, {"tokens": ["The", "running", "sum", ",", "RS", ",", "is", "written", "to", "help", "illustrate", "the", "mechanics", "of", "the", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "running sum"}, {"tokens": ["Adaptive", "data", "augmentation", "like", "AutoAugment", "may", "also", "improve", "performance", "of", "both", "normal", "knowledge", "distillation", "for", "robust", "teachers", "and", "ARD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["To", "further", "evaluate", "the", "performance", "contribution", "of", "FN", "to", "FAN", ",", "here", "we", "compare", "the", "performance", "of", "FAN", "and", "AN", ",", "which", "are", "all", "based", "on", "the", "image", "-", "encoder", "released", "by", "Shi", "shi2016robust", ",", "instead", "of", "the", "ResNet", "-", "based", "encoder", ",", "over", "the", "five", "unconstrained", "datasets", "(", "IIIT5", "K", ",", "SVT", ",", "IC03", ",", "IC13", "and", "IC15", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["This", "model", "generally", "has", "a", "form", "similar", "to", "the", "decoder", ":", "*", "where", "and", "are", "the", "outputs", "of", "the", "encoder", "ANN", "(", "the", "parameter", "set", "is", "composed", "of", "and", ";", "is", "a", "diagonal", "covariance", "matrix", "or", "is", "the", "vector", "of", "its", "diagonal", "entries", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Finally", ",", "we", "still", "depend", "on", "a", "classical", "shape", "modelling", "pipeline", "of", "GPA", "and", "PCA", "where", "more", "sophisticated", ",", "nonlinear", "models", "may", "be", "preferable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized procrustes analysis"}, {"tokens": ["In", "the", "next", "stage", ",", "PIN", "learns", "to", "attend", "the", "proposals", "most", "relevant", "to", "query", "phrase", "to", "further", "reduce", "the", "volume", "of", "region", "proposals", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["illustrates", "a", "CSS", "scenario", "in", "which", "SUs", "independently", "sense", "sub", "-", "channels", "and", "identify", "the", "absence", "and", "presence", "of", "PUs", "by", "and", "bits", ",", "respectively", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cooperative spectrum sensing"}, {"tokens": ["It", "means", "that", "2", "RBs", "are", "needed", "in", "both", "LTE", "and", "NR", "to", "allocate", "all", "necessary", "PDCCH", "symbols", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["GCNN", "is", "a", "gated", "convolutional", "neural", "network", "which", "is", "a", "modification", "of", "the", "convolutional", "layer", "inspired", "by", "the", "gated", "layer", "in", "Long", "short", "-", "term", "memory", "(", "LSTMs", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["Why", "prefer", "OT", "to", "other", "alternatives", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["IDC", ":", "in", "-", "degree", "centrality", ",", "BC", ":", "betweenness", "centrality", ",", "CC", ":", "closeness", "centrality", ",", "EC", ":", "eigenvector", "centrality", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["Its", "form", "isA", "similar", "expression", "is", "derived", "in", "where", "theoretical", "analysis", "on", "sparse", "GP", "regression", "is", "performed", "out", "of", "the", "continual", "learning", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["also", "shows", "that", "the", "proposed", "FL", "scheme", "outperforms", "the", "EB", "-", "FDMA", ",", "FE", "-", "FDMA", ",", "and", "TDMA", "schemes", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Ishai", ",", "Kilian", ",", "Nissim", "and", "Petrank", "(", "referred", "as", "IKNP", "protocol", "henceforth", ")", "presented", "the", "first", "efficient", "OT", "extension", "protocol", "that", "builds", "on", "seed", "OTs", "and", "requires", "computing", "and", "sending", "just", "two", "hash", "values", "per", "extended", "OT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "oblivious transfer"}, {"tokens": ["b", ")", ",", "while", "the", "knowledge", "of", "the", "PAP", ",", "performing", "two", "additional", "reduction", "pre", "-", "steps", "and", "setting", "the", "delayed", "process", "to", "be", "the", "last", "one", "in", "the", "pipeline", ",", "causes", "the", "whole", "operation", "time", "to", "be", "reduced", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["Although", "the", "coupling", "of", "BEM", "and", "FEM", "algorithms", "can", "be", "accomplished", "in", "a", "wide", "majority", "of", "commercially", "available", "finite", "element", "codes", "that", "assimilate", "user", "element", "subroutines", ",", "e.g.", ",", ",", "the", "asymmetric", "and", "dense", "character", "of", "the", "HSSE", "-", "coefficient", "-", "matrix", "still", "restrains", "the", "advantages", "of", "the", "finite", "element", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["Concretely", ",", "we", "are", "interested", "in", "the", "generalisation", "of", "the", "continual", "GP", "scheme", "to", "accept", "extremely", "asymmetric", "cases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Specifically", ",", "we", "compare", "GPA", "against", "HARP", "and", "Random", "on", "the", "graphs", ":", "Enron", ",", "GRQC", ",", "Blog", ",", "and", "Wiki", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["In", "doing", "this", ",", "both", "the", "PLR", "and", "burstiness", "are", "categorised", "and", "used", "as", "input", "to", "configure", "the", "amount", "of", "redundancy", "added", "by", "the", "FEC", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["LTE", "-", "U", "detects"], "acronym_pos": [1, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": [",", "we", "model", "the", "ISP", "stages", "shown", "in", "Figure", "fig", ":", "isp", ":", "denoise", ",", "black", "level", "subtraction", ",", "white", "balance", ",", "tone", "-", "mapping", ",", "demosaic", ",", "color", "correction", ",", "and", "gamma", "correction", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["The", "training", "is", "stopped", "when", "the", "difference", "in", "both", "CTC", "loss", "and", "validation", "error", "between", "epoch", "and", "are", "less", "than", "or", "equal", "to", "0.01", "and", "0.1", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["AIR", "gains", "of", "approximately", "bit/4D", "-", "sym", "are", "observed", "for", "this", "AIR", "range", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "achievable information rates"}, {"tokens": ["Similar", "to", "the", "BOW", "feature", "we", "created", "a", "dictionary", "of", "POS", "tags", "from", "the", "entire", "corpus", "(", "excluding", "the", "health", "data", ")", "and", "used", "this", "dictionary", "to", "label", "each", "tweet", "with", "it", "-", "binary", ",", "i.e.", "whether", "a", "POS", "tag", "is", "present.(We", "also", "experimented", "with", "frequencies", "of", "POS", "tags", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "part of speech"}, {"tokens": ["For", "example", ",", "for", "the", "point", "in", "the", "ROC", "curve", "with", "TPR", "of", "0.8", ",", "given", "a", "pair", "of", "users", "with", "a", "true", "friendship", ",", "GRTM", "has", "80", "probability", "of", "predicting", "it", "correctly", ",", "while", "given", "a", "pair", "of", "users", "without", "a", "friendship", ",", "it", "has", "20", "probability", "of", "predicting", "it", "incorrectly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["S.", "Hongguang", ",", "S.", "Min", ",", "W.", "Xijun", ",", "Z.", "Yan", ",", "L.", "Junyu", "and", "W.", "Kan", ",", "\"", "Resource", "allocation", "for", "maximizing", "the", "device", "-", "to", "-", "device", "communications", "underlaying", "LTE", "-", "Advanced", "networks", ",", "\"", "in", "Proc", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["In", "contrast", ",", "we", "find", "that", "in", "FA", "the", "error", "signal", "is", "still", "created", "by", "a", "backward", "pass", "as", "in", "BP", ",", "but", "this", "time", "with", "the", "final", "per", "-", "neuron", "derivatives", "approximated", "by", "the", "feedback", "weights", "that", "replace", "the", "transpose", "of", "the", "forward", "weights", "in", "the", "BP", "global", "feedback", "pathway", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["The", "Explainable", "Question", "Answering", "(", "XQA", ")", "systems", "are", "an", "emerging", "area", "which", "tries", "to", "address", "the", "shortcomings", "of", "the", "existing", "QA", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["OLS", "has", "been", "widely", "used", "in", "many", "applications", ",", "but", "it", "has", "not", "gained", "much", "attention", "for", "classification", "problems", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["As", "for", "ASF", ",", "the", "mortality", "is", "assumed", "to", "be", "100", "and", "no", "pig", "recovers", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "african swine fever"}, {"tokens": ["As", "shown", "in", "Figure", ",", "the", "effective", "amount", "of", "power", "that", "can", "be", "captured", "by", "a", "sensor", "node", "varies", "with", "the", "distance", "between", "the", "node", "and", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["In", "ARS", ",", "a", "system", "is", "given", "as", "input", "a", "set", "of", "candidate", "responses", "and", "a", "conversational", "context", "in", "a", "single", "language", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "addressee and response selection"}, {"tokens": ["ABEP", ",", ",", "of", "DBPSK", "versus", "the", "number", "of", "relay", "nodes", ",", ",", "for", "different", "average", "transmit", "SNRs", "per", "bit", "and", "dB", ",", "over", "IID", "Rayleigh", "fading", "channels", ":", "(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "maximal ratio diversity"}, {"tokens": ["They", "can", "be", "divided", "into", "two", "categories", ":", "LSSH", ",", "CMFH", "and", "DCH", "are", "supervised", "methods", ";", "SCM", ",", "SePH", "and", "DCMH", "are", "unsupervised", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic correlation maximization"}, {"tokens": ["For", "more", "difficult", "tasks", "on", "TVV", "and", "TAS", "retrieval", ",", "since", "SIFT", "feature", "can", "not", "fully", "capture", "the", "characteristics", "in", "TAS", ",", "the", "fusion", "of", "STIP", "and", "SIFT", "does", "not", "gain", "significant", "improvement", "where", "CCA", "even", "suffers", "great", "loss", "from", "SIFT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transverse abdominal section"}, {"tokens": [",", "the", "probability", "density", "of", "the", "SCF", "model", "is", "proportional", "to", "whereand", "is", "the", "probability", "density", "as", "defined", "by", "the", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "achievable", "rate", "of", "decoding", "message", "is", ":", "where", "is", "the", "bandwidth", "of", "the", "BS", ",", "is", "the", "power", "spectral", "density", "of", "the", "Gaussian", "noise", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "downside", "of", "the", "PS", "becomes", "a", "communication", "bottleneck", "which", "leads", "to", "slow", "down", "the", "training", "process", "and", "to", "limit", "the", "system", "scalability", "in", "very", "large", "-", "scale", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["proposed", "to", "learn", "models", "of", "the", "dynamics", "and", "the", "immediate", "reward", "to", "compute", "an", "approximate", "mean", "function", "of", "the", "GP", ",", "which", "is", "then", "used", "in", "a", "traditional", "BO", "procedure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["PSC", "Bridges", ":"], "acronym_pos": [1, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["Resolution", "limitCommunity", "detection", "algorithms", "are", "in", "general", "easy", "to", "implement", ",", "and", "likely", "to", "be", "faster", "than", "applying", "an", "SBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "stochastic block model"}, {"tokens": ["t", "]", "[", "F1", "score", "of", "different", "approaches", "as", "epoch", "increases", "]", "[", "training", "time", "of", "different", "approaches", "as", "epoch", "increases", "]", "Model", "quality", "and", "time", "efficiency", "comparison", "for", "multiple", "FL", "approaches", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["The", "ICCs", "are", "used", "to", "determine", "the", "number", "of", "robust", "features", "and", "to", "show", "the", "ICC", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["The", "interior", "-", "point", "method", "can", "be", "applied", "to", "GP", "with", "a", "polynomial", "time", "complexity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Experimental", "results", "analysisIn", "experiments", ",", "we", "compare", "the", "proposed", "method", "with", "eight", "methods", ",", "which", "include", "five", "kinds", "of", "state", "-", "of", "-", "the", "-", "art", "methods", "(", "DVN", ",", "HM", ",", "VCL", ",", "TVN", "and", "FGN", "in", "section", ")", ",", "three", "kinds", "of", "base", "-", "line", "methods(FGN", ",", "TFGNSCS-1", "and", "TFGNSCS-2", "in", "section", ")", "and", "a", "alternative", "transfer", "method", "(", "TFGNSCS", "-", "alt", "in", "section", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "hybrid model"}, {"tokens": ["Some", "previous", "NLP", "work", "focused", "on", "composition", "functions", "for", "relation", "prediction", "between", "text", "fragments", ",", "even", "though", "they", "ignored", "SRL", "and", "only", "dealt", "with", "word", "units", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "statistical relational learning"}, {"tokens": ["Evolutionary", "Cost", "-", "sensitive", "Deep", "Belief", "Network", "(", "ECS", "-", "DBN", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["[", "t", "]", ".245", "0.0001", ".245", "0.0001", ".245", "0.0001", ".245", "Example", "photos", "of", "AR", "prediction", "and", "dynamic", "transparency", "under", "1sec", "of", "round", "trip", "delay", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["We", "proposed", "a", "new", "metric", "(", "normalized", "cumulative", "entropy", ",", "NCE", ")", "to", "determine", "the", "diversity", "of", "returned", "results", "from", "different", "record", "types", ",", "assuming", "there", "is", "no", "preference", "for", "a", "particular", "result", "type", "at", "any", "position", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["Regardless", "of", "the", "number", "of", "clusters", ",", "the", "SBM", "finds", "clusters", "which", "do", "not", "contain", "any", "of", "the", "edges;this", "is", "the", "opposite", "of", "what", "we", "expect", "in", "community", "finding", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["We", "discussed", "several", "aspects", "of", "an", "EMS", ",", "such", "as", "information", "modeling", ",", "querying", "and", "analysis", ",", "and", "data", "ingestion", ",", "and", "also", "presented", "our", "work", "on", "location", "uncertainty", "reasoning", "and", "event", "disambiguation", "in", "more", "detail", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "event management system"}, {"tokens": ["The", "information", "held", "by", "the", "failure", "counter", "determines", "whether", "the", "number", "of", "FEC", "recovery", "packets", "is", "increased", "or", "decreased", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Phase-1Following", "the", "principle", "of", "downlink", "NOMA", ",", "BS", "transmits", "a", "superimposed", "composite", "signal", "for", "a", "duration", "of", ",", "where", ",", "are", "the", "data", "symbols", "and", ",", "are", "power", "allocating", "factors", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "deep", "3D", "DPN", "is", "employed", "to", "extract", "features", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "dual path network"}, {"tokens": ["During", "the", "fitness", "evaluation", ",", "if", "the", "obtained", "solution", "satisfies", "an", "adaptive", "constraint", ",", "then", "GA", "-", "SCP", "invokes", "GA", "-", "RSSD", "and", "passes", "and", "its", "maximum", "gap", "metric", "to", "it", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simultaneous closeness - performance"}, {"tokens": ["*", "uara-", "MP", "war", "'", "breast", "'", "NP", "barPIr"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "new persian"}, {"tokens": ["The", "most", "interesting", "result", "is", "that", "random", "clustering", "results", "in", "spectral", "efficiency", "even", "worse", "than", "direct", "UE", "-", "BS", "communication", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["the", "distance", "of", "a", "reference", "location", "is", "defined", "(", "Taken", "from", "https://en.wikipedia.org/wiki/Free-spacepathloss", ")", "as", "follows", ":", ",", "where", "is", "the", "speed", "of", "light", "and", "is", "the", "frequency", "of", "the", "transmitted", "signal", "by", "an", "ET", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "energy transmitters"}, {"tokens": ["the", "overall", "time", "is", "taken", "for", "the", "LR", "attack", "is", "about", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Nokia", "presents", "Mara", ",", "a", "multi", "-", "sensor", "mobile", "phone", "AR", "guidance", "application", "for", "mobile", "phones(Mara", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["In", "CNS", ",", "myelin", "constitutes", "most", "of", "the", "white", "matter", "(", "WM", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central nervous system"}, {"tokens": ["In", "Figures", "and", ",", "the", "performance", "of", "Uni", "-", "MUMAC", "is", "evaluated", "in", "the", "same", "condition", "as", "done", "in", "Figures", "and", "except", "that", "the", "network", "adopts", "the", "new", "frame", "aggregation", "scheme", "(", "AP", "'s", ",", "STA", "'s", ")", "and", "the", "new", "queue", "length", "(", ",", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["We", "specifically", "use", "SOC", "update", "time", "to", "find", "the", "charging", "rates", "and", "use", "the", "battery", "voltage", "to", "determine", "the", "length", "of", "the", "CC", "phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "charging current"}, {"tokens": ["So", "the", "training", "time", "metrics", "for", "PS", "framework", "is", "shown", "as", "below", ":", "Where", "is", "the", "training", "time", "with", "using", "single", "GPU", ",", "is", "the", "communication", "time", "and", "is", "the", "preparation", "time", "for", "opening", "and", "closing", "deep", "learning", "platform", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["We", "propose", "TS", "and", "kl", "-", "UCB", "based", "algorithms", "named", "alg", ":", "CSMD_TS", "and", "alg", ":", "CSMD_KL", "respectively", "for", "such", "online", "feature", "selection", "in", "CSMD", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["generate", "paraphrases", "of", "given", "questions", "to", "increases", "the", "performance", "of", "QA", "systems", ";", "paraphrases", "are", "generated", "relying", "on", "paraphrase", "datasets", ",", "neural", "machine", "translation", "and", "rule", "mining", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Even", "without", "having", "access", "to", "FA", "tools", "and", "reverse", "engineering", "capabilities", ",", "an", "end", "user", "without", "reverse", "engineering", "capability", "can", "still", "exploit", "the", "design", "vulnerabilities", "for", "extracting", "key", "value", "of", "FSM", "or", "logic", "locked", "circuitry", "using", "side", "-", "channel", "analysis", "and", "probing", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["Along", "the", "way", ",", "we", "also", "contribute", "a", "convex", "optimization", "to", "design", "optimal", "OCC", "gains", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "output constrained covariance"}, {"tokens": ["However", ",", "our", "model", "differs", "from", "typical", "implementations", "of", "HG", "and", "OT", "in", "that", "the", "optimal", "structure", "does", "not", ",", "in", "general", ",", "decompose", "into", "a", "unique", "combination", "of", "the", "input", "constituents", "(", "entity", "and", "relation", "embeddings", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimality theory"}, {"tokens": ["Approaches", "based", "on", "Semantic", "ParsingWhile", "the", "TS", "approaches", "described", "above", "are", "based", "on", "syntactic", "information", ",", "there", "are", "a", "variety", "of", "methods", "that", "use", "semantic", "structures", "for", "sentence", "splitting", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["Then", "the", "IB", "curve", "in", "the", "information", "plane", "is", "defined", "by", "the", "following", "equation", ":", "Furthermore", ",", "they", "showed", "that", "the", "IB", "curve", "could", "not", "be", "explored", "by", "optimizing", "the", "IB", "Lagrangian", "for", "multiple", "because", "the", "curve", "was", "not", "strictly", "concave", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["AML", "syntax", ":"], "acronym_pos": [1, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["This", "was", "illustrated", "here", "with", "the", "comparison", "of", "SL", "and", "SP", "languages", "which", "encode", "local", "and", "long", "-", "distance", "dependencies", ",", "respectively", ",", "and", "with", "the", "value", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Moreover", ",", "the", "usefulness", "of", "the", "DC", "-", "SBM", "should", "not", "be", "seen", "as", "an", "indication", "of", "the", "inferiority", "of", "the", "original", "SBM", ",", "as", "it", "captures", "different", "underlying", "structures", "that", "follow", "stochastic", "equivalence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["The", "design", "of", "has", "been", "driven", "by", "the", "aim", "of", "making", "it", "a", "subset", "of", "Java", "8,while", "preserving", "the", "elegance", "and", "compactness", "of", "FJ", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "featherweight java"}, {"tokens": ["Even", "though", "the", "latter", "is", "gaining", "more", "and", "more", "popularity", ",", "AS2", "is", "more", "relevant", "to", "a", "production", "scenario", "since", ",", "a", "combination", "of", "a", "search", "engine", "and", "an", "AS2", "model", "already", "implements", "an", "initial", "QA", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["Furthermore", ",", "the", "detailed", "operational", "procedures", "of", "the", "proposed", "Max", "-", "SR", "PA", "strategy", "are", "presented", "in", "Algorithm", "1", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["[", "Relationship", "between", "the", "convex", "and", "concave", "IB", "Lagrangians", "]", "Consider", "the", "convex", "and", "concave", "IB", "Lagrangians", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Consider", "the", "scenario", "in", "Figure", ",", "the", "MACS", "score", "is", "computed", "times", "for", "the", "four", "terms", ":", "A", ",", "B", ",", "C", "and", "D."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean average conceptual similarity"}, {"tokens": ["In", "the", "population", "level", "vaccination", ",", "IMV", "strategy", "contains", "disease", "within", "the", "outbreak", "of", "1", "K", "infections", "with", "vaccinating", "6", "of", "nodes", "while", "RV", "strategy", "requires", "vaccination", "of", "55", "nodes", "and", "AV", "requires", "35", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["OT", "'s", "advantage", "over", "BS", "was", "in", "the", "color", "distributions", ",", "which", "is", "not", "surprising", "as", "its", "matches", "are", "nearly", "permutations", ",", "while", "BS", "had", "a", "match", "cardinality", "of", "in", "practice", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["GP", "kernel", "estimationThe", "performance", "of", "GP", "registration", "depends", "exclusively", "on", "the", "suitability", "of", "the", "chosen", "kernels", "and", "its", "parameters", "."], "acronym_pos": [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["-0.5em*[t]Model", "accuracy", "when", "noise", "is", "injected", "into", "WikiQA", "and", "TREC", "-", "QA", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["This", "is", "in", "contrary", "to", "the", "current", "implementation", "of", "the", "RB", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "reduced basis"}, {"tokens": ["The", "ST", "provided", "boiler", "on", "-", "time", "(", "BO", ")", "and", "thermostat", "set", "point", "(", "SP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "set point"}, {"tokens": ["The", "MGM", "GAN", "balances", "these", "different", "densities", "and", "consequently", "performs", "significantly", "better", "at", "our", "unsupervised", "domain", "adaptation", "task", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["We", "then", "have", "the", "GP", "predict", "a", "temporal", "pattern", "for", "an", "interval", "of", "where", "=", "168", "for", "the", "hourly", "week", "'s", "profile", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "improvement", "seems", "to", "be", "quite", "modest", ",", "however", ",", "raising", "the", "ACC", "from", "about", "0.46", "to", "0.49", "and", "decreasing", "the", "RMSE", "from", "5.89", "to", "5.73", "at", "best", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "anomaly correlation coefficient"}, {"tokens": ["Although", "this", "provides", "a", "basic", "privacy", "guarantee", "because", "privacy", "-", "sensitive", "data", "is", "not", "transmitted", ",", "it", "still", "suffers", "from", "inference", "attacks", "that", "use", "the", "final", "model", "or", "the", "model", "updates", "exchanged", "during", "the", "FL", "training", "to", "infer", "private", "information", ";", "examples", "of", "such", "attacks", "include", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Next", ",", "we", "present", "the", "RS", "approach", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0], "long_form": "rate saturation"}, {"tokens": ["We", "report", "both", "the", "DP", "rates", "at", "the", "conventional", "threshold", "of", "20", "pixels", "(", "DPR", ")", "and", "the", "OS", "rates", "at", "the", "threshold", "of", "0.5", "(", "OSR", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "overlap success"}, {"tokens": ["Context", "is", "incorporated", "in", "the", "Temporal", "Pooler", "prediction", "process", "by", "having", "the", "TP", "learn", "the", "likelihoods", "of", "each", "context", "element", "from", "each", "provider", "being", "1", ",", "for", "each", "lookbehind", "cluster", "in", "each", "sequence", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal pooler"}, {"tokens": ["Because", "the", "additional", "information", "transmission", "from", "BS", "to", "the", "users", "by", "different", "OAM", "modes", "can", "enhance", "the", "SC", "of", "the", "proposed", "scheme", "than", "other", "compared", "schemes", "significantly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["Eric", "Deng", "contributed", "to", "the", "design", "of", "the", "Kiwi", "robot", "hardware", "and", "the", "overall", "SAR", "system", "for", "time", "-", "extended", "in", "-", "home", "deployments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "original", "suite", "of", "solvers", "included", "GS", "as", "the", "multigroup", "solver", "and", "PI", "with", "inner", "GS", "iteration", "as", "the", "eigenvalue", "solver", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["In", "Figure", "7", ",", "the", "influence", "of", "over", "SC", "is", "plotted", "for", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["Similarly", ",", "we", "get-1.0emWe", "now", "apply", "the", "SDR", "technique", "by", "using", "a", "positive", "-", "semidefinite", "matrix", "and", "relaxing", "the", "rank", "-", "constraint", "on", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semidefine relaxation"}, {"tokens": ["RB", ":", "coefficients", "defines", "the", "RB", "approximation", "of", "the", "deformation", "gradientThe", "microscopic", "energy", ",", "stress", ",", "and", "stiffness", "within", "the", "microstructure", "are", "then", "approximated", "byrespectively", "."], "acronym_pos": [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["SummaryFinally", ",", "other", "than", "CC", "-", "CV", "and", "DLC", ",", "we", "have", "identified", "two", "more", "variants", "of", "these", "two", ",", "one", "of", "them", "applies", "CV", "at", "the", "beginning", "and", "the", "other", "uses", "CC", "at", "the", "end", "of", "charging", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "constant charging"}, {"tokens": ["Mirrored", "disks", "in", "increasing", "order", "of", "their", "MTTDL", "are", "ID", ",", "GRD", ",", "CD", ",", "BM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["We", "therefore", "introduce", "a", "new", "approach", "using", "a", "fully", "convolutional", "network", "for", "the", "automated", "segmentation", "of", "VAT", "and", "SAT", ",", "with", "the", "goal", "of", "investigating", "how", "high", "of", "an", "accuracy", "and", "robustness", "can", "be", "achieved", "on", "this", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["performance", "comparison", "of", "flat", "LR", "approach", "(", "marked", "in", "dotted", "red", ")", "against", "best", "TD", "approach", ",", "Global", "-", "INF", "(", "marked", "in", "solid", "blue", ")", "with", "different", "selection", "of", "threshold", "(", ")", "for", "CLEF", "and", "DMOZ", "-", "SMALL", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["The", "maximum", "number", "of", "disk", "failures", "that", "can", "be", "tolerated", "by", "ID", "is", ",", "while", "for", "BM", ",", "GRD", ",", "and", "CD", "organizations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["The", "LTE", "licensed", "carrier", "frequency", "bandwidth", "can", "only", "be", "up", "to", "20MHz", ";", "the", "30MHz", "is", "due", "to", "carrier", "aggregation", "of", "multiple", "licensed", "carrier", "frequencies", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Let", "us", "now", "focus", "on", "a", "mathematical", "description", "of", "ANN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "artificial neural network"}, {"tokens": ["Figures", "and", "show", "a", "sample", "rule", "over", "the", "same", "dataset", "for", "our", "algorithm", "and", "for", "the", "DT", "surrogate", "method", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["However", "the", "existence", "of", "a", "manual", "process", "in", "itself", "is", "not", "a", "strong", "driver", "to", "DLT", "specifically", "-", "the", "basic", "premise", "of", "almost", "all", "IS"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "information systems"}, {"tokens": ["ConclusionsIn", "this", "work", ",", "we", "propose", "a", "joint", "model", "of", "NER", "and", "MD", "tasks", "that", "removes", "the", "need", "for", "external", "morphological", "disambiguators", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "morphological disambiguation"}, {"tokens": ["However", ",", "in", "a", "practical", "WLAN", "system", ",", "the", "channel", "and", "interference", "seen", "by", "the", "STAs", "are", "generally", "not", "the", "same", "as", "those", "seen", "by", "the", "AP", "due", "to", "their", "different", "transmitting", "/", "receiving", "filters", "and", "PHY", "paths", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["By", "the", "method", "of", "Lagrange", "multiplier", ",", "the", "analytic", "expression", "of", "the", "proposed", "PA", "strategy", "is", "derived", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["High", "PRR", "(", "HP", ")", "scheduling", "is", "the", "second", "algorithm", "where", "the", "node", "with", "higher", "has", "higher", "priority", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high prr"}, {"tokens": ["The", "first", "term", "is", "the", "VAT", "loss", "taken", "from", "miyato2018virtual", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["This", "is", "a", "CC", "server", "operated", "by", "the", "attacker", "that", "controls", "a", "light", "source", "for", "the", "purpose", "of", "modulating", "commands", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "covert channels"}, {"tokens": ["Taking", "everything", "into", "consideration", ",", "this", "thesis", "proposes", "a", "series", "of", "cross", "-", "layer", "video", "-", "aware", "and", "FEC", "-", "based", "mechanisms", "with", "UEP", "to", "enhance", "video", "transmission", "in", "several", "types", "of", "wireless", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["bordes2014question", "(", "which", "outperformed", "ParaSempre", "parasempre", "on", "WebQuestions", ")", "and", "the", "SMT", "-", "like", "SP", "approach", "of", "dong2016language", "seem", "to", "acknowledge", "the", "promise", "of", "neural", "approaches", "with", "embeddings", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic parsing"}, {"tokens": ["By", "the", "first", "condition", "of", "Exact", "-", "MBR", "encoding", "matrix", ",", "the", "can", "be", "reconstructed", "from", "arbitrary", "elements", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["F", "refers", "to", "follow", "-", "up", "relationships", ",", "RT", "to", "RT", ",", "M", "to", "mentions", ",", "RP", "to", "replies", ",", "and", "FT", "to", "favorite", "or", "liked", "tweets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "retweets"}, {"tokens": ["Please", "note", "that", "the", "impact", "of", "sampling", "hyper", "-", "parameters", "is", "illustrated", "in", "Figures", "for", "SWAG", "models", "with", "item", "-", "description", "embeddings", "(", "ID", ")", "as", "the", "input", "(", "for", "reasons", "mentioned", "later", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "item description"}, {"tokens": ["There", "are", "several", "FEC", "codes", "with", "different", "characteristics", "and", "applications", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Although", "the", "use", "of", "UAVs", "in", "SAR", "operations", "can", "help", "to", "present", "potential", "dangers", "to", "crews", "of", "the", "flight", ",", "UAVs", "still", "suffer", "from", "capacity", "scale", "problems", "and", "limitations", "to", "their", "payloads", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["In", "PA", ",", "a", "node", "connects", "with", "another", "node", "with", "probability", "in", "the", "existing", "network", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "preferential attachment"}, {"tokens": ["Results", "for", "the", "exponential", "IB", "Lagrangian", "in", "the", "MNIST", "dataset", "with", ",", "from", "top", "to", "bottom", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["By", "improving", "the", "evaluation", "prompt", "to", "use", "Edits", "instead", ",", "it", "is", "possible", "to", "further", "reduce", "variance", "relative", "to", "humans", "(", "DE", "is", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "data efficiency"}, {"tokens": ["Goal", "-", "based", "methods", "help", "the", "SAR", "system", "to", "select", "actions", "that", "maximize", "the", "user", "\u2019s", "progress", "toward", "an", "assistive", "outcome", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["This", "contrasts", "with", "the", "SBM", ",", "which", "instead", "clusters", "the", "nodes", "into", "9", "high", "-", "degree", "and", "25", "low", "-", "degreenodes", ",", "a", "clustering", "which", "is", "quite", "different", "from", "the", "factional", "split", ";", "this", "SBM", "clustering", "is", "in", "Figure", "FIGkarate000K2SBMw1", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["However", ",", "DTP", "does", "far", "better", "than", "FA", "across", "the", "scenarios", ",", "although", "its", "lacks", "the", "ability", "to", "train", "from", "zero", "initialization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["By", "incorporating", "these", "design", "recommendations", ",", "the", "RS", "creators", "could", "engineer", "negative", "feedback", "loops", "that", "provide", "the", "needed", "checks", "and", "balances", "and", "signal", "the", "user", "when", "those", "thresholds", "have", "been", "reached", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["Our", "approach", "is", "founded", "upon", "the", "Dropout", "technique", ",", "a", "well", "-", "known", "regularization", "technique", "used", "in", "the", "training", "of", "Artificial", "Neural", "Networks", "(", "ANN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["TTP", "executes", "our", "verification", "model", "on", "the", "claimed", "identity", ",", "the", "recorded", "signature", "and", "the", "set", "of", "reference", "signatures", ",", "and", "returns", "the", "classification", "result", "(", "GENUINE", "or", "FORGED", ")", "to", "Bob", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "trusted third party"}, {"tokens": ["This", "is", "because", "the", "changes", "in", "the", "SP", "representation", "degrade", "the", "sequences", "learned", "by", "the", "TP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spatial pooler"}, {"tokens": ["We", "believe", "a", "privacy", "-", "preserving", "FL", "framework", "should", "strive", "for", "strong", "privacy", "guarantees", ",", "high", "communication", "efficiency", ",", "and", "resilience", "to", "changes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["The", "FCA", "resources", "are", "replaced", "by", "NGCC", "located", "at", "the", "Hub", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward capacity auctions"}, {"tokens": ["The", "design", "of", "the", "SAR", "intervention", "was", "conceptualized", "by", "our", "multidisciplinary", "team", "of", "researchers", ",", "leveraging", "established", "game", "design", "principles", ",", "including", "iterative", "prototyping", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["reduction", "of", "cost", "over", "the", "first", "ten", "epochs", "for", "the", "low", "-", "latency", "convolution", "and", "VAT", "models", ":", "a", "zoomed", "-", "in", "version", "of", "fig:500epcThe", "behavior", "of", "cost", "function", "in", "the", "first", "10", "epochs", "is", "seen", "image", "13", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["Recall", "the", "definition", "of", "the", "RB", "in", "eq", ":"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["cm", "Method", "&", "PMF", "&", "BPMF", "&", "AA", "&", "AP", "&", "TDSSM", "&", "RRN", "&", "NCF", "&", "BPTF", "&", "Rating", "Prediction", "&", "&", "&", "&", "&", "&", "&", "&", "&", "Rating", "Inference", "&", "&", "&", "&", "&", "&", "&", "&", "&", "Link", "Prediction", "&", "&", "&", "&", "&", "&", "&", "&", "&", "tabularadjustboxtab", ":", "basaelinestableLink", "Prediction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adamic adar"}, {"tokens": ["The", "generalized", "approach", "for", "architecture", "or", "ontology", "of", "a", "QA", "system", "and", "semantic", "search", "must", "focus", "to", "bring", "all", "state", "-", "of", "-", "the", "advancement", "of", "QA", "under", "a", "single", "umbrella", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["FatSegNet", "PipelineThe", "FatSegNet", "is", "to", "be", "deployed", "as", "a", "post", "-", "processing", "adipose", "analysis", "pipeline", "for", "the", "abdominal", "Dixon", "MR", "images", "acquired", "in", "the", "Rhineland", "Study", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["We", "achieve", "83", "accuracy", "for", "posture", "recognition", "using", "GMM", "with", "angular", "features", "from", "skeletons", "and", "98", "accuracy", "using", "SVM", "with", "HOG", "features", "from", "RGB", "frames", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "histogram of oriented gradient"}, {"tokens": ["An", "additive", "GP", "with", "all", "of", "its", "variance", "coming", "from", "the", "1st", "order", "is", "equivalent", "to", "a", "GAM", ";", "an", "additive", "GP", "with", "all", "its", "variance", "coming", "from", "the", "th", "order", "is", "equivalent", "to", "a", "SE", "-", "GP", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["Feature", "selection", "(", "FS", ")", "plays", "the", "main", "role", "of", "DyFA", ",", "which", "alleviates", "the", "computational", "complexity", "of", "universal", "steganalysis", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feature selection"}, {"tokens": ["tab", ":", "senttabularcccccccData", "&", "2", "&", "3", "&", "4", "&", "5", "&", "6", "&", "7", "Tasks", "&", "28", "&", "56", "&", "84", "&", "42", "&", "86", "&", "126", "tabular[c]@c@Thresholds", "(", "Splits)tabular", "&", "2", "(", "2", ")", "&", "2", "(", "4", ")", "&", "2", "(", "6", ")", "&", "3", "(", "3", ")", "&", "3", "(", "6", ")", "&", "3", "(", "9", ")", "Train", "Size", "&", "120", "&", "60", "&", "40", "&", "80", "&", "40", "&", "26", "STL", "&", "0.429", "(", "0.002", ")", "&", "0.432", "(", "0.001", ")", "&", "0.429", "(", "0.002", ")", "&", "0.400", "(", "0.002", ")", "&", "0.399", "(", "0.003", ")", "&", "0.397", "(", "0.001", ")", "ITL", "&", "0.433", "(", "0.001", ")", "&", "0.440", "(", "0.002", ")", "&", "0.431", "(", "0.001", ")", "&", "0.499", "(", "0.001", ")", "&", "0.486", "(", "0.002", ")", "&", "0.479", "(", "0.001", ")", "SHAMO", "&", "0.423", "(", "0.002", ")", "&", "0.437", "(", "0.006", ")", "&", "0.429", "(", "0.002", ")", "&", "0.498", "(", "0.006", ")", "&", "0.460", "(", "0.002", ")", "&", "0.496"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "single task learning"}, {"tokens": ["SAD", "Results", "on", "Synthetic", "Spheric", "dataset", "(", "40", "db", "noise", ")", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["The", "experimental", "results", "showed", "that", "chaotic", "GWO", "can", "achieve", "results", "that", "are", "more", "accurate", "(", "1", "better", ")", "during", "fewer", "iterations", "(", "68", "less", ")", "compared", "to", "the", "traditional", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "particle swarm optimization"}, {"tokens": ["For", "example", ",", "imagining", "a", "scenario", "that", "a", "sink", "of", "a", "smart", "metering", "sensor", "network", "requests", "an", "AP", "to", "forward", "the", "collected", "data", "to", "a", "user", "'s", "mobile", "phone", ",", "the", "AP", "first", "checks", "whether", "the", "mobile", "phone", "is", "in", "its", "vicinity", "to", "decide", "whether", "to", "forward", "the", "data", "by", "itself", "or", "to", "relay", "the", "data", "to", "other", "APs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Similarly", ",", "one", "finds", "S.", "Tati", "kelma", "'", "worm", "'", "NP", "kirm", ";", "S.", "Tati", "anjila", ",", "Vidari", "injil", "NP", "anjir", "'", "fig", "'", "(", "forms", "elsewhere", "in", "Iranian", "point", "to", "*", "r", ",", "e.g.", ",", "Sogdian", "ancer", ",", "anjer", ";", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["The", "effectiveness", "of", "the", "proposed", "approach", "compared", "to", "the", "baseline", "IB", "and", "the", "TPIB", "systems", "is", "demonstrated", "on", "standard", "NIST", "and", "AMI", "conversational", "meeting", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Parameters", "Used", "in", "Simulations", "LTE", "-", "Advanced", "is", "adopted", "as", "the", "cellular", "air", "interface", "while802.11n", "with", "a", "frame", "aggregation", "level", "of", "15", "K", "Bytes", "is", "used", "for", "the", "WiFi", "air", "interface", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Our", "construction", "put", "in", "the", "context", "of", "other", "OT", "extensions", "are", "presented", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["SAMSAabl", "does", "not", "penalize", "cases", "where", "the", "number", "of", "sentences", "in", "the", "simplified", "output", "is", "lower", "than", "the", "number", "of", "events", "contained", "in", "the", "input", ",", "indicating", "separate", "semantic", "units", "that", "should", "be", "split", "into", "individual", "target", "sentences", "for", "obtaining", "minimal", "propositions.(Prior", "work", "on", "syntactic", "TS", "commonly", "also", "reports", "average", "BLEU", "scores", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "target syntactic"}, {"tokens": ["In", "order", "to", "differentiate", "these", "cases", ",", "we", "introduce", "the", "observation", "that", "correspond", "to", "the", "raw", "sensor", "data", ",", "and", "use", "the", "term", "state", "only", "to", "refer", "to", "low", "dimensional", "representations", "that", "can", "be", "provided", "by", "humans", ",", "or", "can", "be", "learned", "using", "SRL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "state representation learning"}, {"tokens": ["This", "is", "a", "deterministic", "setting", ",", "hence", "the", "experiment", "is", "designed", "to", "showcase", "how", "the", "convex", "IB", "Lagrangians", "allow", "to", "explore", "the", "IB", "curve", "in", "a", "setting", "where", "the", "normal", "IB", "Lagrangian", "can", "not", "and", "the", "relationship", "between", "the", "performance", "plateaus", "and", "the", "clusterization", "phenomena", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Because", "the", "sketch", "is", "generated", "by", "concealing", "the", "final", "codeword", "with", "an", "RV", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "resilience vector"}, {"tokens": ["Contrary", "to", "existing", "works", "such", "as", ",", "which", "have", "studied", "FD", "MIMO", "systems", ",", "we", "focus", "on", "massive", "MIMO", "systems", ",", "and", "examine", "the", "impact", "of", "SI", ",", "when", "RS", "transmission", "is", "applied", "at", "the", "second", "link", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["This", "is", "further", "reinforced", "by", "the", "fact", "that", "because", "many", "IS", "study", "programs", "tend", "to", "be", "marketed", "as", "programs", "\"", "excluding", "the", "hard", "math\"(Below", "are", "some", "exemplary", "quotes", "from", "webpages", "of", "academic", "institutions", "providing", "both", "CS", "and", "IS", "degrees", "on", "the", "comparison", "between", "the", "two", ":", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["BS", "-", "67", "RS"], "acronym_pos": [0, 0, 0, 1], "long_form": "randomly sampled"}, {"tokens": ["Our", "results", "reveal", "why", "DMD", "will", "succeed", "in", "unmixing", "Gaussian", "time", "series", "while", "kurtois", "-", "based", "ICA", "fails", ",", "and", "also", "why", "applying", "DMD", "to", "a", "multivariate", "mixture", "of", "Fourier", "series", "type", "data", ",", "like", "in", "the", "eigen", "-", "walker", "model", ",", "can", "better", "reveal", "non", "-", "orthogonal", "mixing", "matrices", "in", "a", "way", "that", "PCA", "fundamentally", "can", "not", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["We", "show", "mean", "AUC", "and", "AP", "with", "standard", "error", "over", "10", "runs", "with", "random", "weight", "initializations", "on", "fixed", "data", "splits", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["Compared", "with", "the", "source", "tasks", "of", "SAR", "land", "cover", "classification", "and", "MSTAR", "target", "recognition", ",", "the", "features", "in", "the", "first", "layer", "of", "perform", "well", "on", "generalizing", "but", "show", "much", "specificity", "in", "higher", "layers", ",", "performing", "a", "significant", "drop", "when", "transferring", "and", "freezing", "the", "second", "to", "fifth", "convolution", "layers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Feature", "maps", "are", "actively", "determined", "by", "the", "MAD", "unit", ",", "using", "a", "selective", "vector", "to", "decide", "the", "attention", "of", "neurons", "from", "both", "low", "-", "level", "and", "high", "-", "level", "layers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["The", "Receiver", "Operating", "Characteristic", "(", "ROC", ")", "curve", "is", "a", "graphical", "plot", "that", "illustrates", "the", "performance", "of", "a", "binary", "classifier", "system", "as", "its", "discrimination", "threshold", "is", "varied", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["Due", "to", "wireless", "interference", "constraint", ",", "the", "BS", "can", "only", "send", "one", "update", "to", "a", "single", "user", "at", "each", "time", "slot", ",", "which", "imposes", "the", "following", "constraint", "on", "scheduling", "decisions", ":", "Age", "of", "Information", "and", "Age", "of", "SynchronizationTo", "demonstrate", "the", "concept", "of", "AoI", "and", "AoS", ",", "let", "us", "consider", "a", "single", "source", "discrete", "time", "scenario", "as", "an", "example", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["We", "set", "the", "parameters", "for", "the", "algorithms", "in", "our", "portfolio", "to", "the", "following", ":", "the", "size", "of", "reservation", "tables", "used", "for", "FAR", "is", ";", "the", "window", "size", "of", "WHCA", "*", "is", ",", "the", "lookahead", "value", "of", "BMAA", "*", "is", "and", "BMAA"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "flow annotation replanning"}, {"tokens": ["The", "detail", "discussion", "and", "comparison", "between", "LDP", "and", "CDP", "is", "discussed", "in", "the", "section", ".There", "are", "some", "industry", "standard", "like", "RAPPOR", "in", "Google", ",", "Apple", "'s", "Differential", "privacy", "etc", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["The", "macrocell", "BS", "is", "responsible", "in", "gathering", "the", "information", "about", "the", "network", "traffic", "within", "its", "cell", "and", "makes", "the", "right", "decision", "using", "the", "proposed", "solutions", "to", "determine", "the", "active", "BSs", "and", "the", "drones", "to", "be", "used", "in", "the", "next", "time", "slots", "according", "to", "the", "energy", "availability", "at", "the", "drones", "'", "batteries", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Such", "security", "is", "measured", "in", "term", "of", "conditioned", "maximum", "probability", "in", "getting", "similar", "RV", "within", "a", "maximum", "achievable", "tolerance", "distance", "over", "given", "any", "input", "distribution", "and", "a", "noisy", "string", "over", "some", "random", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["The", "SFM", "was", "extended", "by", "several", "researchers", "such", "as", "to", "cope", "with", "some", "of", "its", "problems", "like", "the", "treatment", "of", "inertia", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "social force model"}, {"tokens": ["proposed", "PSO", "-", "based", "chaotic", "Grey", "Wolf", "Optimizer", "algorithm", "for", "dynamic", "controller", "allocation", "in", "a", "SDN", "cloud", "-", "based", "5", "G", "cellular", "networks", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["In", "this", "work", ",", "we", "aim", "to", "optimize", "the", "deployment", "of", "DBSs", "in", "the", "geographical", "area", "covered", "by", "the", "macrocell", "BS", "according", "to", "the", "network", "'s", "need", "and", "QoS", "requirements", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "framework", "is", "implemented", "and", "evaluated", "in", "a", "fully", "autonomous", "SAR", "system", "deployed", "in", "homes", "for", "session", "-", "based", ",", "single", "-", "subject", "interventions", "with", "17", "child", "participants", "diagnosed", "with", "ASD", "aged", "3", "to", "7", "years", "old", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "validation", "error", "is", "calculated", "by", "summing", "over", "CTC", "loss", "on", "1500", "validation", "samples", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["Here", ",", "model", "selection", "is", "made", "by", "observing", "where", "the", "error", "in", "estimating", "the", "ACE", "stabilises", "(", "anywhere", "between", "4", "-", "7", "mixture", "components", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average causal effect"}, {"tokens": ["The", "MSC", "features", "are", "generic", "and", "can", "be", "easily", "applied", "to", "any", "CF", "-", "based", "trackers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "correlation filter"}, {"tokens": ["BNN", "estimates", "the", "posterior", "over", "network", "weights", "while", "optimizing", "the", "training", "objective", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian neural networks"}, {"tokens": ["In", "the", "interpretation", "of", "the", "MAD", ",", "it", "is", "important", "to", "keep", "in", "mind", "that", "overall", "about", "of", "the", "publications", "have", "been", "awarded", "in", "the", "REF", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "median absolute difference"}, {"tokens": ["The", "population", "size", "for", "all", "DE", "-", "based", "methods", "is", ",", "and", "for", "all", "CMA", "-", "ES", "-", "based", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Currently", ",", "most", "researches", "have", "been", "focused", "on", "improving", "the", "recognition", "accuracy", "of", "DCNN", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["The", "VQA", "dataset", "is", "an", "image", "QA", "dataset", "containing", "images", "with", "around", "questions", "on", "average", "per", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["w", "s", "g", "&", "Special", "English", "&", "c", "w", "a", "&", "E", "-", "Prime", "&", "c", "w", "g", "&", "Plain", "Language", "2132", "&", "c", "s", "d", "g", "&", "CAA", "Phraseology", ",", "FAA", "Phraseology", ",", "ICAO", "Phraseology", ",", "PoliceSpeak", ",", "SEASPEAK", "2133", "&", "c", "w"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "civil aviation authority"}, {"tokens": ["Most", "of", "the", "popular", "variants", "of", "PSO", "can", "easily", "be", "adapted", "into", "this", "2D", "learning", "framework", "for", "feature", "selection", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["In", "this", "paper", ",", "we", "will", "explore", "transfer", "learning", "focusing", "on", "SAR", "target", "recognition", "in", "a", "further", "way", "and", "try", "to", "discover", "more", "properties", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Determining", "if", "the", "synthetic", "MR", "images", "are", "visually", "realistic", "or", "not", "was", "done", "via", "a", "perceptual", "study", "by", "one", "of", "the", "authors", "(", "Anders", "Eklund", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["In", "fact", ",", "the", "RB", "protocol", "is", "the", "case", "of", "non", "-", "coherent", "communication", "and", "thus", "has", "the", "expected", "gain", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random beamforming"}, {"tokens": ["Using", "quantum", "tunneling", ",", "the", "QA", "provides", "a", "useful", "heuristic", "algorithm", "to", "solve", "the", "hard", "problem", "that", "is", "surrounding", "many", "local", "minima", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "quantum annealing"}, {"tokens": ["Let", "the", "IB", "curve", "defined", "as", "in", "Definition", "be", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["For", "key", "-", "only", "sort", ",", "our", "best", "achieved", "throughputs", "are", "1.05x", ",", "0.78x", ",", "and", "0.88x", "times", "the", "throughput", "that", "CUB", "provides", "for", "Tesla", "K40c", "(", "ECC", "on", ")", ",", "Tesla", "K40c", "(", "ECC", "off", ")", ",", "and", "GeForce", "GTX", "1080", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["None", "&", "1.70", "&", "6.70", "&", "9.50", "&", "7.65", "Denoise", "&", "1.54", "&", "7.20", "&", "8.00", "&", "8.43", "BL", "+", "TM", "&", "2.65", "&", "8.67", "&", "7.54", "&", "11.33", "BL", "+", "WB", "+", "TM", "&", "1.95", "&", "8.77", "&", "8.02", "&", "10.96", "ISP", "w/o", "denoise", "&", "2.45", "&", "8.50", "&", "8.35", "&", "14.00Full", "ISP", "&", "3.15", "&", "9.90", "&", "8.65", "&", "14.95", "tabularTop-1", "test", "accuracy", "on", "real", "data", "for", "MobileNets", "trained", "on", "simulated", "data", "(", "MN", "=", "MobileNet", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Since", "the", "QA", "models", "usually", "take", "word", "embeddings", "as", "input", ",", "we", "need", "to", "ensure", "that", "the", "word", "embeddings", "in", "these", "two", "languages", "are", "in", "the", "same", "space", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["We", "proceed", "with", "the", "derivation", "of", "the", "DE", "of", "each", "term", "in", "eq", ":", "theorem2.I.mu1", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deterministic equivalent"}, {"tokens": ["Comparative", "AnalysisIn", "the", "following", ",", "we", "compare", "our", "TS", "framework", "with", "state", "-", "of", "-", "the", "-", "art", "rule", "-", "based", "syntactic", "TS", "approaches", "and", "discuss", "the", "strengths", "and", "weaknesses", "of", "each", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["ADEPOS", "with", "B", "-", "OCC", "enables", "saving", "in", "energy", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "one class classifier"}, {"tokens": ["According", "to", ",", "the", "methods", "of", "AML", "are", "focused", "on", "two", "general", "axes", ":", "i", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarial machine learning"}, {"tokens": ["An", "overview", "of", "deep", "learning", "-", "based", "approaches", "for", "FER", "is", "given", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["As", "in", ",", "SLNR", "method", "fixes", "the", "power", "allocation", "factors", "for", "both", "confidential", "signal", "and", "AN", ",", "and", "the", "power", "allocation", "factor", "for", "confidential", "signal", "is", "much", "higher", "than", "that", "of", "AN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "artificial noise"}, {"tokens": ["High", "PRR", "(", "HP", ")", "scheduling", "is", "the", "second", "algorithm", "where", "the", "node", "with", "higher", "has", "higher", "priority", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "packet reception rate"}, {"tokens": ["From", "the", "PDP", "of", "groundnut", ",", "an", "increase", "in", "the", "amount", "of", "average", "and", "minimum", "temperatures", "result", "in", "a", "decrease", "in", "the", "yield", "of", "groundnut", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial dependence plots"}, {"tokens": ["In", "the", "deterministic", "settings", ",", "UE", ",", "SUE", "or", "RUE", "simultaneously", "determines", "the", "mean", "path", "/", "link", "flow", ",", "and", "the", "route", "choice", "probability", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equilibrium"}, {"tokens": ["The", "discriminator", "receives", "two", "sets", "of", "inputs", ":", "generated", "LR", "image", "with", "downsampled", "groundtruth", "heatmaps", "and", "generated", "LR", "images", "with", "predicted", "heatmaps", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["The", "pipeline", "of", "the", "optimal", "bandwidth", "selection", "method", ",", "using", "PSO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "MAD", "is", "defined", "as", "and", "the", "MAPD", "is", "defined", "as", "where", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "median absolute difference"}, {"tokens": ["Figure", "5", "illustrates", "that", "SC", "of", "all", "schemes", "increases", "linearly", "with", "the", "increasing", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["In", "contrast", ",", "our", "algorithm", "is", "able", "to", "use", "information", "from", "prior", "calls", "to", "the", "LAP", "solver", ",", "and", "therefore", "solves", "a", "series", "of", "LAP", "problems", "whose", "sizes", "are", "monotonically", "nonincreasing", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear assignment problem"}, {"tokens": ["uses", "a", "custom", "LSTM", "topology", "along", "with", "CTC", "alignment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["Following", ",", "we", "randomly", "hold", "out", "5,000", "QA", "pairs", "from", "the", "original", "training", "set", "as", "our", "validation", "set", ",", "and", "take", "the", "remaining", "pairs", "as", "our", "new", "training", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "reranking", "and", "predicted", "frame", "systems", "are", "both", "preferred", "to", "TS", ",", "though", "the", "gap", "is", "smaller", "with", "the", "predicted", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature - based sampling"}, {"tokens": ["In", "the", "supplementary", "document", ",", "we", "are", "providing", "the", "expressions", "for", "the", "PDF", "of", "CD", "and", "NND", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "contact distance"}, {"tokens": ["Considering", "9-bin", "histogram", "of", "gradients", "over", "pixels", "sized", "cells", ",", "and", "blocks", "of", "cells", ",", "we", "extract", "9576", "dimensional", "HOG", "feature", "vector", "for", "each", "image", "of", "size", "120", "*", "160", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "histogram of gradients"}, {"tokens": ["[", "Carrying", "conditions", "and", "angle", "variations][Cloth", "and", "angle", "variations][Mean", "under", "different", "conditions", "]", "Comparison", "of", "CCR", "under", "different", "conditions", "for", "body", "-", "part", ",", "whole", "-", "body", "and", "VI", "-", "MGR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["The", "drones", "can", "land", "at", "pre", "-", "planned", "locations", "defined", "by", "the", "mobile", "operator", "and", "at", "the", "macrocell", "BS", "site", "where", "they", "can", "charge", "their", "batteries", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "a", "particular", "case", "of", "the", "MR", ",", "it", "translates", "to", "the", "simplest", "form", ":", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "majority rule"}, {"tokens": ["Again", ",", "we", "believe", "this", "is", "due", "to", "our", "approach", "using", "a", "RV", "instead", "of", "the", "BEV", "representation", "used", "in", "the", "previous", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "range view"}, {"tokens": ["As", "a", "result", ",", "the", "proposed", "learning", "framework", "is", "generic", "and", "it", "can", "be", "used", "to", "adapt", "any", "PSO", "variant", "for", "feature", "selection", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["On", "a", "whole", ",", "BOA", "performs", "similarly", "to", "GA", "and", "DE", "in", "terms", "of", "optimizing", "the", "minimum", "damping", "coefficient", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["PA", "-", "RTC", ":", "formula", "and", "easyinclusion", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "peano 's arithmetics"}, {"tokens": ["This", "is", "due", "to", "a", "combination", "of", "the", "reduction", "in", "number", "of", "neurons", "(", "Section", ")", "along", "with", "reduced", "number", "of", "operations", "due", "to", "the", "choice", "of", "algorithm", "(", "B", "-", "OCC", "as", "opposed", "to", "AE", "-", "OCC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "one class classifier"}, {"tokens": ["The", "fourth", "attention", "region", "covers", "most", "part", "of", "'", "K", "'", ",", "the", "AN", "model", "thus", "returns", "a", "'", "K", "'", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["Multilayer", "Perceptron", ",", "LR", "=", "Logistic", "Regression", ","], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Target", "-", "domain", "prediction", ":", "mean", "predicted", "difficulty", "values", "of", "control", "algorithms", "(", "JC", ",", "SC", ",", "CC", ",", "and", "CFB", ")", "and", "target", "configurations", "(", "T1", ",", "T2", ",", "T3", ",", "and", "T4", ")", "based", "on", "different", "features", "(", "Physiological", "and", "Kinematic", "features", ")", "as", "input", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "steering control"}, {"tokens": ["It", "is", "obvious", "that", ",", "this", "means", "the", "AN", "has", "no", "impact", "on", "Bob", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Furthermore", ",", "because", "of", "the", "extra", "computation", "involved", "in", "DTP", ",", "it", "is", "also", "far", "slower", "than", "LRA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "difference target propagation"}, {"tokens": ["Recall", "that", "when", "the", "cumulative", "coherence", "is", "1", ",", "according", "to", "the", "rate", "for", "MP", "in", "there", "is", "no", "linear", "convergence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["Fortunately", ",", "the", "DMP", "co", "-", "processor", "of", "the", "MPU6050", "already", "implements", "these", "features", "very", "efficiently", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "digital motion processor"}, {"tokens": ["In", "this", "case", ",", "the", "finite", "mixture", "model", "is", "called", "as", "Gaussian", "mixture", "model", "(", "GMM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["TAM"], "acronym_pos": [1], "long_form": "transparent attention model"}, {"tokens": ["The", "RV", "strategy", "is", "also", "applied", "in", "post", "-", "outbreak", "scenarios", "where", "proportion", "of", "neighbour", "nodes", "of", "an", "infected", "node", "are", "chosen", "for", "vaccination", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["Compression", "resultsTables", "and", "summarise", "the", "compression", "results", "of", "ViSTRA2", "for", "JVET", "CTC", "test", "sequences", "when", "integrated", "with", "HM", "16.20", "and", "VTM", "4.01", ",", "using", "PSNR", "and", "VMAF", "as", "quality", "metrics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "common test conditions"}, {"tokens": ["Besides", ",", "on", "Wiki", ",", "DeepWalk", "with", "GPA", "gives", "us", "gain", "in", "micro", "-", "F1", "score", "and", "gain", "in", "macro", "-", "F1", "score", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["TP", ",", "FP", ",", "TN", ",", "FN", "are", "respectively", "True", "Positive", ",", "False", "Positive", ",", "True", "Negative", ",", "False", "Negative", "samples", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "true positives"}, {"tokens": ["They", "also", "propose", "a", "modified", "BNN", ",", "where", "they", "adopt", "the", "strategy", "of", "increasing", "the", "number", "of", "filters", ",", "to", "compensate", "for", "accuracy", "loss", "similar", "to", "wide", "reduced", "-", "precision", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary neural networks"}, {"tokens": ["LTE", "for", "Vehicular", "Networking", ":"], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["We", "also", "include", "TS", "."], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "temperature scaling"}, {"tokens": ["If", "not", ",", "the", "unlabeled", "SAR", "images", "also", "help", "as", "transitive", "transfer", "1", "shows", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["G", "-", "CTS", "and", "G", "-", "ACK", "have", "the", "identical", "frame", "structure", ",", "where", "the", "receiver", "address", "field", "is", "removed", "and", "replaced", "by", "the", "Group", "-", "ID", "field", "in", "the", "IEEE", "802.11ac", "PHY", "frame", ",", "while", "a", "transmitter", "address", "field", "is", "added", "to", "indicate", "the", "AP", "address", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "access point"}, {"tokens": ["We", "demonstrate", "that", "different", "aspects", "of", "linguistic", "structure", "are", "learned", "at", "different", "rates", "within", "a", "single", "recurrent", "layer", ",", "acquiring", "POS", "tags", "early", "but", "continuing", "to", "learn", "global", "topic", "information", "later", "in", "training", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["A", "surprising", "observation", "is", "the", "performance", "of", "LND", ",", "as", "in", "the", "experiments", "of", "CD", "has", "constantly", "outperformed", "LND", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "cosine distance"}, {"tokens": ["Then", ",", "in", "Section", "we", "outline", "the", "important", "results", "used", "about", "the", "IB", "curve", "in", "deterministic", "scenarios", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["This", "value", "was", "chosen", "because", "it", "showed", "a", "good", "tradeoff", "between", "QoE", "and", "network", "overhead", "in", "several", "PLR", ";", "(", "3", ")", "the", "adaptive", "FEC", "-", "based", "mechanism", "(", "uavFEC", ")", ",", "presented", "in", "Section", ";", "(", "4", ")", "a", "related", "work", "implementation", "of", "the", "Cross", "-", "Layer", "Mapping", "Unequal", "Error", "Protection", "(", "CLM", "-", "UEP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Mirrored", "disks", "in", "increasing", "order", "of", "their", "MTTDL", "are", "ID", ",", "GRD", ",", "CD", ",", "BM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["Intuitively", ",", "because", "BQ", "are", "important", "to", "MQ", ",", "the", "weights", "of", "BQ", "also", "can", "be", "considered", "as", "importance", "scores", "and", "the", "BQ", "with", "larger", "weight", "means", "more", "important", "to", "MQ", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["AR", "on", "PASCAL", "VOC", "is", "reported", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0], "long_form": "average recall"}, {"tokens": ["It", "forces", "the", "DG", "community", "to", "be", "closer", "to", "the", "negative", "class", "whereas", "the", "FG", "community", "is", "placed", "further", "away", "from", "the", "negative", "class", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "favoured granted"}, {"tokens": ["To", "improve", "on", "these", "issues", ",", "the", "MINT", "-", "FEC", "mechanism", "was", "proposed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Dense", "segmentation", "annotations", "for", "HR", "images", "are", "obtained", "by", "manually", "correcting", "initial", "segmentations", "generated", "with", "a", "semi", "-", "automatic", "multi", "-", "atlas", "segmentation", "method", ",", "and", "all", "the", "annotations", "are", "performed", "on", "the", "HR", "images", "to", "minimise", "errors", "introduced", "due", "to", "LR", "in", "through", "plane", "direction", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["A", "binary", "vector", "is", "introduced", "to", "indicate", "the", "status", "of", "each", "ground", "MBS", "and", "is", "given", "by", ":", "It", "should", "be", "noted", "that", "we", "always", "keep", "the", "macrocell", "BS", "active", "to", "ensure", "coverage", "and", "minimum", "connectivity", "in", "this", "typical", "HetNet", "(", "i.e.", ",", "one", "macrocell", "BS", "surrounded", "by", "multiple", "of", "MBSs", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["This", "is", "particularly", "important", "since", "SAD", "is", "sensitive", "to", "large", "variations", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["It", "is", "however", "observed", "that", "the", "convergence", "time", "of", "BOA", "is", "much", "lower", "as", "compared", "to", "GA", "and", "DE", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "differential evolution"}, {"tokens": ["The", "parameters", "used", "for", "calculating", "DI", "in", "the", "previous", "section", "i.e.", "NDL", ",", "NTF", "and", "NSIM", "can", "be", "used", "as", "features", "associated", "with", "each", "article", "instance", "in", "the", "bag", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "document index"}, {"tokens": ["Herein", "we", "compare", "the", "performance", "of", "GP", "emulators", "built", "using", "approaches", ",", "which", "we", "call", "mechanistic", "emulation", ",", "and", "which", "we", "call", "data", "-", "driven", "emulation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["QA", "systems", "may", "be", "built", "for", "a", "specific", "domain", ",", "but", "also", "be", "tilted", "towards", "more", "open", "domain", "questions", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "union", "of", "proposals", "generated", "by", "PIN", "and", "IRN", "is", "referred", "to", "as", "\"", "candidate", "proposals", "\"", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["Also", ",", "our", "experience", "has", "shown", "that", "it", "is", "easier", "to", "move", "from", "being", "a", "CS", "major", "to", "an", "IS", "major", "than", "the", "other", "way", "around", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["Total", "training", "runtime", "comparison", "(", "in", "mins", ")", "between", "Global", "-", "INF", "and", "LR", "approach", "centeringConclusion", "and", "Future", "WorkIn", "this", "paper"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["The", "number", "of", "documents", "(", ")", "versus", "the", "number", "of", "LScD", "words", "appearing", "in", "more", "than", "documents", "in", "the", "LSC", "for", "(", "a", ")", "and", "(", "b", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["They", "first", "fine", "-", "tune", "two", "DCNN", "models", "to", "perform", "audio", "and", "visual", "emotion", "recognition", "tasks", "respectively", "on", "the", "corresponding", "labeled", "speech", "and", "face", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["He", "has", "been", "working", "on", "the", "systems", "design", "for", "LTE", "MAC", "/", "RLC", "/", "PDCP", "/", "RRC", "layer", "implementations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Furthermore", ",", "so", "far", ",", "we", "have", "only", "evaluated", "the", "two", "algorithms", "MP", "and", "CF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "collaborative filtering"}, {"tokens": ["(", "a", ")", ",", "CC", "has", "been", "estimated", "for", "all", "papers", "in", "Phys", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaboration coefficient"}, {"tokens": ["The", "BS", "uses", "the", "functions", "and", "where", "is", "the", "th", "row", "of", "matrix", "and", "we", "define", "the", "functions", "and", "in", "Algorithm", "1", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "for", "the", "UE", "are", "determined", ",", "based", "on", "UE", "measurements", "of", "the", "received", "downlink", "RSRQ", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["For", "these", "reasons", ",", "we", "develop", "ARD", "for", "distilling", "a", "variety", "of", "teachers", "in", "order", "to", "produce", "robust", "students", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["We", "train", "the", "model", "for", "epochs", "with", "an", "early", "stopping", "patience", "of", "and", "for", "the", "LA", "and", "PA", "tasks", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["We", "design", "our", "decentralized", "approach", "via", "a", "non", "-", "cooperative", "CSG", "with", "the", "following", "properties", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "cost sharing game"}, {"tokens": ["The", "analysis", "shows", "that", "RV", "strategy", "requires", "to", "70", "of", "nodes", "to", "be", "vaccinated", "and", "AV", "strategy", "requires", "40", "of", "nodes", "to", "be", "vaccinated", "for", "safe", "prevention", "whereas", "IMV", "strategy", "requires", "only", "2", "nodes", "to", "be", "vaccinated", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["Both", "OMP", "and", "OLS", "can", "be", "used", "to", "approximate", "the", "sparsest", "solution", "in", "eq", ":", "l0", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["If", "a", "GPS", "method", "is", "formulated", "as", "described", "in", "Section", "and", "Hyp", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["Among", "them", ",", "LambdaMART", ",", "CA", "and", "SS", "all", "had", "more", "than", "1", "improvement", "in", "NCE", "compared", "to", "baseline", ",", "while", "RankSVM", "have", "around", "0.38", "improvement", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["SRNN", "-", "POS", "-", "X", "and", "BRNN", "-", "POS", "-", "X", "refer", "to", "our", "RNN", "variants", ":", "In", "means", "input", "layer", ",", "H1", "means", "first", "hidden", "layer", "and", "H2", "means", "second", "hidden", "layer", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "user", "power", "allocation", "and", "the", "receiver", "coefficient", "design", "sub", "-", "problems", "are", "solved", "through", "the", "GP", "approach", "and", "the", "generalized", "eigenvalue", "problem", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["ROC", "curve", "showing", "predictive", "performance", "of", "the", "meta", "-", "learner", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "published", "papers", "have", "been", "classified", "into", "five", "different", "categories", "and", "discussion", "related", "to", "their", "problem", "formulation", ",", "PSO", "methodology", "used", ",", "testing", "of", "the", "technique", "for", "the", "formulated", "model", ",", "the", "output", "results", ",", "and", "its", "effectiveness", "have", "been", "analyzed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Therefore", ",", "ECS", "-", "DBN", "with", "evolutionary", "algorithm", "to", "find", "the", "appropriate", "misclassification", "costs", "is", "quite", "efficient", "for", "imbalanced", "multiclass", "classification", "and", "thus", "makes", "ECS", "-", "DBN", "to", "be", "applicable", "in", "diagnostic", "module", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "this", "section", ",", "the", "energy", "efficiency", "of", "the", "SBS", "cooperation", "strategy", "with", "the", "received", "signal", "power", "constraint", "is", "analyzed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["The", "authors", "of", "investigated", "the", "maximization", "of", "the", "minimum", "SINR", "for", "an", "RIS", "-", "assisted", "multi", "-", "user", "MISO", "scheme", "in", "rank", "-", "one", "or", "full", "-", "rank", "LOS", "channels", "between", "the", "BS", "and", "the", "RIS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "first", "one", "is", "the", "adaptive", "cross", "-", "layer", "VIdEo", "-", "aWare", "FEC", "-", "based", "Mechanism", "with", "Unequal", "Error", "Protection", "scheme", "(", "ViewFEC", ")", "in", "Section"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "accordance", "with", "the", "architecture", "shown", "in", "Figure", "fig", ":", "ANN1", ",", "the", "goal", "of", "ANN", "is", "to", "find", "the", "set", "of", "weights", "that", "will", "map", "accurately", "to", "the", "exact", "output", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["In", "spite", "of", "all", "these", "technological", "advancements", "there", "are", "some", "challenges", "in", "AR", "that", "needs", "to", "be", "worked", "on", "and", "requires", "proper", "study", "as", "well", "as", "research", "in", "order", "to", "get", "more", "from", "AR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "augmented reality"}, {"tokens": ["NBC", "has", "the", "advantage", "of", "adapting", "the", "model", "complexity", "(", "i.e.", ",", "the", "number", "of", "clusters", ")", "to", "the", "amount", "of", "data", "available", ",", "and", "thus", "avoiding", "the", "problem", "of", "over", "-", "fitting", "and", "under", "-", "fitting", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "non - parametric bayesian classification"}, {"tokens": ["PS", "satisfies", ",", ",", "and", "."], "acronym_pos": [1, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["Energy", "Efficiency", "of", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAMEnergy", "efficiency", "is", "the", "ratio", "of", "ergodic", "sum", "channel", "capacity", "(", ")", "and", "the", "total", "transmitted", "power", "by", "the", "BS", "for", "direct", "transmissions", "and", "transmission", "power", "from", "CCU", "for", "relaying", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "this", "example", ",", "we", "will", "further", "illustrate", "that", "the", "norm", "of", "residual", "generated", "by", "OLS", "is", "smaller", "than", "OMP", "but", "they", "are", "both", "not", "optimal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["CNet", "-", "NIC", "ArchitectureFig", "."], "acronym_pos": [0, 0, 1, 0, 0], "long_form": "neural image caption"}, {"tokens": ["Moreover", ",", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "scheme", "provides", "higher", "EE", "than", "other", "schemes", "due", "to", "higher", "SC", "can", "be", "achieved", "by", "different", "OAM", "mode", "based", "transmission", "from", "BS", "to", "the", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Similarly", ",", "TI", "also", "uses", "an", "additive", "correction", ",", "although", "the", "idea", "is", "to", "increase", "the", "constellation", "size", "so", "that", "each", "of", "the", "points", "in", "the", "original", "basic", "constellation", "can", "be", "mapped", "into", "several", "equivalent", "points", "in", "the", "expanded", "constellation", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tone injection"}, {"tokens": ["In", "Public", "Health", ",", "the", "MAD", "is", "slightly", "higher", "than", "percentage", "points", "in", "PP", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "median absolute difference"}, {"tokens": ["Arguing", "that", "the", "points", "in", "the", "worst", "-", "case", "distribution", "are", "most", "close", "to", "each", "other", ",", "it", "must", "offer", "highest", "probability", "of", "success", "in", "getting", "a", "similar", "RV", "within", "distance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["To", "overcome", "the", "limitations", "of", "closed", "domain", "QA", "systems", ",", "researchers", "have", "shifted", "their", "focus", "to", "open", "domain", "QA", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["Aiming", "at", "recognizing", "the", "SAR", "ship", "targets", "of", "OpenSARShip", "dataset", "with", "only", "hundreds", "of", "labeled", "images", ",", "the", "first", "thought", "would", "be", "transferring", "layers", "from", "a", "close", "dataset", "such", "as", "MSTAR", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["We", "refer", "to", "the", "proposed", "approach", "as", "DDE", "-", "MGM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "markov geographic model"}, {"tokens": ["It", "also", "utilizes", "the", "efficacy", "of", "interaction", "measurements", "like", "MDR", "CCR", "and", "Rule", "Utility", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "multifactor dimensionality reduction"}, {"tokens": ["In", "accordance", "with", "the", "standard", "-greedy", "methodology", "typically", "seen", "in", "reinforcement", "learning", ",", "at", "each", "epoch", ",", "for", "some", "preset", ",", "the", "algorithm", "takes", "a", "backpropagation", "update", "with", "probability", "and", "a", "FA", "/", "DFA", "step", "with", "probability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["For", "the", "hidden", "layer", "of", "TAAN", ",", "we", "assume", ":", "if", ",", "there", "exists", "a", "GMM", "with", "diagonal", "covariance", "matrix", "in", "each", "component", "and", "a", "positive", "scalar", "such", "that", "the", "pre", "-", "activation", "satisfies", ",", "where", "is", "the", "data", "input", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["When", "an", "attacker", "-", "controlled", "UI", "element", "is", "presented", "underneath", "a", "trustworthy", "but", "transparent", "element", ",", "this", "gives", "the", "attacker", "limited", "control", "over", "the", "trustworthy", "element", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user interface"}, {"tokens": ["Computational", "State", "Space", "Models", "(", "CSSM", ")", "CSSMs", "allow", "the", "knowledge", "-", "based", "construction", "of", "state", "spaces", "for", "BF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "bayesian filtering"}, {"tokens": ["Figure", "7", "shows", "that", "the", "proposed", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "provides", "better", "SC", "than", "other", "schemes", "for", "different", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["The", "FJ", "power", "is", "traded", "as", "a", "single", "object", ",", "and", "the", "sources", "only", "bid", "zero", "or", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["An", "instance", "of", "PSC", "problem", "consists", "of", "a", "ground", "set", "and", "a", "family", "of", "subsets", "and", "a", "coverage", "requirement", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial set cover"}, {"tokens": ["We", "also", "observe", "that", "BS", "consistently", "performs", "better", "thanother", "individual", "ranking", "functions", "in", "median", "rank", "metric", ",", "i.e.", ",", "it", "rarely", "places", "a", "relevant", "to", "the", "end", "of", "the", "list", ",", "which", "is", "one", "of", "our", "desired", "features", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian sets"}, {"tokens": ["Katta06:Solution", "mention", "that", "PS", "can", "be", "extended", "to", "partial", "orders", "but", "we", "are", "not", "aware", "of", "a", "(", "formal", "or", "informal", ")", "work", "that", "explicitly", "defines", "such", "an", "extension", "and", "studies", "its", "properties", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["Buttons", "are", "generated", "in", "a", "matrix", "format", "defined", "in", "the", "system", "based", "on", "patient", "'s", "range", "of", "movements", "(", "ROM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "range of motion"}, {"tokens": ["[", "Downlink", "-", "dominant", ":", "STA", "Mbps", ",", "AP", "Mbps][PP", "Scenario", ":", "STA", "Mbps", ",", "AP", "Mbps]Average", "delay", "against", "Figure", "shows", "the", "-st", "round", "collision", "probability", "increases", "with", "and", "converges", "when", "the", "system", "becomes", "saturated", ",", "which", "confirms", "the", "down", "/", "up", "-", "link", "saturation", "trend", "as", "discussed", "in", "Figures", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Logic", ",", "however", ",", "does", "not", "appear", "to", "be", "in", "this", "intersection", "-", "almost", "none", "of", "the", "IS", "undergraduate", "study", "programs", "include", "such", "course", "in", "their", "curriculum", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": [":", "This", "is", "the", "traditional", "WLAN", "traffic", "scenario", ",", "where", "the", "AP", "manages", "a", "much", "heavier", "traffic", "load", "compared", "to", "that", "of", "STAs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Specifically", ",", "to", "solve", "Problem", ",", "one", "should", "check", "whether", "Problem", "is", "feasible", "or", "not", "for", "each", "given", "user", "set", "and", "each", "given", "set", "of", "UE", "-", "RRH", "associations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "number", "of", "comparisons", "(", "computing", "the", "number", "of", "edges", "in", "the", "shortest", "path", ")", "required", "for", "computing", "a", "single", "MACS", "score", "is", "twice", "of", "times", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "mean average conceptual similarity"}, {"tokens": ["As", "discussed", "in", "Section", ",", "in", "the", "most", "PSO", "variants"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "particle swarm optimization"}, {"tokens": ["In", "addition", ",", "DyFA", "applied", "a", "hybrid", "FA", "which", "combines", "the", "filter", "method", "(", "t", "-", "test", "and", "regression", ")", "and", "wrapper", "method", "for", "FS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "feature selection"}, {"tokens": ["The", "results", "were", "evaluated", "for", "50", "different", "speakers", "from", "two", "different", "databases", "(", "SRE-18", "and", "YOHO)The", "speaker", "models", "were", "constructed", "and", "classified", "using", "two", "well", "-", "defined", "classifiers", "based", "on", "GMM", "-", "UBM", "and", "i", "-", "Vector", "-", "PLDA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Figure", "contrasts", "the", "HKL", "hull", "-", "selection", "method", "with", "the", "Additive", "GP", "hyperparameter", "-", "learning", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["-Greedy", "methodsThis", "method", "takes", "a", "reinforcement", "learning", "viewpoint", "on", "the", "problem", ",", "framing", "the", "step", "taken", "by", "backpropagation", "as", "a", "'", "greedy", ",", "'", "or", "exploitative", "update", ",", "with", "the", "update", "taken", "by", "FA", "/", "DFA", "as", "an", "exploratory", "step", "over", "the", "loss", "surface", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["While", "for", "specific", "priors", "(", "with", "precision", "kernels", "given", "by", "differential", "operators", ")", "an", "exact", "treatment", "in", "terms", "of", "solutions", "of", "ODEs", "or", "PDEs", "is", "possible", ",", "we", "will", "again", "resort", "to", "the", "sparse", "GP", "approximation", "instead", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["PIN", "takes", "each", "query", "phrase", "and", "image", "as", "input", "and", "in", "two", "stages", ",", "retrieves", "a", "set", "of", "\"", "indexed", "region", "proposals", "\"", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "proposal indexing network"}, {"tokens": ["DCNN", "includes", "convolutional", "layers", ",", "fully", "connected", "layers", ",", "pooling", "layers", "for", "feature", "extraction", ",", "image", "representation", ",", "and", "dimensionality", "reduction", "respectively", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["More", "precisely", ",", "represents", "a", "family", "of", "MPC", "algorithms", "in", "which", "a", "specific", "instance", "is", "defined", "by", "a", "choice", "of", ":", "the", "MPC", "objective", "in", "eq", ":", "per", "-", "round", "loss", ",", "the", "form", "of", "the", "control", "distribution", ",", "andthe", "Bregman", "divergence", "in", "eq", ":", "DMD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["Table", "shows", "the", "average", "integrality", "gaps", "(", "given", "the", "best", "known", "upper", "bound", ",", "from", "PSPLIB", "and", "MISTA", "websites", ",", "and", "an", "obtained", "dual", "bound", ",", "the", "integrality", "gap", "is", "computed", "as", "follows", ":", ",", ")", "and", "the", "average", "computing", "times", "in", "seconds", "that", "have", "been", "obtained", "with", "the", "original", "LP", "relaxations", "and", "the", "strengthened", "LR", "for", "the", "instances", "from", "PSPLIB", "and", "MISTA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lp relaxation"}, {"tokens": ["Efficiency", "of", "DDE", "-", "MGM", "(", "experiments", "on", "the", "PAMAP", "dataset", ")"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Similar", "to", "CF", "task", ",", "the", "CTR", "data", "likelihood", "is", ":", "Then", "the", "factorisation", "machine", "with", "logistic", "activation", "function", "is", "adopted", "to", "model", "the", "click", "probability", "over", "a", "specific", "ad", "impression", ":", "where", "is", "modelled", "by", "interactions", "among", "3-side", "featuresDual", "-", "Task", "BridgeTo", "model"], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["have", "discussed", "the", "merits", "and", "demerits", "of", "PSO", "in", "solving", "ELD", "problems", "of", "power", "system", "operations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Other", "models", "focus", "only", "on", "the", "performance", "of", "the", "QA", "taskmodelsemisupervised", ",", "modelqgforqa", "and", "not", "explicitly", "on", "the", "quality", "of", "the", "generated", "questions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["In", "another", "study", "commissioned", "by", "the", "The", "Royal", "Society", "UK", ",", "BGT", "data", "were", "analysed", "for", "DSA", "jobs", "in", "the", "UK", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["Using", "terrestrial", "networks", ",", "the", "UAV", "sends", "the", "images", "and", "their", "GPS", "locations", "to", "the", "GCS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["This", "ability", "was", "confirmed", "through", "the", "simulation", "results", "where", "the", "ViewFEC", "mechanism", "outperformed", "non", "-", "adaptive", "FEC", "-", "based", "schemes", "in", "both", "the", "video", "quality", "and", "the", "network", "overhead", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "healthy", "pigs", "which", "are", "free", "from", "ASF", "infection", "are", "classified", "as", "Susceptibles", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "african swine fever"}, {"tokens": ["We", "study", "how", "the", "channel", "access", "parameterscan", "be", "tuned", "for", "the", "IFW", ",", "which", "uses", "the", "WiFi", "air", "interface", ",", "and", "for", "theDBF", ",", "which", "uses", "the", "LTE", "air", "interface", "in", "the", "unlicensed", "band", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "trained", "ANN", "is", "used", "for", "all", "the", "test", "recordings", "independently", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Section", "and", "Section", "introduce", "cost", "-", "sensitive", "deep", "belief", "network", "and", "present", "the", "proposed", "ECS", "-", "DBN", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Technically", ",", "the", "distance", "between", "documents", "in", "VSM", "is", "calculated", "by", "comparing", "the", "deviation", "of", "angles", "between", "vectors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vector space model"}, {"tokens": ["This", "leads", "to", "a", "lower", "classification", "accuracy", "and", "hence", "a", "lower", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "average precision"}, {"tokens": ["This", "can", "be", "attributed", "to", "the", "presence", "of", "data", "from", "two", "different", "sources", "in", "the", "RS", "-", "task", "which", "was", "also", "discussed", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random split"}, {"tokens": ["Metaio", "was", "a", "major", "player", "in", "distribution", "of", "AR", "technology", "to", "developers", "through", "their", "SDK", ",", "which", "ends", "abruptly", "now", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Related", "WorkMost", "QA", "work", "focuses", "on", "understanding", "text", "documents", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["More", "importantly", ",", "CNet", "-", "NIC", "substantially", "outperforming", "the", "competing", "methods", "on", "CIDEr", "-", "D", ",", "a", "variant", "of", "the", "CIDEr", ",", "the", "only", "measure", "that", "is", "designed", "explicitly", "for", "evaluating", "image", "captioning", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural image caption"}, {"tokens": ["Based", "on", "Theorem", "3", ",", "an", "implementation", "of", "the", "common", "fairness", "protocol", "at", "the", "BS", "is", "outlined", "by", "Algorithm", "2", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["For", "each", "of", "these", "modes", "of", "the", "residual", "GMM", ",", "we", "can", "reverse", "engineer", "a", "hypothetical", "Gaussian", "measurement", "noise", "that", "if", "applied", "to", "the", "system", "in", "isolation", "would", "generate", "a", "Gaussian", "residual", "equal", "to", "that", "mode", "of", "the", "residual", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["To", "explicitly", "show", "how", "fast", "DDE", "-", "MGM", "can", "model", "a", "streaming", "time", "series", ",", "we", "investigate", "the", "maximally", "-", "allowed", "streaming", "rate", "-", "the", "maximum", "points", "from", "the", "time", "series", "that", "can", "be", "updated", "to", "the", "MGM", "model", "in", "one", "second", ",", "as", "shown", "in", "the", "last", "row", "of", "Table", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Besides", ",", "while", "formerly", "proposed", "approaches", "start", "with", "the", "identification", "of", "candidate", "argument", "pairs", ",", "ReVerb", "follows", "a", "relation", "-", "centric", "approach", "by", "first", "determining", "relational", "phrases", "that", "satisfy", "above", "-", "mentioned", "constraints", ",", "and", "then", "finding", "a", "pair", "of", "NP", "arguments", "for", "each", "such", "phrase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "noun phrase"}, {"tokens": ["The", "RA", "is", "bandwidth", "-", "optimal", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "ring allreduce"}, {"tokens": ["sec", ":", "text", ":", "one", "built", "from", "the", "texts", "VSM", ",", "and", "another", "built", "from", "the", "semantically", "enriched", "texts", "VSM+Sem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vector space model"}, {"tokens": ["Overall", ",", "the", "performance", "of", "these", "methods", "with", "regard", "to", "the", "reconstruction", "error", "are", "COLS", "OLS", "OMP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["In", "contrast", ",", "a", "general", "IR", "based", "QA", "system", "comprises", "question", "processing", "(", "to", "extract", "the", "query", "from", "the", "input", "and", "to", "determine", "the", "answer", "type", ")", ",", "passage", "retrieval", ",", "document", "retrieval", ",", "passage", "extraction", ",", "and", "finally", "answer", "selection", "depending", "on", "the", "relatedness", "of", "the", "named", "entities", "found", "to", "the", "question", "keyword", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Assume", "that", "the", "AP", "has", "perfect", "CSI", ",", "and", ",", "the", "uplink", "achievable", "rate", "from", "the", "-th", "sensor", "for", "the", "MRC", "/", "MRT", "processing", "scheme", "at", "the", "HAP", "can", "be", "lower", "bounded", "as:-1.2emMoreover", ",", "if", "and", "becomes", "infinity", ",", "then-1.1emproof", ":", "The", "proof", "follows", "from", "the", "convexity", "of", "and", "using", "Jensen", "'s", "inequality", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Furthermore", ",", "the", "s", "-", "RNNs", "performed", "comparably", "to", "the", "LSTMs", "in", "many", "of", "the", "SP", "experiments", ",", "and", "in", "fact", "out", "-", "performed", "the", "LSTMs", "on", "the", "most", "complex", "SP", "learning", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Each", "word", "includes", "three", "features", "Word", ",", "POS", "tag", "and", "position", "(", "which", "is", "a", "pairs", "of", "related", "distances", "to", "both", "target", "entities", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["Profiling", "indicates", "that", "on", "many", "graphs", ",", "both", "RBP", "and", "RS", "spend", "more", "than", "90", "of", "runtime", "during", "the", "sort", "-", "and", "-", "select", "step", ",", "up", "to", "98", "for", "certain", "runs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["The", "input", "is", "the", "current", "belief", "state", "computed", "by", "the", "DST", "module", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["(", "a", ")", "RGB", "(", "b", ")", "IMSHARP", "(", "c", ")", "BF", "(", "d", ")", "GF", "(", "e", ")", "WLS", "(", "f", ")", "BFWLSAVG", "(", "g", ")", "FCMAX", "(", "ours", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bilateral filtering"}, {"tokens": ["For", "more", "details", "of", "the", "hybrid", "IB", "/", "FE", "framework", ",", "please", "refer", "to", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "immersed boundary"}, {"tokens": ["Another", "possible", "avenue", "is", "to", "work", "on", "the", "application", "of", "metaheurisitc", "algorithms", "like", "TS", "or", "other", "evolutionary", "computing", "or", "nature", "inspired", "algorithm", "for", "threat", "detection", "and", "feature", "selection", "because", "these", "optimization", "algorithms", "have", "also", "shown", "better", "results", "in", "other", "domains", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["(", "1x", ")", "6*turn90K40c", "(", "ECC", "off)turn", "&", "3*turn0key", "-", "onlyturn", "&", "WMS", "&", "17.57", "(", "1.35", "x", ")", "&", "16.47", "(", "1.26", "x", ")", "&", "13.36", "(", "1.04", "x", ")", "&", "10.18", "(", "0.80", "x", ")", "&", "7.80", "(", "0.68", "x", ")", "&", "-", "&", "-", "&", "-", "&", "&", "BMS", "&", "15.26", "(", "1.17", "x", ")", "&", "13.89", "(", "1.06", "x", ")", "&", "12.76", "(", "0.99", "x", ")", "&", "10.91", "(", "0.85", "x", ")", "&", "9.49", "(", "0.82", "x", ")", "&", "6.85", "(", "1.06", "x", ")", "&", "4.53", "(", "0.70", "x", ")", "&", "2.68", "(", "0.42", "x", ")", "&", "&", "CUB", "&", "13.05", "(", "1x", ")", "&", "13.06"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["OEC", "has", "smaller", "values", "than", "sk", "-", "means", ",", "which", "indicate", "that", "in", "this", "dataset", ",", "OEC", "results", "in", "a", "better", "separation", "between", "the", "expected", "clusters", "than", "sk", "-", "means", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["The", "number", "of", "documents", "(", "n", ")", "versus", "the", "number", "of", "LScDC", "words", "contained", "in", "n", "or", "less", "documents", "in", "the", "LSC", "(", "for", "those", "words", "appearing", "in", "at", "most", "30", "documents", ")", "after", "cleaning", "words", "appearing", "in", "not", "greater", "than", "10", "(", ")", "documents", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["The", "algorithm", "is", "similar", "to", "RV", ";", "for", "all", "groups", "the", "fundamental", "matrices", "are", "estimated", "using", "the", "initial", "labels", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random voting"}, {"tokens": ["[", "CC", ",", "35", "runs", ",", "12", "clust", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "connected caveman"}, {"tokens": ["gmm", ":", "select", ":", "whereIn", "the", "original", "GMM", "work", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["GCS", "locates", "GPS", "coordinates", "for", "the", "targeted", "objects", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["Finally", ",", "hybrid", "approaches", "combine", "CB", "and", "CF", "methods", "to", "overcome", "their", "specific", "limitationsburke2002", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["ModelOpen", "-", "domain", "QA", "systems", "aim", "to", "find", "an", "answer", "for", "a", "given", "question", "from", "a", "massive", "article", "collection", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Misclassified", "digits", "by", "DBN", "."], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "deep belief network"}, {"tokens": ["Currently", ",", "we", "focus", "on", "popularity", "and", "CF", "-", "based", "recommendation", "algorithms", ",", "but", "the", "RE", "module", "could", "be", "easily", "extended", "with", "further", "algorithms", "as", "well", "(", "e.g.", ",", "content", "-", "based", "filtering", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["However", ",", "we", "consider", "that", "the", "transmission", "of", "the", "private", "message", "takes", "place", "by", "using", "RZF", "due", "to", "the", "prohibitive", "complexity", ",", "as", "mentioned", "in", "a", "previous", "section(Note", "that", "an", "extra", "gain", "of", "RS", "over", "NoRS", "can", "be", "achieved", "by", "jointly", "optimizing", "the", "power", "allocation", "as", "well", "as", "the", "precoders", "of", "the", "common", "and", "private", "messages", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["Hall", "-", "DMD", "show", "that", "the", "dynamic", "regret", "of", "DMD", "scales", "with", "how", "much", "the", "optimal", "decision", "sequence", "deviates", "from", "(", "i.e.", ",", ",", "which", "is", "proportional", "to", "the", "unpredictable", "elements", "of", "the", "problem", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["The", "reasons", "for", "that", "are", "twofold", ":", "1", ")", "the", "AP", "traffic", "load", "is", "inherently", "higher", "than", "that", "of", "STAs", ",", "and", "2", ")", "the", "AP", "adopts", "the", "frame", "aggregation", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Thus", "using", "PAP", "optimized", "all", "-", "reduce", "algorithm", "can", "decrease", "the", "elapsed", "time", "by", "or", "less", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["The", "main", "contributions", "of", "our", "work", "are", "as", "follows", ":", "enumerate", "a", "novel", "loss", "that", "facilitates", "using", "a", "GAN", "to", "sample", "from", "the", "manifold", "geometry", "the", "cycle", "-", "consistent", "alignment", "framework", "of", "the", "MGM", "GAN", "demonstration", "of", "the", "difference", "between", "density", "generation", "and", "geometry", "generation", "on", "many", "datasetsenumeratePrevious", "WorkMuch", "work", "has", "been", "devoted", "to", "the", "topic", "of", "modeling", "manifold", "geometry", ",", "largely", "focused", "on", "graph", "and", "distance", "based", "methods", "tenenbaum2000global", ",", "lindenbaum2018geometry", ",", "wang2013manifold", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["In", "this", "work", ",", "they", "implement", "a", "DTN", "routing", "protocol", "on", "the", "top", "of", "traditional", "and", "unmodified", "AODV", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "disruption tolerant networking"}, {"tokens": ["Considering", "the", "aforementioned", "issues", ",", "this", "chapter", "describes", "the", "design", "and", "evaluates", "three", "adaptive", "FEC", "-", "based", "mechanisms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["acl_natbibPerformance", "Out", "Of", "DomainBecause", "SEM", "tags", "and", "PTB", "POS", "tags", "were", "both", "trained", "on", "the", "GMB", "corpus"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["NCE", "is", "based", "on", "Shannon", "entropy", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0], "long_form": "normalized cumulative entropy"}, {"tokens": ["In", "our", "test", "items", ",", "the", "coordinated", "subject", "NP", "is", "followed", "by", "a", "predicative", "adjective", ",", "which", "either", "takes", "on", "masculine", "or", "feminine", "gender", "morphology", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "noun phrase"}, {"tokens": ["SVM", "provides", "testing", "accuracy", ",", "whereas", "DBN", "produces", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "downlink", "transmission", "from", "BS", "to", "the", "users", "is", "performed", "by", "two", "consecutive", "phases", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["[", "cloud", ",", "below", "of", "=", "gc", ",", "node", "distance", "=", "2", "cm", "]", "(", "m", ")", "Race", "Classification", ";", "[", "cloud", ",", "below", "of", "=", "init", ",", "node", "distance", "=", "2", "cm", "]", "(", "f", ")", "Race", "Classification", ";", "[", "block3", ",", "below", "left", "of", "=", "m", ",", "node", "distance", "=", "1.5", "cm", "]", "(", "of", ")", "BM", "Age", "Estimator", ";"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "black males"}, {"tokens": ["A", "SP", "grammar", "is", "a", "set", "of", "-subsequences", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["The", "downside", "is", "that", "they", "lead", "to", "a", "lower", "FEC", "encoding", "efficiency", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Here", ",", "the", "CNN", "-", "BLSTM", "encoder", "transforms", "an", "input", "image", "into", "high", "level", "sequence", "of", "features", ",", "the", "RNN", "decoder", "generates", "each", "target", "character", ",", "and", "FN", "focuses", "the", "attention", "of", "AN", "on", "the", "right", "target", "character", "regions", "in", "the", "input", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["(", "b", ")", "GP", "-", "PF", ";", "(", "c", ")", "BS", ";", "(", "d", ")", "LESF", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "the", "parallel", "stream", "model", ",", "there", "are", "competing", "and", "parallel", "streams", "of", "MB", "and", "MF", "learning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "model - based"}, {"tokens": ["This", "provides", "three", "advantages", ":", "i", ")", "like", "GPR", ",", "NP", "provides", "the", "necessary", "estimates", "of", "predictive", "uncertainty", "at", "test", "time", ";", "ii", ")", "similar", "to", "MT", "-", "GPR", ",", "it", "provides", "the", "possibility", "of", "learning", "structured", "variation", ";", "and", "iii", ")", "unlike", "alternatives", ",", "it", "is", "computationally", "scalable", "without", "restrictive", "assumptions", "on", "the", "orthogonality", "of", "lower", "dimensional", "representations", "of", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["In", "particular", "set", "of", "16", ",", "17", ",", "30", ",", "50", "and", "50", "significant", "calls", "filtered", "with", "WFS", "(", "GS", ")", ",", "CFS", ",", "IG", ",", "CHI", ",", "and", "SU", "are", "grouped", "together", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "genetic search"}, {"tokens": ["These", "meshes", "are", "then", "rigidly", "aligned", "using", "Generalised", "Procrustes", "Analysis", "(", "GPA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "generalized procrustes analysis"}, {"tokens": ["In", "Bayesian", "approach", ",", "GMM", "parameters", "are", "also", "modeled", "with", "probability", "distributions", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["To", "address", "the", "problem", ",", "proposes", "a", "harvest", "-", "then", "-", "transmit", "protocol", "in", "a", "WPCN", "with", "a", "single", "-", "antenna", "HAP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "hybrid access point"}, {"tokens": ["noted", "that", ",", "in", "a", "latent", "feature", "model", ",", "the", "possible", "combinations", "of", "latent", "features", "is", ",", "compared", "to", "the", "possible", "combinations", "of", "group", "memberships", "in", "an", "SBM", ",", "and", "so", "standard", "Gibbs", "samplers", "are", "unlikely", "to", "be", "scalable", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Most", "of", "these", ",", "including", ",", "require", "accurate", "knowledge", "of", "the", "channel", "from", "all", "potential", "users", "to", "the", "BS", "-which", "in", "Massive", "MIMO", "case", "is", "completely", "infeasible", "to", "obtain", ";", "proposed", "a", "greedy", "user", "selection", "scheme", "by", "exploiting", "the", "instantaneous", "CSI", "of", "all", "users", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "comparison", ",", "GP", "in", "our", "work", "performs", "RSS", "filtering", "and", "shaping", "automatically", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Starting", "from", "the", "intuition", "that", "low", "-", "level", "linguistic", "information", "is", "useful", "to", "learn", "more", "complex", "taggers", ",", "we", "also", "introduce", "three", "new", "RNN", "variants", "to", "take", "into", "account", "external", "(", "POS", ")", "information", "in", "multilingual", "SST", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "presence", "of", "differential", "equations", "(", "gradients", ")", ",", "random", "choice", "and", "updates", "of", "weights", "are", "the", "keys", "to", "ANN", "success", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Then", ",", "a", "merging", "layer", "is", "trained", "on", "top", "of", "the", "pretrained", "PNN", "and", "RNN", "to", "integrate", "the", "information", "from", "both", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["The", "Adaptive", "Cross", "-", "Layer", "FEC", "(", "ACFEC", ")", "mechanism", "uses", "packet", "-", "level", "error", "correction", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "diagonal", "elements", "(", ")", "of", "the", "stochastic", "block", "matrix", "are", "the", "probabilities", "that", "vertices", "of", "block", "are", "neighbours", ",", "whereas", "the", "off", "-", "diagonal", "elements", "give", "the", "edge", "probabilities", "between", "different", "blocks(In", "another", "definition", "of", "SBM", "the", "number", "of", "edges", "between", "blocks", "and", "is", "fixed", "(", ")", ",", "instead", "of", "the", "edge", "probabilities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Our", "CPN", ":", "(", "PN", "+", "VAT", "+", "ENT", ")", "&", "97.14", "0.16", "&", "44.48", "0.22", "&", "66.94", "0.20"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["c", "Model", "&", "B@1", "&", "B@2", "&", "B@3", "&", "B@4", "&", "M", "&", "R", "&", "C", "NIC", "&", "&", "&", "&", "&", "-", "&", "-", "&", "-", "LRCN", "&", "&", "&", "&", "&", "-", "&", "-", "&", "-", "Soft", "Attention", "&", "&", "&", "&", "&", "&", "-", "&", "-", "Hard", "Attention", "&", "&", "&", "&", "&", "&", "-", "&", "-", "ATT", "&", "&", "&", "&", "30.4", "&", "&", "-", "&", "-", "Sentence", "Condition", "&", "&", "&", "&", "&", "&", "-", "&", "LSTM", "-", "A", "&", "73", "&", "&", "&", "&", "25.1", "&", "53.8", "&", "98.6", "CNet", "-", "NIC", "&", "&", "54.9", "&", "40.5", "&", "&", "&", "&"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural image caption"}, {"tokens": ["The", "higher", "SC", "is", "achieved", "by", "utilizing", "the", "different", "OAM", "modes", "to", "transmitting", "additional", "symbols", "to", "the", "CCU", "and", "CEU", "from", "the", "BS", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["As", "expected", ",", "both", "FEC", "-", "based", "mechanisms", "produce", "more", "valuable", "results", "when", "the", "network", "has", "a", "higher", "PLR", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "Department", "of", "Energy", "will", "provide", "public", "access", "to", "these", "results", "of", "federally", "sponsored", "research", "in", "accordance", "with", "the", "DOE", "Public", "Access", "Plan", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "department of energy"}, {"tokens": ["We", "adopt", "the", "GP", "-", "based", "solution", "to", "optimize", "the", "PS", "ratios", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["The", "distances", "between", "the", "AP", "and", "the", "vehicles", "are", "assumed", "to", "be", "randomly", "generated", "within", "m", "m", ",", "and", "the", "following", "results", "are", "obtained", "by", "averaging", "over", "200", "vehicle", "location", "generations", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["We", "choose", "AP", "as", "our", "starting", "point", "due", "the", "following", "two", "reasons", ":", "AP", "already", "possesses", "many", "desirable", "properties", ",", "for", "example", ",", "no", "need", "for", "a", "(", "hard", ")", "specification", "of", "the", "number", "of", "clusters", ",", "no", "initialization", "issues", "and", "low", "complexity", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["Since", "is", "initialized", "by", "using", "the", "output", "from", "the", "UE", "selection", "algorithm", ",", "is", "a", "feasible", "solution", "of", "Problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["The", "received", "signal", "at", "and", "from", "the", "BS", "by", "different", "OAM", "modes", "are", "given", "belowAccordingly", ",", "the", "received", "SINR", "for", "symbol", "at", "can", "be", "expressed", "as", "[", "27", "-", "31]where", "is", "the", "singular", "value", "of", "the", "channel", "response", "matrix", "of", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "system", "[", "22,27,30].", "OAM", "beam", "has", "divergence", "in", "its", "high", "-", "intensity", "region", "which", "caused", "attenuation", "[", "27", "-", "30]."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Let", "and", "denote", "the", "information", "beamforming", "matrix", "and", "the", "AN", "beamforming", "matrix", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["The", "friendly", "jammers", "act", "as", "the", "sellers", "which", "compete", "for", "selling", "the", "FJ", "powers", "to", "the", "source", "to", "improve", "its", "secrecy", "capacity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["Moreover", ",", "the", "antenna", "electric", "field", "pattern", "can", "be", "given", "byRemark", "1:The", "distance", "between", "the", "BS", "and", "single", "-", "bounce", "cluster", "(", ")", "is", "given", "by", "geometrical", "calculation", ":", "rCl(c_0BS", ",", "C)^2", "&", "=", "&", "(", "h_BS", "-", "h_MS+d_BS", ",", "C())^2", "+", "&", "&", "(", "d_BS", ",", "MS", "-", "d_BS", ",", "C()())^2,where", "denotes", "the", "velocity", "of", "light", ",", "is", "the", "distance", "between", "the", "user", "and", "the", "BS", "in", "plane", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Based", "on", "this", "hypothesis", "and", "by", "adding", "requirements", "restricting", "the", "exploration", "step", "direction", "and", "length", "for", "the", "GPS", "method", ",", "one", "can", "formulate", "Thm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["We", "see", "in", "these", "decision", "boundary", "plots", "that", "knowledge", "distillation", "from", "a", "robust", "teacher", "preserves", "some", "robustness", ",", "while", "ARD", "produces", "a", "student", "who", "closely", "mimics", "the", "teacher", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["It", "also", "utilizes", "the", "efficacy", "of", "interaction", "measurements", "like", "MDR", "CCR", "and", "Rule", "Utility", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["Factorial", "approximations", "is", "used", "in", "DBN", "to", "replace", "the", "intractable", "true", "posterior", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "explicit", "FEM", "solver", "in", "Abaqus", "6.14", "-", "3", "is", "used", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["Using", "expressions", "derived", "in", "Section", ",", "we", "next", "obtain", "closed", "-", "form", "expressions", "for", "the", "statistics", "of", "a", "pure", "RS", "scheme", "that", "combines", "at", "the", "signals", "from", "and", "using", "a", "time", "-", "diversity", "version", "of", "MRD", "as", "well", "as", "of", "a", "rate", "-", "selective", "one", "that", "utilizes", "pure", "RS", "only", "if", "it", "is", "beneficial", "in", "terms", "of", "achievable", "rate", "over", "the", "direct", "transmission", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Subsequently", ",", "in", ",", "the", "authors", "extended", "the", "idea", "of", "to", "multi", "-", "beam", "DM", "scenarios", "in", "broadcasting", "systems", ",", "where", "a", "conditional", "maximizing", "signal", "-", "to", "-", "leakage", "noise", "ratio", "(", "Max", "-", "SLNR", ")", "was", "presented", "to", "design", "the", "beamforming", "vector", "of", "confidential", "messages", "and", "maximizing", "the", "signal", "-", "to", "-", "artificial", "-", "noise", "ratio", "(", "Max", "-", "SANR", ")", "at", "the", "desired", "receivers", "was", "employed", "to", "design", "projection", "matrix", "of", "AN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "artificial noise"}, {"tokens": ["Each", "GP", "in", "the", "iteration", "loop", "(", "line", "3", "-", "7", ")", "tries", "to", "improve", "the", "accuracy", "of", "the", "approximations", "to", "a", "particular", "minimum", "in", "the", "original", "feasible", "region", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["900", "Comparison", "of", "PI", "and", "RQI", "with", "and", "without", "Preconditioning", ",", "11", "Energy", "Sets", "exceeded", "walltime", "limit", "RQI", "Strong", "ScalingAfter", "demonstrating", "that", "RQI", "can", "be", "better", "than", "PI", "for", "a", "real", "problem", ",", "we", "looked", "at", "how", "it", "performs", "in", "a", "strong", "scaling", "study", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["Applying", "DMD", "in", "eq", ":", "DMD", "to", "the", "online", "learning", "problem", "described", "in", "sec", ":", "online", "learning", "setup", "leads", "to", "an", "MPC", "algorithm", "shown", "in", "alg", ":", "dmd", "-", "mpc", ",", "which", "we", "call", "."], "acronym_pos": [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["Compared", "with", "the", "traditional", "synthesis", "method", "that", "implemented", "DM", "at", "RF", "front", "-", "end", ",", "this", "synthesis", "method", "can", "be", "easily", "implemented", "in", "baseband", "signal", "by", "utilizing", "the", "beamforming", "scheme", "and", "added", "AN", ",", "and", "in", "this", "case", ",", "it", "can", "further", "ensure", "that", "different", "constellation", "points", "are", "transmitted", "in", "different", "time", "slots", ",", "in", "other", "words", ",", "the", "dynamic", "DM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["FJ", "power", "allocation", "for", "multiple", "source", "-", "destination", "pairs", "based", "on", "pricing", "models", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["Output", "from", "a", "network", "trained", "on", "downsampled", "version", "of", "HR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "high - resolution"}, {"tokens": ["Correlation", "between", "classification", "accuracy", "and", "upper", "bound", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "average precision"}, {"tokens": ["Only", "deep", "neural", "networks", "-", "based", "architectures", "are", "reported", "in", "this", "comparison", "as", "they", "are", "performing", "better", "than", "shallow", "learning", "-", "based", "methods", "on", "FER", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["The", "large", "area", "under", "the", "ROC", "shows", "that", "more", "true", "cases", "have", "been", "identified", "correctly", "than", "any", "other", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["For", "each", "dataset", ",", "is", "an", "input", "vector", "of", "user", "and", "is", "its", "corresponding", "output(For", "simplicity", ",", "we", "consideran", "FL", "algorithm", "with", "a", "single", "output", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["on", "another", "pass", "in", "the", "FS", ",", "if", "the", "terrain", "is", "zoomed", "in", ",", "details", "are", "going", "to", "be", "further", "added", "through", "the", "introduction", "of", "tiling", "refinement", "with", "fractal", "noise", "and", "displacement", ","], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "fragment shader"}, {"tokens": ["The", "main", "objective", "of", "DDE", "-", "MGM", "is", "computational", "efficiency", "from", "the", "aspects", "of", "both", "computing", "time", "and", "memory", "consumption", ",", "while", "preserving", "superior", "classification", "accuracy", "as", "compared", "to", "the", "state", "-", "of", "-", "the", "-", "art", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Specifically", ",", "GPA", "takes", "two", "phases", "in", "its", "computing", "framework", ",", "namely", "the", "preprocessing", "phase", "and", "the", "initialization", "phase", ",", "as", "shown", "in", "Figure", "fig", ":", "framework", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["Interestingly", ",", "in", "white", "/", "noise", "BG", "and", "object", "-", "only", "cases", ",", "the", "AP", "-", "large", "increases", "but", "the", "AP", "-", "small", "decreases", "(", "compared", "to", "orig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["In", "each", "slot", ",", "the", "BS", "activates", "one", "arm", "and", "sends", "update", "information", ",", "while", "the", "remaining", "arms", "remain", "passive", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "class", "sem", ":", "Event(sem", "is", "the", "prefix", "within", "SEM", "namespace", ",", "https://semanticweb.cs.vu.nl/2009/11/sem/", ")", "indicates", "what", "happened", ",", "the", "class", "sem"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "simple event model"}, {"tokens": ["Because", "the", "samples", "is", "long", "in", "time", "and", "repetitive", "in", "patterns", ",", "e.g.", ",", "walking", "for", "tens", "of", "minutes", ",", "this", "dataset", "is", "adopted", "to", "mainly", "examine", "the", "efficiency", "of", "DDE", "-", "MGM", "in", "aspects", "of", "run", "time", "and", "memory", "cost", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Now", "we", "are", "prepared", "to", "develop", "a", "theoretical", "framework", "to", "analyze", "the", "downlink", "coverage", "probability", "for", "the", "typical", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["[", "CC", ",", "100", "runs", ",", "24", "clust", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "connected caveman"}, {"tokens": ["Parameterization", "Space", ":", "During", "the", "experiments", ",", "we", "used", "DMP", "controllers", "as", "parameterized", "policies", "to", "generate", "time", "-", "bounded", "motor", "actions", "sequences", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic movement primitives"}, {"tokens": ["FR", "and", "XGB", "denote"], "acronym_pos": [1, 0, 0, 0], "long_form": "faster r - cnn"}, {"tokens": ["In", "case", "of", "PS", ",", "developers", "should", "determine", "how", "many", "PS", "nodes", "will", "be", "suitable", "for", "the", "workload", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["have", "proposed", "a", "method", "of", "using", "epidemic", "protocols", "(", "gossip", "protocols", ")", "to", "estimate", "unseen", "neighbors", ",", "which", "has", "made", "it", "possible", "to", "execute", "CF", "algorithms", "in", "a", "decentralized", "setting", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["In", "DST", ",", "it", "captures", "correlation", "between", "the", "decoded", "slots", "easily", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["NP_architecture", "depicts", "a", "schematic", "of", "the", "employed", "NP", "architecture", "with", "detailed", "hyperparameter", "descriptions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "neural processes"}, {"tokens": ["The", "bases", "of", "this", "is", "to", "predict", "RTT", "for", "a", "new", "packet", "sent", "to", "a", "destination", "IP", "via", "particular", "AS", "link", "on", "a", "given", "ISP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "internet service providers"}, {"tokens": ["Average", "Precision", "(", "AP", ")", "against", "log", "size", "(", ")", "of", "the", "1447", "queries", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["presents", "a", "software", "-", "defined", "architecture", "for", "LTE", "system", "modifying", "the", "CN", "as", "well", "as", "RAN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["lemmaproofOutside", ",", "the", "objectives", "and", "coincide", ",", "so", "outside", ",", "the", "MD", "strategy", "from", "Lemma"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["That", "is", ",", "the", "algorithms", "and", "rates", "will", "be", "invariant", "under", "affine", "transformations", "and", "re", "-", "parameterizations", "of", "the", "optimization", "domain", "(", "a", "property", "which", "was", "known", "for", "Newton", "'s", "method", "and", "FW", "methods", ",", "but", "is", "novel", "in", "the", "MP", "context", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["Experiments", "involving", "the", "latter", "datasets", "are", "meant", "to", "test", "the", "applicability", "of", "our", "general", "graph", "and", "polyglot", "method", "to", "related", "SP", "tasks", ",", "and", "are", "also", "used", "for", "comparison", "against", "our", "main", "technical", "documentation", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic parsing"}, {"tokens": ["By", "improving", "the", "evaluation", "prompt", "to", "use", "Edits", "instead", ",", "it", "is", "possible", "to", "further", "reduce", "variance", "relative", "to", "humans", "(", "DE", "is", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "data efficiency"}, {"tokens": ["MPIwithIO", "-", "clusters", "shows", "the", "scaling", "on", "SDSC", "Comet", ",", "LSU", "SuperMIC", ",", "and", "PSC", "Bridges", "using", "MPI", "-", "based", "parallel", "HDF5", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["Within", "the", "range", "of", "vaccination", "rates", ",", "RV", "and", "AV", "strategies", "fail", "to", "contain", "the", "disease", "spreading", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "Bimodal", "network", "has", "a", "much", "lower", "ratio", "between", "the", "FP", "rate", "and", "TP", "high", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "true positives"}, {"tokens": ["For", "this", "simple", "elastic", "dynamics", "problem", ",", "i.e.", ",", "simple", "boundary", "condition", "and", "elastic", "material", "behaviour", ",", "FEM", "is", "a", "well", "-", "established", "and", "deterministic", "method", "to", "calculate", "shock", "-", "induced", "structural", "response", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["ResultsDistinct", "Active", "Sets", "in", "DC-", "and", "AC", "-", "OPF", "SamplesBased", "on", "the", "generated", "samples"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["For", "our", "simulations", ",", "we", "deploy", "users", "uniformly", "in", "a", "square", "area", "of", "size", "m", "m", "with", "the", "BS", "located", "at", "its", "center", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["While", "in", "both", "noiseless", "and", "natural", "differential", "privacy", "definitions", "the", "randomness", "is", "solely", "over", "the", "data", "generating", "distribution", ",", "in", "GDP", "the", "randomness", "is", "both", "over", "the", "data", "generating", "distribution", "and", "the", "randomness", "of", "the", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["rulepropcentertabularlccccccRules", "&", "&", "&", "&", "&", "&", "NS1", "&", "14", "&", "67", "&", "1", "&", "29", "&", "12", "&", "11", "NS2", "&", "40", "&", "21", "&", "42", "&", "36", "&", "68", "&", "32", "GS", "&", "13", "&", "4", "&", "1", "&", "9", "&", "12", "&", "48", "Non", "-", "Pru", "&", "33", "&", "8", "&", "56", "&", "26", "&", "8", "&", "9", "tabularcentertableTesting", "the", "Effectiveness", "of", "Sweep", "Rules", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group sweep"}, {"tokens": ["schmit2017human", "propose", "to", "measure", "RS", "performance", "by", "adapting", "the", "notion", "of", "regret", "from", "the", "multi", "-", "armed", "bandit", "literature", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "recommender systems"}, {"tokens": ["Gaussian", "process", "(", "GP", ")", "models", "can", "powerfully", "perform", "tasks", "such", "as", "classification", "and", "regression", "and", "are", "popular", "algorithms", "in", "machine", "learning", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["They", "also", "combine", "this", "idea", "with", "the", "BBK", "kernel", "and", "follow", "a", "regular", "BO", "procedure", "where", "at", "each", "iteration", "they", "re", "-", "compute", "the", "mean", "function", "of", "the", "GP", "with", "the", "newly", "learned", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Closer", "investigation", "revealed", "that", "some", "employees", "in", "the", "same", "group", "found", "by", "SBM", "talked", "about", "different", "topics", "than", "the", "rest", "of", "the", "group", ",", "hence", "the", "splitting", "of", "a", "group", "into", "smaller", "ones", "found", "by", "STBM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["The", "comparison", "required", "for", "computing", "the", "MACS", "score", "for", "A", "are", ":", ",", ",", ",", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean average conceptual similarity"}, {"tokens": ["In", "LTE", ",", "1", "CCE", "is", "formed", "by", "9", "REGs", "and", "1", "REG", "is", "formed", "in", "turn", "by", "4", "REs", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Some", "real", "LR", "images", "with", "keypoints", "predicted", "from", "the", "are", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["In", "the", "case", "of", "GRD", "and", "RAID0/1", "up", "to", "disks", "on", "either", "side", "can", "fail", "as", "long", "as", "they", "are", "all", "one", "side", ":"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group rotate declustering"}, {"tokens": ["Additionally", ",", "the", "residual", "spatial", "misalignment", "between", "the", "2D", "LR", "stacks", "and", "HR", "volumes", "is", "corrected", "using", "a", "rigid", "transformation", "estimated", "by", "an", "intensity", "based", "image", "registration", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Non", "-", "cooperative", "gameIn", "practice", ",", "a", "source", "can", "be", "equipped", "with", "multiple", "antennas", ",", "and", "it", "can", "generate", "the", "FJ", "signal", "along", "with", "the", "information", "signal", "without", "requiring", "an", "external", "friendly", "jammer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["dB", "over", "IID", "Nakagami-", "fading", "channels", "with", "different", "values", "of", ":", "(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["An", "equilibrium", "is", "used", "to", "model", "deterministic", "route", "choices", "(", "similar", "to", "classical", "UE", "and", "RUE", ")", ",", "while", "neither", "of", "them", "considered", "day", "-", "to", "-", "day", "route", "choice", "variation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equilibrium"}, {"tokens": ["The", "FEM", "has", "several", "benefits", "like", "the", "possibility", "to", "precisely", "represent", "complex", "meshes", "by", "using", "small", "irregular", "volume", "elements", "and", "the", "ability", "to", "compute", "physically", "accurate", "solutions", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["The", "greedy", "search", "in", "BS", "2", "was", "slightly", "more", "likely", "to", "verbatim", "copy", ",", "for", "example", "in", "the", "oil", "image", "where", "it", "obtained", "an", "innovation", "capacity", "of", "as", "opposed", "to", "and", "achieved", "by", "OT", "and", "random", "convolution", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bidirectional similarity"}, {"tokens": ["Instead", ",", "in", "Appendix", ",", "we", "derive", "the", "accurate", "closed", "-", "form", "expression", "of", "data", "rate", "for", "one", "special", "case", "under", "three", "assumptions", ":", "1", ")", "The", "RRH", "serving", "cluster", "is", "the", "same", "as", "the", "CSI", "cluster", "for", "each", "UE", ":", ";", "2", ")", "The", "RRH", "serving", "cluster", "for", "each", "UE", "is", "non", "-", "overlapped", "with", "each", "other", ":", ";", "3", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["These", "systems", "combine", "context", "QA", "systems", "and", "task", "-", "oriented", "dialogue", "systems", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["ET", "-", "Small", "&", "0.78", "&", "0.89", "&", "0.74", "ET", "-", "Large", "&", "0.78", "&", "0.94", "&", "0.75"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "elastic transformations"}, {"tokens": ["The", "LB", "divergence", "is", "derived", "from", "the", "generalized", "Bregman", "divergence", "parameterized", "by", "the", "Lovasz", "extension", "of", "a", "submodular", "function", ",", "where", "a", "submodular", "function", "can", "be", "defined", "via", "the", "diminishing", "return", "property", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["In", "this", "scheme", ",", "the", "set", "of", "selected", "relays", ",", "their", "transmit", "power", "levels", ",", "and", "their", "PS", "ratios", "are", "jointly", "optimized", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["CUB", "'s", "radix", "sort", "greatly", "improves", "on", "Tesla", "K40c", "when", "ECC", "is", "disabled", "(", "Table", "table", ":", "reference", ")", ",", "and", "because", "of", "it", ",", "RB", "-", "sort", "improves", "accordingly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["Concluding", "RemarksWe", "have", "studied", "the", "PHY", "-", "layer", "security", "in", "a", "cooperative", "wireless", "subnetwork", "that", "includes", "a", "source", "-", "destination", "pair", ",", "multiple", "relays", ",", "and", "a", "malevolent", "active", "eavesdropper", ",", "which", "can", "transmits", "AN", "with", "a", "multiple", "-", "antenna", "transmitter", "to", "degrade", "the", "achievable", "secrecy", "rate", "of", "the", "legitimate", "channels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Then", ",", "for", "each", "RBC", ",", "there", "is", "a", "BA", "instance", "to", "agree", "whether", "it", "did", "terminate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary agreement"}, {"tokens": ["We", "then", "analyse", "the", "DSA", "occupations", "according", "to", "each", "of", "these", "five", "variables", "and", "find", "compelling", "evidence", "for", "how", "these", "features", "are", "predictive", "of", "skill", "shortages", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["[", ",", "STA", "Mbps", ",", "AP", "Mbps]Non", "-", "saturated", "throughput", "Average", "delay"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["It", "forces", "the", "DG", "community", "to", "be", "closer", "to", "the", "negative", "class", "whereas", "the", "FG", "community", "is", "placed", "further", "away", "from", "the", "negative", "class", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "favoured granted"}, {"tokens": ["In", "this", "figure", "one", "object", "in", "the", "SEM", "image", "is", "cropped", "and", "classified", "using", "a", "trained", "CNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["NomenclatureADASYN", ",", "SMOTE", "and", "its", "various", "resampling", "methods", "are", "applied", "with", "DBN", "to", "generate", "synthetic", "minority", "data", "on", "the", "imbalanced", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["We", "compare", "the", "performance", "of", "LSTMS", "on", "SP", "languages", "with", "their", "performance", "on", "learning", "SL", "languages", ",", "another", "simple", "class", "of", "regular", "languages", ",", "but", "one", "which", "only", "encodes", "local", "dependencies", "in", "sequences", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Figure", "fig", ":", "ExpertAnnot1", "shows", "an", "example", "with", "two", "consecutive", "slices", "of", "a", "patient", "affected", "with", "CD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "crohn 's disease"}, {"tokens": ["ARD", "not", "only", "produces", "more", "robust", "students", "than", "knowledge", "distillation", ",", "but", "ARD", "also", "works", "for", "teachers", "and", "datasets", "on", "which", "knowledge", "distillation", "is", "ineffective", "for", "transferring", "robustness", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["-0.5emSum", "-", "rate", "versus", "bandwidth", "of", "the", "BS", "(", "users", ",", ",", "and", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["hyper", "-", "parametersThe", "weight", "given", "to", "the", "VAT", "loss", "on", "the", "labelled", "data", "is", "0.2", "for", "all", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["In", "Table", ",", "we", "present", "the", "lengths", "of", "CC", "phases", "of", "top", "14", "models", "and", "notice", "that", "Galaxy", "S2/3/4", "'s", "CC", "phase", "lengths", "are", "close", "to", "what", "we", "measured", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["We", "show", "that", "ECS", "-", "DBN", "allows", "us", "to", "determine", "the", "unknown", "misclassification", "costs", "without", "prior", "domain", "knowledge", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["At", "each", "iteration", "of", "the", "BB", ",", "Algorithm", "is", "executed", "to", "find", "the", "corresponding", "solution", "using", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "geometric programming"}, {"tokens": ["Because", "the", "hyperparameters", "can", "specify", "which", "degrees", "of", "interaction", "are", "important", ",", "the", "additive", "GP", "is", "an", "extremely", "general", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["For", "analytical", "assessment", "of", "the", "PS", ",", "P2P", ",", "and", "RA", "architectures", ",", "we", "develop", "models", "for", "latency", "(", "total", "time", "for", "training", "one", "epoch", ")", ",", "which", "includes", "computing", "time", ",", "and", "communication", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["devised", "a", "three", "-", "factor", "user", "authentication", "scheme", "for", "SG", "environments", "based", "on", "lightweight", "cryptographic", "primitives", "such", "as", "one", "-", "way", "hash", "functions", ",", "bitwise", "XOR", "operations", "and", "ECC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["Assuming", "that", "is", "our", "past", "learned", "variational", "distribution", "and", "we", "want", "to", "infer", "the", "probability", "values", "on", "an", "implicit", "vector", "of", "inducing", "points", ";", "the", "continual", "GP", "prior", "follows", "the", "expressionand", "if", "we", "assume", "that", ",", "this", "is", ",", "evaluate", "the", "conditional", "predictive", "distribution", "on", "the", "future", "inducing", "points", ",", "the", "previous", "formula", "takes", "the", "form", "of", "a", "Gaussian", "distribution", "whose", "expression", "isMulti", "-", "output", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": ["Contour", "estimation", "Tables", "and", "show", "the", "results", "of", "contour", "estimation", "with", "the", "proposed", "GP", "-", "PF", "using", "various", "types", "of", "commonly", "used", "covariance", "functions", "on", "the", "nanoparticles", "dataset", "using", "both", "the", "ground", "truth", "contour", "evidences", "and"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["We", "assume", "that", "a", "dynamic", "drone", "can", "be", "in", "three", "different", "states", ":", "1", ")", "the", "drone", "is", "in", "an", "idle", "mode", "and", "placed", "at", "the", "charging", "station", "assumed", "to", "be", "located", "in", "the", "center", "of", "the", "cell", "(", "i.e.", ",", "in", "the", "macrocell", "BS", "site", ".", ")", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Finally", ",", "we", "inspected", "the", "role", "of", "numerical", "integrators", "in", "the", "sampling", "efficiency", "of", "HMC", "and", "MD", "simulations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["While", "BP", "and", "DTP", "will", "fail", "in", "this", "setting", ",", "DFA", "and", "FA", "will", "not", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "difference target propagation"}, {"tokens": ["We", "found", "the", "best", "word", "vectors", "from", "SSWE", "and", "the", "common", "crawl", "42B", "300", "dimension", "Glove", "vectors", "by", "five", "fold", "stratified", "cross", "validation", "for", "the", "NP", "methods", "and", "the", "highest", "accuracy", "on", "the", "validation", "set", "for", "the", "LSTM", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural pooling"}, {"tokens": ["Motivation", "-", "ContributionsFollowing", "the", "research", "trends", "and", "needs", "in", "massive", "MIMO", "and", "FD", "systems", ",", "we", "consider", "a", "collection", "of", "sources", "communicating", "with", "another", "collection", "of", "destinations", "through", "an", "intermediate", "massive", "MIMO", "FD", "relay", "station", ",", "and", "we", "focus", "on", "the", "application", "of", "RS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "rate saturation"}, {"tokens": ["TREC", "-", "QATable", "reports", "the", "results", "of", "our", "experiments", "with", "TREC", "-", "QA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "question answering"}, {"tokens": ["Indeed", ",", "the", "AIR", "of", "the", "CM", "scheme", "with", "symbol", "-", "wise", "HDD", "is", "much", "worse", "than", "that", "of", "the", "scheme", "with", "SDD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "coded modulation"}, {"tokens": ["ROC", "analysis", "for", "different", "datasets", "used", "in", "this", "paper", ":", "(", "a", ")", "glass5", ",", "(", "b", ")", "yeast6", ",", "(", "c", ")", "yeast5", ","], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": [",", "max^DIThe", "test", "performance", "for", "the", "DI", "case", "does", "not", "depend", "on", ",", "therefore", ",", "for", "the", "DI", "case", "no", "further", "optimization", "is", "needed", "over", "the", "sensing", "matrix", ",", "other", "than", "selecting", "the", "non", "-", "zero", "entries", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "direct inspection"}, {"tokens": ["To", "minimize", "latency", ",", "a", "broadband", "analog", "aggregation", "multi", "-", "access", "scheme", "was", "designed", "in", "for", "FL", "by", "exploiting", "thewaveform", "-", "superposition", "property", "of", "a", "multi", "-", "access", "channel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Different", "from", "ILP", ",", "NLM", "represent", "the", "outputs", "and", "inputs", "of", "neural", "networks", "as", "grounding", "tensors", "of", "predicates", "for", "existing", "facts", "and", "new", "facts", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural logic machines"}, {"tokens": ["In", "the", "second", "time", "slot", ",", "via", "the", "beamforming", "scheme", ",", "the", "DM", "transceiver", "operates", "in", "transmit", "model", ",", "sends", "the", "confidential", "messages", "to", "the", "desired", "user", ",", "and", "projects", "AN", "towards", "the", "eavesdropper", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Multi", "-", "Layer", "Perceptron", "Random", "Forest", "ROC", "curve", ":", "ROC", "curve", "for", "each", "attack", "type", "(", "tuned", "model", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "continuous", "and", "dashed", "black", "lines", "correspond", "to", "the", "forward", "and", "backward", "links", "of", "the", "legitimate", "network", ",", "while", "the", "dashed", "blue", "line", "shows", "the", "AN", "propagated", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Finally", ",", "there", "is", "a", "period", "between", "September", "and", "November", "when", "area", "is", "known", "and", "yield", "can", "be", "estimated", "with", "EO", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "earth observation"}, {"tokens": ["Metric", "We", "measure", "the", "performance", "of", "our", "models", "with", "what", "we", "refer", "to", "as", "the", "turn", "level", "accuracy", "metric", ",", "which", "measures", "the", "ratio", "of", "how", "many", "of", "the", "gold", "turn", "labels", "are", "predicted", "by", "the", "DST", "model", "at", "each", "turn", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["Experimental", "results", "and", "discussionDataset", "descriptionWe", "evaluated", "the", "performance", "of", "DBN", "and", "CNN", "on", "a", "benchmark", "dataset", "called", "CMATERdb", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["It", "is", "concluded", "that", "DE", "is", "more", "efficient", "for", "relay", "node", "deployment", "in", "3D", "settings", "than", "ABC", "and", "GSA", "as", "shown", "in", "the", "experimental", "results", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Importantly", ",", "estimating", "the", "ACE", "only", "requires", "computing", "a", "distribution", "in", "Figure", "fig", ":", "cases", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average causal effect"}, {"tokens": ["The", "channel", "sounding", "time", "and", "the", "CSI", "volume", "are", "proportional", "to", "the", "number", "of", "AP", "'s", "antennas", ",", "which", "would", "occupy", "considerable", "amount", "of", "time", "and", "bandwidth", ",", "especially", "in", "the", "Massive", "MIMO", "case", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Preconditioned", "RQI", "was", "significantly", "faster", "than", "preconditioned", "PI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "power iteration"}, {"tokens": ["ExperimentsDatasetsWe", "generate", "two", "datasets", "SBM", "(", ",", ",", ",", ")", "that", "correspond", "to", "associative", "and", "disassociative", "cases", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["&", "&", "UCSD", "to", "&", "Mall", "to", "Method", "&", "Mall", "&", "UCSD", "FA", "&", "7.47", "&", "4.44", "HGP", "&", "4.36", "&", "3.32", "GPA", "&", "4.18", "&", "2.79", "GPTL", "&", "3.55", "&", "2.91", "Bidirectional", "ConvLSTM", "&", "2.63", "&", "1.82", "-2em"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feature alignment"}, {"tokens": ["Architecture", "of", "the", "proposed", "Consensus", "Attention", "Sum", "Reader", "(", "CAS", "Reader", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "consensus attention sum"}, {"tokens": ["The", "BPM", "values", "were", "computed", "by", "an", "estimation", "algorithm", ",", "as", "part", "of", "the", "Echo", "Nest", "API", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "beat per minute"}, {"tokens": ["Examples", "include", "personalized", "tutoring", "systems", "in", "human", "-", "computer", "interaction", "research", ",", "personalized", "robot", "tutors", "in", "HRI", "and", "SAR", "research", ",", "and", "optimal", "challenge", "points", "and", "the", "Zone", "of", "Proximal", "Development", "methodologies", "in", "education", "research", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["The", "graph", "embedding", "features", "perform", "consistently", "better", "than", "the", "textual", "features", "(", "Topics", ")", "for", "the", "majority", "of", "the", "predictive", "models", "on", "both", "tasks", "except", "for", "the", "LR", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "logistic regression"}, {"tokens": ["The", "final", "version", "of", "the", "pipeline", "uses", "11", "views", ",", "which", "provides", "the", "best", "OS", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "orientation score"}, {"tokens": ["We", "applied", "our", "method", "to", "build", "RNN", "POS", "taggers", "for", "four", "target", "languages", "-", "French", ",", "German", ",", "Greek", "and", "Spanish", "-", "with", "English", "as", "the", "source", "language", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "results", "also", "show", "that", "XOR", "-", "based", "coding", "outperforms", "the", "RLC", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "random linear coding"}, {"tokens": ["Unlike", "the", "DC", "-", "OPF", "case", ",", "the", "gain", "of", "the", "perfect", "classification", "can", "not", "be", "related", "simply", "to", "the", "ratio", "of", "inequality", "and", "equality", "constraints", "anymore", ":", "the", "computationally", "most", "expensive", "part", "is", "the", "calculation", "of", "the", "first", "and", "second", "derivatives", "of", "the", "non", "-", "convex", "equality", "constraints", "that", "are", "always", "binding", "(", "see", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["The", "proposed", "TCR", "method", "obtains", "superior", "performance", "over", "the", "SDM", ",", "which", "assumes", "a", "'", "closed", "world", "'", "training", "/", "test", "environment", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transductive cascaded regression"}, {"tokens": ["OPIUM", "-", "B", "OCC", "not", "only", "consumes", "lesser", "energy", "during", "learning", "and", "inference", "phase", "but", "also", "has", "a", "lower", "memory", "footprint", "than", "existing", "AE", "-", "OCC", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "one class classifier"}, {"tokens": ["If", "the", "detected", "nodule", "of", "center", "within", "one", "of", "ground", "truth", "nodule", "regions", ",", "it", "is", "in", "the", "TP", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "true positives"}, {"tokens": ["Both", "FEC", "and", "ARQ", "methods", "are", "discussed", "below", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["In", "both", "the", "case", "studies", ",", "our", "protocol", "turns", "out", "to", "be", "the", "best", "choice", "among", "the", "actively", "secure", "OT", "extensions", "and", "second", "best", "overall", "closely", "trailing", "KK13", "which", "is", "the", "overall", "winner", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Additionally", ",", "we", "would", "like", "to", "have", "(", "at", "most", ")", "80", "of", "the", "instances", "from", "the", "original", "data", "in", "order", "to", "learn", "the", "classifier", "(", "otherwise", ",", "the", "method", "would", "be", "very", "similar", "to", "CC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "classifier chain"}, {"tokens": ["We", "compare", "the", "results", "with", "those", "found", "by", "the", "basic", "SBM", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["tab", ":", "sentfulltabularccccccccData", "&", "1", "&", "2", "&", "3", "&", "4", "&", "5", "&", "6", "&", "7", "Tasks", "&", "14", "&", "28", "&", "56", "&", "84", "&", "42", "&", "86", "&", "126", "tabular[c]@c@Thresholds", "(", "Splits)tabular", "&", "1", "(", "1", ")", "&", "2", "(", "2", ")", "&", "2", "(", "4", ")", "&", "2", "(", "6", ")", "&", "3", "(", "3", ")", "&", "3", "(", "6", ")", "&", "3", "(", "9", ")", "Train", "Size", "&", "240", "&", "120", "&", "60", "&", "40", "&", "80", "&", "40", "&", "26", "STL", "&", "0.749", "(", "0.003", ")", "&", "0.429", "(", "0.002", ")", "&", "0.432", "(", "0.001", ")", "&", "0.429", "(", "0.002", ")", "&", "0.400", "(", "0.002", ")", "&", "0.399", "(", "0.003", ")", "&", "0.397", "(", "0.001", ")", "ITL", "&", "0.713", "(", "0.002", ")", "&", "0.433", "(", "0.001", ")", "&", "0.440", "(", "0.002", ")", "&", "0.431", "(", "0.001", ")", "&", "0.499", "(", "0.001", ")", "&", "0.486", "(", "0.002", ")", "&", "0.479", "(", "0.001", ")", "SHAMO", "&", "0.721", "(", "0.005", ")", "&", "0.423", "(", "0.002", ")", "&", "0.437", "(", "0.006", ")", "&", "0.429", "(", "0.002", ")", "&", "0.498", "(", "0.006", ")", "&", "0.460", "(", "0.002", ")", "&", "0.496", "(", "0.013", ")", "CMTL", "&", "0.713", "(", "0.002", ")", "&", "0.557", "(", "0.016", ")", "&", "0.436", "(", "0.007", ")", "&", "0.429", "(", "0.004", ")", "&", "0.508", "(", "0.002", ")", "&", "0.486", "(", "0.002", ")", "&", "0.476"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "single task learning"}, {"tokens": ["The", "received", "signal", "in", "the", "LTE", "-", "U", "BSS", "has", "higher", "energy", "on", "average", "for", "more", "Wi", "-", "Fi", "APs", ",", "thus", "there", "are", "differences", "in", "the", "mean", "values", "for", "each", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": [":", "Power", "consumption", "of", "cooling", "at", "CC", "/", "EC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["For", "instance", ",", "let", "us", "imagine", "our", "network", "maps", "all", "class", "prototypes", "to", "the", "same", "point", ",", "producing", "a", "uniform", "class", "distribution", "for", "any", "point", ",", "the", "VAT", "loss", "would", "go", "to", "zero", ",", "the", "entropy", "loss", "would", "be", "maximized", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["However", ",", "in", "SC", ",", "signals", "are", "sent", "over", "all", "three", "links", ",", "and", "the", "hub", "receives", "three", "copies", "of", "the", "signal", ",", "and", "the", "one", "with", "the", "best", "quality", "is", "subsequently", "chosen", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "selection combining"}, {"tokens": ["&", "Less", "than", "1", "Kg", "/", "LAP", "/NA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low altitude platform"}, {"tokens": ["In", "this", "work", ",", "we", "always", "assume", ",", "that", "is", ",", "we", "take", "a", "single", "sample", "per", "each", "independent", "-th", "GP", "prior", ",", "reducing", "coregionalisation", "matrices", "to", "be", "rank", "-", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Taking", ",", ",", "in", "eq", ":", "PVI", ",", "and", ",", "in", "eq", ":", "DPVI", ",", "and", "adding", "the", "obtained", "inequalities", "and", "equations", "to", "eq", ":", "e", ",", "we", "have", "where", "Multiplying", "eq", ":", "h", "by", "and", "summing", "over", ";", ",", "we", "obtain_n=0^m-1", "(", "e_B^n+1-e_B^n", ",", "e_B^n+1)+_n=0^m-1(e_N^n+1-e_N^n", ",", "e_N^n+1", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parabolic variational inequality"}, {"tokens": ["following", "description", "of", "the", "multi", "-", "parameter", "GP", "prior", "is", "built", "on", "the", "heterogeneous", "MOGP", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["h", "]", "Summary", "of", "the", "test", "accuracy", "across", "7", "different", "algorithms", ",", "i.e.", "ECS", "-", "DBN", ",", "DBN", "and", "a", "group", "of", "resampling", "methods", "including", "ADASYN", "-", "DBN", ",", "SMOTE", "-", "DBN", ",", "SMOTE", "-", "borderline1-DBN", ",", "SMOTE", "-", "borderline2-DBN", ",", "SMOTE", "-", "SVM", "-", "DBN", ",", "on", "58", "KEEL", "benchmark", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Pipeline", "-", "based", "QA", ":", "provides", "automatic", "integration", "of", "the", "state", "-", "of", "-", "the", "-", "art", "QA", "implementations", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["where", "basis", "pursuit", "denoising", "(", "BPD", ")", "was", "adopted", "to", "exploit", "the", "sparsity", "of", "vibration", "signals", "in", "different", "domains", "in", "order", "to", "detect", "and", "extract", "fault", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basis pursuit denoising"}, {"tokens": ["In", "MD", ",", "the", "knowledge", "is", "distilled", "from", "the", "more", "complex", "model", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "model distillation"}, {"tokens": ["The", "analog", "precoder", "at", "the", "BS", "is", "and", "the", "analog", "combiner", "at", "each", "user", "is", "where", "is", "the", "quantization", "of", "the", "angle", "in", "the", "parentheses", "according", "to", "the", "resolution", "of", "the", "phase", "shifters", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["However", ",", "IMV", "strategy", "can", "work", "for", "the", "contact", "information", "availability", "of", "50", "of", "the", "nodes", "while", "RV", "and", "AV", "strategy", "fails", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["The", "scheduling", "scheme", "jointly", "considers", "the", "CSI", "history", ",", "the", "AP", "'s", "queueing", "state", "and", "the", "frames", "'", "application", "categories", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Given", "Lemma", ",", "it", "is", "straightforward", "to", "define", "an", "finite", "inner", "product", "and", "distance", "of", "two", "activation", "functions", "as", "the", "integration", "weighted", "by", "a", "Gaussian", "Mixture", "Model", "(", "GMM", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["On", "the", "website", ",", "a", "map", "can", "be", "generated", "using", "the", "GPS", "coordinates", "from", "the", "database", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["PreliminariesThe", "Definition", "of", "the", "LB", "DivergenceThe", "LB", "divergence", "as", "a", "utility", "function", "was", "firstly", "proposed", "by", "and", "this", "can", "be", "used", "for", "measuring", "the", "divergence", "between", "a", "score", "-", "based", "permutation", "and", "an", "order", "-", "based", "permutation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "lovasz bregman"}, {"tokens": ["Finally", ",", "we", "elucidate", "the", "relationship", "between", "FW", "algorithms", "and", "our", "proposed", "generalized", "MP", "variants", ",", "by", "showing", "that", "the", "iterates", "of", "FW", "converge", "to", "those", "of", "MP", "as", ",", "if", "the", "atom", "set", "of", "FW", "is", "scaled", "by", "a", "growing", "factor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "matching pursuit"}, {"tokens": ["Within", "this", "context", ",", "the", "optimal", "receiver", "TS", "strategies", "in", "a", "SISO", "fading", "channel", "under", "co", "-", "channel", "interference", "are", "studied", "in", "to", "maximize", "the", "average", "data", "rate", "under", "an", "average", "EH", "constraint", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time switching"}, {"tokens": ["First", "column", "are", "the", "exemplars", ",", "second", "and", "third", "are", "computed", "with", "OT", ",", "BS", "respectively", "with", "a", "patch", "size", "of", "4", "and", "fourth", "column", "is", "synthesis", "with", "a", "random", "filter", "gram", "loss", "with", "256", "filters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["[", "h]1", "AP", "Overall", ",", "our", "experiments", "show", "that", "and", "NN", "-", "methods", "are", "the", "top", "two", "methods", "with", "excellent", "overall", "performance", "on", "both", "low", "dimensional", "synthetic", "and", "real", "datasets", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["proposed", "an", "overlapping", "model", "that", "is", "similar", "to", "but", "not", "an", "overlapping", "SBM", ",", "because", "the", "connections", "between", "the", "nodes", ",", "which", "they", "called", "actors", ",", "are", "unknown", "in", "the", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Furthermore", ",", "unlike", "DTP", "and", "BP", ",", "DFA", "and", "FA", "can", "train", "networks", "from", "zero", ",", "although", "LRA", "does", "a", "much", "better", "job", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["In", "particular", ",", "for", "each", "AP", ",", "multiple", "packet", "traces", "are", "collected", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["The", "MIFE", "scheme", "also", "guarantees", "that", "the", "decryptor", ",", "the", "aggregator", "in", "our", "FL", "framework", ",", "can", "only", "acquire", "the", "function", "results", ",", "i.e.", ",", "the", "average", "weight", ",", "but", "not", "the", "original", "data", ",", "i.e.", ",", "weights", "of", "the", "participants", "'", "local", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Additionally", ",", "C4.5", "(", "one", "decision", "tree", ")", "significantly", "outperformed", "RF", "and", "GBM", "(", "ensembles", "of", "trees", ")", "on", "the", "EEG", "Eye", "state", "data", "set", "indicating", "that", "an", "exact", "fit", "to", "the", "data", "is", "required", "and", "an", "ensemble", "approach", "will", "not", "be", "specific", "enough", "to", "be", "accurate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["htbp", "]", "Total", "NED", "results", "of", "AN", "and", "FAN", "on", "unconstrained", "benchmarks", "with", "the", "image", "-", "encoder", "released", "by", "Shi", "shi2016robust", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["PIN", "indexing", "performanceSimilar", "to", "Flickr30k", ",", "we", "do", "performance", "analysis", "to", "judge", "the", "effectiveness", "of", "PIN", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "proposal indexing network"}, {"tokens": ["t]ABEP", ",", ",", "of", "DBPSK", "for", "RS", "versus", "the", "average", "relay", "SNR", "per", "bit", ",", ",", "and", "for", "dB", "over", "INID"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["First", "row", ":", "visual", "similarity", "using", "GMM", ",", "the", "measure", "is", "shown", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Univariate", "optimization", "procedures", "such", "as", "Golden", "Section", "Search", "result", "in", "many", "loops", "of", "some", "procedure", "to", "optimize", "over", ",", "which", "in", "our", "restricted", "case", "must", "each", "time", "compute", "a", "full", "solution", "to", "a", "LAP", "with", "weights", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "linear assignment problem"}, {"tokens": ["DiscussionsCompared", "with", "FNN", ",", "PNN", "has", "a", "product", "layer", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Our", "inner", "LAP", "solver", "was", "the", "package", "lapsolver", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "linear assignment problem"}, {"tokens": ["BA", "forms", "a", "balanced", "combination", "of", "PSO", "and", "intensive", "local", "search", "[", "87]."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Moreover", ",", "and", "are", "the", "capacity", "of", "CCU", "and", "CEU", "for", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "technique", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Different", "lengths", "of", "MD", "trajectories", "in", "HMC", "simulations", "were", "also", "explored", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["We", "investigate", "why", "some", "models", "on", "the", "PA", "dataset", "strongly", "outperform", "others", "and", "find", "that", "spoofed", "recordings", "in", "the", "dataset", "tend", "to", "have", "longer", "silences", "at", "the", "end", "than", "genuine", "ones", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "physical access"}, {"tokens": ["In", "each", "iteration", "of", "the", "bisection", "UE", "search", "algorithm", ",", "we", "only", "need", "to", "check", "whether", "the", "C", "-", "RAN", "can", "support", "all", "users", "in", "or", "not", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["It", "can", "be", "seen", "that", "again", "DE", "-", "SB", "and", "CMA", "-", "ES", "-", "SB", "dominate", "the", "performances", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["As", "for", "-iterative", "improvement", ",", "a", "combination", "of", "suffices", "to", "recognize", "all", "those", "characters", "that", "can", "be", "recognized", "by", "DMD", "EMD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "deficient mapping dissolution"}, {"tokens": ["The", "BS", "and", "user", "heights", "are", "assumed", "to", "be", "m", "and", "m", ",", "respectively", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "first", "experiment", ",", "which", "served", "as", "a", "baseline", ",", "was", "carried", "out", "without", "any", "enhancement", "(", "Without", "FEC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "forward error correction"}, {"tokens": ["To", "explore", "this", "question", ",", "we", "imaged", "the", "cortical", "vascular", "networks", "in", "young", "and", "old", "mouse", "models", "of", "AD", "(", "young", "AD", "and", "old", "AD", ")", "and", "their", "young", "and", "old", "WT", "littermates", "(", "young", "WT", "and", "old", "WT", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0], "long_form": "wild type"}, {"tokens": ["For", "practical", "LTE", "networks", ",", "Mogensen", "et", "al", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["This", "paper", "considers", "an", "uplink", "multiuser", "system", "where", "the", "BS", "is", "equipped", "with", "antennas", "and", "serves", "decentralized", "single", "antenna", "users", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Then", ",", "a", "policy", ",", "that", "takes", "a", "state", "as", "input", "and", "outputs", "action", ",", "is", "learned", "to", "solve", "the", "task", ":", "In", "the", "next", "sections", ",", "we", "present", "approaches", "of", "SRL", "that", "are", "implemented", "in", "our", "toolbox", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["KL*KD*ARDAppendixAppendix", "A", ":", "Space", "and", "time", "efficiency", "of", "student", "and", "teacher", "modelsWe", "perform", "our", "primary", "experiments", "for", "ARD", "with", "WideResNet", "(", "34", "-", "10", ")", "and", "ResNet18", "teacher", "models", "as", "well", "as", "a", "MobileNetV2", "student", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["For", "UE", ",", "we", "construct", "an", "environment", "with", "a", "character", "/", "target", "walking", "following", "a", "fixed", "path", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "unreal engine"}, {"tokens": ["Explicitly", ",", "the", "EQPO", "algorithm", "succeeds", "in", "identifying", "almost", "the", "entire", "set", "of", "Parero", "-", "optimal", "routes", ",", "since", "it", "is", "only", "incapable", "of", "identifying", "as", "few", "as", "0.1", "of", "the", "entire", "true", "OPF", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "optimal pareto front"}, {"tokens": ["Evaluating", "TCR", "on", "Common", "Landmarks"], "acronym_pos": [0, 1, 0, 0, 0], "long_form": "transductive cascaded regression"}, {"tokens": ["&", "100", "g", "/", "LAP", "/", "20", "min", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "low altitude platform"}, {"tokens": ["A", "user", "-", "centric", "clustering", "model", ",", "based", "on", "a", "tier", "-", "specific", "RSS", "threshold", ",", "is", "proposed", "in", "for", "SBS", "cooperation", "in", "the", "downlink", "heterogeneous", "cellular", "networks", ",", "and", "a", "power", "minimization", "problem", "with", "a", "minimum", "spectral", "efficiency", "constraint", "is", "formulated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "small - cell base stations"}, {"tokens": ["Training", "on", "such", "a", "large", "dataset", "allows", "DCNN", "to", "learn", "highly", "discriminative", "features", ",", "each", "neuron", "in", "the", "network", "would", "be", "sensitive", "to", "different", "texture", ",", "edge", ",", "corner", "and", "object", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["We", "use", "a", "simple", "(", "multilingual", ")", "vector", "representation", "based", "on", "the", "occurrence", "of", "source", "and", "target", "words", "in", "a", "parallel", "corpus", "and", "we", "let", "the", "RNN", "learn", "the", "best", "internal", "representations", "(", "corresponding", "to", "the", "hidden", "layers", ")", "specific", "to", "the", "task", "(", "SST", "or", "POS", "tagging", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "analysis", "is", "done", "with", "ORL", "and", "IFD", "dataset", ",", "the", "recognition", "performance", "for", "both", "algorithms", "are", "evaluated", "and", "the", "experimental", "results", "shows", "that", "N", "-", "PCA", "gives", "a", "better", "recognition", "rate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "indian face database"}, {"tokens": ["The", "ROC", "score", "is", "in", "the", "interval", ",", "and", "a", "higher", "ROC", "value", "means", "a", "higher", "prediction", "accuracy", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "UE", "admission", "control", "and", "total", "NPC", "minimization", "were", "jointly", "optimized", "in", ",", "where", "a", "single", "-", "stage", "optimization", "problem", "was", "formulated", "by", "introducing", "a", "weighting", "factor", "in", "the", "admission", "control", "part", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["We", "also", "use", "LSC", ",", "SSC", ",", "and", "SC", "to", "allow", "low", "-", "frequency", "information", "to", "bypass", "so", "the", "network", "can", "focus", "on", "residual", "learning", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long skip connections"}, {"tokens": ["First", ",", "OPF", "is", "a", "non", "-", "convex", "and", "non", "-", "linear", "constrained", "optimization", "problem", "that", "can", "take", "a", "mixed", "-", "integer", "form", "when", "solving", "the", "unit", "commitment", "problem", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["The", "idea", "is", "to", "make", "these", "metrics", "flexible", "so", "that", "the", "weight", "assigned", "to", "answerability", "and", "-gram", "similarity", "can", "be", "adjusted", "depending", "on", "the", "task", "(", "document", "QA", ",", "Knowledge", "-", "Base", "QA", ",", "Visual", "QA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["After", "the", "nearest", "D2D", "-", "R", "agrees", ",", "the", "BS", "send", "a", "percentage", "of", "D2D", "cluster", "clients", "to", "it", "(", "offloading", ")", "by", "informing", "each", "of", "the", "client", "for", "th", "following", ":", "If", "the", "contacted", "D2DR", "is", "inband", "D2D", ",", "the", "agreed", "frequency", "channel", "to", "used", "and", "the", "frequency", "channel", "of", "the", "contacted", "D2DR"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Because", "according", "to", "Figure", "6", ",", "the", "SC", "of", "the", "proposed", "scheme", "is", "significantly", "higher", "than", "other", "schemes", "due", "to", "additional", "symbol", "transmission", "from", "BS", "to", "the", "users", "by", "different", "OAM", "modes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["As", "shown", ",", "while", "c", "-", "VAE", "decreased", "the", "task", "performance", "in", "comparison", "to", "AlexNet", ",", "cIBP", "-", "VAE", "significantly", "improved", "the", "lesion", "classification", "accuracy", "(", "0.04", ")", "and", "improved", "the", "ROC", "-", "AUC", "score", "from", "0.75", "(", "AlexNet", ")", "to", "0.79", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["However", ",", "we", "can", "observe", "from", "(", "h", ")", "that", "by", "enforcing", "a", "MAD", "unit", "to", "actively", "look", "for", "neuron", "attention", "among", "feature", "channels", ",", "the", "outcome", "could", "have", "clear", "and", "strong", "signal", "as", "to", "where", "to", "find", "potential", "objects", ",", "which", "could", "benefit", "the", "classification", "and", "regression", "in", "the", "RPN", "layer", "in", "a", "great", "deal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["In", "December", "1993", "the", "Global", "Positioning", "System", "(", "GPS", ",", "official", "name", "\"", "NAVSTAR", "-", "GPS", "\"", ")", "achieves", "initial", "operational", "capability", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["FatSegNet", "Dice", "score", "outperforms", "manual", "raters", "on", "VAT", "(", "0.850", "vs.", "0.788),and", "produces", "comparable", "results", "on", "SAT", "(", "0.975", "vs.", "0.982", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Additive", "GPs", "also", "introduce", "a", "tractable", "new", "type", "of", "structure", "into", "the", "GP", "framework", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Comparisons", "of", "coding", "timeTABLE", "provides", "the", "encoding", "time", "and", "decoding", "time", "of", "several", "MDC", "methods", "for", "comparison", "when", "testing", "on", "an", "image", "with", "a", "size", "of", "512x512", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["In", "the", "rest", "of", "this", "paper", ",", "we", "first", "formally", "describe", "the", "MGM", "GAN", "framework", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["Such", "an", "approach", "is", "quite", "popular", ",", "and", "such", "DR", "and", "DE", "techniques", "are", "used", "in", "diverse", "domains", "such", "as", "engineering", ",", "astronomy", ",", "biology", ",", "remote", "sensing", ",", "economics", ",", "social", "media", ",", "and", "finance", ";", "and", "this", "class", "of", "techniques", "has", "a", "large", "extant", "literature", "(", "see", ",", "e.g.", ",", "and", "references", "therein", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["studied", "a", "dynamic", "SBM", ",", "and", "derived", "a", "threshold", "as", "a", "function", "of", "the", "rate", "of", "change", "and", "the", "strength", "of", "the", "groups", "/", "communities", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["and", "values", "for", "OEC", "clusters", "in", "Experiments", "with", "real", "dataSince", "we", "have", "only", "assumed", "information", "about", "the", "ground", "truth", "in", "the", "real", "datasets", "it", "is", "harder", "to", "interpret", "the", "values", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "online elliptical clustering"}, {"tokens": ["In", "this", "paper", ",", "we", "present", "a", "comprehensive", "analysis", "of", "IFT", "/", "formal", "Trojan", "detection", "techniques", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "information flow tracking"}, {"tokens": ["Augmented", "Reality", "(", "AR", ")", "versus", "Virtual", "Reality", "(", "VR)An", "augmented", "reality", "user", "is", "able", "to", "obtain", "useful", "information", "about", "location", "or", "objects", "and", "can", "interact", "with", "virtual", "contents", "in", "the", "real", "world", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["It", "is", "very", "similar", "to", "the", "phraseologies", "by", "FAA", "and", "CAA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "civil aviation authority"}, {"tokens": ["SRNN", "variants", "with", "POS", "information", "at", "three", "levels", ":", "(", "a", ")", "input", "layer", ",", "(", "b", ")", "forward", "layer", ",", "(", "c", ")", "compression", "layer", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "second", "option", "is", "a", "double", "translation", ",", "in", "which", "IPv4", "packets", "are", "translated", "to", "IPv6", "packets", "as", "specified", "in", "RFC6145", "and", "on", "the", "edge", "of", "the", "ISP", "network", "a", "second", "translation", "from", "IPv6", "back", "to", "IPv4", "is", "made", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "internet service providers"}, {"tokens": ["In", "the", "Canonical", "version", "of", "the", "PSO", ",", "Euclidean", "distance", "from", "the", "exemplar", "is", "often", "used", "as", "a", "learning", "concept", "as", "illustrated", "in", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Since", "OLS", "produces", "lower", "signal", "reconstruction", "error", "compared", "to", "OMP", "under", "similar", "condition", "(", "such", "as", "the", "same", "sparsity", "level", ",", "same", "dictionary", "etc", ".", ")"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["Table", "compares", "the", "Dice", "metrics", "(", "averaged", "across", "LV", ",", "myocardium", "and", "RV", ")", "for", "short", "-", "axis", "image", "segmentation", "between", "the", "U", "-", "net", "trained", "from", "scratch", "and", "self", "-", "supervised", "learning", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["The", "cover", "complexity", "(", "CC", ")", "is", "The", "CD", "is", "defined", "as", "the", "difference", "between", "the", "mean", "of", "SC", "and", "the", "mean", "of", "MC", ",", "since", "each", "category", "occurs", "with", "the", "same", "probability", "(", ")", "in", "the", "data", "sets", "mostly", "used", "in", "practice", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cover difference"}, {"tokens": ["We", "further", "observe", "the", "occurrence", "probability", "of", "TI", "1", ",", "TI", "2", "in", "Figure", "(", "c", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal interactions"}, {"tokens": ["The", "OT", "metric", "(", "e.g.", ",", "Wasserstein", "loss", ")", "is", "promised", "to", "be", "superior", "than", "other", "options", "to", "modeling", "data", "on", "general", "space", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["In", "particular", ",", "authors", "in", "and", "considered", "vehicular", "-", "type", "communication", "systems", "where", "the", "transmitting", "and", "receiving", "nodes", "are", "distributed", "along", "roads", "and", "modeled", "by", "a", "linear", "PPP", ",", "while", "roads", "random", "tessellations", "are", "modeled", "by", "a", "PLP", ",", "i.e.", ",", "the", "process", "of", "nodes", "is", "doubly", "stochastic", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "poisson line process"}, {"tokens": ["As", "we", "move", "to", "100", "continuations", ",", "we", "find", "that", "using", "our", "frame", "control", "variable", "leads", "to", "better", "diversity", "than", "TS", ",", "suggesting", "that", "the", "move", "to", "100", "samples", "has", "introduced", "some", "amount", "of", "repetition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature - based sampling"}, {"tokens": ["Third", ",", "passage", "ranker", "for", "selecting", "high", "-", "quality", "passages", "has", "been", "shown", "to", "be", "very", "useful", "in", "previous", "open", "-", "domain", "QA", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["With", "the", "same", "error", "distribution", ",", "we", "obtain", "a", "\"", "mixed", "\"", "RUM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "random utility maximization"}, {"tokens": ["For", "larger", "grids", "we", "expect", "a", "much", "higher", "number", "of", "possibly", "binding", "constraints", "(", "Table", ")", "and", "more", "significant", "difference", "of", "the", "meta", "-", "loss", "between", "the", "reduced", "OPF", "formulations", "and", "full", "model", "that", "reduce", "the", "possibility", "of", "the", "appearance", "of", "these", "trivial", "minima", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["In", "authors", "suggested", "that", ",", "A", "fast", "SEM", "image", "collected", "from", "the", "backside", "thinned", "IC", "can", "be", "compared", "with", "the", "golden", "layout", "available", "to", "the", "designer", "for", "detecting", "potential", "malicious", "circuitry", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["vqm_cost", "also", "shows", "a", "large", "standard", "deviation", "for", "the", "scenario", "without", "FEC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "forward error correction"}, {"tokens": ["Mean", "Recall", "(", "MR", ")", "averages", "such", "measures", "for", "all", "requests", "from", "the", "dataset", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean recall"}, {"tokens": ["Figure", "fig", ":", "landscape", "depicts", "how", "an", "ISP", "is", "typically", "used", "in", "embedded", "CV", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["These", "results", "indicate", "that", "generally", "performance", "on", "the", "TDW", "is", "slightly", "better", "than", "for", "the", "SDD", "for", "the", "same", "set", "of", "tasks", ",", "with", "the", "notable", "exception", "that", "self", "-", "rated", "experts", "actually", "performed", "slightly", "worse", "on", "the", "TDW", "for", "the", "Galaxy", "search", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["It", "results", "that", "HEFT", "and", "DADA", "perform", "well", "for", "various", "experimental", "conditions", ",", "but", "that", "DADA", "performs", "better", "for", "larger", "systems", "and", "number", "of", "GPUs", ",", "and", ",", "inmost", "cases", ",", "generates", "much", "lower", "data", "transfers", "than", "HEFT", "to", "achieve", "the", "sameperformance", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["GP", "based", "mechanistic", "emulator"], "acronym_pos": [1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["High", "Resolution", "Landmark", "Detector", "(", "HR", "-", "LD", ")"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["INTRODUCTIONGaussian", "processes", "(", "GP", ")", "provide", "highly", "flexible", "nonparametric", "prior", "distributions", "over", "functions", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Future", "Worksec", ":", "futureThis", "work", "demonstrates", "the", "benefits", "in", "CNN", "prediction", "performance", "and", "system", "efficiency", "of", "ISPs", ",", "however", "we", "expect", "that", "an", "ISP", "could", "provide", "additional", "benefits", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["complexity", "illustrates", "the", "trade", "-", "offs", "between", "cost", "and", "accuracy", "for", "different", "ISP", "configurations", "and", "MobileNet", "widths", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Step", "2", ":", "Extracting", "Words", "from", "AbstractsAfter", "pre", "-", "processing", "the", "abstracts", "of", "LSC", ",", "there", "are", "1,673,824", "processed", "plain", "texts", "for", "further", "analysis", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["NLM", "Dropout", "Variant", "(", "Validation", "/", "Test", ")"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural language modelling"}, {"tokens": ["NBC", "has", "the", "advantage", "of", "adapting", "the", "model", "complexity", "(", "i.e.", ",", "the", "number", "of", "clusters", ")", "to", "the", "amount", "of", "data", "available", ",", "and", "thus", "avoiding", "the", "problem", "of", "over", "-", "fitting", "and", "under", "-", "fitting", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "non - parametric bayesian classification"}, {"tokens": ["For", "the", "sake", "of", "simplicity", ",", "we", "employ", "linear", "precoding", "during", "the", "application", "of", "the", "RS", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "rate splitting"}, {"tokens": ["weighted", "images", "were", "acquired", "using", "a", "-", "T", "MR", "imaging", "unit", "(", "Intera", ",", "Philips", "Healthcare", ",", "Best", ",", "TheNetherlands", ")", "with", "a", "-channel", "torso", "phased", "array", "body", "coil", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["Second", ",", "the", "proposed", "MGM", "effectively", "and", "efficiently", "models", "the", "trajectory", "of", "the", "recursive", "patterns", "of", "different", "classes", "in", "the", "embedding", "space", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["The", "receiver", "operating", "characteristic", "(", "ROC", ")", "curves", "for", "all", "the", "models", "are", "also", "presented", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "evaluation", "set", "has", "around", "and", "test", "utterances", "in", "the", "LA", "and", "PA", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "physical access"}, {"tokens": ["To", "declare", "an", "extracted", "representation", "as", "useful", ",", "we", "expect", "it", "tosurpass", "the", "accuracy", "score", "of", "LR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "logistic regression"}, {"tokens": ["We", "observe", "that", "PCA", "fails", "dramatically", ",", "due", "to", "the", "non", "-", "orthogonality", "of", "the", "mixing", ",", "and", "that", "ICA", "does", "as", "well", ",", "due", "to", "the", "Gaussianity", "of", "the", "marginal", "distributions", "of", "the", "AR(2", ")", "processes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["Since", "a", "separate", "physical", "channel", "is", "used", ",", "MBSFN", "employs", "different", "reference", "signals", "compared", "to", "LTE", "unicast", "and", "SC", "-", "PTM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Theoretical", "bijection", "between", "and", "different", "from", "to", "1.5", "in", "the", "power", "IB", "Lagrangian", "(", "top", ")", ",", "and", "different", "in", "the", "domain", "in", "the", "exponential", "IB", "Lagrangian", "(", "bottom", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["POS", "achieves", "this", "by", "using", "DVFS", "techniques", "shekar2010energy", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial optimal slacking"}, {"tokens": ["For", "the", "-th", "frame", ",", "the", "BPD", "is", "calculated", "as", ":", "where", "is", "the", "normalized", "angular", "frequencies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "baseband phase difference"}, {"tokens": ["Moreover", ",", "we", "use", "the", "Python", "Toolbox", "sklearn", "to", "solve", "the", "optimization", "problem", "in", "eq", ":", "huber", "-", "loss_opt_prob", "to", "estimate", "the", "FOE", ",", "and", "the", "EMD", "implementation", "from", "the", "pyemd", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "earth mover 's distance"}, {"tokens": ["The", "ACM", "IS", "curriculum", "guidelines", "(", ")", ",", "which", "mention", "statistics", "and", "probability", "as", "required", "core", "IS", "topics", "and", "discrete", "mathematics", "as", "an", "optional", "one", ",", "but", "do", "not", "refer", "to", "logic", "as", "relevant", ":", "\"", "Even", "though", "IS", "professionals", "do", "not", "need", "the", "same", "level", "ofmathematical", "depth", "as", "many", "other", "computing", "professionals", ",", "there", "are", ",", "however", ",", "somecore", "elements", "that", "are", "very", "important", "for", "IS", "professionals", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information systems"}, {"tokens": ["Two", "different", "number", "of", "steps", "in", "the", "MD", "trajectories", ",", ",", "have", "been", "tested", "in", "the", "HMC", "experiments", "for", "each", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["Yilmaz2009:Random", ",", "Athanassoglou11:House", "extend", "PS", "to", "the", "housing", "markets", "problem", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["ANN", "is", "a", "suitable", "and", "reliable", "solution", "for", "its", "ability", "to", "approximate", "high", "dimension", "and", "highly", "nonlinear", "models", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Also", "learning", "spatio", "-", "temporal", "features", "that", "capture", "the", "dynamic", "variation", "of", "facial", "physical", "structure", "and", "the", "dynamic", "temporal", "evolution", "of", "expression", "boosts", "the", "performance", "of", "FER", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "facial expression recognition"}, {"tokens": ["The", "proposals", "estimated", "from", "both", "the", "neighboring", "phrases", "(", "subject", "and", "object", ")", "are", "added", "to", "the", "proposals", "generated", "by", "PIN", "IRN", "enhances", "the", "proposal", "set", "and", "is", "especially", "useful", "for", "smaller", "objects", "which", "are", "often", "missed", "by", "proposal", "generators", "(", "Figure", ",", "query", "3", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["Tracking", "on", "the", "best", "original", "peaks", "also", "shows", "good", "results", "but", "is", "missing", "small", "parts", "of", "the", "lateral", "projections", "of", "the", "CST", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "corticospinal tract"}, {"tokens": ["Results-.5emFor", "our", "simulations", ",", "we", "deploy", "users", "uniformly", "in", "a", "square", "area", "of", "size", "m", "m", "with", "the", "BS", "located", "at", "its", "center", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["This", "penalty", "forces", "the", "forward", "weights", "to", "align", "with", "a", "set", "of", "fixed", "random", "matrices", ",", "as", "in", "FA", ",", "but", "without", "using", "the", "separate", "matrix", "for", "error", "propagation", "(", "Figure", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["Both", "networks", "achieve", "a", "slightly", "lower", "performance", "on", "the", "test", "data", ",", "but", "the", "U", "-", "Net", "still", "reaches", "an", "average", "error", "of", "less", "than", "3", "for", "the", "more", "difficult", "VAT", "volume", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Moreover", ",", "the", "proposed", "technique", "(", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", ")", "provides", "higher", "SC", "than", "other", "conventional", "techniques", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["The", "UAV", "starting", "from", "an", "initial", "position", "is", "given", "a", "budget", "and", "initializes", "GP", "with", "zero", "mean", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "CCC", "can", "be", "defined", "as", ":", "where", "is", "the", "Pearson", "'s", "Correlation", "Coefficient", "between", "annotator", "labels", "and", "the", "gold", "standard", ",", "and", "denote", "the", "mean", "for", "annotator", "labels", "and", "the", "gold", "standard", "and", "and", "are", "the", "corresponding", "variances", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "congruence coefficient correlation"}, {"tokens": ["The", "POS", "frequencies", "provides", "the", "model", "with", "information", "on", "the", "grammatical", "aspect", "of", "the", "text", "and", "can", "be", "used", "to", "exploit", "the", "frequency", "of", "these", "labels", "in", "a", "text", "to", "identify", "headings", "and", "contribute", "to", "the", "accuracy", "of", "the", "model", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["For", "these", "reasons", ",", "we", "replaced", "inner", "product", "with", "SAD", "at", "the", "encoder", "layer", "to", "obtain", "more", "discriminative", "and", "separable", "hidden", "abstracts", "as", "well", "as", "endmembers", "from", "hyperspectral", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["CDA", "combined", "with", "nearest", "-", "neighbor", "were", "applied", "for", "classification", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "canonical discriminant analysis"}, {"tokens": ["DI", "is", "a", "heuristic", "measure", "-", "each", "of", "the", "parameters", "can", "be", "weighted", "as", "per", "dataset", "characteristics", "and", "user", "requirements", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "document index"}, {"tokens": ["Apart", "from", "the", "implementation", "details", "and", "the", "background", "data", ",", "roughly", "speaking", ",", "the", "research", "community", "introduced", "the", "following", "categories", "of", "QA", "systems", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["While", "applied", "the", "SBM", "to", "real", "directed", "graphs", ",", "they", "assumed", "that", "the", "block", "structure", "is", "known", "a", "priori", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["IoT", ",", "Blockchain", "Authorization", ",", "Hyperledger", "Fabric", ",", "BC", ",", "Blockchain", "Integrity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["Conversely", ",", "if", "a", "high", "level", "of", "redundancy", "is", "chosen", ",", "these", "FEC", "blocks", "will", "be", "more", "resilient", "to", "packet", "loss", ",", "however", ",", "a", "larger", "network", "overhead", "occurs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "hand", "-", "eye", "correction", "from", "is", "implemented", "on", "the", "master", "side", ",", "so", "the", "predicted", "AR", "slave", "-", "tools", "use", "the", "correction", "corresponding", "to", "the", "image", "data", "they", "will", "be", "displayed", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Next", ",", "for", "each", "of", "these", "5", "DSA", "skills", ",", "we", "calculate", "the", "top", "300", "skills", "with", "the", "highest", "similarity", "scores", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["HOG", "is", "widely", "used", "for", "human", "detection", "in", "an", "image", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "histogram of gradients"}, {"tokens": ["The", "calculation", "of", "RV", "iteration", "number", "was", "performed", "as", "follows", ":", "for", "every", "trial", ",", "following", "the", "maximum", "iterations", "termination", "criteria", "by", "default", "is", "150", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random voting"}, {"tokens": ["alignedequation*Hence", "finitely", "branching", "almost", "-", "sure", "Buchi", "games", "are", "strongly", "MD", "-", "determined", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["Researchers", "developed", "and", "tailored", "FA", "to", "work", "well", "with", "steganalysis", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "firefly algorithm"}, {"tokens": ["and", "FAR", "with", "a", "(", "from", "to", ")", "and", "(", "to", ")", "reduction", ",", "respectively", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "flow annotation replanning"}, {"tokens": ["This", "problem", "is", "NP", "-", "complete", "by", "an", "easy", "reduction", "from", "the", "standard", "Subset", "Sum", "problem", ",", "which", "asks", "instead", "for", "a", "0", "-", "1", "linear", "combination", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "natural problem"}, {"tokens": ["[", "(", "PA", "-", "Ax)](z')z", "'", "<", "z", "'", "&", "(", "10,0)(0,7)8", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "peano 's arithmetics"}, {"tokens": ["On", "the", "other", "hand", ",", "each", "user", "can", "be", "associated", "with", "one", "BS", "at", "most", "using", "one", "RB", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "resource blocks"}, {"tokens": ["Similarly", ",", "the", "signal", "received", "at", "the", "-th", "eavesdropper", "iswhere", "the", "right", "hand", "side", "of", "(", ")", "is", "composed", "of", "the", "-th", "confidential", "message", "intercepted", "by", ",", "the", "messages", "sent", "to", "the", "other", "(", "-1", ")", "destination", "users", "that", "are", "intercepted", "by", ",", "the", "AN", "to", "disturb", "and", "the", "AWGN", "satisfying", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["For", "a", "3D", "DM", ",", "the", "beamforming", "scheme", ",", "including", "AN", "projection", "matrix", "and", "confidential", "beamforming", "vectors", "in", ",", "is", "extended", "to", "the", "3D", "polar", "coordinate", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["For", "this", "purpose", "we", "present", "the", "reformulated", "version", "of", "AP", ",", "described", "in", ",", "involving", "binary", "optimization", "variables", ":", "Let", "us", "define", "a", "matrix", "of", "binary", "variables", ",", "where", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["In", "this", "article", ",", "we", "show", "that", "previous", "work", "on", "relation", "prediction", "between", "texts", "implicitly", "uses", "compositions", "from", "baseline", "SRL", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "statistical relational learning"}, {"tokens": ["The", "actively", "secure", "protocol", "incurs", "a", "communication", "of", "bits", "in", "Base", "OT", "Phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["OUTIS", "claims", "that", "it", "provides", "a", "bridge", "between", "LDP", "and", "CDP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "centralized differential privacy"}, {"tokens": ["The", "AP", "extracts", "the", "interested", "information", "from", "RTSs", "sent", "by", "the", "contending", "STAs", ",", "and", "then", "makes", "scheduling", "decisions", "for", "simultaneous", "frame", "transmissions", "(", "i.e.", ",", "the", "scheduled", "transmissions", ")", ",", "or", "the", "AP", "just", "responds", "to", "the", "received", "RTSs", "to", "notify", "who", "have", "won", "the", "channel", "contention", "(", "i.e.", ",", "the", "un", "-", "scheduled", "transmissions", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["IB", "based", "diarization", "systems", "are", "significantly", "fast", "and", "are", "suitable", "for", "real", "time", "applications", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["GMM", "selects", "a", "group", "out", "of", "composed", "by", "the", "global", "minimum", "and", "the", "local", "minima", "in", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group marching method"}, {"tokens": ["As", "can", "be", "seen", "from", "the", "simulation", "results", ",", "the", "PSO", "algorithm", "provides", "better", "results", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Both", "GP", "density", "methods", "recover", "well", "the", "structure", "of", "the", "data", ",", "but", "the", "VB", "seems", "to", "overestimate", "the", "width", "of", "the", "Gaussian", "noise", "compared", "to", "the", "Gibbs", "sampler", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["ConclusionIn", "this", "paper", ",", "we", "propose", "a", "deep", "multiple", "description", "coding", "framework", "in", "which", "MD", "quantizers", "are", "automatically", "learned", "in", "an", "end", "-", "to", "-", "end", "manner", "during", "training", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["PSO", "is", "inspired", "by", "the", "behaviour", "of", "a", "flock", "of", "birds", "or", "fish", "swarms", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["GPA", "is", "much", "faster", "than", "HARP", "on", "all", "datasets", "with", "at", "least", "20", "performance", "gain", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph partition algorithm"}, {"tokens": ["From", "controlling", "a", "trustworthy", "UI", "element", "it", "is", "not", "a", "long", "way", "to", "spoofing", "system", "security", "marks", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user interface"}, {"tokens": ["More", "specifically", ",", "MBS", "can", "be", "turned", "off", "during", "low", "traffic", "periods", "and", "the", "small", "number", "of", "active", "users", "are", "offloaded", "to", "nearby", "DBSs", "or", "macrocell", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Our", "analysis", ",", "culminating", "in", "Theorem", ",", "reveals", "that", "DMD", "will", "succeed", "in", "this", "setting", ",", "even", "as", "ICA", "fails", ";", "see", "Figure", "for", "an", "illustration", "where", "ICA", "fails", "to", "unmix", "two", "mixed", ",", "independent", "Gaussian", "AR(1", ")", "processes", "while", "DMD", "succeeds", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "independent component analysis"}, {"tokens": ["However", "computation", "of", "the", "stroke", "map", "was", "done", "once", "with", "the", "algorithms", "by", ",", "i.e.", "only", "DMD", ",", "only", "EMD", ",", "and", "combined", ",", "and", "once", "with", "iterative", "improvement", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "excessive mapping dissolution"}, {"tokens": ["=", "feature", "available", "from", "VM", "or", "BM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0], "long_form": "bare metal"}, {"tokens": ["The", "out", "-", "of", "-", "context", "term", "will", "increase", "the", "average", "conceptual", "similarity", "and", "hence", "the", "MACS", "score", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mean average conceptual similarity"}, {"tokens": ["Despite", "the", "large", "diversity", "between", "natural", "images", "and", "SAR", "targets", ",", "the", "low", "-", "level", "features", "are", "general", "and", "transferable", ",", "and", "fixing", "with", "more", "knowledge", "of", "SAR", "images", "via", "multi", "-", "source", "transitive", "transferring", "can", "notably", "increase", "the", "transferability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["DADA", "(", ")", "is", "the", "most", "costly", "policy", "while", "DADA()and", "HEFT", "have", "similar", "impacts", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["ANN", "evaluates", "the", "training", "error", "based", "on", "inputs", "and", "minimizes", "the", "errorpANN1", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["In", "order", "to", "mitigate", "the", "AP", "bottle", "-", "neck", "effect", "and", "compensate", "the", "downlink", "disadvantage", "when", "STAs", "choose", "a", "big", ",", "we", "set", "the", "maximum", "number", "of", "frames", "that", "the", "AP", "can", "aggregate", "in", "an", "A", "-", "MPDU", "to", "(", ")", ",", "while", "keeping", "the", "number", "of", "frames", "aggregated", "by", "each", "STA", "to", "in", "the", "following", "simulations", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["For", "each", "attribute", ",", "we", "generate", "continuations", "for", "each", "of", "its", "values", ",", "and", "compare", "to", "BS", "and", "TS", "systems", "with", "the", "same", "number", "of", "outputs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "beam search"}, {"tokens": ["The", "Vacationing", "Server", "Model", "(", "VSM", ")", "utilized", "in", "extends", "the", "analysis", "in", "to", "analyze", "RAID5", "performance", "in", "normal", ",", "degraded", ",", "and", "rebuild", "modes", "with", "an", "M", "/", "G/1", "rather", "than", "M", "/", "M/1", "queueing", "model", "with", "general", "rather", "than", "exponential", "disk", "service", "times", "utilized", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vacationing server model"}, {"tokens": ["The", "fundamental", "increase", "of", "GMV", ",", "ROI", ",", "CVR", "and", "decrease", "of", "PPC", "follows", "the", "right", "logic", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "pay per click"}, {"tokens": ["The", "test", "-", "retest", "ICC", "was", "calculated", "directly", "between", "the", "same", "features", "in", "both", "images", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["As", "non", "-", "Gaussian", "likelihoods", "are", "also", "permitted", "in", "the", "multi", "-", "task", "setup", ",", "the", "continual", "GP", "model", "is", "useful", "for", "heterogeneous", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "comparison", ",", "the", "coordinated", "uplink", "channel", "access", "lets", "the", "AP", "to", "mediate", "the", "uplink", "transmissions", "by", "either", "just", "notifying", "a", "group", "of", "STAs", "that", "successfully", "won", "the", "channel", "contention", "or", "making", "a", "scheduling", "decision", "that", "aims", "to", "optimize", "the", "system", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["At", "this", "stage", "there", "is", "a", "high", "confidence", "in", "the", "features", "labeling", ",", "therefore", "an", "additional", "weight", "is", "added", "to", "the", "voting", "histogram", "so", "that", "RV", "will", "affect", "the", "unlabeled", "ones", "more", "than", "the", "labeled", "ones", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random voting"}, {"tokens": ["FJ", "power", "allocation", "in", "cognitive", "two", "-", "way", "relay", "networks", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "friendly jamming"}, {"tokens": ["The", "segmentation", "method", "developed", "in", "this", "work", "provides", "robust", "and", "efficient", "analysis", "which", "enabled", "us", "to", "quantify", "and", "compare", "capillary", "diameters", "and", "other", "vascular", "parameters", "from", "in", "vivo", "cortex", "images", "across", "multiple", "animals", ",", "with", "varying", "age", "as", "well", "as", "across", "WT", "mice", "and", "AD", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "wild type"}, {"tokens": ["Thus", "to", "design", "the", "analog", "precoder", "at", "the", "BS", ",", "the", "knowledge", "of", "the", "downlink", "AOD", "corresponding", "to", "the", "LOS", "path", "is", "enough", ",", "instead", "of", "the", "whole", "knowledge", "of", "channel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Clearly", ",", "DE", "-", "SB", "and", "CMA", "-", "ES", "-", "SB", "are", "significantly", "faster", "then", "the", "other", "methods", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["NP", "palan", "'", "pack", "-", "saddle", "'"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["In", "the", "unlicensed", "band", ",", "if", "the", "fBS", "senses", "good", "channel", "quality", "while", "the", "CQI", "from", "the", "UE", "report", "is", "constantly", "below", "a", "threshold", ",", "the", "fBS", "may", "determine", "that", "the", "UE", "is", "under", "high", "interference", "from", "hidden", "terminals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Based", "on", "the", "average", "ranks", "in", "terms", "of", "both", "accuracy", "and", "G", "-", "mean", "on", "all", "datasets", ",", "the", "proposed", "ECS", "-", "DBN", "ranked", "first", "in", "the", "majority", "of", "the", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["c", "c", "c", "c", "c", "c", "c", "&", "3cSensitivity", "&", "3cSpecificity", "&", "ET", "&", "WT", "&", "TC", "&", "ET", "&", "WT", "&", "TC", "Development", "set", "&", "0.735", "&", "0.851", "&", "0.664", "&", "0.998", "&", "0.994", "&", "0.997", "Validation", "set", "&", "0.723", "&", "0.879", "&", "0.619", "&", "0.998", "&", "0.994", "&", "0.998", "Results", "for", "BraTS", "2017", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["In", "the", "GUS", "scheme", ",", "it", "has", "been", "proposed", "that", "the", "receiver", "BS", "selects", "users", "that", "maximize", "the", "number", "of", "distinct", "clusters", "in", "the", "cell", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "order", "to", "make", "all", "superlinear", "SCCs", "purely", "superlinear", ",", "we", "apply", "a", "sequence", "of", "substituting", "operations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strongly connected components"}, {"tokens": ["In", "particular", "set", "of", "16", ",", "17", ",", "30", ",", "50", "and", "50", "significant", "calls", "filtered", "with", "WFS", "(", "GS", ")", ",", "CFS", ",", "IG", ",", "CHI", ",", "and", "SU", "are", "grouped", "together", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "genetic search"}, {"tokens": ["Indeed", ",", "for", "DBP", "checking", ",", "we", "can", "generalise", "Theorem", "stating", "NP", "-", "completeness", "of", "DBP", "checking", "for", "coBuchi", "automata", ":", "Checking", "whether", "a", "Rabin", "(", "or", "Streett", ",", "Muller", ")", "automata", "is"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["ht]Confusion", "matrix", "for", "Posture", "Recognition", "by", "SVMPosture", "Recognition", "using", "CNNWe", "observe", "that", "GMM", "and", "SVM", "classifiers", "for", "posture", "recognition", "are", "able", "to", "perform", "well", "on", "crafted", "features", "like", "skeleton", "angle", "and", "HOG", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "histogram of gradients"}, {"tokens": ["A", "near", "optimal", "solution", "based", "on", "GP", "has", "been", "investigated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["DCI", "Format", "1C", "for", "M", "-", "RNTI", "in", "LTE"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1], "long_form": "long term evolution"}, {"tokens": ["ConclusionIn", "this", "letter", ",", "a", "deep", "transfer", "learning", "method", "combining", "the", "top-2", "smooth", "loss", "was", "proposed", "to", "solve", "the", "land", "cover", "classification", "problem", "for", "a", "large", "-", "scale", "HR", "TSX", "dataset", ",", "with", "highly", "imbalanced", "classes", ",", "geographic", "diversity", "and", "noisy", "labels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["According", "to", "the", "concept", "of", "DL", "CNOMA", "[", "4,10", "-", "14", "]", ",", "the", "lower", "power", "(", ")", "is", "assigned", "for", "CCU", "and", "higher", "power", "is", "assigned", "(", ")", "for", "CEU", "based", "on", "their", "channel", "conditions", "from", "BS", "[", "3].", "and", "are", "the", "normalized", "distances", "from", "BS", "to", "CCU", "and", "CEU", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["The", "baseband", "received", "signal", "at", "UE", "on", "SC", "is", "given", "bywhere", "is", "the", "channel", "vector", "from", "RRH", "to", "UE", "on", "SC", ",", "and", "is", "the", "additive", "complex", "white", "Gaussian", "noise", "following", "the", "distribution", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Zeilengleichheit", ",", "allerdings", "sind", "in", "RB", "'s", "personlichen", "Passagen", "24"], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "rosi braidotti"}, {"tokens": ["Our", "approachhas", "the", "longest", "lift", "time", "because", "the", "communication", "between", "two", "cell", "phones", "is", "always", "relayed", "by", "the", "RS", "with", "the", "highest", "potential", "energy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["Collinear", "placement", "of", "all", "nodes", "(", "e.g.", "BS", ",", ",", "and", ")", "and", "normalized", "distances", "between", "any", "two", "nodes", "are", "considered", ",", "where", ",", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["For", "the", "CNS", "dataset", ",", "the", "variables", "contributing", "the", "most", "to", "PC", "0", "(", "e.g.", "such", "that", ")", "are", ",", "in", "order", ",", "the", "activity", "space", "size", ",", "the", "social", "circle", "size", ",", "the", "number", "of", "new", "locations", "/", "week", ",", "the", "activity", "space", "entropy", "and", "the", "number", "of", "new", "ties", "/", "week", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["(", "a", ")", "Violin", "plots", "for", "original", "responses", "to", "the", "three", "feedback", "questions", "for", "users", "in", "the", "\"", "with", "CF", "\"", "condition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Evolving", "Curves", "of", "Graph", "Scan", "StatisticsFigure", "presents", "the", "comparison", "between", "our", "method", "and", "GenFusedLasso", "on", "the", "scores", "of", "the", "best", "connected", "subgraphs", "that", "are", "identified", "at", "different", "iterations", "based", "on", "the", "Kulldorff", "'s", "scan", "statistic", "and", "the", "EMS", "statistic", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "elevated mean scan statistic"}, {"tokens": ["QUORAM", "is", "also", "a", "permissioned", "public", "BC", "and", "based", "on", "Ethereum", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["Only", "19", "thinks", "that", "scientists", "understand", "the", "health", "consequences", "of", "GM", "foods", "very", "well", ",", "even", "though", "scientists", "have", "formed", "a", "consensus", "that", "GM", "foods", "are", "safe", "to", "eat", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "genetically modified"}, {"tokens": ["The", "BS", "is", "assumed", "to", "have", "CSI", "only", "of", "the", "selected", "users", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Gaussian", "process", "(", "GP", ")", "models", "are", "not", "excluded", "from", "this", "necessity", "of", "real", "-", "time", "adaptation", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "results", "show", "that", "the", "prediction", "precision", "is", "remarkably", "higher", "than", "that", "of", "PA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "preferential attachment"}, {"tokens": ["proposed", "a", "bare", "-", "bones", "multi", "-", "objective", "PSO", "(", "BB", "-", "MOPSO", ")", "algorithm", "suitable", "for", "solving", "EED", "problems", "of", "power", "systems", "operations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Meanwhile", ",", "due", "to", "the", "limited", "energy", "budget", "of", "the", "wireless", "users", ",", "both", "local", "computation", "energy", "and", "transmission", "energy", "must", "be", "considered", "during", "the", "FL", "process", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["Since", "the", "BN", "is", "estimated", "from", "limited", "real", "-", "world", "batch", "data", ",", "there", "exists", "the", "model", "risk", "(", "MR", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "model risk"}, {"tokens": ["Similar", "to", "this", ",", "NLM", "employs", "neural", "networks", "as", "a", "differentiable", "chain", "for", "forward", "inference", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural logic machines"}, {"tokens": ["For", "a", "wide", "range", "of", "step", "sizes", "and", "MD", "trajectory", "lengths", ",", "AIA", "outperformed", "other", "tested", "integrating", "schemes", "in", "accuracy", "and", "sampling", "efficiency", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["present", "a", "SAR", "ship", "dataset", "of", "Sentinel-1", ",", "containing", "11346", "ship", "chips", "from", "41", "Sentinel-1", "SAR", "images", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["A", "true", "comparison", "between", "PI", "and", "RQI", "is", "difficult", "because", "PI", "never", "finished", "the", "calculations", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "power iteration"}, {"tokens": ["Eventually", ",", "the", "best", "found", "misclassification", "costs", "are", "obtained", "and", "applied", "to", "the", "output", "layer", "of", "DBN", "to", "form", "ECS", "-", "DBN", "as", "shown", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["And", "in", "order", "to", "interfere", "with", "the", "eavesdroppers", ",", "the", "BS", "employs", "the", "beamforming", "technique", "to", "steer", "(", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["DE", "-", "SB", "and", "CMA", "-", "ES", "-", "SB", "continue", "to", "show", "the", "best", "results", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["The", "best", "learning", "rate", "strategy", "has", "been", "to", "divide", "by", "a", "factor", "of", "2", "the", "learning", "rate", "after", "the", "first", "eight", "training", "epochs", "with", "a", "fixed", "LR", "of", "0.019326", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "learning rate"}, {"tokens": ["In", "the", "proposed", "algorithm", ",", "the", "velocity", "component", "of", "the", "conventional", "PSO", "has", "been", "replaced", "by", "a", "phase", "angle", "vector", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["There", "are", "two", "types", "of", "differential", "privacy", "-", "Centralized", "differential", "privacy", "or", "CDP", "and", "Local", "differential", "privacy", "or", "LDP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "centralized differential privacy"}, {"tokens": ["The", "first", "reference", "case", "is", "when", "all", "the", "requested", "files", "are", "placed", "in", "EC", ",", "then", "all", "the", "baseband", "processing", "must", "be", "placed", "at", "the", "EC", ",", "and", "the", "connection", "from", "EC", "and", "CC", "is", "provided", "by", "backhaul", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Figure", "illustrates", "the", "general", "framework", "of", "representation", "learning", "by", "DCNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["In", "a", "cellular", "setting", ",", "ACI", "will", "be", "relative", "small", "in", "the", "uplink", ",", "if", "power", "control", "is", "used", "to", "equalize", "the", "received", "powers", ",", "and", "in", "the", "downlink", ",", "if", "users", "associate", "with", "the", "closest", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["From", "Table", ",", "we", "observe", "that", "ECS", "-", "DBN", "excels", "in", "34", "out", "of", "58", "benchmark", "datasets", "in", "terms", "of", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "authors", "of", "investigated", "the", "impact", "of", "PA", "parameter", "based", "on", "the", "asymptotic", "achievable", "SR", "in", "MIMO", "system", "with", "an", "active", "eavesdropper", "when", "the", "number", "of", "transmit", "antennas", "was", "infinite", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["This", "approach", "has", "been", "successfully", "used", "to", "transfer", "several", "linguistic", "annotations", "between", "languages", "(", "efficient", "learning", "of", "POS", "taggers", "and", "accurate", "projection", "of", "word", "senses", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["We", "only", "train", "network", "with", "the", "subsampled", "AFLW", "training", "images", "using", "the", "loss", "function", "in", "Equation", ",", "and", "evaluate", "the", "performance", "on", "generated", "LR", "AFLW", "test", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Sinem", "Guven", "presents", "a", "mobile", "AR", "authoring", "system", "for", "creating", "and", "editing", "3D", "hypermedia", "narratives", "that", "are", "interwoven", "with", "a", "wearable", "computer", "user", "'s", "surrounding", "environment(http://graphics.cs.columbia.edu", "/", "projects", "/", "mars", "/", "Authoring.html", ")", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["In", "further", "detail", ",", "the", "SSIM", "score", "achieved", "by", "neuralFEC", "for", "the", "Harbour", "video", "sequence", "was", "of", "0,675", "against", "0,662", "for", "the", "video", "-", "aware", "mechanism", "and", "0,485", "for", "the", "mechanism", "without", "FEC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "forward error correction"}, {"tokens": ["We", "computed", "the", "accumulated", "meta", "-", "loss", "of", "a", "test", "set", "before", "(", "pre", ")", "and", "after", "(", "post", ")", "the", "meta", "-", "optimization", "and", "computed", "the", "gain", "in", "the", "meta", "-", "loss", "relative", "to", "the", "full", "OPF", "problem", "in", "each", "case", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["On", "the", "other", "way", ",", "if", "you", "want", "to", "take", "the", "use", "of", "the", "natural", "images", "pre", "-", "trained", "models", "to", "SAR", "related", "problems", ",", "we", "will", "give", "an", "advice", "to", "learn", "some", "information", "from", "SAR", "images", "based", "on", "the", "model", "as", "transitive", "transfer", "2", "shows", "in", "Fig", ".", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["The", "CFDP", "was", "designed", "for", "file", "transfer", "from", "source", "to", "destination", "based", "on", "store", ",", "carry", "and", "forward", "approach", "for", "DTN", "paradigm", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "disruption tolerant networking"}, {"tokens": ["Moreover", ",", "the", "OAM", "channel", "from", "the", "BS", "-", "to", "-", "CCU", "(", "Link", "3", ")", "is", "denoted", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["When", "each", "UE", "has", "only", "one", "antenna", "with", "perfect", "CSI", ",", "the", "rank", "of", "channel", "covariance", "matrices", "will", "be", "equal", "to", "one", ",", "i.e.", ",", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["NP", "xun", "(", "MP", "xon", ")", "has", "either", "undergone", "a", "metathesis", "between", "*", "u", "and", "*", "h", ",", "or", "was", "subject", "to", "the", "same", "irregular", "x", "-", "prothesis", "as", "MP", "xayag", ",", "NP", "xaya", "'", "egg", "'", ",", "xirs", "'", "bear", "'", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["We", "take", "CTR", "estimation", "in", "online", "advertising", "as", "the", "working", "example", "to", "explore", "the", "learning", "ability", "of", "our", "PNN", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["The", "GP", "model", "predicts", "the", "missing", "parts", "of", "the", "evidence", "and", "estimates", "the", "full", "contours", "of", "the", "objects", "accurately", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Figure", "E", "depicts", "the", "CM", "for", "the", "TFL1", "gene", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "canalizing map"}, {"tokens": ["Comparison", "of", "the", "average", "computational", "time", "across", "7", "algorithms", "(", "i.e.", "ECS", "-", "DBN", ",", "DBN", ",", "ADASYN", "-", "DBN", ",", "SMOTE", "-", "DBN", ",", "SMOTE", "-", "borderline1-DBN", ",", "SMOTE", "-", "borderline2-DBN", "and", "SMOTE", "-", "SVM", "-", "DBN", ")", "with", "5-fold", "cross", "validation", "on", "the", "gun", "drilling", "imbalanced", "dataset", "over", "10", "trials", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["[", "]", "The", "performance", "of", "the", "proposed", "GP", "-", "PF", "method", "with", "different", "covariance", "functions", "on", "the", "ground", "truth", "contour", "evidences", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["This", "is", "quite", "evident", "as", ",", "under", "the", "original", "SBM", ",", "the", "expected", "degree", "is", "the", "same", "for", "all", "nodes", "in", "each", "group", ",", "given", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["While", "the", "pixel", "-", "wise", "mixing", "weights", "can", "be", "viewed", "as", "the", "pixel", "-", "wise", "channel", "attention", ",", "which", "also", "can", "be", "directly", "generated", "by", "a", "DCNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["EvaluationIn", "Table", ",", "comparable", "results", "of", "our", "experiments", "with", "object", "-", "based", "CNN", "and", "pixel", "-", "based", "MVFCNN", "are", "presented", "using", "SEM", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Recently", ",", "by", "the", "basic", "idea", "of", "IA", "with", "some", "constraints", "shows", "that", "one", "can", "achieve", "DoF", "for", "the", "fast", "fade", "interference", "channel", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interference alignment"}, {"tokens": ["In", "order", "to", "calculate", "the", "CF", "-", "based", "recommendations", "for", "the", "first", "set", "of", "users", ",", "we", "first", "filtered", "their", "edits", "to", "only", "include", "articles", "(", "rather", "than", "talk", "/", "user", "pages", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["-", "Second", "pass", ":", "The", "latent", "features", "are", "used", "along", "with", "the", "spectral", "features", "in", "the", "second", "pass", "of", "IB", "clustering", "which", "is", "then", "followed", "by", "a", "KL", "-", "HMM", "based", "realignment", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Feasibility", "and", "sensitivity", "of", "GP", "are", "given", "in", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["Therefore", ",", "there", "exists", "an", "MD", "strategy", "with", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["Performance", "on", "BraTS2017", "training", "and", "validation", "setsEvaluation", "of", "the", "results", "is", "performed", "merging", "the", "predicted", "labels", "into", "three", "classes", ":", "enhancing", "tumor", "ET", "(", "label", "1", ")", ",", "whole", "tumor", "WT", "(", "labels", "1", ",", "2", ",", "4", ")", ",", "and", "tumor", "core", "TC", "(", "labels", "1", ",", "4", ")", ",", "using", "Dice", "score", ",", "Hausdorff", "distance", ",", "Sensitivity", "and", "Specificity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "whole tumor"}, {"tokens": ["Once", "decided", "the", "FEC", "block", "sizes", ",", "it", "is", "necessary", "to", "configure", "the", "encoding", "FEC", "algorithm", "which", "will", "generate", "the", "redundant", "data", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Receiver", "operating", "characteristic", "(", "ROC", ")", "curves", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["As", "stated", "by", ",", "the", "(", ")", "meets", "the", "two", "conditions", "of", "Exact", "-", "MBR", "encoding", "matrix", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["A", "failure", "analysis", "(", "FA", ")", "tool", ",", "an", "early", "version", "of", "which", "is", "described", "by", ",", "provided", "reporting", "and", "analysis", "of", "IR", "component", "performance", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "failure analysis"}, {"tokens": ["propose", "a", "generative", "approach", "for", "detecting", "out", "-", "of", "-", "distribution", "samples", "but", "evaluates", "calibration", "performance", "comparing", "their", "method", "with", "TS", "as", "the", "decoupled", "calibration", "technique", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "temperature scaling"}, {"tokens": ["For", "all", "RV", "over", "a", "family", "of", "distributions", ",", "the", "conditioned", "maximum", "probability", "to", "look", "for", "any", "distinct", "RV", "in", "optimal", "distribution", "over", "(", "i.e.", "for", "all", ")", "when", "is", "measured", "to", "be", "For", ",", "it", "means", "that", "there", "would", "have", "one", "noisy", "string", ",", "where", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["This", "confirms", "that", "the", "ANN", "model", "in", "TPIB", "-", "ITL", "gets", "better", "over", "time", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["After", "that", ",", "AA", "theory", "was", "developed", "and", "has", "been", "applied", "to", "OPF", "problems", "in", "power", "systems", ",", "which", "can", "take", "the", "correlation", "among", "variables", "into", "account", "and", "yield", "much", "tighter", "lower", "and", "upper", "bounds", "compared", "to", "IA", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affine arithmetic"}, {"tokens": ["Also", ",", "eqn.graph_ypq_mmfh13", "can", "be", "compared", "with", "eqn.graph_ypq_micro", "in", "the", "microcanonical", "SBM", "below", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "two", "polar", "-", "coded", "signalling", "schemes", "are", "designed", "with", "both", "SC", "and", "SCL", "decoding", "techniques", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "successive cancellation"}, {"tokens": ["On", "top", "of", "that", ",", "for", "each", "(", "user", "or", "publisher", ")", "feature", "of", "the", "CF", "task", ",", "its", "weight", "and", "latent", "vector", "act", "as", "a", "prior", "of", "the", "counterparts", "and", "in", "CTR", "task", "while", "learning", "the", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["In", "CF", ",", "a", "generally", "adopted", "similarity", "measure", "is", "called", "Pearson", "Correlation", "which", "measures", "the", "extent", "to", "which", "two", "variables", "linearly", "relate", "with", "each", "other", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["In", "general", ",", "we", "will", "assume", "that", "the", "discretizations", "of", "the", "BEM", "and", "the", "FEM", "meshes", "have", "different", "number", "of", "nodes", "and", "therefore", "compatibility", "must", "be", "enforced", "through", "displacement", "and", "coupling", "matrices", "and", ",", "as", "specified", "in", "coupling", "Matrices;and", "where", "the", "normal", "vectors", "satisfy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["ResultsWe", "received", "a", "total", "of", "279", "responses", ",", "180", "of", "which", "were", "from", "the", "\"", "with", "CF", "\"", "set", "while", "the", "remaining", "99", "were", "\"", "no", "CF", "\"", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["That", "is", ",", "the", "attention", "regions", "of", "AN", "deviate", "in", "some", "degree", "from", "the", "proper", "regions", "of", "target", "characters", "in", "the", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["This", "proves", "that", "MINT", "-", "FEC", "is", "capable", "of", "better", "identifying", "the", "most", "QoE", "-", "sensitive", "data", "and", "adds", "a", "precise", "amount", "of", "QoE", "-", "aware", "redundancy", "to", "it", ",", "resulting", "in", "higher", "video", "quality", "and", "less", "network", "overhead", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["thbp", "]", "Illustration", "of", "attention", "drift", "in", "the", "AN", "model", "and", "the", "focusing", "mechanism", "in", "the", "FAN", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["(", "ECC", "off", ")", "&"], "acronym_pos": [0, 1, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["As", "we", "can", "see", "from", "the", "table", ",", "the", "LR", "approach", "outperforms", "Global", "-", "INF", "approach", "for", "CLEF", ",", "DIATOMS", "and", "IPC", "datasets", "because", "these", "datasets", "are", "well", "balanced", "and", "have", "smaller", "number", "of", "categories", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["The", "VOI", "map", "construction", "accounts", "for", "the", "fact", "that", "the", "whole", "tumor", "is", "a", "superset", "of", "ET", ",", "NCR", "/", "NET", "and", "ED", ",", "and", "the", "tumor", "core", "includes", "ET", "and", "NCR", "/", "NET", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["One", "feature", "construction", "method", "geared", "specifically", "towards", "capturing", "feature", "interactions", "is", "multifactor", "dimensionality", "reduction", "(", "MDR", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "multifactor dimensionality reduction"}, {"tokens": ["The", "experimental", "results", "show", "that", "the", "proposed", "methods", "produce", "the", "lowest", "SAD", "results", "compared", "to", "the", "baseline", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "spectral angle distance"}, {"tokens": ["The", "details", "of", "AON", "and", "FG", "will", "be", "described", "in", "next", "section", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "filter gate"}, {"tokens": ["Let", "denote", "the", "SCC", "of", "and", "let", "be", "the", "PSP", "obtained", "by", "restricting", "to", "the", "-components", "and", "replacing", "all", "variables", "in", "lower", "SCCs", "by", "the", "constant", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "strongly connected components"}, {"tokens": ["This", "charging", "pattern", "during", "the", "CC", "phase", "was", "also", "present", "with", "the", "Galaxy", "S2", "and", "S4", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["The", "detailed", "review", "of", "PSO", "based", "feature", "selection", "methods", "has", "been", "discussed", "in", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["In", "each", "iteration", ",", "the", "atom", "selected", "by", "OMP", "is", "not", "designed", "to", "minimize", "the", "residual", "norm", "after", "projecting", "the", "target", "signal", "onto", "the", "selected", "elements", ",", "while", "OLS", "selects", "the", "atom", "that", "minimizes", "the", "residual", "based", "on", "the", "previously", "selected", "atoms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["To", "sequentially", "evaluate", "the", "approximated", "lower", "bound", "on", "our", "marginal", "likelihood", "distribution", ",", "we", "have", "to", "reconstruct", "the", "continual", "prior", "using", "the", "conditional", "predictive", "formula", "of", "GP", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Ad", "-", "hoc", "QA", ":"], "acronym_pos": [0, 0, 0, 1, 0], "long_form": "question answering"}, {"tokens": ["ABEP", ",", ",", "of", "square", "-QAM", "versus", "the", "number", "of", "relay", "nodes", ",", ",", "for", "average", "transmit", "SNR", "dB", "and", "dB", "over", "IID", "Nakagami-", "fading", "channels", "with", "different", "values", "of", ":", "(", "A", ")", "Pure", "RS", ",", "(", "B", ")", "Rate", "-", "Selective", "RS", ",", "(", "C", ")", "Repetitive", "transmission", "with", "MRD", "and", "(", "D", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "maximal ratio diversity"}, {"tokens": ["Thus", ",", "it", "seems", "reasonable", "to", "try", "using", "ARD", "with", "a", "naturally", "trained", "teacher", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Figure", "6", "also", "illustrates", "that", "due", "to", "the", "increase", "of", ",", "the", "SC", "of", "the", "proposed", "scheme", "is", "comparatively", "higher", "than", "other", "conventional", "schemes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["The", "deallocation", "of", "that", "agent", "can", "be", "easily", "implemented", "using", "the", "following", "command", ":", "DestroyAgent(&A", ",", "_", "PSO", "_", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Outside", "the", "single", "peak", ",", "there", "are", "only", "weak", "confidential", "message", "power", "seriously", "corrupted", "by", "AN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "artificial noise"}, {"tokens": ["(", "GI", ":", "gradient", "initialization", ",", "SSS", ":", "staggered", "sample", "selection", ",", "SOM", ":", "standard", "SOM", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient initialization"}, {"tokens": ["The", "RMSE", "of", "the", "Maximum", "Voiced", "Frequency", "prediction", "is", "in", "the", "range", "of", "654", "-", "1177", "Hz", ",", "indicating", "that", "for", "some", "speakers", "the", "MVF", "can", "be", "estimated", "with", "lower", "error", ",", "while", "for", "Female", "1", "this", "task", "was", "more", "difficult", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["One", "common", "characteristic", "of", "the", "previous", "literature", "on", "shilling", "attacks", "on", "CF", "-", "RS", "is", "their", "focus", "on", "assessing", "the", "global", "impact", "of", "shilling", "attacks", "on", "different", "CF", "models", "by", "examining", "the", "success", "of", "attacks", "from", "the", "perspective", "of", "attacker", "'s", "knowledge", "and", "the", "size", "of", "attack", "(", "i.e.", "the", "number", "of", "shilling", "profiles", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Here", ",", "we", "use", "the", "non", "-", "linear", "expressiveness", "of", "neural", "networks", "with", "the", "IB", "principle", "to", "recover", "a", "low", "-", "dimensional", "interpretable", "representation", "for", "approximating", "the", "causal", "effects", "of", "an", "intervention", "more", "effectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Specifically", ",", "we", "aim", "to", "jointly", "optimize", "the", "bandwidth", "unit", "and", "power", "allocation", "to", "minimize", "the", "TTP", "while", "guaranteeing", "each", "vehicle", "'s", "minimum", "throughput", "requirement", "and", "the", "budget", "of", "the", "total", "available", "bandwidth", "units", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "total transmit power"}, {"tokens": ["b", ")", "Boundary", "-", "based", "OCC", "is", "trained", "to", "produce", "a", "value", "of", "at", "the", "output", "for", "healthy", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "one class classifier"}, {"tokens": ["Therefore", ",", "Figure", "indicates", "a", "tradeoff", ",", "namely", ",", "higher", "guarantees", "more", "data", "packets", "collected", "from", "individual", "node", "while", "sacrificing", "the", "system", "throughput", ";", "smaller", "achieves", "a", "higher", "system", "throughput", ",", "however", ",", "it", "does", "not", "guarantee", "most", "of", "data", "can", "be", "collected", "from", "individual", "node", "since", "the", "BS", "gives", "the", "priority", "to", "the", "one", "with", "larger", "after", "all", "nodes", "satisfy", "the", "fairness", "constraint", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Through", "a", "heuristic", "algorithm", ",", "the", "AM", "-", "FEC", "protection", "minimises", "the", "amount", "of", "redundant", "information", "sent", "with", "the", "original", "data", "set", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Proof", "of", "Proposition", "1The", "standard", "form", "of", "GP", "is", "defined", "as", "follows", ":", "rCl", "s.t", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["This", "is", "for", "the", "exponential", "IB", "Lagrangian", "vs.", "for", "the", "power", "IB", "Lagrangian", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "MGM", "GAN", "leverages", "the", "manifolds", "arising", "from", "a", "pre", "-", "trained", "autoencoder", "to", "bridge", "the", "gap", "between", "formal", "manifold", "alignment", "literature", "and", "existing", "GAN", "work", ",", "and", "demonstrate", "the", "advantages", "of", "modeling", "the", "manifold", "geometry", "over", "its", "density", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "manifold geometry matching"}, {"tokens": ["Overall", "the", "performance", "of", "CNet", "-", "NIC", "is", "comparable", "to", "or", "better", "than", "all", "other", "models", "on", "all", "measures", ",", "especially", "with", "respect", "to", "CIDEr", "-", "D", ",", "the", "only", "measure", "that", "is", "explicitly", "designed", "for", "the", "purpose", "of", "evaluating", "image", "captions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural image caption"}, {"tokens": ["As", "mentioned", "in", "Section", "2", ",", "interpretation", "and", "explanatory", "power", "are", "important", "aspects", "of", "using", "AI", "for", "data", "mining", ",", "and", "therefore", "GP", "methods", "that", "produce", "concise", "models", ",", "e.g.", "by", "local", "search", "or", "Pareto", "optimization", ",", "are", "important", "options", "to", "include", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["The", "RMSE", "improvement", "of", "the", "ANN", "model", "over", "the", "LMEM", "model", "exceeded", "35", "when", "the", "applied", "current", "was", "in", "the", "range", "of", "30", "-", "35", "A", ",", "while", "the", "improvement", "of", "the", "RF", "model", "was", "around", "20", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["According", "to", ",", "the", "auxiliary", "variables", "act", "as", "a", "support", "for", "the", "covariance", "function", "of", "the", "GP", "thereby", "allowing", "it", "to", "be", "evaluated", "on", "these", "points", "instead", "of", "the", "entire", "dataset", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Tetracam", "ADC", "-", "lite", "camera", ",", "GPS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0], "long_form": "global positioning system"}, {"tokens": ["However", ",", "in", "general", ",", "the", "PRR", "works", "fine", "for", "both", "modes", "of", "PAT", "delay", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pre - reduced ring"}, {"tokens": ["Compression", "resultsTables", "and", "summarise", "the", "compression", "results", "of", "ViSTRA2", "for", "JVET", "CTC", "test", "sequences", "when", "integrated", "with", "HM", "16.20", "and", "VTM", "4.01", ",", "using", "PSNR", "and", "VMAF", "as", "quality", "metrics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "common test conditions"}, {"tokens": ["CM", "is", "a", "diagonal", "matrix", "in", "ideal", "case", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "confusion matrix"}, {"tokens": ["We", "define", "the", "gain", "of", "the", "computational", "cost", "to", "the", "full", "OPF", "problem", "as", ":", "where", "and", "are", "the", "computational", "times", "(", "or", "meta", "-", "losses", ")", "of", "the", "original", "full", "OPF", "problem", "and", "the", "machine", "-", "learning", "based", "approach", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["This", "leads", "to", "the", "following", "practical", "needs", "of", "an", "IS", "practitioner", ":", "(", "1", ")", "read", ",", "write", "and", "understand", "formal", "specifications", ",", "(", "2", ")", "be", "able", "to", "formalize", "informal", "specifications", ",", "(", "3", ")", "analyze", "specifications", "and", "detect", "sources", "of", "incompleteness", ",", "inconsistency", "and", "complexity", ",", "(", "4", ")", "reason", "about", "specifications", ",", "and", "(", "5", ")", "check", "a", "system", "against", "a", "specification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["We", "use", "the", "IB", "proposed", "in", "as", "our", "bottleneck", "module", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Although", "the", "angles", "are", "comparable", ",", "constrained", "BP", "still", "slightly", "outperforms", "FA", "(", "Table", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["However", ",", "unlike", "VAE", "-", "GAN", "that", "uses", "different", "networks", "for", "discriminator", "and", "encoder", ",", "IAN", "combines", "the", "discriminator", "and", "encoder", "into", "a", "single", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "introspective adversarial network"}, {"tokens": ["As", "mentioned", "before", ",", "LSC", "is", "a", "collection", "which", "texts", "are", "from", "252", "different", "categories", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Notice", "that", "the", "formulated", "problem", "in", "Rmax", "-", "epsilon", "is", "designed", "to", "optimize", "the", "management", "of", "RE", "and", "RF", "energies", "for", "EH", "nodes", "using", "the", "PS", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power splitting"}, {"tokens": ["Theorem", "1", "provides", "a", "general", "convergence", "rate", "for", "FL", "with", "an", "arbitrary", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["The", "number", "of", "data", "packets", "received", "by", "the", "BS", "in", "a", "super", "frame", "is", "defined", "as", ",", "whereSimilarly", ",", "for", "all", "super", "frames", ",", "the", "data", "received", "by", "the", "BS", "from", "any", "node", "is", "defined", "as", ",", "where", "Energy", "ModelThe", "energy", "consumption", "of", "nodes", "arises", "from", "the", "transmissions", "in", "RCAP", "and", "SDTP", "as", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Following", "the", "same", "methodology", ",", "it", "is", "possible", "to", "build", "an", "end", "-", "to", "-", "end", "speech", "interfaced", "QA", "system", "with", "deep", "neural", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "accuracy", "was", "evaluated", "using", "two", "different", "classifier", "system", "(", "i.e.", ",", "GMM", "adapted", "with", "UBM", "and", "i", "-", "Vector", "-", "PLDA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "below", "2000", "Hz", "is", "between", "the", "square", "root", "of", "the", "sine", "transmissibility", "and", "the", "twice", "the", "square", "root", "of", "sine", "transmissibility", "(", "when", "the", "is", "the", "result", "from", "FEM", "simulation", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["+", "(", "-^x)equationWhere", "is", "the", "LR", "model", "parameter", "(", "regression", "coefficients", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["In", "FL", ",", "each", "participant", "trains", "a", "model", "locally", "and", "exchanges", "only", "model", "parameters", "with", "others", ",", "instead", "of", "the", "active", "privacy", "-", "sensitive", "training", "data", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["Let", "be", "the", "set", "of", "sensor", "nodes", "that", "can", "communicate", "with", "the", "AP", "when", "the", "sensor", "deployment", "is", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Of", "course", ",", "these", "two", "ideas", "are", "quite", "closely", "linked", "since", ",", "for", "example", ",", "doing", "DR", "to", "a", "dimension", "smaller", "than", "suggested", "by", "DE", "will", "likely", "lead", "to", "information", "loss", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["For", "one", "case", ",", "EMD", "succeeds", "to", "find", "the", "optimal", "mapping", "whereas", "DMD", "fails", ",", "and", "in", "the", "other", "case", ",", "the", "reverse", "is", "true", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deficient mapping dissolution"}, {"tokens": ["[", "CC", ",", "35", "runs", ",", "24", "clust", "]"], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "connected caveman"}, {"tokens": ["Syntax", "-", "driven", "Rule", "-", "based", "ApproachesThe", "line", "of", "work", "on", "structural", "TS", "starts", "with", "Chandrasekar:1996:MMT:993268.993361", ",", "who", "manually", "defines", "a", "set", "of", "rules", "to", "detect", "points", "where", "sentences", "may", "be", "split", ",", "such", "as", "relative", "pronouns", "or", "conjunctions", ",", "based", "on", "chunking", "and", "dependency", "parse", "representations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tree structures"}, {"tokens": ["ConclusionIn", "this", "paper", ",", "we", "look", "at", "learning", "from", "multiple", "API", "libraries", "and", "datasets", "in", "the", "context", "of", "learning", "to", "translate", "text", "to", "code", "representations", "and", "other", "SP", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "semantic parsing"}, {"tokens": ["The", "idea", "of", "the", "algorithm", "bases", "on", "the", "assumption", "that", "the", "PAP", "is", "known", "during", "process", "scheduling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "process arrival pattern"}, {"tokens": ["The", "convex", "IB", "Lagrangian", "was", "calculated", "using", "the", "nonlinear", "-", "IB", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "information bottleneck"}, {"tokens": ["Editora", "Blucher", ",", "Sao", "Paulo", ",", "SP", "(", "2011", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "sao paulo"}, {"tokens": ["This", "suggests", "that", "the", "decisions", "where", "the", "GCNN", "hesitates", "are", "those", "that", "are", "intrinsically", "difficult", ",", "since", "on", "those", "the", "expert", "hesitates", "more", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["Continual", "GP", "vs.", "Baseline", "methods)In", "our", "last", "experiment", ",", "we", "are", "interested", "in", "the", "comparison", "of", "the", "continual", "GP", "framework", "with", "previous", "baselines", "techniques", "in", "the", "literature", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "ViewFEC", "mechanism", "imposes", ",", "on", "average", ",", "40", "less", "network", "overhead", "than", "the", "non", "-", "adaptive", "Video", "-", "aware", "FEC", ",", "with", "equal", "or", "slightly", "better", "video", "quality", ",", "as", "shown", "in", "Figure", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["gun_drilling_results_all_metric_byalg_cmp_others.eps", "Illustration", "of", "the", "performance", "between", "different", "machine", "learning", "algorithms", ",", "i.e.", "DBN", "and", "SVM", ",", "MLP", ",", "KNN", ",", "GB", ",", "LR", ",", "AdaBoost", ",", "Lasso", ",", "and", "SGD", ",", "on", "gun", "drilling", "imbalanced", "dataset", "in", "terms", "of", "accuracy", ",", "G", "-", "Mean", ",", "AUC", ",", "precision", ",", "F1-score", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["We", "however", "only", "study", "the", "dynamic", "version", "of", "treating", "IAN", "and", "leave", "the", "other", "cases", "for", "future", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interference as noise"}, {"tokens": ["They", "reported", "a", "strong", "correlation", "between", "VAT", "-", "V", "and", "age", "both", "in", "men", "and", "women", ",", "whereas", "SAT", "-", "V", "only", "slightly", "increased", "with", "age", "in", "women", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Similarly", "for", "IFD", ",", "using", "N", "-", "PCA", "method", "figure", "shows", "the", "correct", "face", "recognition", "result", "and", "figure", "presents", "incorrect", "recognition", "result", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "indian face database"}, {"tokens": ["In", "the", "classification", "experiments", ",", "GP", "inference", "was", "done", "using", "Expectation", "Propagation", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["However", ",", "the", "IA", "labeling", "error", "rate", "drops", "to", "25.9", "on", "post", "-", "edited", "MT", "outputs-", "only", "a", "1.5", "increase", "in", "NLU", "errors", "caused", "by", "translation", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intent analyst"}, {"tokens": ["The", "introduction", "of", "a", "generalized", "learning", "framework", "can", "help", "in", "transferring", "most", "of", "the", "existing", "PSO", "related", "research", "from", "continuous", "domain", "(", ")", "to", "the", "feature", "selection", "problem", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["We", "see", "that", "RS", "outperforms", "RBP", "and", "both", "outperform", "SRBP", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["Neural", "Transition", "ModelIn", "a", "SSM", ",", "the", "temporal", "evolution", "of", "latent", "states", "is", "determined", "by", "the", "transition", "matrix", "as", "in", "Equation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state space model"}, {"tokens": ["liu", "proposed", "an", "ISP", "that", "can", "selectively", "disable", "stages", "based", "on", "application", "needs", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["However", ",", "for", "obtaining", "a", "reasonable", "performance", "on", "handwritten", "word", "recognition", "tasks", ",", "the", "CTC", "-", "based", "approaches", "have", "to", "stay", "along", "with", "its", "limitations", ",", "such", "as", "the", "high", "complexity", "and", "the", "slowness", "to", "train", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["For", "instance", "every", "DBP", "automaton", "is", "GFG", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["The", "selected", "SAR", "images", "were", "taken", "in", "High", "Resolution", "Spotlight", "mode", "with", "the", "pixel", "spacing", "of", "1.25", "m", ",", "acquired", "with", "an", "incidence", "angle", "between", "20", "and", "50", ",", "and", "with", "descending", "and", "ascending", "pass", "directions", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["t", "]", "Block", "Diagram", "of", "SAR", "System", "Using", "UAVs", "with", "Machine", "Learning", "Technology", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["Finally", ",", "as", "the", "number", "of", "antennas", "increases", ",", "the", "optimal", "PA", "factor", "becomes", "large", "and", "tends", "to", "one", "in", "the", "medium", "and", "high", "SNR", "region", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["Table", "shows", "the", "average", "RMSE", ",", "PR", ",", "and", "CCC", "for", "the", "models", "trained", "with", "one", ",", "two", ",", "three", "and", "four", "shared", "layers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["A", "feature", "was", "considered", "robust", "if", "ICC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["Particularly", ",", "our", "method", "improves", "the", "F", "-", "score", "by", "more", "than", ",", "while", "advances", "CD", "a", "large", "step", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "chamfer distance"}, {"tokens": ["In", "the", "case", "of", "FEC", "-", "based", "mechanisms", ",", "a", "number", "of", "open", "issues", "arose", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Here", ",", "we", "assume", "that", "the", "BS", "-", "MS", "antenna", "height", "difference", "is", "sufficiently", "small", "so", "that", "a", "horizontal", "communication", "link", "can", "be", "considered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Kernels", "of", "the", "GP", "are", "estimated", "by", "using", "variograms", "and", "a", "discrete", "grid", "search", "method", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["By", "contrast", ",", "the", "average", "Pareto", "completion", "is", "defined", "as", "the", "specific", "fraction", "of", "the", "solutions", "on", "the", "true", "OPF", "identified", "by", "the", "EQPO", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "optimal pareto front"}, {"tokens": ["Also", ",", "a", "low", "-", "complexity", "UE", "selection", "algorithm", "was", "proposed", "to", "guarantee", "the", "feasibility", "of", "the", "NPC", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["depicts", "the", "average", "sum", "-", "rate", "with", "total", "number", "of", "receive", "antennas", "at", "the", "BS", ",", "and", "two", "values", "of", "the", "number", "of", "selected", "users", "and", "while", "adopting", "the", "proposed", "scheme", "with", "ZF", "receiver", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["app5", "Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "left", ")", "and", "MB", "-", "enumerating", "(", "right", ")", "algorithms", "on", "graphs", "where", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["Cumulative", "energy", "error", "distribution", "per", "direction", "for", "the", "RB", "of", "the", "fibrous", "microstructure", "under", "validation", "boundary", "conditions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["HTER", "reflects", "the", "overall", "performance", "of", "the", "algorithm", "in", "a", "balanced", "setting", "where", "FAR", "is", "equal", "to", "FRR", ",", "for", "Equal", "Error", "Rate", "(", "EER", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "false acceptance rate"}, {"tokens": ["The", "core", "component", "of", "a", "PS", "agent", "is", "its", "clip", "network", "which", "is", "comprised", "of", "units", "of", "episodic", "memory", "called", "clips", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "projective simulation"}, {"tokens": ["t]By", "solving", "the", "problem", "(", ")", ",", "we", "can", "obtain", "the", "optimal", "information", "beamforming", "matrices", "and", "the", "AN", "beamforming", "matrix", "Q.However", ",", "the", "objective", "function", "in", "(", ")", "is", "non", "-", "convex", "and", "difficult", "to", "tackle", ",", "as", "it", "comprises", "the", "logarithms", "of", "the", "product", "of", "fractional", "quadratic", "functions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["We", "evaluate", "three", "performance", "metrics", ":", "number", "of", "data", "packets", "received", "by", "the", "BS", "(", "data", "reception", ")", ",", "the", "number", "of", "fair", "nodes", "and", "the", "number", "of", "dead", "nodes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "the", "future", "work", ",", "we", "will", "explore", "PNN", "with", "more", "general", "and", "complicated", "product", "layers", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Our", "work", "indicates", "that", "the", "GCNN", "model", ",", "especially", "using", "sum", "convolutions", "with", "the", "proposed", "prenorm", "layer", ",", "is", "a", "good", "architectural", "prior", "for", "the", "task", "of", "branching", "in", "MILP", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["Using", "GMM", ",", "three", "optimum", "clusters", "corresponding", "to", "low", ",", "moderate", "and", "high", "progression", "rate", "were", "identified", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["This", "switch", "in", "AP", "association", "can", "be", "triggered", "by", "the", "mobile", "device", "(", "e.g.", "stronger", "wireless", "signal", ")", "or", "by", "the", "network", "management", "system", "(", "e.g.", "load", "balancing", ")", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["ExperimentsWe", "experimented", "with", "two", "main", "types", "of", "resources", ":", "45", "API", "documentation", "datasets", "and", "two", "multilingual", "benchmark", "SP", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "semantic parsing"}, {"tokens": ["Because", "LR", "does", "not", "naturally", "handle", "temporal", "data", ",", "24", "one", "-", "hour", "buckets", "of", "patient", "history", "are", "concatenated", "into", "one", "vector", "along", "with", "the", "static", "demographic", "vector", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Therefore", ",", "the", "SINR", "coverage", "probability", "of", "the", "network", "can", "be", "computed", "using", "the", "total", "probability", "law", "as", "followswhere", "and", "is", "the", "conditional", "coverage", "and", "association", "probability", "given", "that", "the", "typical", "UE", "is", "associated", "with", "a", "BS", "in", "tier", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Filter", "-", "based", "FS", "is", "the", "easy", "technique", "to", "implement", "and", "can", "be", "adapted", "to", "each", "engineering", "problems", "independently", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feature selection"}, {"tokens": ["Future", "work", "will", "consider", "a", "more", "fine", "-", "grained", "set", "of", "DAs", "for", "a", "deeper", "analysis", "of", "CDA", "modeling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "concurrent dialogue acts"}, {"tokens": ["PSO", "like", "other", "evolutionary", "algorithms", "searches", "for", "the", "global", "optimum", "rather", "than", "local", "optimum", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "primary", "assumption", "in", "GP", "is", "that", "the", "data", "can", "be", "represented", "as", "a", "sample", "from", "a", "multivariate", "Gaussian", "distribution", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "hybrid", "mobility", "concept", "relies", "on", "a", "network", "-", "controlled", "mobility", "and", "an", "UE", "-", "autonomous", "mobility", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["As", "to", "how", "to", "teach", "logic", "to", "IS", "students", ",", "i.e.", ",", "designing", "concrete", "teaching", "methodologies", ",", "the", "following", "considerations", "need", "to", "be", "taken", "into", "account", ":", "Examples", "from", "software", "domains", "are", "useful", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["Then", "there", "is", "a", "bijective", "mapping", "from", "Lagrange", "multipliers", "from", "the", "convex", "IB", "Lagrangian", "to", "points", "in", "the", "IB", "curve", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Using", "TAS", "and", "SWIPT", "-", "Based", "Cooperative", "Transmissions", ",", "IEEE", "Transactions", "on", "Green", "Communications", "and", "Networking", ",", "2018", ",", "2(1", ")", ",", "pp", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transmit antenna selection"}, {"tokens": ["In", "addition", ",", "system", "performance", "using", "PLDA", "classifier", "is", "respectively", "higher", "than", "for", "GMM", "-", "UBM", "under", "noisy", "conditions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["WF", "Age", "Estimator", ";", "[", "-", ">", "]"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0], "long_form": "white females"}, {"tokens": ["For", ",", "a", "class", "of", "Exact", "-", "MBR", "codes", ",", "termed", "as", "repair", "-", "by", "-", "transfer", "codes", ",", "have", "been", "developed", "in", "prior", "work", "to", "avoid", "arithmetic", "operations", "in", "node", "repairing", "process", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "minimum bandwidth regenerating"}, {"tokens": ["Our", "results", "and", "contributions", "are", "summarized", "as", "follows", ":", "1", ")", "We", "show", "a", "novel", "user", "scheduling", "scheme", "for", "cellular", "systems", "equipped", "with", "a", "large", "antenna", "array", "at", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["presented", "a", "mixed", "picture", "in", "which", "the", "DC", "-", "SBM", "always", "dominated", "the", "original", "SBM", ",", "even", "more", "so", "at", "smaller", ",", "but", "the", "ICL", "criterion", "actually", "increased", "with", ",", "thus", "potentially", "requiring", "some", "penalty", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["In", "this", "paper", ",", "we", "present", "a", "comprehensive", "analysis", "of", "IFT", "/", "formal", "Trojan", "detection", "techniques", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "information flow tracking"}, {"tokens": ["In", "the", "first", "row", ",", "from", "left", "to", "right", ",", "the", "power", "IB", "Lagrangian", "with", "different", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "Basics", "of", "Grant", "-", "Free", "Random", "AccessThe", "conventional", "GB", "scheduling", "procedure", "in", "LTE", "networks", "involves", "exchanging", "multiple", "messages", "between", "nodes", "to", "facilitate", "exclusive", "channel", "access", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["A", "node", "with", "high", "BC", "may", "have", "considered", "more", "influential", "within", "the", "network", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["The", "lower", "accuracy", "for", "MIM", "-", "GOLD", "should", "thus", "not", "have", "been", "surprising", ",", "even", "though", "it", "has", "more", "data", "than", "IFD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "icelandic frequency dictionary"}, {"tokens": ["It", "is", "shown", "that", "DE", "-", "based", "deployment", "improves", "the", "network", "lifetime", "better", "than", "other", "optimization", "heuristics", "considered", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["PS", "is", "both", "and", "in", "single", "-", "type", "resources", "allocations", ",", "but", "not", "in", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["Generally", "speaking", ",", "there", "are", "two", "key", "parameters", "that", "affect", "DE", "process", "namely", "mutation", "factor", "and", "crossover", "probability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["PA", "-", "RTClem", ":"], "acronym_pos": [1, 0, 0, 0], "long_form": "peano 's arithmetics"}, {"tokens": ["User", "engagement", "is", "an", "important", "measure", "of", "SAR", "'s", "effectiveness", "and", "is", "inherently", "tied", "to", "learning", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["In", "Figure", "9", ",", "the", "EE", "w.r.t", "is", "plotted", "for", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "and", "compared", "with", "CNOMA", "-", "SWIPT", "-", "PS", ",", "CNOMA", "-", "SWIPT", "-", "TS", ",", "and", "OMA", "-", "SWIPT", "-", "PS", "-", "OAM", "schemes", "as", "well", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Scenario", "5", ":", "The", "attacker", "manipulates", "the", "malware", "instances", "by", "adopting", "LR", "function", "and", "bio", "-", "inspired", "solution", "to", "find", "a", "global", "solution", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Since", "any", "probability", "density", "function", "can", "be", "expressed", "as", "a", "Gaussian", "mixture", "model", ",", "the", "key", "insight", "from", "Lemma", "is", "not", "that", "the", "residual", "can", "be", "expressed", "as", "a", "GMM", ",", "but", "rather", "that", "the", "residual", "GMM", "can", "be", "found", "analytically", "from", "the", "GMMs", "of", "the", "system", "and", "measurement", "noises", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Note", "that", "since", "MBSs", "are", "distributed", "as", "PPP", ",", "the", "analytical", "expression", "in", "Lemma", "is", "the", "true", "distance", "distribution", "of", "nearest", "LOS", "/", "NLOS", "MBS", "to", "typical", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["Figure", "depicts", "an", "example", "of", "how", "the", "real", "location", "of", "a", "device", "is", "sensed", "by", "the", "wireless", "management", "system", "through", "AP", "associations", "(", "red", "stars", ")", "and", "finally", "how", "the", "discrete", "-", "time", "series", "is", "obtained", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["By", "introducing", "this", "layer", "into", "the", "IB", "module", ",", "our", "framework", "takes", "the", "channel", "-", "wise", "significance", "of", "each", "semantic", "feature", "into", "consideration", "and", "keeps", "balanced", "information", "constraints", "between", "them", "based", "on", "their", "respective", "significance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["A", "smoothing", "parameter", "value", "between", "(", "robust", "features", ":", "34.0", ";", "median", "ICC", ":", "0.85", ";", "median", "CI", "width", ":", "0.29", ")", "and", "(", "robust", "features", ":", "43.0", ";"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["Jensen", "-", "Shannon", "divergence", "LMG", ":", "Lindeman", ",", "Merenda", "and", "Gold", "unsrtSupplementary", "Material", "for", "Understanding", "the", "interplay", "between", "social", "and", "spatial", "behaviourResults", "obtained", "with", "the", "MDC", "datasetTables", ",", "and", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["The", "difference", "between", "OR", "and", "SC", "is", "that", "in", "OR", ",", "the", "best", "path", "is", "chosen", "prior", "to", "the", "sensor", "transmission", "and", "only", "the", "best", "path", "is", "activated", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "opportunistic relaying"}, {"tokens": ["Commonly", "Used", "Abbreviations", ":", "CD", "-", "Chained", "Declustering", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["To", "have", "a", "well", "-", "balanced", "scheme", "that", "is", "applicable", "in", "the", "low", "Mach", ",", "low", "Froude", "regime", ",", "we", "extend", "the", "second", "order", "AP", "IMEX", "scheme", "developed", "for", "the", "homogeneous", "Euler", "equations", "to", "include", "also", "a", "gravitational", "source", "term", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "asymptotic preserving"}, {"tokens": [":", "MGF_end_Final_Equalm", "over", "INID", "and", "IID", "Nakagami-", "fading", "channels", ",", "respectively", ",", "with", "integer", "fading", "parameters", ",", "the", "ASEP", "of", "several", "modulation", "formats", "for", "pure", "RS", "can", "be", "easily", "calculated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["Such", "an", "intuition", "is", "derived", "from", "the", "gradient", "of", "loss", "with", "respect", "to", "MAD", "unit", "(", "see", "Section", "sec", ":", "training", "-", "with", "-", "recursive", "-", "regression", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["Many", "similar", "systems", "of", "PS", "has", "adapted", "key", "-", "value", "store", "interfaces", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["In", "this", "example", "we", "approximate", "solutions", "to", "a", "scalar", "PVI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "parabolic variational inequality"}, {"tokens": ["The", "above", "method", "improved", "CER", ",", "but", "discardsmost", "of", "the", "information", "computed", "with", "the", "neuralnetwork", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["PSO", "consists", "of", "a", "swarm", "of", "particles", "that", "fly", "through", "hyperspace", "of", "the", "of", "objective", "function", "'s", "landscape", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Hence", ",", "we", "need", "to", "train", "the", "networks", "on", "real", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["Skeleton", "n", "-", "grams", "with", "universal", "POS", ":", "Natural", "practise", "and", "practice", "in", "your", "wizardry", "!"], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["This", "is", "best", "demonstrated", "by", "the", "easy", "chain", "dataset", "(", ")", "where", "RS", "takes", "significantly", "longer", "than", "LBP", ",", "which", "converges", "very", "quickly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "residual splash"}, {"tokens": ["[", "]", "Top", ":", "Distribution", "system", "constraint", "violations", "at", "node", "10", "avoided", "by", "using", "Con", "-", "TS", "-", "RTP", "instead", "of", "an", "unconstrained", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "thompson sampling"}, {"tokens": ["itemize(privacy", ")", "Algorithm", "(", "Algorithm", "alg", ":", "privGen", ")", "is", "-generalized", "differentially", "private", "(", "GDP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["Our", "model", "exhibits", "a", "relative", "improvement", "of", "in", "epoch", "-", "wise", "accuracy", "on", "the", "SC", "-", "task", "and", "on", "the", "RS", "-", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sleep cassette"}, {"tokens": ["Very", "recent", "works", "use", "pre", "-", "trained", "Transformer", "models", "for", "MR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "machine reading"}, {"tokens": ["The", "received", "signal", "power", "at", "UE", "from", "is", "expressed", "aswhere", "refers", "to", "the", "Rayleigh", "fading", "between", "UE", "and", ",", "which", "is", "distributed", "as", "an", "exponential", "distribution", "with", "mean", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Tx", "power", "&", "43", "dBm", "Height", "of", "Tx", "&", "20", "meter", "Height", "of", "Rx", "&", "3", "meter", "Height", "of", "Evaporation", "Duct", "&", "25", "meter", "Cable", "loss", "&", "3", "dBm", "Antenna", "Pattern", "&", "Omnidirectional", "Carriers", "per", "RB", "&", "12", "Noise", "Variance", "&", "1", "Problem", "formulation", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resource blocks"}, {"tokens": ["Joint", "model", "for", "NER", "and", "MDWe", "have", "experimented", "with", "three", "approaches", "for", "jointly", "learning", "NER", "and", "MD", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "morphological disambiguation"}, {"tokens": ["obtain", "almost", "identical", "ROC", "curves", ",", "we", "chose", "to", "show", "the", "one", "in", "fig", ":", "example_1_results(a", ")"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "list", "of", "top", "150", "DSA", "skills", "can", "viewed", "in", "the", "online", "appendix", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["FER_RF_ratethird", "confirm", "that", "the", "performance", "of", "turbo", "coded", "system", "with", "falls", "between", "BIPCM", "and", "MLPC", "with", "both", "SC", "decoding", "and", "SCL", "decoding", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "successive cancellation"}, {"tokens": ["2D", "CNN", "MTL", ",", "3D", "CNN", "ID", "and", "3D", "CNN", "LOC", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multi - task learning"}, {"tokens": ["In", "Section", "we", "will", "discuss", "how", "this", "analysis", "can", "be", "extended", "to", "the", "case", "when", "is", "obtained", "using", "an", "approximation", "to", "the", "LTE", "rate", "function", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Based", "on", "that", "the", "inefficient", "of", "the", "traditional", "PS", "framework", "on", "distributed", "deep", "learning", ",", "we", "applied", "parallel", "ring", "architecture", "to", "our", "temporal", "convolution", "network", "and", "received", "a", "good", "result", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["The", "highest", "possible", "ICC", "value", "is", "1.00", ",", "which", "indicates", "that", "feature", "values", "are", "fully", "repeatable", "between", "test", "-", "retest", "images", "or", "perturbations", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["ASR", "errors", "on", "question", "will", "affect", "the", "reasoning", "of", "a", "QA", "model", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "question answering"}, {"tokens": ["Similarly", ",", "if", "the", "fBS", "senses", "bad", "channel", "quality", "while", "the", "CQI", "from", "the", "UE", "report", "is", "constantly", "above", "a", "threshold", ",", "the", "fBS", "may", "determine", "that", "the", "fBS", "itself", "experiences", "exposed", "terminal", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["This", "was", "especially", "necessary", "for", "AC", "-", "OPF", "cases", ",", "where", "finding", "the", "same", "solution", "is", "less", "evident", "due", "to", "the", "non", "-", "convex", "nature", "of", "the", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["NP", "guzar(dan)PIr"], "acronym_pos": [1, 0], "long_form": "new persian"}, {"tokens": ["PLaTIBART", "uses", "Ethereum", "as", "its", "BC", "implementation", ",", "i.e", "DSL", "has", "Ethereum", "-", "specific", "required", "setting", "such", "as", "ChainID", "and", "GasLimit", "etc", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "blockchain"}, {"tokens": ["For", "HEVC", "-", "compatible", "MD", "video", "coding", ",", "the", "redundancy", "allocation", "is", "assigned", "based", "on", "a", "visual", "saliency", "model", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description"}, {"tokens": ["These", "two", "eliminators", "include", "(", "1", ")", "the", "use", "of", "gradient", "initialization", "to", "compute", "the", "initial", "values", "of", "the", "prototype", "vector", "of", "cloud", "type", "node", "(", "denoted", "as", "GI", ")", ";", "(", "2", ")", "staggered", "sample", "selection", "to", "feed", "cloud", "data", "for", "training", "(", "denoted", "as", "SSS", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "staggered sample selection"}, {"tokens": ["With", "difficult", "level", "3", ",", "only", "SC", "+", "Masking", "solves", "the", "game", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "score contextualisation"}, {"tokens": ["The", "RF", "and", "the", "ANN", "model", "reduced", "the", "root", "mean", "squared", "error", "of", "the", "LMEM", "when", "predicting", "the", "field", "magnitude", "by", "around", "40", "and", "80", ",", "respectively", ",", "over", "the", "entire", "current", "range", "of", "the", "eMNS", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "GP", "is", "defined", "by", "a", "mean", "function", "(", "in", "this", "paper", ",", "we", "consider", "only", "constant", "mean", "functions", ")", "and", "covariance", "kernel", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["recently", "used", "GANs", "to", "improve", "registration", "and", "segmentation", "of", "MR", "images", ",", "by", "generating", "new", "data", "and", "using", "multimodal", "algorithms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["The", "digital", "precoder", "at", "the", "BS", "is", "ZF", "precoder", "based", "on", "the", "equivalent", "channel", "in", "(", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["T=30", ",", "Distribution", "of", "social", "(", "above", "line", ")", "and", "spatial", "(", "bottom", "line", ")", "metrics", "for", "the", "CNS", "and", "MDC", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["The", "main", "feature", "of", "CSS", "is", "that", "signals", "with", "different", "SFs", "can", "be", "distinguished", "and", "received", "simultaneously", ",", "even", "if", "they", "are", "transmitted", "at", "the", "same", "time", "on", "the", "same", "channel", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "chirp spread spectrum"}, {"tokens": ["ECS", "-", "DBN", "outperforms", "all", "other", "competing", "algorithms", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["in", "pr", ":", "proximal", "update", ",", "the", "update", "rule", "in", "eq", ":", "KL", "-", "proximal", "update", "with", "natural", "parameter", "becomesIn", "other", "words", ",", "when", ",", "the", "update", "to", "the", "expectation", "parameter", "in", "eq", ":", "DMD", "is", "simply", "a", "convex", "combination", "of", "the", "sufficient", "statistics", "and", "the", "previous", "expectation", "parameter", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["The", "second", "and", "third", "setups", "consist", "of", "two", "and", "four", "PS", "respectively", "with", "workers", "ranging", "from", "one", "to", "seven", "machines", "located", "on", "separated", "machines", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "parameter server"}, {"tokens": ["However", ",", "the", "charging", "current", "(", "mA", ")", "drawn", "from", "the", "charger", "during", "the", "CC", "phase", "of", "charging", "does", "not", "change", "as", "the", "FCC", "of", "the", "battery", "decreases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["The", "computational", "complexity", "of", "AP", "is", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["When", "split", "happens", "at", "Split", "1", ",", "then", "all", "the", "functions", "are", "centralized", "at", "CC", "resulting", "in", "CRAN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["Similar", "to", "the", "original", "PNNproduct", "-", "based", "-", "nn", ",", "the", "PNN", "context", "encoder", "is", "composed", "of", "three", "layers", ":", "embedding", "layer", ",", "product", "layer", ",", "and", "FC", "layer", ",", "as", "shown", "in", "Figure", "fig", ":", "IPNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["median", "ICC", ":", "0.88", ";", "median", "CI", "width", ":", "0.23", ")", "offers", "a", "good", "compromise", "between", "aliasing", "and", "lack", "of", "image", "details", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["width=0.8", "Best", "and", "mean", "scores", "across", "similarity", "measures", "(", "CD", ",", "LND", ",", "JSD", ")", "on", "semantic", "representations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cosine distance"}, {"tokens": ["Given", "complete", "and", "effective", "features", ",", "GBM", "learns", "a", "sequence", "of", "tree", "classifiers", "for", "residual", "errors", "and", "is", "an", "effective", "method", "to", "build", "an", "advanced", "classifier", "from", "these", "featuresgbt", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gradient boosting machine"}, {"tokens": ["More", "people", "choosing", "the", "generated", "palette", "results", "in", "a", "higher", "FR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "fooling rate"}, {"tokens": ["Among", "all", "research", "studies", "had", "been", "done", ",", "according", "to", "the", "ABC", ",", "BA", ",", "BCO", "and", "HBMO", "are", "found", "the", "most", "useful", "application", ",", "from", "the", "highest", "number", "to", "the", "lowest", "number", ",", "in", "large", "scale", "engineering", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bee algorithm"}, {"tokens": ["This", "could", "be", "because", ",", "despite", "the", "noisiness", "of", "the", "DMD", "-", "MPC", "update", ",", "the", "setpoint", "controller", "in", "the", "car", "'s", "steering", "servo", "acts", "as", "a", "filter", ",", "smoothing", "out", "the", "control", "signal", "and", "allowing", "the", "car", "to", "drive", "on", "a", "consistent", "path", "(", "fig", ":", "speed_64", "in", "app", ":", "real", "world", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic mirror descent"}, {"tokens": ["BC", "of", "a", "node", "is", ",", "where", ",", "is", "the", "number", "of", "the", "shortest", "paths", "from", "node", "to", "passing", "through", "node", "and", "is", "the", "total", "number", "of", "shortest", "paths", "from", "node", "to", "node", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["40", ")", "for", "Flutes", "vs", "Cellos", ",", "5min-2h", "temporal", "and", "AP", "/", "Bldg", "spatial", "granularity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "access point"}, {"tokens": ["Mirrored", "disks", "such", "as", "ID", ",", "GRD", ",", "and", "CD", "are", "referred", "to", "as", "semistructured", "and", "shown", "to", "outperform", "BM", "as", "far", "as", "seek", "distances", "are", "concerned", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["The", "idea", "of", "the", "proposed", "solution", "of", "is", "to", "lock", "the", "masks", "using", "a", "key", "of", "SKE", ",", "secret", "share", "the", "key", "and", "allow", "to", "recover", "the", "key", "only", "when", "uses", "less", "than", "or", "equal", "to", "elements", "in", "the", "set", "inclusion", "protocols", "(", "i.e.", "in", "the", "OT", "executions", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "TI", "technique", "is", "more", "problematic", "than", "the", "TR", "scheme", "since", "the", "injected", "signal", "occupies", "the", "frequency", "band", "as", "the", "information", "bearing", "signals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tone reservation"}, {"tokens": ["combined", "the", "SBM", "and", "LDA", "to", "form", "the", "stochastic", "topic", "block", "model", "(", "STBM", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["The", "interference", "power", "with", "the", "received", "signal", "power", "constraint", "aggregated", "at", "UE", "is", "expressed", "asThe", "Laplace", "transforms", "of", "the", "desired", "received", "signal", "power", "and", "the", "interference", "power", "with", "the", "received", "signal", "power", "constraint", "are", "calculated", "byandwhere", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Shapley", "share", "coefficients", "(", ")", "for", "modelling", "UK", "(", "LHS", ")", "and", "US", "(", "RHS", ")", "GDP", "on", "a", "one", "-", "year", "horizon", "for", "different", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gross domestic product"}, {"tokens": ["t]Average", "ECE", "15", "(", ")", "and", "ACC", "(", ")", "on", "test", "set", "comparing", "the", "uncalibrated", "model", ",", "and", "the", "model", "calibrated", "with", "MFVI", "and", "MFVILR", "for", "each", "database", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "accuracy"}, {"tokens": ["For", "FL", "with", "redundant", "data", ",", "an", "energy", "-", "aware", "user", "scheduling", "policy", "was", "proposed", "in", "to", "maximize", "the", "average", "number", "of", "scheduled", "users", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["The", "PI", "=", "TRUE", "prints", "the", "prediction", "intervals", "used", "in", "nnar", "models", ",", "but", "may", "take", "long", "time", "processing", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "prediction intervals"}, {"tokens": ["In", "Table", "we", "present", "the", "detailed", "per", "class", "IoU", "for", "the", "GMM", "selection", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["NBC", "has", "the", "advantage", "of", "adapting", "the", "model", "complexity", "(", "i.e.", ",", "the", "number", "of", "clusters", ")", "to", "the", "amount", "of", "data", "available", ",", "and", "thus", "avoiding", "the", "problem", "of", "over", "-", "fitting", "and", "under", "-", "fitting", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "non - parametric bayesian classification"}, {"tokens": ["For", "training", "with", "distractor", ",", "is", "2.5", ",", "the", "VAT", "is", "75", ",", "and", "are", "0", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["The", "battery", "voltage", "first", "increases", "sharply", "within", "battery", "level", "five", "and", "then", "the", "voltage", "increases", "almost", "linearly", "as", "the", "SOC", "increases", "over", "the", "remaining", "CC", "phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "constant current"}, {"tokens": ["In", "help", "of", "deconvolution", ",", "we", "can", "align", "spatially", "the", "MAD", "vector", "with", "feature", "maps", "to", "be", "weighted", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "map attention decision"}, {"tokens": ["Since", "the", "RB", "model", "is", "trained", "on", "only", "the", "rotationally", "invariant", "part", "of", "but", "should", "be", "applied", "to", "general", "deformation", "gradients", ","], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["Two", "different", "backend", "classifiers", "were", "used-", "GMM", "-", "UBM", "and", "i", "-", "Vector", "\u2013", "PLDA", "along", "with", "GMM", "to", "evaluate", "the", "CI", "-", "user", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["To", "implement", "Algorithm", "3", ",", "the", "BS", "needs", "to", "gather", "the", "information", "of", ",", ",", ",", ",", ",", "and", ",", "which", "can", "be", "uploaded", "by", "all", "users", "before", "the", "FL", "process", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Motivated", "by", "the", "invariance", "properties", "of", "delay", "embedding", ",", "especially", "the", "invariance", "to", "the", "phase", "and", "length", "changes", "of", "the", "time", "series", ",", "we", "develop", "the", "online", "modeling", "and", "classification", "scheme", ",", "DDE", "-", "MGM", ",", "taking", "advantage", "of", "the", "invariance", "properties", "and", "high", "efficiency", "from", "the", "delay", "embedding", "technique", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Hence", ",", "we", "also", "compute", "the", "ROC", "convex", "hulls", ",", "since", "the", "points", "lying", "on", "the", "ROC", "convex", "hull", "are", "potentially", "optimal", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "mean", "values", "of", "the", "features", "that", "are", "robust", "according", "to", "the", "panel", "ICC", "are", "then", "included", "into", "the", "modelling", "process", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["Li", ",", "K.", ",", "Bao", ",", "J.", ",", "Lu", ",", "Z.", ",", "Qi", ",", "Q.", ",", "Wang", ",", "J.", ":", "A", "PSO", "-", "based", "virtual", "SDN", "customization", "for", "multi", "-", "tenant", "cloud", "services", "'", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["The", "aim", "of", "this", "section", "is", "to", "provide", "brief", "review", "of", "various", "learning", "approaches", "employed", "in", "PSO", "in", "the", "context", "of", "the", "feature", "selection", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Both", "the", "beamformer", "at", "the", "BS", "and", "the", "RIS", "phase", "shifts", "are", "jointly", "optimized", "to", "enhance", "the", "secrecy", "rate", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["(", ")", "Suppose", "is", "DBP", ",", "and", "let", "be", "an", "equivalent", "DCA", "obtained", "from", "by", "removing", "transitions", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "determinisable by pruning"}, {"tokens": ["The", "weight", "connections", "in", "DBN", "are", "between", "contiguous", "layers", ",", "there", "is", "no", "connections", "between", "the", "hidden", "neurons", "within", "the", "same", "layer", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "this", "way", ",", "the", "control", "parameters", "are", "automatically", "updated", "to", "appropriate", "values", "without", "the", "need", "of", "prior", "parameter", "setting", "knowledge", "in", "DE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "differential evolution"}, {"tokens": ["The", "distribution", "of", "the", "offsets", "are", "given", "as", ":", "The", "vector", "can", "be", "split", "into", "the", "parameters", "of", "the", "GMM", "as", ":", "The", "weight", "for", "each", "of", "the", "component", "in", "the", "GMM", "is", "calculated", "as", ":", "We", "then", "apply", "and", "operations", "to", "ensure", "that", "the", "standard", "deviations", "are", "non", "-", "negative", "and", "correlation", "is", "in", "the", "range", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["In", "this", "work", ",", "we", "instead", "employ", "two", "additional", "U", "-", "Nets", "that", "serve", "to", "tweak", "the", "predictions", "for", "ET", "and", "TC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "enhancing tumor"}, {"tokens": ["In", "the", "first", "stage", ",", "PIN", "module", "classifies", "the", "region", "proposals", "into", "higher", "-", "level", "phrase", "categories", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "phrase indexing network"}, {"tokens": ["In", "our", "experiments", ",", "PNN", "models", "outperform", "major", "state", "-", "of", "-", "the", "-", "art", "models", "in", "the", "CTR", "estimation", "task", "on", "two", "real", "-", "world", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["With", "the", "exception", "of", "SL2", "and", "SP2", "experiments", ",", "there", "is", "generally", "a", "drop", "in", "accuracy", "for", "LSTMs", "on", "the", "SP", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["6", "illustrates", "that", "the", "EHS", "-", "CNOMA", "with", "MRC", "provides", "the", "same", "OP", "than", "HS", "-", "CNOMA", "with", "SC", "for", "at", "CCU", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "selection combining"}, {"tokens": ["We", "however", "only", "study", "the", "dynamic", "version", "of", "treating", "IAN", "and", "leave", "the", "other", "cases", "for", "future", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "interference as noise"}, {"tokens": ["Experiment", "type", "1", "-", "3", "indicates", "the", "influence", "of", "upper", "-", "level", "results", ",", "previous", "time", "scales", "and", "different", "GMM", "component", "number", "separately", "Predicting", "Results", "by"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["Since", "this", "test", "is", "part", "of", "the", "DI", "strategy", ",", "we", "add", "the", "superscript", "to", "the", "test", "error", "probabilities", "and", "and", "have", ":", "What", "we", "can", "guarantee", ",", "since", "is", "that", "eq", ":", "max_MD_prob", "_", "i^DI1-(_i(1-_i)r_i_i(1+_minn_i))^n_i_min=_i"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "direct inspection"}, {"tokens": ["Neighborhood", "MatchingIn", "practice", ",", "a", "testing", "trajectory", "can", "not", "perfectly", "match", "an", "MGM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "markov geographic model"}, {"tokens": ["We", "assume", "that", "users", "exist", "within", "the", "macrocell", "BS", "unless", "otherwise", "stated", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Further", ",", "we", "would", "like", "to", "propose", "efficient", "generative", "models", "of", "temporal", "networks", "that", "preserve", "the", "CC", "property", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "core connected"}, {"tokens": ["At", "each", "epoch", ",", "we", "compute", "the", "CTC", "loss", "and", "validation", "error", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["OverviewThe", "adaptive", "FEC", "-", "based", "mechanism", "proposed", "in", "this", "section", "uses", "several", "video", "characteristics", "and", "packet", "loss", "rate", "prediction", "to", "shield", "real", "-", "time", "video", "transmission", "over", "wireless", "mesh", "networks", ",", "improving", "both", "the", "user", "experience", "and", "the", "usage", "of", "resources", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["The", "main", "challenge", "for", "the", "DST", "module", "is", "to", "handle", "the", "uncertainty", ",", "which", "stems", "from", "the", "errors", "made", "by", "the", "ASR", "module", "and", "the", "NLU", "unit", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dialogue state tracker"}, {"tokens": ["In", "summary", ",", "FN", "generates", "the", "dense", "outputs", "over", "the", "attention", "regions", "in", "the", "input", "image", "based", "on", "the", "glimpse", "vectors", "provided", "by", "AN", ",", "and", "AN", "in", "turn", "updates", "the", "glimpse", "vectors", "based", "on", "FN", "'s", "feedback", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["While", "the", "absolute", "average", "elapsed", "time", "savings", "of", "PRR", "algorithm", "are", "higher", "for", "longer", "messages", "(", "up", "to", "82ms", "for", "8", "M", ")", ",", "the", "high", "speedup", "values", "occur", "for", "all", "message", "sizes", "providing", "relative", "savings", "up", "to", "15", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "pre - reduced ring"}, {"tokens": ["Based", "on", "the", "comments", ",", "ACC", "is", "least", "preferred", "because", "it", "is", "perceived", "as", "taking", "full", "control", "over", "the", "speed", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adaptive cruise control"}, {"tokens": ["to", "subfigure", "fig", ":", "varyingoct", "Runtimes", "of", "the", "MIB", "-", "enumerating", "(", "top", ")", "and", "MB", "-", "enumerating", "(", "bottom", ")", "algorithms", "on", "graphs", "where", "and", "all", "expected", "edge", "densities", "are", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal biclique"}, {"tokens": ["SAR", "operations", "employing", "machine", "learning", "technology", "face", "many", "challenges", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["An", "ROC", "curve", "is", "generated", "by", "plotting", "the", "probability", "of", "a", "false", "alarm", "against", "the", "probability", "of", "detection", "as", "the", "threshold", "level", "is", "varied", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["It", "is", "easy", "to", "see", "that", "the", "higher", "the", "CC", "strength", ",", "the", "higher", "the", "likelihood", "that", "path", "-", "based", "high", "centrality", "vertices", "will", "be", "in", "the", "innermost", "core", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "core connected"}, {"tokens": ["For", "TFN", ",", "LMF", ",", "and", "MFM", ",", "we", "re", "-", "did", "experiments", "with", "using", "our", "features", "for", "a", "fair", "comparison", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "low - rank multimodal fusion"}, {"tokens": ["Due", "to", "all", "these", "advancements", ",", "AR", "is", "going", "to", "become", "better", "and", "quicker", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": ["As", "a", "result", ",", "some", "portion", "of", "this", "growing", "labour", "demand", "for", "DSA", "skills", ",", "particularly", "the", "highly", "technical", "DSA", "skills", ",", "could", "be", "explained", "by", "accelerating", "AI", "adoption", "by", "Australian", "firms", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["We", "chose", "to", "measure", "the", "quality", "of", "sampling", "through", "the", "positional", "RMSD", "from", "the", "native", "structure", "as", "a", "function", "of", "the", "simulation", "steps", "in", "both", "HMC", "and", "MD", "cases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["The", "DBF", "is", "backward", "compatible", "with", "existing", "LTE", "devices", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "long term evolution"}, {"tokens": ["The", "chosen", "techniques", "also", "consider", "an", "IPv6", "only", "ISP", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "internet service providers"}, {"tokens": ["Nakagami-", "fading", "is", "given", "byTo", "analyze", "the", "performance", "of", "ODF", "relaying", "schemes", ",", "the", "direct", "channel", "plus", "the", "RS", "-", "assisted", "channels", "are", "effectively", "considered", "as", "paths", "between", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["At", "every", "timestep", ",", "the", "UAV", "updates", "the", "GP", "mean", "and", "variance", "functions", "(", "Lines", "10", "and", "13", ")", "by", "using", "measurements", "collected", "up", "to", "and", "including", "the", "previous", "timestep", "(", "Line", "20", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "first", "one", "is", "without", "any", "type", "of", "FEC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "forward error correction"}, {"tokens": ["Performance", "of", "the", "UE", "selection", "algorithmFig", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Power", "control", "techniques", "have", "also", "been", "proposed", "to", "coordinate", "the", "interference", ",", "the", "work", "conducts", "a", "comparative", "study", "of", "LTE", "power", "control", "techniques", "applied", "to", "D2D", "communications", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["(", "ii", ")", "the", "calendar", "of", "official", "statistics", "data", "collection", "(", "Figure", "-", "Official", "Statistics", ")", ",", "and", "(", "iii", ")", "the", "time", "at", "which", "early", "estimations", "of", "cropland", "area", ",", "crop", "area", "and", "crop", "yield", "can", "theoretically", "be", "available", "based", "on", "EO", "data", "(", "Figure", "-", "Early", "Estimators", ")", ":", "What", "is", "the", "lowest", "error", "of", "crop", "production", "estimation", "achievable", "along", "the", "season", "?"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "earth observation"}, {"tokens": ["The", "rising", "challenges", "regarding", "the", "credibility", ",", "reliability", ",", "and", "validity", "of", "the", "state", "-", "of", "-", "the", "-", "art", "QA", "systems", "are", "of", "high", "importance", ",", "especially", "on", "critical", "domains", "such", "as", "life", "-", "science", "involved", "with", "human", "life", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["Inception", "score", "(", "IS", ")", "salimans2016improvedGAN", "evaluates", "an", "image", "based", "on", "the", "entropy", "in", "class", "probability", "distribution", "when", "it", "is", "put", "into", "a", "pre", "-", "trained", "image", "classifier", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "inception score"}, {"tokens": ["detect", "-", "mode", "=", "trueAblation", "study", "of", "our", "GCNN", "model", "on", "the", "set", "covering", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph convolutional neural network"}, {"tokens": ["The", "remaining", "power", "is", "allocated", "for", "the", "transmission", "of", "the", "common", "message", "of", "RS", ",", "which", "boosts", "the", "sum", "rate", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["The", "proposed", "method", "integrates", "the", "proposed", "GP", "based", "contour", "estimation", "method", "with", "the", "previously", "proposed", "contour", "segmentation", "and", "segment", "grouping", "methods", ",", "enabling", "improvements", "compared", "to", "existing", "segmentation", "methods", "with", "higher", "detection", "rate", "and", "segmentation", "accuracy", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["There", "are", "recordings", "(", "from", "SC", "subjects", "from", "ST", "subjects", ")", "in", "the", "training", "set", "and", "recordings", "(", "from", "SC", "subjects", "from", "ST", "subjects", ")", "in", "the", "test", "set", "of", "the", "RS", "-", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "subset compared"}, {"tokens": ["In", "conclusion", ",", "I", "have", "demonstrated", "that", "the", "Adv", "-", "BNN", "approach", "shows", "a", "performance", "increment", "tested", "on", "adversarial", "examples", "generated", "by", "the", "naive", "PGD", "method", "compared", "to", "the", "adversarial", "training", "of", "a", "standard", "CNN", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian neural networks"}, {"tokens": ["Corpus", "is", "converted", "to", "POS", "SkeletonsThe", "english", "measures", "were", "implemented", "as", "follows", ",", "with", "each", "measure", "being", "run", "with", "both", "standard", "and", "universal", "POS", "taggers", ":", "POS", "Skeleton", ":"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0], "long_form": "part of speech"}, {"tokens": ["For", "instance", ",", "the", "exponential", "IB", "Lagrangian", "could", "be", "more", "desirable", "than", "the", "power", "IB", "Lagrangian", "when", "we", "want", "to", "draw", "the", "IB", "curve", "since", "it", "has", "a", "finite", "range", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "joint", "-", "optimization", "approach", "using", "BPSO", "is", "compared", "to", "three", "other", "approaches", ":", "a", "BB", "-", "based", "solution", "with", "GP", ",", "a", "BPSO", "-", "based", "solution", "with", "the", "dual", "method", ",", "and", "a", "BB", "-", "based", "solution", "with", "the", "dual", "method", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["For", "the", "evaluation", "of", "QA", "systems", ",", "several", "benchmarks", "have", "been", "proposed", "such", "as", "WebQuestions", "or", "SimpleQuestions", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["As", "it", "is", "shown", ",", "the", "ROC", "curve", "of", "the", "GRTM", "clearly", "dominates", "the", "other", "two", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["An", "improvement", "to", "the", "above", "vocabulary", "matching", "system", ",", "which", "we", "refer", "to", "as", "probabilistic", "CER", ",", "uses", "character", "probabilities", "instead", "of", "the", "discrete", "top", "character", "prediction", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["However", ",", "these", "biases", "do", "not", "impede", "this", "research", "too", "significantly", ",", "as", "a", "major", "component", "of", "this", "research", "is", "comparing", "different", "classes", "of", "DSA", "jobs", ",", "which", "are", "all", "considered", "in", "the", "'", "Professionals", "'", "or", "'", "Managers", "'", "classes", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["We", "design", "deep", "3D", "neural", "nets", "based", "on", "3D", "DPN", "because", "of", "its", "compactness", "and", "effectiveness", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "dual path network"}, {"tokens": ["Every", "voxel", "is", "labelled", "as", "tumour", "or", "background", ",", "and", "compared", "to", "the", "ground", "truth", "using", "sensitivity", "(", ")", "and", "specificity", "(", ")", ",", "generated", "over", "a", "range", "of", "thresholds", "to", "obtain", "ROCs", "for", "each", "case", "and", "the", "mean", "ROC", "with", "95", "confidence", "intervals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["DE", "-", "SB", "clearly", "outperforms", "DE", "and", "DE", "-", "INV", "-", "SB", "."], "acronym_pos": [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Because", "the", "classes", "in", "this", "dataset", "are", "highly", "separable", "with", "regard", "to", "their", "BPM", ",", "we", "specifically", "included", "this", "'", "purposefully", "biased", "'", "dataset", "as", "an", "example", "of", "how", "a", "learned", "representation", "may", "effectively", "capture", "temporal", "dynamics", "properties", "present", "in", "a", "target", "dataset", ",", "as", "long", "as", "learning", "sources", "also", "reflected", "these", "properties", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "beat per minute"}, {"tokens": ["Similarly", ",", "the", "comparisons", "required", "for", "computing", "the", "MACS", "score", "for", "B", "are", ":", ",", ",", ",", ",", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean average conceptual similarity"}, {"tokens": ["On", "the", "other", "hand", ",", "the", "abundant", "unlabeled", "SAR", "images", "can", "be", "easily", "collected", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Despite", "these", "observations", ",", "the", "lower", "performance", "on", "the", "test", "set", "as", "compared", "to", "the", "cross", "-", "validation", "indicates", "that", "the", "presented", "method", "should", "not", "be", "understood", "as", "a", "general", "solution", "to", "VAT", "and", "SAT", "segmentation", "in", "water", "-", "fat", "MRI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Due", "to", "the", "assumed", "close", "distance", "between", "CCU", "and", "BS", ",", "Rician", "fading", "channel", "is", "considered", "[", "8].The", "NOMA", "link", "will", "not", "interfere", "with", "the", "OAM", "link", "due", "to", "the", "difference", "in", "OAM", "mode", "[", "13", "-", "15]."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["al", "have", "also", "provided", "equilibrium", "existence", "proofs", "for", "Bertrand", "competition", "between", "single", "-", "product", "firms", "that", "apply", "to", "the", "Logit", "RUM", ",", "assuming", "utility", "is", "linear", "in", "price", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random utility maximization"}, {"tokens": ["Therefore", ",", "there", "is", "a", "statistical", "meaningful", "difference", "between", "classifiers", "and", "sensitivity", ",", "precision", ",", "f", "measure", ",", "specificity", ",", "MCC", "and", "accuracy", "rates", "with", "95", "confidence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["Both", "methods", "yield", "an", "explicit", "result", "for", "the", "approximate", "GP", "posterior", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "the", "following", "experiments", ",", "the", "CER", "and", "WER", "metrics", "will", "range", "from", "[", "0", "-", "100]."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["For", "more", "difficult", "tasks", "on", "TVV", "and", "TAS", "retrieval", ",", "since", "SIFT", "feature", "can", "not", "fully", "capture", "the", "characteristics", "in", "TAS", ",", "the", "fusion", "of", "STIP", "and", "SIFT", "does", "not", "gain", "significant", "improvement", "where", "CCA", "even", "suffers", "great", "loss", "from", "SIFT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "transverse abdominal section"}, {"tokens": ["ConclusionWe", "presented", "a", "comprehensive", "approach", "for", "RV", "segmentation", "in", "cardiac", "MRI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "right ventricle"}, {"tokens": ["The", "PSO", "strategy", "allows", "the", "regulation", "of", "the", "transmitted", "power", "in", "order", "to", "maximize", "the", "energy", "efficiency", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Minimum", "Read", "ESQ", "(", "MR", "-", "ESQ", ")", ":"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "minimum read"}, {"tokens": ["With", "allocated", "transmission", "time", ",", "the", "energy", "consumed", "by", "MTCD", "can", "be", "modeled", "asWith", "allocated", "transmission", "time", ",", "the", "system", "energy", "consumption", ",", "denoted", "by", ",", "is", "modeled", "aswhere", "is", "the", "energy", "harvested", "by", "all", "MTCDs", "during", "the", "transmission", "time", "for", "MTCG", "to", "transmit", "data", "to", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["Nevertheless", ",", "here", ",", "both", "two", "gains", "are", "rendered", "to", "be", "adaptive", "by", "using", "theorems", "of", "guaranteeing", "robustnesses", "of", "STA", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["We", "also", "use", "the", "vector", "embedding", "of", "words", "and", "incorporate", "them", "with", "the", "VSM", "approach", "as", "mentioned", "above", "to", "estimate", "the", "semantic", "similarity", "between", "the", "source", "-", "language", "and", "the", "target", "-", "language", "documents", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "vector space model"}, {"tokens": ["CNS", "dataset", ":", "correlation", "between", "the", "four", "dimensions", "of", "social", "and", "spatial", "behaviour", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "copenhagen networks study"}, {"tokens": ["The", "SBM", "estimates", "6", "clusters", ";", "it", "does", "manage", "to", "partially", "detect", "the", "community", "structure", "byclustering", "the", "mid", "-", "level", "and", "peripheral", "nodes", "together", ",", "but", "itsplits", "the", "central", "nodes", "off", "into", "clusters", "of", "their", "own", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Personalized", "SAR", "Intervention", "Design", "details", "the", "study", "design", ",", "data", "collection", ",", "and", "outcome", "measures", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["c", "c", "c", "c", "c", "c", "c", "c", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "&", "Balancing", "loads", "in", "CD", "after", "fails", "and", "and", "failures", "by", "routing", "read", "requests", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "consecutive disks"}, {"tokens": ["Depending", "on", "the", "microstructure", "(", "especially", "the", "geometry", ",", "material", "nonlinearities", ",", "and", "phase", "contrast", ")", ",", "the", "loading", "conditions", ",", "and", "the", "size", "of", "the", "RB", ",", "speed", "-", "up", "factors", "are", "in", "the", "order", "of", "5", "-", "100", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "reduced basis"}, {"tokens": ["One", "implements", "the", "operational", "semantics", "of", "Take", "in", "AML", "semantic", "rules", ":", "Upon", "taking", "a", "message", "from", "the", "head", "of", "the", "actor", "queue", ",", "the", "respective", "method", "body", "is", "selected", "in", "terms", "of", "the", "method", "name", "to", "be", "executed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["We", "also", "compared", "the", "results", "obtained", "from", "TS", "-", "RF", "with", "GA", "-", "LR", "proposed", "by", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "tabu search"}, {"tokens": ["When", "RS", "-", "based", "transmission", "is", "used", ",", "one", "time", "slot", "is", "needed", "for", "the", "relay", "node", "with", "the", "most", "favourable", "channel", "conditions", "to", "forward", "'s", "signal", "to", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate - selective"}, {"tokens": ["that", "the", "TTP", "required", "by", "all", "the", "methods", "decreases", "with", "the", "channel", "coherence", "bandwidth", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "total transmit power"}, {"tokens": ["MMP", "wrg", "/warrag/", "NP", "barrah", "'", "lamb'*parna-"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["Because", "CIDEr", "-", "D", "measures", "the", "similarity", "of", "a", "candidate", "image", "caption", "to", "a", "collection", "of", "human", "generated", "reference", "captions", ",", "our", "results", "suggest", "that", "the", "incorporation", "of", "background", "knowledge", "from", "ConceptNet", "enables", "CNet", "-", "NIC", "to", "produce", "captions", "that", "are", "more", "similar", "to", "those", "generated", "by", "humans", "than", "those", "produced", "by", "methods", "that", "do", "not", "leverage", "such", "background", "knowledge", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural image caption"}, {"tokens": ["As", "expected", "DADA()+CP", "and", "DADA", "(", ")", "are", "the", "policies", "with", "the", "lowest", "bandwidth", "footprint", "up", "to", "6", "GPU", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["FEC", "-", "based", ":", "accounts", "for", "mechanisms", "that", "employ", "FEC", ";", "ARQ", "-", "based", ":", "mark", "mechanisms", "that", "use", "ARQ", ";", "QoE", "-", "sensitive", "data", ":", "this", "parameter", "demonstrates", "mechanisms", "that", "identity", "and/or", "considerate", "the", "video", "content", "to", "define", "the", "EC", "policy", ";", "Video", "-", "aware", ":", "check", "mark", "is", "given", "to", "mechanisms", "that", "use", "any", "video", "characteristics", "to", "define", "the", "amount", "of", "redundancy", "and/or", "retransmission", ";", "High", "-", "quality", "video", ":", "it", "is", "marked", "if", "the", "mechanisms", "are", "using", "videos", "equal", "or", "higher", "than", "720p", "(", "HD", "ready", ")", ";", "Network", "status", ":", "this", "parameter", "defines", "if", "the", "mechanisms", "use", "the", "information", "about", "the", "network", "healthy", "to", "define", "the", "redundant", "data", ";", "UEP", "-", "enabled", ":", "means", "that", "different", "amounts", "of", "redundancy", "are", "being", "added", "to", "distinct", "portions", "of", "the", "video", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Also", ",", "it", "is", "of", "our", "interest", "to", "consider", "the", "impact", "of", "various", "shilling", "attack", "types", "on", "CF", "models", "using", "item", "content", "as", "side", "information", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "rationale", "for", "this", "threshold", "level", "was", "that", "occupations", "just", "below", "this", "cutoff", "are", "questionably", "considered", "DSA", "occupations", "-", "take", "for", "example", ",", "'", "Web", "Developer", "'", "and", "'", "UI", "/", "UX", "Designer", "/", "Developer", "'", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["The", "first", "is", "lack", "of", "mathematical", "background", ":", "the", "undergraduate", "IS", "study", "program", "at", "the", "University", "of", "Haifa", "does", "not", "include", "a", "course", "in", "logic", ",", "and", "the", "majority", "of", "students", "have", "only", "a", "background", "in", "discrete", "mathematics", ",", "where", "they", "are", "taught", "very", "basic", "concepts", "of", "set", "theory", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information systems"}, {"tokens": ["Data", "CollectionTo", "build", "a", "spoken", "version", "QA", "dataset", ",", "we", "conducted", "the", "following", "procedures", "to", "generate", "spoken", "documents", "and", "questions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["ROC", "curves", "for", "both", "schemes", "[", "h", "!", "]"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["When", "excluding", "the", "sample", "being", "tested", "from", "the", "training", "set", ",", "the", "highest", "CCR", "averaged", "over", "all", "tested", "samples", "was", "68.58", ",", "which", "is", "a", "24.97", "less", "than", "the", "CCR", "reported", "in", "the", "original", "work", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "correct classification ratio"}, {"tokens": ["GP", "is", "data", "-", "efficient", "and", "has", "much", "less", "parameters", "than", "neural", "network", ",", "but", "its", "expressive", "capability", "is", "not", "as", "good", "as", "neural", "network", ",", "especially", "in", "high", "-", "dimensional", "problems", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "TS", "consists", "in", "spectral", "bands", "resampled", "at", "10", "m", "and", "additional", "radiometric", "indices", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "time series"}, {"tokens": ["Therefore", ",", "routes", "of", "the", "users", "are", "selected", "such", "that", "the", "sum", "of", "the", "BC", "of", "the", "nodes", "appearing", "in", "the", "user", "'s", "route", "is", "minimum", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "betweenness centrality"}, {"tokens": ["Sens", "defines", "the", "true", "positive", "rate", "i.e.", "correctly", "identified", "by", "the", "classifier", ",", "gini", "coefficient", "determines", "the", "inequality", "in", "the", "distribution", "and", "it", "should", "be", "between", "0", "and", "1", ",", "where", "N", "is", "the", "total", "number", "of", "data", "points", ",", "TP", "is"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "true positives"}, {"tokens": ["The", "results", "demonstrate", "that", "DBN", "with", "the", "input", "of", "all", "force", ",", "torque", "and", "vibration", "signals", "have", "better", "performance", "in", "terms", "of", "RMSE", ",", "R2Score", "and", "MAPE", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Since", "the", "MPEG", "standard", "allows", "the", "use", "of", "distinct", "macroblock", "sizes", ",", "the", "CORVETTE", "mechanism", "adopts", "the", "same", "procedure", "of", "the", "uavFEC", "and", "MINT", "-", "FEC", "mechanisms", "by", "computing", "the", "area", "of", "each", "macroblock", "and", "using", "the", "number", "of", "pixels", "that", "are", "being", "moved", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["PS", "drives", "use", "Advanced", "Technology", "Attachment", "-", "ATA", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "personal storage"}, {"tokens": ["Indeed", ",", "BNN", "performs", "Bayesian", "ensembling", "by", "nature", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "bayesian neural networks"}, {"tokens": ["Efficiency", "ofSince", "efficiency", "is", "the", "prime", "focus", "of", "this", "paper", "and", "we", "build", "an", "OT", "extension", "protocol", "in", "KK13", "style", "secure", "against", "malicious", "adversaries", ",", "we", "recall", "the", "communication", "complexity", "of", "KK13", "from", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["As", "shown", "in", "the", "figure", ",", "the", "considered", "vehicular", "fog", "computing", "environment", "primarily", "consists", "of", "the", "following", "entities", "which", "actively", "participate", "in", "provisioning", "the", "designed", "authentication", "and", "key", "exchange", "solution", "in", "the", "considered", "VFC", "setup", "based", "on", "blockchain", "and", "ECC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "elliptic curve cryptography"}, {"tokens": ["In", "such", "a", "case", ",", "detecting", "the", "location", "of", "antifuse", "is", "difficult", "with", "SEM", "imaging", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["Skeleton", "n", "-", "grams", "with", "standard", "POS", ":", "Sorcery", "over", "mindsMagic", "of", "the", "practiceWhen", "the", "practice", "goes", "crazy", ",", "cultivate", "like", "wizardry", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["This", "loss", "function", "emphasizes", "the", "boundaries", "between", "classes", "and", "supports", "learning", "of", "unbalanced", "classes", "such", "as", "VAT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["Wireless", "Transmission-.5emAfter", "local", "computation", ",", "all", "users", "upload", "their", "local", "FL", "parameters", "to", "the", "BS", "via", "frequency", "domain", "multiple", "access", "(", "FDMA", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "federated learning"}, {"tokens": ["BERT", "-", "Base", "model", "fine", "-", "tuned", "on", "ASNQ", "TREC", "-", "QA", "achieves", "a", "MAP", "and", "MRR", "of", "0.898", "and", "0.929", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["The", "gap", "between", "UAP", "and", "model", "AP", "here", ",", "however", ",", "is", "much", "smaller", "than", "VOC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["If", "we", "generate", "data", "strictly", "according", "to", "the", "SBM", "or", "SCFthe", "degree", "distribution", "is", "more", "homogenous", ",", "especially", "thedistribution", "of", "the", "degrees", "within", "a", "single", "cluster", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["In", "this", "scenario", ",", "we", "randomly", "select", "important", "features", "from", "the", "benign", "dataset", "using", "the", "LR", "algorithm", "and", "select", "10", "samples", "of", "the", "malware", "dataset", "which", "are", "near", "to", "the", "legitimate", "samples", ",", "which", "takes", "of", "the", "order", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["However", ",", "in", "our", "previous", "discussion", "we", "find", "that", "this", "conclusion", "can", "not", "be", "simply", "applied", "to", "SAR", "target", "recognition", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["I", "(", "Autism", "Brain", "Imaging", "Date", "Exchange", ")", "dataset", "was", "downloaded", "via", "http://fcon_1000.projects.nitrc.org", "/", "indi", "/", "abide", "/", "abide_I.html", "and", "is", "available", "under", "the", "Creative", "Commons", "CC", "BY", "-", "NC", "-", "SA", "license", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "creative commons"}, {"tokens": ["The", "MAD", "in", "Physics", "reaches", "almost", "percentage", "points", "in", "PP", "(", ")", "when", "switching", "from", "peer", "review", "to", "metrics", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "median absolute difference"}, {"tokens": ["Owing", "to", "these", "factors", ",", "the", "use", "of", "video", "-", "aware", "FEC", "-", "based", "mechanisms", "is", "suitable", "to", "transmit", "videos", "with", "better", "quality", ",", "although", "it", "needs", "additional", "bandwidth", "to", "send", "the", "redundant", "information", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Specifically", ",", "the", "eavesdropper", "is", "active", "and", "utilizes", "a", "hybrid", "overhearing", "and", "AN", "generating", "mechanism", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "artificial noise"}, {"tokens": ["Abdominal", "adipose", "tissue", "(", "AAT", ")", ",", "composed", "of", "subcutaneous", "and", "visceral", "adipose", "tissue", "(", "SAT", "and", "VAT", ")", ",", "has", "long", "been", "associated", "with", "an", "increased", "risk", "of", "chronic", "cardiovascular", "diseases", ",", "glucose", "impairment", ",", "and", "dyslipidemia", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["First", ",", "we", "derive", "the", "DE", "of", "the", "normalization", "parameter", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "deterministic equivalent"}, {"tokens": ["The", "reason", "for", "sinc2-h", "-", "NSF", "'s", "poor", "performance", "is", "the", "'", "under", "-", "estimated", "'", "MVF", "in", "voiced", "regions", ",", "as", "Figure", "shows", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["Loss", "and", "Meta", "-", "loss", "During", "Conventional", "OptimizationTo", "demonstrate", "that", "conventional", "loss", "optimization", "is", "not", "necessarily", "able", "to", "improve", "the", "meta", "-", "loss", ",", "we", "performed", "the", "following", "experiment", "on", "a", "smaller", "(", "73-ieee", "-", "rts", ")", ",", "and", "a", "larger", "(", "162-ieee", "-", "dtc", ")", "grid", "with", "DC", "-", "OPF", "formulations", "using", "the", "standard", "grid", "parameters", "on", "k", "samples", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["First", ",", "four", "kinds", "of", "MDC", "methods", "are", "reviewed", "in", "Section", "II", "and", "the", "problem", "formulation", "of", "deep", "image", "compression", "is", "presented", "in", "Section", "III", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["We", "can", "see", "that", ",", "despite", "having", "more", "measurements", ",", "such", "approach", "gives", "a", "much", "lower", "utility", "than", "DI", "as", "well", "as", "the", "proposed", "GT", ",", "due", "to", "the", "negative", "effect", "of", "noise", "folding", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "direct inspection"}, {"tokens": ["Figure", "(", "a", ")", "and", "(", "b", ")", "show", "AP", "of", "each", "class", "on", "(", "27.3", ")", "and", "gains", "of", "each", "class", "brought", "by", "(", "29.7", ")", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["This", "can", "be", "proved", "by", "induction", "on", "the", "structure", "of", "the", "formula", ",", "whereas", "it", "is", "already", "shown", "for", "STL", "operators", "(", "atomic", "propositions", ",", "Boolean", "and", "temporal", "operators", ",", "for", "fixed", "locations", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "signal temporal logic"}, {"tokens": ["LS", ":", "are", "all", "requests", "made", "via", "the", "local", "search", "functionality", "of", "each", "ontology", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "local search"}, {"tokens": ["For", "various", "synthetic", "grids", ",", "using", "DC-", "and", "AC", "-", "OPF", "formulations", "we", "demonstrated", "that", "NN", "classifiers", "optimized", "by", "meta", "-", "optimization", "resulted", "in", "a", "significantly", "shorter", "solve", "time", "of", "the", "iterative", "feasibility", "test", "than", "those", "of", "conventional", "loss", "optimization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["First", ",", "we", "find", "the", "model", "-", "specific", "voltage", "curve", "and", "the", "length", "of", "the", "CC", "phase", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "constant current"}, {"tokens": ["Now", ",", "the", "Adv", "-", "BNN", "attacked", "by", "A", "-", "PGD", "was", "not", "significantly", "more", "robust", ",", "but", "even", "weaker", "for", "large", "adversarials", "than", "the", "non", "-", "Bayesian", "network", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian neural networks"}, {"tokens": ["It", "is", "found", "that", "all", "strategies", "have", "the", "maximum", "performance", "of", "RV", "strategy", "if", "50", "of", "nodes", "provide", "contact", "information", "for", "the", "vaccination", "procedure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random vaccination"}, {"tokens": ["The", "result", "shows", "that", "84", "looks", "are", "the", "most", "proper", "subsets", "rather", "than", "80", ",", "particularly", "for", "SPAM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "subtractive pixel adjacency matrix"}, {"tokens": ["(", "c", ")", "Foreground", "detected", "by", "the", "proposed", "DCP", "method", ",", "(", "d", ")", "MSSTBM", ",", "(", "e", ")", "GMM", "-", "Zivkovic", ","], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["We", "can", "think", "of", "each", "element", "of", "parameter", "vector", "as", "a", "non", "-", "linear", "transformation", "of", "a", "Gaussian", "process", "prior", ",", "such", "that", "where", "acts", "as", "a", "link", "function", "(", "deterministic", "function", ")", "that", "maps", "the", "GP", "output", "to", "the", "appropriate", "domain", "for", "the", "parameter", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Later", "on", ",", "as", "the", "RNN", "-", "CTC", "model", "became", "the", "state", "-", "of", "-", "the", "-", "art", "on", "handwritten", "word", "recognition", "tasks", ",", "how", "to", "effectively", "integrate", "a", "language", "model", "into", "a", "recognizer", "has", "been", "a", "hot", "topic", "concurrent", "with", "the", "development", "of", "a", "handwriting", "recognizer", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["The", "primary", "difference", "between", "GDP", "and", "the", "other", "related", "definitions", "is", "that", "it", "incorporates", "both", "the", "randomness", "in", "the", "underlying", "data", "set", "and", "the", "randomness", "of", "the", "Algorithm", ",", "where", "as", "other", "notions", "consider", "either", "the", "randomness", "of", "the", "data", "or", "the", "randomness", "of", "the", "algorithm", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "generalized differential privacy"}, {"tokens": ["As", "with", "the", "pre", "-", "match", "data", ",", "we", "trained", "both", "sliding", "window", "training", "datasets", "into", "a", "LR", "algorithm", "and", "into", "a", "RF", "predictor", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["According", "to", "the", "main", "idea", ",", "the", "allocation", "of", "the", "fraction", "results", "by", "setting", "thetotal", "transmit", "power", "of", "the", "private", "messages", "of", "RS", ",", "in", "order", "to", "achieve", "approximately", "the", "same", "sum", "rate", "as", "the", "conventional", "multi", "-", "user", "BC", "with", "full", "power", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "broadcast channel"}, {"tokens": ["GDP", "is", "also", "the", "dominant", "variable", "in", "this", "model", "measured", "by", "relative", "to", "the", "other", "features", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gross domestic product"}, {"tokens": ["'", "s.", "itemize", "The", "non", "-", "emptiness", "of", "the", "intersection", "can", "be", "checked", "in", "NP", "by", "Kopczynski", "and", "To", "KopczynskiTo", ":", "LICS2010", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "non - emptiness problem"}, {"tokens": ["such", "that", ",", ",", ",", "and", "for", ",", "for", "all", ",", "belonging", "to", "the", "same", "interval", "(", "The", "fact", "that", "we", "can", "always", "obtain", "a", "finite", "interval", "covering", "is", "a", "consequence", "of", "the", "restriction", "to", "closed", "intervals", ",", ",", "in", "STL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "signal temporal logic"}, {"tokens": ["Similarly", ",", "compared", "many", "different", "signature", "schemes", "(", "ECDSA", ",", "XTR", "-", "DSA", ",", "and", "NTRUSing", ")", "in", "terms", "of", "energy", "consumption", ",", "memory", ",", "keys", "length", "and", "signature", ",", "and", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "digital signature algorithm"}, {"tokens": ["State", "Learning", "RepresentationFor", "the", "SRL", "methods", ",", "we", "used", "an", "altered", "form", "of", "ResNet", "(", "Table", ")", ",", "which", "is", "more", "compact", "for", "our", "needs", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["Here", ",", "we", "consider", "the", "elements", ",", "in", "solution", "vector", ",", "as", "the", "weights", "of", "the", "corresponding", "BQ", "in", "BQ", "matrix", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["Then", ",", "we", "have", "derived", "a", "closed", "-", "form", "expression", "for", "DL", "based", "channel", "estimation", "and", "compared", "its", "estimation", "performance", "with", "the", "LS", "and", "LMMSE", "estimators", "under", "linear", "and", "nonlinear", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["As", "an", "example", "of", "the", "continual", "GP", "performance", "over", "binary", "data", ",", "we", "choose", "the", "banana", "dataset", ",", "used", "for", "demonstrative", "experiments", "of", "scalable", "GP", "classification", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "the", "initial", "experimental", "refinement", "phase", ",", "a", "test", "group", "of", "five", "non", "-", "astronomers", "was", "given", "the", "same", "introduction", "to", "the", "TDW", "as", "they", "were", "to", "the", "SDD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "standard desktop display"}, {"tokens": ["A", "higher", "CMI", "leads", "to", "stronger", "controllability", "with", "a", "bit", "more", "risk", "of", "text", "disfluency", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "conditional mutual information"}, {"tokens": ["So", ",", "from", "(", "8)", "the", "channel", "capacity", "for", "from", "BS", "to", "CEU", "for", "the", "considered", "system", "is", "written", "as", "below", "[", "10", "-", "11,18]:Let", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["Actually", ",", "the", "RS", "method", "includes", "two", "different", "types", "of", "precoders", "for", "the", "transmission", "of", "the", "private", "and", "common", "messages", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["To", "verify", "the", "effects", "of", "different", "signal", "states", ",", "the", "simulations", "of", "DBN", "with", "the", "signals", "from", "different", "kinds", "of", "sensors", "have", "been", "carried", "out", "in", "this", "section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["We", "set", "the", "parameters", "empirically", "to", "ensure", "that", "DE", "generally", "converges", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["Although", "scientists", "are", "among", "the", "most", "trusted", "group", "in", "the", "U.S.", ",", "Americans", "have", "cynical", "views", "toward", "scientists", "when", "considering", "GM", "foods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "genetically modified"}, {"tokens": ["When", "applied", "currents", "were", "small", ",", "where", "linear", "assumptions", "of", "the", "LMEM", "still", "held", ",", "the", "LMEM", "and", "the", "ANN", "model", "showed", "similar", "performance", ",", "while", "the", "RF", "performed", "worse", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Simulation", "and", "numerical", "results", "show", "that", ",", "in", "medium", "and", "high", "SNR", "regions", ",", "the", "proposed", "OPA", "can", "substantially", "improve", "the", "SR", "performance", "compared", "with", "some", "typical", "PA", "factors", "such", "as", "0.1", ",", "0.5", ",", "and", "0.9", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power allocation"}, {"tokens": ["Obviously", ",", "the", "coordinated", "scheme", "will", "introduce", "overheads", "(", "e.g.", ",", "extra", "fields", "in", "RTS", "/", "CTS", ")", "that", "are", "needed", "for", "the", "AP", "to", "best", "exploit", "the", "spatial", "domain", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["Second", ",", "it", "is", "important", "to", "remark", "that", "in", "some", "models", "TS", "has", "degraded", "calibration", "by", "a", "factor", "of", "three", "in", "the", "worst", "case", "while", "BNNs", "do", "not", ",", "as", "seen", "in", "the", "results", "provided", "in", "the", "supplementary", "material", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temperature scaling"}, {"tokens": ["Finally", ",", "the", "significant", "improvement", "of", "ECS", "-", "DBN", "over", "some", "other", "methods", "manifests", "the", "effectiveness", "of", "optimization", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Similar", "to", "this", ",", "NLM", "employs", "neural", "networks", "as", "a", "differentiable", "chain", "for", "forward", "inference", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "neural logic machines"}, {"tokens": ["Statistically", "significant", "difference", "between", "improvement", "and", "worsening", ",", "MRD", "="], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "mean rank difference"}, {"tokens": ["This", "is", "also", "reflected", "in", "the", "recommendation", "accuracy", "results", "presented", "in", "Table", "as", "the", "unpersonalized", "MP", "approach", "provides", "better", "results", "than", "the", "personalized", "CF", "one", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Given", "a", "predicted", "label", "map", "and", "the", "number", "of", "voxels", "classified", "as", "(", "VAT", "or", "SAT", ")", "in", "session", "(", "test", "-", "retest", ",", "or", "manual", "-", "automated", ")", ",", "the", "absolute", "percent", "difference", "(", "APD", "(", ")", ")", "of", "a", "label", "volume", "measures", "variability", "across", "sessions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "visceral adipose tissue"}, {"tokens": ["To", "verify", "the", "effectiveness", "of", "correlation", "constraints", "among", "the", "training", "dataset", ",", "we", "test", "two", "versions", "of", "the", "correspondence", "-", "evaluation", "networks", ":", "trained", "from", "dataset", "with", "correlation", "constraints", "(", "CorrNet", ")", "and", "without", "correlation", "constraints", "(", "CorrNet", "w/o", "CC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "correlation constraints"}, {"tokens": ["ConclusionA", "promising", "approach", "to", "reduce", "the", "computational", "time", "of", "solving", "OPF", "problems", "is", "to", "solve", "a", "reduced", "formulation", ",", "which", "is", "a", "considerably", "smaller", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["This", "strengthens", "our", "argument", "regarding", "heterogeneity", "between", "the", "subsets", "explains", "the", "accuracy", "difference", "between", "RS", "-", "task", "SC", "-", "task", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "sleep cassette"}, {"tokens": ["Also", ",", "our", "tools", "were", "designed", "with", "SRL", "in", "mind", "and", "offer", "a", "gradual", "difficulty", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "state representation learning"}, {"tokens": ["row", "of", "matrix", "is", "where", "is", "the", "input", "of", "the", "receiver", "for", "the", "th", "extended", "OT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "oblivious transfer"}, {"tokens": ["BOA", "performs", "better", "in", "terms", "of", "eigenvalue", "analysis", "but", "similar", "to", "GA", "and", "DE", "in", "terms", "of", "optimizing", "the", "minimum", "damping", "coefficient", "for", "the", "control", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["In", "scenarios", "with", "dynamic", "RA", ",", "it", "is", "easy", "to", "make", "an", "upper", "-", "triangular", "matrix", "during", "the", "RA", "phase", "by", "relabelling", "the", "REs", "and", "users", ",", "provided", "that", "there", "exists", "orthogonal", "users(On", "the", "occasion", "that", "there", "are", "not", "orthogonal", "active", "users", "in", "the", "system", ",", "we", "can", "relabel", "the", "layers", "rather", "than", "the", "users", "and", "some", "minor", "modifications", "to", "the", "SD", "algorithm", "will", "be", "needed", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "resource allocation"}, {"tokens": ["We", "similarly", "accelerate", "performance", "for", "ARD", "by", "adapting", "\"", "free", "\"", "adversarial", "training", "to", "distillation", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["Following", "the", "MGF", "-", "based", "approach", "and", "using", "the", "expressions", "given", "by", "Eq", ":", "MGF_end_Def_Rep", "for", "repetitive", "transmission", "with", "MRD", "and", "Eq", ":", "MGF_end_Final_repSD", "and", "Eq", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal ratio diversity"}, {"tokens": ["Table", "shows", "that", "non", "-", "astronomer", "collaborators", "match", "or", "exceed", "the", "performance", "of", "a", "single", "astronomer", "and", "show", "marked", "improvement", "of", "TDW", "over", "SDD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "standard desktop display"}, {"tokens": ["Similarly", ",", "we", "find", "SCP", "loss", "to", "achieve", "best", "results", "on", "RG", "and", "MEN", ",", "both", "the", "smallest", "and", "largest", "datasets", "of", "the", "set", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "squared cosine proximity"}, {"tokens": ["We", "also", "add", "professor", ",", "which", "does", "not", "have", "a", "clear", "definition", "as", "per", "CPS", "but", "has", "been", "known", "to", "have", "different", "gender", "splits", "at", "senior", "and", "junior", "levels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "current population survey"}, {"tokens": [":", "Power", "consumption", "of", "cache", "processing", "at", "CC", "/", "EC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["It", "appears", "that", "the", "participants", "were", "more", "easily", "able", "to", "identify", "individual", "screens", "that", "they", "had", "already", "searched", ";", "compared", "to", "trying", "to", "remember", "which", "region", "they", "had", "searched", "of", "the", "image", "on", "the", "SDD", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "standard desktop display"}, {"tokens": ["the", "SIR", "threshold", ",", "the", "outage", "probability", "of", "the", "typical", "UE", "can", "be", "computed", "as", "the", "probability", "that", "the", "signal", "strength", "over", "the", "interference", "is", "less", "than", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["In", "this", "section", ",", "we", "focus", "on", "several", "experiment", "scenarios", ":", "single", "-", "task", "SRL", ",", "single", "-", "task", "SRL", "with", "AL", ",", "MTL", ",", "and", "MTL", "with", "AL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["MCC", "computation", "is", "done", "at", "the", "end", "of", "each", "iteration", ",", "to", "find", "the", "parent", "community", "of", "the", "deleted", "node", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximal connected component"}, {"tokens": ["The", "fronthaul", "between", "the", "CC", "and", "ECs", "can", "be", "implemented", "using", "a", "short", "fiber", "or", "wireless", "links", ",", "e.g.", ",", "mm", "-", "Wave", "links", "or", "optical", "links", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "central cloud"}, {"tokens": ["ConclusionAs", "a", "method", "of", "ANN", "search", ",", "interests", "of", "many", "researchers", "as", "well", "as", "companies", "have", "been", "attracted", "to", "hashing", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "approximate nearest neighbor"}, {"tokens": ["Finite", "Element", "MethodFEM", "model", "known", "as", "FEM", "Modelgm97", ",", "is", "the", "most", "accurate", "physical", "model", "compared", "to", "other", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element methodgm97"}, {"tokens": ["The", "first", "experiment", "serves", "as", "a", "baseline", "as", "there", "was", "no", "FEC", "mechanism", "in", "use", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["We", "observed", "during", "the", "development", "of", "the", "S", "-", "RL", "Toolbox", ",", "that", "PPO", "was", "one", "of", "the", "best", "RL", "algorithm", "for", "SRL", "benchmarking", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "state representation learning"}, {"tokens": ["Country", "totals", "of", "agreement", "and", "disagreement", "as", "a", "proportion", "of", "country", "area", "are", "shown", "in", "Table", "1", "(", "see", "SI", "for", "additional", "countries", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "satellite imagery"}, {"tokens": ["In", "VAT", ",", "we", "are", "not", "using", "Gaussian", "noise", ",", "but", "adding", "the", "adversarial", "noise", ",", "and", "this", "has", "been", "shown", "to", "be", "a", "big", "component", "in", "its", "effectiveness", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "virtual adversarial training"}, {"tokens": ["Our", "final", "candidate", "model", "employs", "an", "additional", "OT", "unit", "with", "two", "Sinkhorn", "losses", "imposed", "on", "each", "module", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "optimal transport"}, {"tokens": ["[", "tb][Performance", "of", "DADA", "(", ")", ".", "]"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["For", "that", "purpose", ",", "3GPP", "has", "generalized", "the", "LTE", "DC", "design", "to", "enable", "the", "support", "of", "multi", "radio", "access", "technology", "DC", "(", "MR", "-", "DC", ")", ",", "i.e.", ",", "DC", "between", "NR", "and", "LTE", "in", "the", "downlink", "and", "uplink", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["We", "say", "that", "an", "objective", "isstrongly", "MD", "-", "determined", "iff", "for", "every", "state", "eitheritemizethere", "exists", "an", "MD", "-", "strategy", "such", "that", ",", "for", "all", ",", "we", "have", ",", "orthere", "exists", "an", "MD", "-", "strategy", "such", "that", ",", "for", "all", ",", "we", "have", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["We", "restrict", "our", "focus", "to", "simply", "the", "set", "of", "verbal", "predicates", "in", "the", "SRL", "structure", ";", "this", "would", "presumably", "be", "simpler", "to", "use", "in", "interactive", "settings", "where", "users", "would", "specify", "attribute", "values", "for", "generating", "continuations", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["ECS", "-", "DBN", "proposed", "by", "Zhang", "et", "al", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "channel", "access", "scheme", "aligns", "with", "LTE", "frame", "structure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Evaluation", "DatasetFor", "the", "automatic", "evaluation", "of", "the", "QA", "system"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "question answering"}, {"tokens": ["Logistic", "regressor", "as", "a", "baseline", "is", "reported", "as", "LR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "logistic regression"}, {"tokens": ["We", "record", "the", "best", "modelwhich", "has", "the", "bigger", "ROC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["In", "other", "words", ",", "membership", "of", "a", "string", "in", "any", "LTT", "stringset", "is", "determined", "solely", "by", "the", "number", "of", "occurences", "each", "factor", "occurs", "in", ",", "counting", "them", "only", "up", "to", "some", "threshold", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "locally threshold testable"}, {"tokens": ["However", ",", "the", "exploration", "and", "exploitation", "capabilities", "of", "DE", "are", "mainly", "controlled", "by", "two", "key", "parameters", ",", "i.e.", "the", "mutation", "factor", "and", "crossover", "probability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["The", "population", "of", "the", "corpus", "being", "compiled", "from", "scientific", "text", "is", "similar", "to", "the", "LSC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["Bayesian", "Information", "Criterion", "(", "BIC", ")", "was", "used", "to", "select", "the", "optimum", "number", "of", "clusters", "in", "GMM", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian mixture model"}, {"tokens": ["[", "DTN", "]", "Disruption", "Tolerant", "Networking", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0], "long_form": "disruption tolerant networking"}, {"tokens": ["BAM", "configuration", "involves", "3", "phases", ":", "i", ")", "the", "definition", "of", "classes", "of", "services", "(", "TCs", "-", "Traffic", "Classes", ")", "with", "common", "requirements", "(", "QoS", ",", "SLA", "or", "other", "user/", "application", "parameter", ")", ";", "ii", ")", "the", "definition", "of", "the", "amount", "of", "bandwidth", "per", "class", "(", "BC", "-", "Bandwidth", "Constraint", ")", ";", "and", "iii", ")", "BAM", "model", "configuration", "with", "an", "inherent", "behavior", "for", "resource", "sharing", "among", "TCs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bandwidth constraint"}, {"tokens": ["Using", "instantaneous", "CSI", "and", "Eq", ":", "g_end_PureRS", ",", "rate", "-", "selective", "RS", "chooses", "between", "direct", "(", "non", "-", "relay", "assisted", ")", "and", "relay", "-", "assisted", "transmission", "based", "on", "the", "following", "criterionAs", "shown", "in", ",", "the", "MGF", "of", "can", "be", "obtained", "using", "the", "of", "pure", "RS", "aswhere", "is", "a", "RV", "with", "CDF", "given", "by", "which", "can", "be", "obtained", "using", "inverse", "sampling", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random variable"}, {"tokens": ["Earlier", ",", "proposed", "a", "similar", "method", "that", "after", "clustering", "the", "dataset", "by", "using", "-means", ",", "instances", "that", "are", "close", "to", "the", "centroid", "of", "the", "cluster", ",", "which", "they", "belong", "to", ",", "were", "pruned", ",", "and", "LDOF", "was", "used", "merely", "on", "instances", "that", "were", "away", "from", "the", "centroid", ",", "i.e.", ",", "outside", "of", "a", "predefined", "radius", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "local distance - based outlier factor"}, {"tokens": ["We", "demonstrate", "the", "capability", "of", "our", "method", "on", "several", "DC-", "and", "AC", "-", "OPF", "problems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal power flow"}, {"tokens": ["If", "examples", "from", "the", "A", "-", "PGD", "attack", "are", "used", "to", "train", "the", "Adv", "-", "BNN", ",", "the", "performance", "increases", "again", "and", "yields", "a", "slightly", "higher", "accuracy", "than", "the", "adversarially", "trained", "standard", "CNN", "and", "the", "Adv", "-", "BNN", "based", "on", "the", "naive", "PGD", "attack", ",", "even", "though", "one", "can", "argue", "that", "this", "small", "advantage", "is", "not", "significant", "but", "merely", "based", "on", "the", "choice", "of", "hyperparamters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "bayesian neural networks"}, {"tokens": ["Top", "-", "Right", ")", "BNN", "training", "approximation", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "binary neural networks"}, {"tokens": ["O.", "Khan", ",", "R.", "Burns", ",", "J.", "S.", "Plank", ",", "W.", "Pierce", "and", "C.", "Huang", ",", "\"", "Rethinking", "Erasure", "Codes", "for", "Cloud", "File", "Systems", ":", "Minimizing", "I", "/", "O", "for", "Recovery", "and", "Degraded", "Reads", ",", "\"", "FAST", "2012", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "file and storage technologies"}, {"tokens": ["In", "the", "case", "of", "GRD", "with", "disks", ",", "disks", "can", "participate", "in", "rebuild", "processing", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "group rotate declustering"}, {"tokens": ["We", "aim", "to", "extend", "this", "work", "in", "future", "by", "distinguishing", "between", "more", "than", "two", "Wi", "-", "Fi", "APs", ",", "thus", "enabling", "even", "finer", "duty", "cycle", "adjustments", "of", "a", "LTE", "-", "U", "BS", "and", "improved", "coexistence", "with", "Wi", "-", "Fi", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Computational", "Personalization", "To", "personalize", "the", "SAR", "system", ",", "the", "proposed", "hHRL", "controller", "was", "instantiated", "as", "a", "group", "of", "domain", "controllers", ",", "based", "on", "the", "abstract", "controllers", "defined", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Hence", ",", "these", "observations", "suggest", "that", "RS", "will", "be", "effective", "in", "the", "mitigation", "of", "the", "SI", "and", "the", "consecutive", "circumvention", "of", "the", "rate", "saturation", "due", "to", "the", "overall", "imperfect", "CSIT", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate splitting"}, {"tokens": ["The", "first", "atom", "selected", "by", "OLS", "and", "OMP", "is", "the", "same", "and", "fixed", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["This", "confirms", "Lambaek", "'s", "concern", "of", "privacy", "breach", "of", "his", "PSI", "protocol", "that", "may", "result", "from", "privacy", "breach", "of", "the", "underlying", "OT", "protocols", "and", "further", "confirms", "the", "necessity", "of", "maliciously", "secure", "OT", "extension", "in", "Lambaek", "'s", "PSI", "protocol", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Edge", "system", "dynamicswe", "denote", "the", "system", "state", "vector", "at", "time", "by", ",", "which", "contains", "the", "number", "of", "active", "VMs", ",", ",", "transmission", "drivers", ",", ",", "and", "the", "EB", "level", ",", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "energy buffer"}, {"tokens": ["Output", "threads", "send", "packets", "via", "faces", "then", "queue", "them", "for", "transmission", "on", "their", "respective", "NIC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "network interface card"}, {"tokens": ["Our", "results", "indicate", "that", "the", "ISP", "has", "a", "more", "significant", "impact", "on", "smaller", "CNN", "models", ",", "and", "our", "results", "on", "ResNet-50", "and", "ResNet-101", "are", "consistent", "with", "this", "trend", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["To", "our", "best", "knowledge", ",", "there", "is", "not", "yet", "adequate", "evidence", "indicating", "whether", "the", "optical", "images", "can", "or", "can", "not", "be", "transferred", "to", "SAR", "images", "with", "effect", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "sensing application recently"}, {"tokens": ["Intervention", "(", "Int", ")", "results", "on", "the", "development", "set", "of", "PA", "tasks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "physical access"}, {"tokens": ["Initially", ",", "the", "model", "obtained", "an", "average", "of", "This", "means", "that", ",", "although", "the", "continual", "variational", "approach", "suffers", "a", "small", "reduction", "in", "the", "predictive", "precision", "once", "past", "training", "samples", "are", "never", "revisited", "again", ",", "the", "accuracy", "still", "remains", "constant", "9", "steps", "after", "its", "maximization", ",", "that", "is", ",", "9", "GP", "prior", "reconstructions", "and", "9", "optimization", "processes", "where", "the", "learned", "uncertainty", "measurements", "are", "not", "overwritten", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["In", "Table", ",", "the", "confusion", "matrix", "of", "the", "MVFCNN", "approach", "(", "fine", "tuned", "with", "balanced", "and", "augmented", "SEM", "training", "data", ")", "as", "the", "best", "performing", "method", "without", "matrix", "(", "ferrite", ")", ",", "is", "shown", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "scanning electron microscopy"}, {"tokens": ["We", "denote", "the", "outputs", "obtained", "by", "receiver", "from", "the", "OT", "invocations", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "main", "idea", "of", "LTE", "-", "U", "is", "the", "same", "as", "the", "DBF", "framework", "in", "this", "paper", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["These", "data", "is", "then", "sent", "to", "the", "MDC", "application", ",", "which", "is", "interpreted", "by", "the", "Python", "-", "SGX", "interpreter", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "metering data collector"}, {"tokens": ["We", "know", "the", "solutions", "of", "the", "IB", "Lagrangian", "optimization", "(", "if", "existent", ")", "are", "solutions", "of", "the", "IB", "functional", "by", "the", "Lagrange", "'s", "sufficiency", "theorem", "(", "Theorem", "5", "in", "Appendix", "A", "of", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "authors", ",", "in", "particular", ",", "analyzed", "the", "minimization", "of", "the", "total", "transmit", "power", "at", "the", "BS", "by", "jointly", "optimizing", "the", "transmit", "beamforming", "vectors", "of", "the", "BS", "and", "the", "phase", "shifts", "of", "the", "RIS", "by", "imposing", "SINR", "constraints", "for", "the", "users", "considering", "a", "multi", "-", "user", "downlink", "communication", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["In", "general", ",", "the", "total", "energy", "consumption", "of", "the", "network", "during", "time", "slot", "can", "be", "expressed", "aswhere", ",", "using", "MacroUsers", "and", "BSpowermodel", ",", "and", "represents", "the", "energy", "consumption", "of", "the", "macrocell", "BS", "during", "time", "slot", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["where", "basis", "pursuit", "denoising", "(", "BPD", ")", "was", "adopted", "to", "exploit", "the", "sparsity", "of", "vibration", "signals", "in", "different", "domains", "in", "order", "to", "detect", "and", "extract", "fault", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basis pursuit denoising"}, {"tokens": ["Right", ":", "comparison", "of", "the", "speedups", "of", "GMB", "on", "BA", "and", "of", "IA", "on", "RK", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "incremental approximation"}, {"tokens": ["Task", "DefinitionThe", "task", "is", "defined", "as", "a", "CDA", "recognition", "problem", "where", "for", "each", "utterance", "(", "the", "-th", "utterance", ")", "in", "a", "dialogue", ",", "we", "predict", "a", "subset", "of", "DA", "labels", "that", "describes", "the", "functionality", "of", "the", "utterance", "from", "a", "candidate", "set", "of", "DA", "labels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concurrent dialogue acts"}, {"tokens": ["We", "also", "found", "that", "using", "back", "-", "translation", "and", "TTS", "to", "augment", "the", "text", "-", "based", "QA", "training", "examples", "can", "help", "SQA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["CD", "is", "based", "on", "cosine", "similarity", "which", "measures", "the", "cosine", "of", "the", "angle", "between", "two", "non", "-", "zero", "vectors", "with", "equal", "magnitudes", ":"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cosine distance"}, {"tokens": ["The", "use", "of", "Euclidean", "distance", "could", "improve", "AP", "by", "around", "0.5", "(", "see", "Table", ",", "(", "d", ")", "case", ")", ",", "but", "does", "not", "gain", "as", "much", "as", "OT", "does", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "optimal transport"}, {"tokens": ["At", "this", "point", ",", "iteration", "through", "the", "entire", "dataset", "stops", "and", "we", "calculate", "the", "values", "of", "the", "difference", "function", "(", "FAR", "-", "FRR", ")", "for", "these", "remaining", "40", "values", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "false acceptance rate"}, {"tokens": ["If", "we", "now", "consider", "a", "stochastic", "scenario", "like", "the", "TREC-6", "dataset", "with", ",", "for", "and", "the", "range", "of", "the", "Lagrange", "multipliers", "that", "allow", "the", "IB", "curve", ",", "according", "to", "Corollary", ",", "is", ",", "where", "and", "are", "defined", "as", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Former", "is", "a", "system", "that", "converts", "the", "output", "of", "a", "SRL", "system", "into", "an", "Open", "IE", "extraction", "by", "treating", "the", "verb", "as", "the", "relational", "phrase", ",", "while", "taking", "its", "role", "-", "labeled", "arguments", "as", "the", "Open", "IE", "argument", "phrases", "related", "to", "the", "relation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "semantic role labeling"}, {"tokens": ["GPS", "ConvergenceGPS", "methods", "under", "the", "aforementioned", "defined", "framework", "have", "some", "important", "convergence", "properties", "shown", "in", "and", "summarized", "here", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "general pattern search"}, {"tokens": ["After", "that", ",", "AA", "theory", "was", "developed", "and", "has", "been", "applied", "to", "OPF", "problems", "in", "power", "systems", ",", "which", "can", "take", "the", "correlation", "among", "variables", "into", "account", "and", "yield", "much", "tighter", "lower", "and", "upper", "bounds", "compared", "to", "IA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "interval analysis"}, {"tokens": ["That", "is", ",", "if", "the", "derivatives", "with", "respect", "to", "the", "activations", "of", "layer", "are", "for", "backpropagation", "and", "FA", ",", "respectively", ",", "then", "we", "can", "writeThis", "technique", "has", "the", "interesting", "property", "of", "actually", "modifying", "the", "gradient", "itself", ",", "as", "opposed", "to", "merging", "the", "final", "updates", "of", "two", "(", "or", "more", ")", "separate", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "feedback alignment"}, {"tokens": ["At", "testing", "time", ",", "we", "evaluated", "our", "model", "with", "both", "LR", "-", "HR", "clinical", "image", "data", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "high - resolution"}, {"tokens": ["Because", "3D", "ConvNet", "contains", "too", "many", "parameters", "and", "is", "hard", "to", "train", "on", "relatively", "small", "public", "lung", "CT", "datasets", ",", "we", "employ", "3D", "dual", "path", "networks", "as", "the", "components", "since", "DPN", "uses", "less", "parameters", "and", "obtains", "better", "performance", "than", "residual", "networkchen2017dual", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dual path network"}, {"tokens": ["&", "&", "UCSD", "to", "&", "Mall", "to", "Method", "&", "Mall", "&", "UCSD", "FA", "&", "7.47", "&", "4.44", "HGP", "&", "4.36", "&", "3.32", "GPA", "&", "4.18", "&", "2.79", "GPTL", "&", "3.55", "&", "2.91", "Bidirectional", "ConvLSTM", "&", "2.63", "&", "1.82", "-2em"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process adaptation"}, {"tokens": ["Finally", "they", "were", "normalized", "between", "and", ",", "which", "is", "a", "usual", "procedure", "for", "ANN", "inputs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["The", "proposed", "deep", "learning", "model", "is", "named", "as", "Product", "-", "based", "Neural", "Network", "(", "PNN", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Thus", ",", "the", "Dispatcher", "simply", "implements", "a", "layer", "of", "communication", "with", "the", "bus", "via", "ZeroMQ", "and", "communicates", "with", "the", "MDC", "through", "simple", "sockets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "metering data collector"}, {"tokens": ["This", "is", "unlike", "AP", "where", "variations", "in", "have", "strong", "impact", "on", "the", "number", "of", "clusters", "obtained", "and", "the", "cluster", "assignments", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "affinity propagation"}, {"tokens": ["For", "instance", ",", "in", ",", "a", "dictionary", "learning", "-", "based", "method", "is", "introduced", "for", "compact", "patch", "representation", ",", "whereas", "in", ",", "a", "GMM", "model", "is", "learned", "from", "natural", "image", "groups", "based", "on", "NSS", "scheme", "and", "used", "as", "a", "prior", "for", "denoising", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["TractQuerier", "showed", "severe", "oversegmentation", "of", "both", "the", "CST", "and", "OR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "corticospinal tract"}, {"tokens": ["Due", "to", "the", "high", "transmit", "power", "at", "the", "BS", "and", "the", "high", "bandwidth", "that", "can", "be", "used", "for", "data", "broadcasting", ",", "the", "downlink", "time", "is", "neglected", "compared", "to", "the", "uplink", "data", "transmission", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["A.", "Unler", ",", "A.", "Murat", ",", "R.", "B.", "Chinnam", ",", "PSO", ":", "a", "maximum", "relevance", "minimum", "redundancy", "feature", "selection", "method", "based", "on", "swarm", "intelligence", "for", "support", "vector", "machine", "classification", ",", "Information", "Sciences", "181", "(", "20", ")", "(", "2011", ")", "4625", "-", "4641", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "particle swarm optimization"}, {"tokens": ["Robustness", "was", "measured", "using", "the", "intraclass", "correlation", "coefficient", "(", "1,1", ")", "(", "ICC", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "intraclass correlation coefficient"}, {"tokens": ["Let", "also", "be", "the", "bottleneck", "variable", "that", "solves", "the", "IB", "functional", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["CD", "is", "then", "defined", "as*Experiment", "1", ":", "Simulating", "second", "-", "order", "context", "overlapIn", "order", "to", "see", "whether", "SGNS", "captures", "second", "-", "order", "co", "-", "occurrence", "information", ",", "we", "artificially", "simulate", "context", "overlap", "for", "first-", "and", "second", "-", "order", "co", "-", "occurrence", "separately", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "cosine distance"}, {"tokens": ["Using", "88", "features", "including", "pitch", ",", "Mel", "-", "PLP", ",", "and", "TRAP", "-", "DCT", "input", "into", "a", "bottleneck", "DNN", ",", "they", "are", "able", "to", "improve", "the", "CER", "to", "40.2", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "perceptual linear prediction"}, {"tokens": ["While", "reachability", "objectives", "in", "finitely", "branching", "countable", "games", "are", "not", "strongly", "MD", "determined", "in", "general", ",", "we", "show", "that", "strong", "MD", "determinacy", "holds", "for", "many", "interesting", "subclasses", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "memoryless deterministic"}, {"tokens": ["These", "are", "the", "desired", "centres", "of", "LV", ",", "RV", ",", "RA", "and", "LA", "cavities", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "right atrium"}, {"tokens": ["For", "example", ",", "in", "our", "BMS", ",", "the", "integer", "division", "costs", "0.72x", ",", "0.70x", ",", "and", "0.90x", "geometric", "mean", "decrease", "in", "our", "key", "-", "only", "throughput", "for", "Tesla", "K40c", "(", "ECC", "on", ")", ",", "Tesla", "K40c", "(", "ECC", "off", ")", "and", "GeForce", "GTX", "1080", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["This", "enables", "receiver", "to", "compute", "the", "random", "pads", "of", "OT", "for", "the", "rest", "bins", "corresponding", "to", "dummy", "elements", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["The", "final", "sketch", "is", "formed", "by", "hiding", "with", "RV", "generated", "from", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "resilience vector"}, {"tokens": ["BS", ":"], "acronym_pos": [1, 0], "long_form": "bayesian sets"}, {"tokens": ["The", "figure", "demonstrates", "that", "GP", "predictors", "provides", "a", "better", "prediction", "with", "respect", "to", "simply", "using", "the", "profiles", "of", "similar", "wards", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["also", "tried", "adding", "a", "coverage", "constraint", "to", "ensure", "the", "decoder", "covers", "all", "the", "selected", "tokens", ",", "but", "we", "find", "it", "brings", "no", "tangible", "help", "since", "a", "higher", "CMI", "can", "already", "discourage", "including", "redundant", "tokens", "into", "the", "selection", ".", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "conditional mutual information"}, {"tokens": ["In", "Figure", ",", "we", "also", "observe", "that", "for", "half", "of", "sentences", "Dijikstra", "'s", "and", "shortest", "path", "algorithms", "have", "similar", "MACS", "score", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mean average conceptual similarity"}, {"tokens": ["Rather", "than", "aimlessly", "increasing", "the", "model", "complexity", ",", "one", "should", "aim", "at", "modifying", "or", "extending", "an", "SBM", "to", "realistically", "capture", "the", "properties", "of", "real", "-", "world", "networks", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Context", "QA", ":"], "acronym_pos": [0, 1, 0], "long_form": "question answering"}, {"tokens": ["These", "conclusions", "are", "also", "supported", "by", "the", "results", "obtained", "in", "HMC", "and", "MD", "simulations", "of", "216", "molecules", "of", "water", "at", "300", "K."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "molecular dynamics"}, {"tokens": ["After", "training", ",", "the", "ARNN", "scores", "the", "items", "conditioning", "on", "both", "the", "PNN", "-", "produced", "contextual", "preference", "and", "the", "RNN", "hidden", "state", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product - based neural network"}, {"tokens": ["Note", "that", "BM", "is", "the", "most", "reliable", "among", "the", "four", "mirrored", "disk", "organizations", "followed", "by", "CD", ",", "while", "ID", "is", "more", "reliable", "than", "GRD", "since", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "interleaved declustering"}, {"tokens": ["Hashimoto14:Two", "provide", "two", "characterizations", "of", "PS", ":", "(", "1", ")", "by", ",", ",", "and", ",", "and", "(", "2", ")", "by", "and", "non", "-", "wastefulness", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "probabilistic serial"}, {"tokens": ["CC", ",", "middle", "right", ":", "IFOF", "(", "R", ")", ")"], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "corpus callosum"}, {"tokens": ["illustrates", "the", "overall", "performances", "of", "the", "7", "variations", "of", "DBN", "algorithms", "on", "58", "benchmark", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["The", "first", "parameter", "of", "the", "parity", "code", ",", ",", "is", "used", "to", "build", "the", "Flexible", "FEC", "Block", "(", "FFBlock", ")", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["FEM", "modal", "used", "for", "frequency", "extraction", "Modal", "Information", "For", "PCB", "Based", "on", "Eq", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "finite element method"}, {"tokens": ["Therefore", ",", "there", "is", "a", "need", "to", "design", "and", "implement", "on", "-", "board", ",", "low", "power", ",", "and", "efficient", "deep", "learning", "solutions", "in", "support", "of", "SAR", "operations", "using", "UAVs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["Computational", "personalization", "stands", "out", "as", "a", "central", "computational", "challenge", "as", "it", "is", "necessary", "to", "enable", "SAR", "systems", "to", "adapt", "to", "each", "child", "'s", "unique", "and", "changing", "needs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["AlRashidi", "and", "El", "-", "Hawary", ",", "presented", "a", "new", "hybrid", "optimization", "algorithm", "by", "combining", "Newton", "-", "Raphson", "and", "PSO", "suitable", "to", "solve", "multi", "-", "objective", "EED", "problems", "of", "power", "system", "operation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["Q", "refers", "to", "a", "SATB", "quartet", "with", "one", "singer", "per", "section", "and", "CM", "refers", "to", "a", "SATB", "choir", "mix", "with", "4", "singers", "per", "section", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "choir mix"}, {"tokens": ["Our", "approach", "extends", "the", "existing", "prior", "-", "posterior", "recursion", "of", "online", "Bayesian", "inference", ",", "i.e.", "past", "posterior", "discoveries", "become", "future", "prior", "beliefs", ",", "to", "the", "infinite", "functional", "space", "setting", "of", "GP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "gaussian process"}, {"tokens": [",", "we", "compare", "our", "method", "with", "the", "latest", "standard", "-", "compatible", "CNN", "-", "based", "MDC", "method", ",", "with", "convolutional", "auto", "-", "encoder", "-", "based", "multiple", "description", "coding", ",", "and", "with", "a", "multiple", "description", "coding", "approach", "with", "randomly", "offset", "quantizers", ",", "which", "are", "denoted", "as", "\"", "MDCNN", "\"", ",", "\"", "CAE", "\"", ",", "and", "\"", "MDROQ", "\"", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["In", "this", "paper", ",", "the", "path", "loss", "exponents", "of", "the", "links", "between", "UE", "and", "are", "assumed", "to", "be", "independent", "identically", "distributed", "random", "variables", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["This", "involves", "computing", "the", "ACE", "."], "acronym_pos": [0, 0, 0, 0, 1, 0], "long_form": "average causal effect"}, {"tokens": ["Lin", ",", "M.", ",", "Hsu", ",", "W.J.:Mining", "GPS", "data", "for", "mobility", "patterns", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "global positioning system"}, {"tokens": ["There", "is", "therefore", "an", "opportunity", "to", "develop", "RL", "-", "based", "personalized", "long", "-", "term", "learning", "SAR", "systems", ",", "especially", "when", "teaching", "abstract", "concepts", "such", "as", "mathematics", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["i.e.", "counting", "how", "many", "times", "a", "particular", "POS", "tag", "occurs", "in", "the", "tweet", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["These", "lead", "to", "the", "Bernoulli", "SBM", "for", "binary", "graphs", "described", "in", "Section", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["This", "version", ",", "Fast", "-", "ARD", ",", "described", "in", "Algorithm", ",", "is", "equally", "fast", "to", "knowledge", "distillation", "(", "see", "Table", "for", "a", "list", "of", "training", "times", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["if", "one", "wishes", "to", "consider", "RL", "paradigms", "other", "than", "PS", ",", "QEC", "codes", "other", "than", "surface", "codes", ",", "or", "noise", "models", "other", "than", "those", "considered", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "projective simulation"}, {"tokens": ["RPNI", "'s", "results", "suggest", "that", "training", "data", "was", "sufficient", "in", "almost", "all", "of", "the", "SP", "experiments", ",", "but", "only", "in", "one", "-", "third", "of", "the", "SL", "experiments", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "strictly piecewise"}, {"tokens": ["Some", "real", "images", "processed", "by", "AN", "and", "FAN", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["The", "CNN", "trained", "in", "Subsection", "(", "for", "RA", ")", "is", "reused", "here", "without", "further", "training", ",", "where", "unweighted", "networks", "with", "average", "degrees", "are", "employed", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "random attack"}, {"tokens": ["Section", "exposes", "the", "DE", "analysis", ",", "which", "enables", "the", "design", "of", "the", "precoder", "of", "the", "common", "message", ",", "and", "mainly", ",", "the", "derivation", "of", "the", "achievable", "rates", "in", "the", "presence", "of", "SI", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deterministic equivalent"}, {"tokens": ["Writer", "adaptation", "results", ",", "in", "terms", "of", "the", "CER", ",", "ranked", "by", "the", "improvement", "percentage", "with", "respect", "to", "the", "synthetic", "training", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "character error rate"}, {"tokens": ["Lookup", "functionsFollowing", "the", "definition", "of", "FJ", "(", "Figure", "19", "-", "2", "of", ")", "the", "evaluation", "and", "typing", "rules", "of", "use", "partial", "functions", "which", "give", "the", "set", "of", "fields", "of", "a", "class", "and", "the", "body", "of", "a", "method", "in", "a", "class", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "featherweight java"}, {"tokens": ["DSA", "skills", "are", "multi", "-", "disciplinary", ",", "adopting", "methods", "from", "fields", "such", "as", "statistics", ",", "mathematics", ",", "and", "computer", "science", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["However", ",", "it", "is", "important", "to", "point", "out", "that", ",", "in", "the", "above", "discussion", ",", "the", "possession", "of", "CSI", "is", "assumed", "at", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access part"}, {"tokens": ["Then", ",", "we", "feed", "the", "sequence", "of", "features", "to", "an", "AN", "for", "generating", "alignment", "factors", "and", "glimpse", "vectors", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "attention network"}, {"tokens": ["The", "area", "under", "the", "ROC", "curve", "is", "indicated", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["In", "the", "SBS", "cooperation", "strategy", "with", "a", "distance", "constraint", ",", "selecting", "cooperative", "SBSs", "is", "based", "on", "the", "distances", "between", "the", "UE", "and", "SBSs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["Based", "on", "the", "DBN", ",", "we", "can", "quickly", "establish", "the", "belief", "update", "of", "trust", ",", "i.e.", ",", ",", "using", "the", "forward", "algorithm", "by", "applying", "the", "principle", "of", "dynamic", "programming", "to", "avoid", "incurring", "exponential", "computation", "time", "due", "to", "the", "increase", "of", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dynamic bayesian network"}, {"tokens": ["Adoption", "was", "rather", "small", ",", "but", "the", "affordable", "price", "of", "the", "HMD", "made", "it", "really", "popular", "in", "AR", "research", "labs", "and", "for", "the", "development", "of", "wearable", "AR", "prototype", "(", "see", "Fig", ".", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "augmented reality"}, {"tokens": [":", "Integer", "variable", "indexing", "the", "DU", "hosting", "CPs", "of", "cell", "at", "CC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "central cloud"}, {"tokens": ["In", "segmentation", ",", "the", "model", "achieves", "sub", "-", "pixel", "accuracy", "for", "given", "LR", "input", "image", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "low resolution"}, {"tokens": ["Comparison", "of", "the", "delays", "with", "that", "of", "an", "equivalent", "M", "/", "M/1", "-", "PS", "queue", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "processor sharing"}, {"tokens": ["The", "DBN", "is", "then", "trained", "to", "produce", "a", "probability", "distribution", "over", "the", "possible", "labels", "of", "the", "data", "based", "on", "posterior", "probability", "distribution", "of", "the", "data", "samples", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Full", "ISP", "&", "13.10", "&", "27.60", "&", "22.35", "&", "29.20", "tabularTop-5", "test", "accuracy", "on", "real", "data", "for", "MobileNets", "trained", "on", "simulated", "data", "(", "MN", "=", "MobileNet", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Model]fig", ":", "capturecapture", "-", "model.epsKey", "components", "of", "the", "ISP", "and", "capture", "models", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "image signal processor"}, {"tokens": ["Average", "AP", "of", "the", "three", "layers", "on", "the", "dataset", "after", "feature", "selection", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["We", "apply", "this", "method", "to", "uncover", "the", "set", "of", "DSA", "skills", "and", "DSA", "occupations", ",", "starting", "from", "a", "seed", "set", "of", "common", "DSA", "skills", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["The", "received", "signal", "at", "and", "from", "the", "BS", "by", "different", "OAM", "modes", "are", "given", "belowAccordingly", ",", "the", "received", "SINR", "for", "symbol", "at", "can", "be", "expressed", "as", "[", "27", "-", "31]where", "is", "the", "singular", "value", "of", "the", "channel", "response", "matrix", "of", "CNOMA", "-", "SWIPT", "-", "PS", "-", "OAM", "system", "[", "22,27,30].", "OAM", "beam", "has", "divergence", "in", "its", "high", "-", "intensity", "region", "which", "caused", "attenuation", "[", "27", "-", "30]."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power splitting"}, {"tokens": ["Single", "Cell", "Point", "to", "MultipointSC", "-", "PTM", "is", "another", "LTE", "PTM", "solution", "which", "aims", "at", "providing", "broadcasting", "service", "to", "groups", "of", "users", "in", "one", "single", "cell", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["When", "the", "penalty", "increases", "with", "respect", "to", "the", "reward", ",", "the", "GT", "approach", "for", "spectrum", "sensing", "will", "be", "conservative", "and", "not", "transmit", "in", "any", "of", "the", "channels", "in", "a", "group", "that", "tested", "positively;nevertheless", ",", "as", "the", "priors", "increase", ",", "it", "is", "possible", "to", "find", "multiple", "empty", "sub", "-", "bands", "with", "just", "one", "test", "and", "gain", "in", "utility", "compared", "to", "the", "DI", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "direct inspection"}, {"tokens": ["Dynamic", "modeling", "and", "analysis", "of", "PCM", "-", "controlled", "DCM", "-", "operating", "buck", "converters", "-", "a", "reexamination", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "peak current mode"}, {"tokens": ["In", "Fig", ",", "we", "plot", "number", "of", "GP", "iterations", "needed", "to", "find", "the", "best", "approximation", "solution", "given", "in", "Algorithm", "1", "(", "line", "3", "-", "7", ")", "for", "each", "BPSO", "iteration", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "geometric programming"}, {"tokens": ["We", "can", "upper", "bound", "the", "IB", "Lagrangian", "by", "where", "the", "first", "and", "second", "inequalities", "use", "the", "DPI", "(", "Theorem", "2.8.1", "from", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["The", "gains", "are", "computed", "by", "APAP", ",", "where", "AP", "and", "AP", "are", "AP", "of", "each", "class", "for", "and", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "average precision"}, {"tokens": ["We", "are", "studying", "DTN", "approaches", "in", "this", "case", ",", "though", "NS-3", "does", "not", "support", "delay", "tolerant", "networks", "at", "this", "point", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "delay tolerant networks"}, {"tokens": ["Figure", "shows", "when", "there", "are", "two", "evaluated", "solutions", "and", ",", "the", "BSP", "tree", "has", "two", "leaf", "nodes", "at", "depth", "1", "(", "depth", "0", "represents", "the", "root", "node", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["As", "a", "summary", "of", "the", "listening", "test", ",", "a", "slight", "(", "but", "not", "significant", ")", "preference", "towards", "the", "proposed", "vocoder", "could", "be", "observed", "when", "the", "CNN", "-", "predicted", "ContF0", "and", "MVF", "values", "were", "used", "with", "the", "original", "spectral", "features", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["The", "model", "for", "and", "and", "are", "the", "same", "in", "the", "SCF", "as", "in", "the", "SBM", ",", "therefore", "we", "will", "simplyuse", "and", "for", "these", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Mathematical", "analysis", "is", "presented", "to", "inspect", "the", "SC", "of", "CNOMA", "-", "OAM", "scheme", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "sum capacity"}, {"tokens": ["Therefore", ",", "ECS", "-", "DBN", "could", "generate", "comparable", "performance", "not", "only", "on", "benchmark", "dataset", "but", "also", "on", "real", "-", "world", "application", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["Set", "indices", "of", "basic", "arms", "of", "selected", "arm", "Select", "arm", "and", "observe", "update", "Combinatorial", "TS", "based", "Algorithm", ":", "Thompson", "Sampling", "is", "used", "for", "combinatorial", "bandits", "problem", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["An", "example", "of", "a", "PDP", "is", "shown", "in", "Figure", "fig", ":", "screenshot", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "product display page"}, {"tokens": ["Connectionist", "Temporal", "Classification", "(", "CTC", ")", "further", "eliminates", "the", "need", "for", "precise", "alignment", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "connectionist temporal classification"}, {"tokens": ["However", ",", "in", "most", "of", "the", "experiments", ",", "GSA", "got", "trapped", "in", "local", "minimum", "in", "less", "than", "100", "iterations", ",", "which", "is", "an", "indication", "of", "poor", "performance", "in", "comparison", "with", "DE", "and", "ABC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["For", "ResNet", ",", "we", "obtain", "F1-measure", "of", "and", "using", "SVM", "and", "LR", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "logistic regression"}, {"tokens": ["Convergence", "study", "of", "different", "OCC", "methods", "A", "comparative", "study", "of", "ELM", "-", "based", "algorithms", "and", "traditional", "AEsA", "comparative", "convergence", "study", "of", "online", "training", "among", "ELM", "and", "traditional", "methods", "in", "bearings", "health", "monitoring", "is", "summarized", "in", "Table", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "one class classifier"}, {"tokens": ["Basic", "Question", "GenerationWe", "now", "describe", "how", "to", "generate", "the", "BQ", "of", "a", "query", "question", ",", "illustrated", "by", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["ECS", "-", "DBN", "shows", "better", "performance", "than", "other", "resampling", "methods", "in", "terms", "of", "G", "-", "mean", ",", "AUC", "and", "precision", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "directed belief net"}, {"tokens": ["After", "assessment", ",", "rescue", "teams", "can", "identify", "the", "targeted", "search", "area", "and", "commence", "SAR", "operations", "accordingly", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "search and rescue"}, {"tokens": ["Among", "these", "approaches", ",", "some", "of", "the", "sampling", "-", "based", "MDC", "methods", "can", "be", "compatible", "with", "standard", "image", "/", "video", "compression", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["We", "also", "discuss", "the", "proposed", "method", "for", "predicting", "landmarks", "directly", "on", "LR", "images", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "low resolution"}, {"tokens": ["\u2018", "DW=0.000009SL(3.047", ")", "\u2019", ")", "limite", "&", "8", "&", "French", "word", "resultan", "&", "1", "&", "French", "word", "resultadoscon", "&", "1", "&", "Spanish", "word", "with", "error", ":", "ResultadosCon", "(", "\u2018", "resultado", "\u2019", "means", "result", "in", "English", "and", "appears", "90", "times", "in", "the", "LSC", ")"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["We", "construct", "features", "by", "concatenating", "the", "learned", "deep", "3D", "DPN", "features", "(", "the", "second", "last", "layer", ",", "2,560", "dimension", ")", ",", "nodule", "size", ",", "and", "raw", "3D", "cropped", "nodule", "pixels", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dual path network"}, {"tokens": ["Set", "1", "&", "PiB", "Angular", "L", "/", "R", "&", "PiB", "Cingulum", "Ant", "L", "/", "R", "&", "PiB", "Cingulum", "Post", "L", "/", "R", "&", "PiB", "Frontal", "Med", "Orb", "L", "/", "R", "&", "PiB", "Precuneus", "L", "/", "R", "&", "PiB", "Temporal", "Sup", "L", "/", "R", "&", "PiB", "Temporal", "Mid", "L", "/", "R", "&", "PiB", "SupraMarginal", "L", "Set", "2", "&", "FA", "Cerebral", "peduncle", "R", "&", "FA", "Cerebral", "peduncle", "L", "&", "MD", "Corticospinal", "tract", "R", "&", "MD", "Corticospinal", "tract", "L", "&", "Trail", "-", "Making", "Test", "Part"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mean diffusivity"}, {"tokens": ["For", "instance", ",", "in", "our", "experiments", "we", "were", "able", "to", "attain", "the", "same", "baseline", "accuracy", "with", "about", "8", "and", "16", "smaller", "models", "for", "CF", "on", "MovieLens", "and", "CTR", "prediction", "on", "Criteo", "Kaggle", "datasets", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["Question", "answering", "(", "QA", ")", "is", "one", "of", "the", "central", "functionalities", "required", "for", "conversational", "search", "(", "interactive", "question", "answering", ")", "konstantinova2013interactive", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "question answering"}, {"tokens": ["In", "training", "the", "GMM", ",", "we", "sample", "from", "the", "256-dimensional", "representations", "only", "24k", "from", "all", "the", "images", "in", "the", "Cityscapes", "Dense", "training", "set", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["The", "local", "computation", "step", "is", "essentially", "the", "phase", "during", "which", "each", "user", "calculates", "its", "local", "FL", "parameters", "by", "using", "its", "local", "data", "set", "and", "the", "received", "global", "FL", "parameters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "federated learning"}, {"tokens": ["Such", "extra", "information", "could", "be", "obtained", "in", "a", "precise", "communication", "model", "to", "predictprocessing", "time", "of", "each", "task", "or", "in", "a", "more", "flexible", "information", "such", "as", "the", "affinity", "in", "DADA", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "distributed affinity dual approximation"}, {"tokens": ["We", "chose", "DT", ",", "because", "all", "the", "studied", "techniques", "performed", "best", "on", "Decision", "Trees", "classifier", "in", "the", "benchmarking", "study", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "decision tree"}, {"tokens": ["Additionally", ",", "to", "achieve", "consistency", "in", "DE", "and", "make", "the", "DE", "process", "independent", "of", "range", "of", "numeric", "values", "we", "use", ",", "which", "normalizes", "the", "values", "(", "figure", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "dimension estimation"}, {"tokens": ["The", "map", "is", "an", "inclusion", "modified", "from", "the", "Heaviside", "step", "function", ":", "Consider", "STA", "with", "Observer", ",", "gains", ",", "and", "law", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["While", "evaluating", "our", "models", ",", "we", "calculated", "their", "performance", "in", "terms", "of", "precision", ",", "recall", ",", "F", "-", "Score", ",", "MCC", ",", "and", "AUC", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "matthews correlation coefficient"}, {"tokens": ["The", "difference", "between", "GP", "based", "mechanistic", "emulation", "and", "maximum", "entropy", "methods", "is", "that", "in", "the", "latter", ",", "the", "mechanistic", "knowledge", "is", "added", "as", "constraints", "on", "the", "moments", "of", "the", "predictive", "or", "posterior", "distribution", ",", "while", "in", "the", "former", "its", "is", "added", "as", "the", "dynamics", "of", "the", "prior", "model", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["Figure", "7", "illustrates", "that", "due", "to", "increasing", "values", "of", ",", "the", "SC", "is", "decreasing", "for", "all", "schemes", "except", "CNMOMA", "-", "SWIPT", "-", "TS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "time switching"}, {"tokens": ["Compared", "with", "the", "baseline", "h", "-", "NSF", "model", "using", "pre", "-", "defined", "FIR", "filters", "to", "merge", "the", "harmonic", "and", "noise", "waveform", "components", ",", "the", "new", "h", "-", "NSF", "model", "predicts", "a", "time", "-", "variant", "MVF", "from", "the", "input", "acoustic", "features", "to", "adjust", "the", "frequency", "response", "of", "the", "FIR", "filters", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "maximum voice frequency"}, {"tokens": ["In", "a", "multi", "-", "tier", "scenario", ",", "the", "serving", "BS", "may", "not", "always", "be", "the", "nearest", "BS", "for", "a", "given", "UE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "user equipment"}, {"tokens": ["Linear", "SystemsWe", "firstly", "compare", "the", "MSEs", "using", "the", "LS", ",", "LMMSE", ",", "and", "DL", "estimators", "versus", "SNR", "under", "linear", "signal", "model", "r_train", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "linear systemswe"}, {"tokens": ["The", "set", "of", "AML", "models", "is", "specified", "by", ",", "where", "the", "second", "component", "corresponds", "to", "the", "main", "block", "consisting", "of", "a", "sequence", "of", "message", "send", "statements", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "actor modeling language"}, {"tokens": ["Since", "we", "are", "primarily", "interested", "in", "DE", "using", "AE", "innermost", "hidden", "layer", ",", "which", "does", "not", "natively", "provide", "singular", "value", "equivalent", ",", "we", "need", "to", "create", "singular", "value", "proxies", "to", "use", "innermost", "hidden", "layer", "for", "DE", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "dimension estimation"}, {"tokens": ["EMDlei2007fault", ",", "Bispectrumyang2002third", ",", "AR", "Frequency", "Spectrawang2008fault", ",", "NNwang2001fault", ",", "yam2001intelligent", ",", "huang2007residual", ",", "HMMocak2007online", ",", "zhang2010hidden", ",", "Fuzzy", "logicsatish2005fuzzy", ",", "GAfeng2009ga", ",", "ARMAgalati2006application", ",", "Stochastic", "Modelli2000stochastic", ",", "wang2002model", ",", "PCAzhang2005integratedGear", "&", "Manufacturing", "error", ",", "tooth", "missing", ",", "tooth", "pitting", "/", "spall", ",", "gear", "crack", ",", "gear", "fatigue", "/", "wear", "&", "High", "noise", ";", "high", "dynamics", ";", "signal", "modulated", "with", "other", "factors", ";", "gear", "specs", "need", "to", "be", "known", "&", "Vibration", ",", "oil", "debris", ",", "acoustic", "emission", "&", "Time", "domain", "statistical", "features", ",", "vibration", "signature", "frequencies", ",", "oil", "debris", "quantity", "and", "chemical", "analysis", "&", "FTchoy1996analysis", ",", "STFTkar2006technical", ",", "bartelmus2009vibration", ",", "WTpeng2004application", ",", "suh1999machinery", ",", "EMDloutridis2004damage", ",", "wang2007gearbox", ",", "liu2006gearbox", ","], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "auto - regression"}, {"tokens": ["Based", "on", "the", "CSI", "estimated", "from", "the", "sequential", "pilots", ",", "the", "AP", "sends", "a", "Notifying", "-", "CTS", "(", "N", "-", "CTS", ")", "to", "inform", "the", "selected", "STAs", "for", "parallel", "transmissions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["fig", ":", "diabetesCMED", "-", "TS", "and", "fig", ":"], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0], "long_form": "thompson sampling"}, {"tokens": ["For", "the", "STA", ",", "several", "adaptive", "laws", "have", "been", "developed", "based", "on", "the", "concept", "ofequivalent", "control", "as", "well", "as", "Lyapunov", "functions", "directly", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["We", "also", "testify", "OT", "divergence", "on", "CIFAR-10", "where", "feature", "maps", "between", "stages", "are", "aligned", "via", "OT", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "optimal transport"}, {"tokens": ["An", "ANN", "contains", "many", "connected", "neurons", "arranged", "in", "layers", "to", "produce", "network", "outputs", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["Comparison", "of", "the", "average", "computational", "time", "across", "7", "algorithms", "(", "i.e.", "ECS", "-", "DBN", ",", "DBN", ",", "ADASYN", "-", "DBN", ",", "SMOTE", "-", "DBN", ",", "SMOTE", "-", "borderline1-DBN", ",", "SMOTE", "-", "borderline2-DBN", "and", "SMOTE", "-", "SVM", "-", "DBN", ")", "with", "5-fold", "cross", "validation", "on", "the", "overall", "58", "benchmark", "datasets", "over", "10", "trials", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["First", ",", "we", "qualitatively", "select", "5", "common", "DSA", "skills", "as", "seed", "inputs", ":", "'", "Artificial", "Intelligence", "'", ",", "'", "Big", "Data", "'", ",", "'", "Data", "Mining", "'", ",", "'", "Data", "Science", "'", ",", "and", "'", "Machine", "Learning", "'", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["The", "new", "standard", "is", "larger", "than", "the", "older", "one", ",", "IFD", "(", "see", "Section", ")", ",", "and", "contains", "more", "diverse", "texts", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "icelandic frequency dictionary"}, {"tokens": ["Since", "multivariate", "regression", "is", "needed", "to", "predict", "these", "three", "values", "describing", "the", "field", ",", "a", "RF", "and", "an", "ANN", "were", "used", "in", "this", "study", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "artificial neural network"}, {"tokens": ["b", ")", "Results", "of", "our", "DTN", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0], "long_form": "domain transfer network"}, {"tokens": ["Firstly", ",", "we", "experiment", "the", "AlexNetConv", "pre", "-", "trained", "with", "ImageNet", "denoted", "as", ",", "SAR", "land", "cover", "dataset", "denoted", "as", "and", "MSTAR", "denoted", "as", "respectively", "in", "transferring", "to", "OpenSARShip", "and", "the", "results", "can", "be", "found", "in", "Fig", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["In", "the", "online", "experiment", ",", "although", "DDE", "-", "MGM", "is", "not", "the", "most", "efficient", ",", "it", "achieves", "the", "highest", "accuracy", ",", "even", "in", "the", "earlier", "stage", "(", "fewer", "samples", ")", "as", "illustrated", "in", "Fig", ".", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "markov geographic model"}, {"tokens": ["Approximate", "nearest", "neighbor", "search", "(", "ANN", ")", "can", "achieve", "this", "by", "organizing", "data", "with", "structures", "that", "keep", "distance", "metric", "as", "well", "as", "reduce", "the", "search", "space", "of", "each", "step", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "approximate nearest neighbor"}, {"tokens": ["It", "was", "ILSVRC", "2012", "winner", "with", "a", "DCNN", "that", "outperformed", "other", "handcrafted", "features", "resulting", "in", "a", "top-5", "error", "rate", "of", "16.4", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep convolutional neural network"}, {"tokens": ["POS", "achieves", "this", "by", "using", "DVFS", "techniques", "shekar2010energy", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "partial optimal slacking"}, {"tokens": ["Inspired", "by", "the", "UE", "selection", "problem", "formulations", "(", "28)-(30", ")", "in", ",", "we", "first", "construct", "the", "following", "alternative", "optimization", "problem", "by", "introducing", "a", "series", "of", "auxiliary", "variables", "(", "The", "authors", "in", "considered", "the", "single", "-", "channel", "case", "by", "introducing", "auxiliary", "variables", "in", "each", "UE", "'s", "useful", "signal", "power", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["MP", "buland", "NP", "buland", "'", "high'PIr"], "acronym_pos": [0, 0, 1, 0, 0, 0], "long_form": "new persian"}, {"tokens": ["We", "also", "compare", "against", "importance", "sampling", "as", "presented", "in", ",", "which", "we", "refer", "to", "as", "IS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "importance sampling"}, {"tokens": ["This", "is", "reflected", "in", "the", "results", "shown", "in", "Table", "as", "both", "algorithms", ",", "MP", "and", "CF", ",", "provide", "the", "worst", "results", "across", "all", "use", "cases", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "most popular"}, {"tokens": ["Depending", "on", "who", "computes", "the", "CSI", ",", "there", "are", "two", "CSI", "feedback", "schemes", ":", "(", "1", ")", "the", "implicit", "feedback", "(", "Figure", ")", ",", "where", "the", "AP", "computes", "the", "CSI", "by", "estimating", "training", "sequences", "sent", "from", "STAs", ",", "and", "(", "2", ")", "the", "explicit", "one", "(", "Figure", ")", ",", "where", "STAs", "calculate", "the", "CSI", "by", "estimating", "the", "training", "sequence", "sent", "from", "the", "AP", ",", "and", "then", "STAs", "feedback", "the", "calculated", "CSI", "to", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access part"}, {"tokens": ["Here", ",", "energy", "cooperation", "decisions", "are", "made", "using", "only", "the", "currently", "available", "EB", "levels", "and", "users", "'", "location", "information", ",", "obtained", "from", "the", "energy", "profiles", "/", "reports", "and", "the", "LS", "API", ",", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "location service"}, {"tokens": ["Our", "experiments", "with", "TREC", "-", "QA", "show", "that", "a", "simple", "union", "of", "the", "dataset", "with", "ASNQ", "is", "sub", "-", "optimal", "than", "sequential", "fine", "-", "tuning", "over", "ASNQ", "followed", "by", "TREC", "-", "QA", "."], "acronym_pos": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "question answering"}, {"tokens": ["Hence", ",", "RS", "proves", "to", "be", "robust", "since", "the", "rate", "does", "not", "saturate", ",", "and", "it", "is", "even", "more", "preferable", "at", "high", "SNR", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "rate saturation"}, {"tokens": ["Following", "the", "same", "core", "structure", "as", "uavFEC", ",", "the", "MINT", "-", "FEC", "mechanism", "also", "depends", "on", "Fuzzy", "logic", "and", "thus", "several", "fuzzy", "components", "need", "to", "be", "defined", ",", "such", "as", "the", "sets", ",", "membership", "functions", ",", "and", "rules", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "forward error correction"}, {"tokens": ["Our", "multisplit", "methods", "are", "also", "almost", "always", "superior", "to", "the", "RB", "-", "sort", "method", "(", "except", "for", "the", "key", "-", "only", "case", "on", "Tesla", "K40c", "with", "ECC", "off", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], "long_form": "error correcting code"}, {"tokens": ["They", "proposed", "information", "filtering", "for", "mobile", "AR", "based", "on", "techniques", "such", "as", "physically", "-", "based", "methods", ",", "methods", "using", "the", "spatial", "model", "of", "interaction", ",", "rule", "-", "based", "filtering", ",", "and", "a", "combination", "of", "these", "methods", "to", "reduce", "the", "information", "overload", "in", "mobile", "AR", "scenarios", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "augmented reality"}, {"tokens": ["Adaptive", "-", "gain", "designThis", "section", "proposes", "an", "approach", "to", "simultaneously", "adjustinggains", "and", "in", "STA", "on", "-", "line", "to", "drive", "thestate", "vector", "to", "the", "origin", "precisely", "in", "finite", "time", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "super - twisting algorithms"}, {"tokens": ["Illustration", "the", "performance", "of", "between", "different", "imbalance", "learning", "methods", ",", "i.e.", "ECS", "-", "DBN", ",", "CSDBN", ",", "SMOTE", "-", "SVM", "-", "DBN", ",", "ADASYN", "-", "DBN", ",", "SMOTE", "-", "borderline1-DBN", ",", "SMOTE", "-", "borderline2-DBN", ",", "SMOTE", "-", "DBN", "and", "baseline", "DBN", ",", "on", "gun", "drilling", "imbalanced", "dataset", "in", "terms", "of", "accuracy", ",", "G", "-", "Mean", ",", "AUC", ",", "precision", ",", "F1-score", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["if", ",", "for", "each", "task", ",", "there", "exists", "a", "GMM", "with", "diagonal", "covariance", "matrix", "in", "each", "component", "and", "a", "positive", "scalar", "such", "that", "the", "pre", "-", "activation", "satisfies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian mixture model"}, {"tokens": ["DE", "is", "popular", "and", "its", "control", "parameters", "are", "well", "studied", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "differential evolution"}, {"tokens": ["We", "introduce", "a", "hierarchical", "framework", "for", "HRL", "(", "hHRL", ")", "as", "one", "that", "decomposes", "SAR", "interventions", "into", "computationally", "tractable", "state", "-", "action", "subspaces", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["Taking", "NSP", "as", "beamforming", "scheme", ",", "we", "numerically", "examine", "the", "effect", "of", "on", "the", "performance", "gain", "achieved", "by", "the", "optimal", "PA", "strategy", "in", "comparison", "with", "some", "typical", "PA", "strategies", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "power allocation"}, {"tokens": ["Then", ",", "if", "is", "a", "monotonically", "increasing", "and", "strictly", "convex", "function", ",", "the", "IB", "curve", "can", "always", "be", "recovered", "by", "the", "solutions", "of", ",", "with", "That", "is", ",", "for", "each", "point", "s.t", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["By", "incorporating", "the", "Dirichlet", "process", "in", "the", "SBM", ",", "as", "did", "and", ",", "can", "be", "estimated", "along", "other", "parameters", "and", "latent", "variables", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "sequential monte carlo"}, {"tokens": ["Moreover", ",", "the", "occupations", "with", "a", "DSA", "skill", "intensity", "level", "just", "above", "the", "threshold", "represented", "occupations", "where", "the", "authors", "considered", "DSA", "skills", "to", "likely", "become", "more", "prevalent", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "data science and analytics"}, {"tokens": ["Overall", ",", "RS", "is", "beneficial", "for", "both", "FD", "and", "HD", ",", "but", "FD", "outperforms", "HD", "due", "to", "the", "prelog", "factor", "and", "the", "mitigation", "of", "SI", ",", "especially", "at", "high", "SNR", "(", "increasing", "gap", "with", "increasing", ")", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["This", "is", "informed", "by", "the", "observation", "that", "when", "the", "data", "is", "non", "-", "linearly", "separable", ",", "an", "SVM", "with", "a", "non", "-", "linear", "kernel", "outperforms", "LR", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "logistic regression"}, {"tokens": ["(", "7", ")", "Send", "the", "energy", "quantity", "back", "to", "the", "initiator", "Algorithm", "of", "computation", "for", "potential", "energyroutingfig", "Selection", "(", ")", "Compare", "the", "three", "energy", "quantities", "from", "the", "three", "relay", "stations", "Select", "the", "RS", "with", "highest", "energy", "values", "Hands", "over", "to", "the", "RS", "Send", "payload", "to", "the", "RS", "Algorithm", "of", "hand", "overroutingfigPerformance"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "relay station"}, {"tokens": ["Hence", ",", "it", "is", "important", "to", "design", "and", "represent", "SAR", "intervention", "interactions", "in", "a", "manner", "that", "maximizes", "observability", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "socially assistive robots"}, {"tokens": ["In", "the", "second", "row", ",", "from", "left", "to", "right", ",", "the", "exponential", "IB", "Lagrangian", "with", "different", "values", "of", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["CD", "and", "EMD", "are", "heavily", "influenced", "by", "the", "outliers", "."], "acronym_pos": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "chamfer distance"}, {"tokens": ["In", "this", "paper", ",", "we", "present", "a", "classification", "method", "based", "on", "OLS", ",", "which", "implements", "OLS", "in", "a", "classwise", "manner", "to", "perform", "the", "classification", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["For", "more", "detailed", "information", "about", "the", "differences", "between", "these", "two", "algorithms", ",", "readers", "can", "refer", "to", "and", "a", "-step", "analysis", "of", "OMP", "and", "OLS", "can", "be", "found", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "orthogonal least square"}, {"tokens": ["It", "should", "be", "noted", "that", "to", "overcome", "the", "major", "weaknesses", "of", "CF", "-", "based", "recommendation", "systems", ",", "many", "models", "have", "been", "proposed", ",", "such", "as", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaborative filtering"}, {"tokens": ["The", "average", "SRQM", "and", "TI", "values", "for", "each", "sequence", ",", "together", "with", "tested", "initial", "base", "QP", "values", "(", "22", ",", "27", ",", "32", ",", "37", "and", "42", ")", ",", "were", "employed", "as", "input", "features", "to", "train", "a", "fully", "connected", ",", "shadow", "neural", "network", ",", "which", "contains", "a", "hidden", "layer", "and", "an", "output", "layer", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "temporal information"}, {"tokens": ["Finally", ",", "from", "Equation", "eq", ":", "sparse", "GP", "model", "and", "eq", ":"], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["shows", "Jain", "'s", "index", "versus", "under", "various", "maximal", "transmission", "power", "constraints", "of", "the", "BS", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "base station"}, {"tokens": ["The", "DOE", "is", "designed", "as", "a", "distorted", "phase", "gratings", ",", "also", "referred", "to", "as", "a", "multifocal", "gratings", "(", "MFG", ")", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "diffractive optical element"}, {"tokens": ["Hence", ",", "RRH", "8", "will", "transmit", "useful", "signals", "to", "both", "UE", "4", "and", "UE", "5", ",", "rather", "than", "only", "interference", "signals", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user equipment"}, {"tokens": ["There", "has", "been", "a", "significant", "amount", "of", "research", ",", "both", "from", "academia", "and", "industry", "on", "LTE", "/", "Wi", "-", "Fi", "coexistence", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["We", "observe", "that", "workers", "prefer", "the", "BS", "baseline", "over", "TS", ",", "although", "TS", "yields", "higher", "diversity", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "beam search"}, {"tokens": ["We", "discussed", "several", "aspects", "of", "an", "EMS", ",", "such", "as", "information", "modeling", ",", "querying", "and", "analysis", ",", "and", "data", "ingestion", ",", "and", "also", "presented", "our", "work", "on", "location", "uncertainty", "reasoning", "and", "event", "disambiguation", "in", "more", "detail", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "event management system"}, {"tokens": ["As", "a", "result", ",", "some", "of", "structured", "abstracts", "in", "the", "LSC", "require", "additional", "process", "of", "correction", "to", "split", "such", "concatenated", "words", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "leicester scientific corpus"}, {"tokens": ["The", "BS", "outputs", ",", "by", "comparison", ",", "are", "sensical", "and", "mostly", "on", "-", "topic", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "beam search"}, {"tokens": ["They", "first", "considered", "a", "variation", "of", "the", "Bernoulli", "(", "or", "Poisson", ")", "SBM", ",", "in", "which", "the", "memberships", "are", "relaxed", "in", "the", "way", "described", "in", "the", "paragraph", "above", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "stochastic block model"}, {"tokens": ["Constraints", "(", ")", "and", "(", ")", "specify", "that", "at", "any", "data", "transmission", "time", "slot", "only", "one", "node", "communicates", "with", "the", "BS", "to", "prevent", "transmission", "collisions", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "base station"}, {"tokens": ["shows", "a", "schematic", "of", "the", "CNet", "-", "NIC", "system", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "neural image caption"}, {"tokens": ["V.", "Sathya", ",", "M.", "Merhnoush", ",", "M.", "Ghosh", ",", "and", "S.", "Roy", ",", "\"", "Auto", "-", "correlation", "based", "sensing", "of", "multiple", "Wi", "-", "Fi", "BSSs", "for", "LTE", "-", "U", "CSAT", "\"", ",", "in", "IEEE", "VTC", ",", "September", ",", "2019", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "long term evolution"}, {"tokens": ["Section", "details", "the", "preliminary", "different", "attack", "scenarios", "proposed", "in", "AML", "architecture", "and", "the", "related", "components", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "adversarial machine learning"}, {"tokens": ["In", "the", "second", "step", ",", "we", "carry", "out", "fault", "prognosis", "by", "using", "appropriate", "DBN", "models", "to", "learn", "feature", "representations", "automatically", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "addition", ",", "the", "limited", "energy", "of", "wireless", "devices", "is", "a", "key", "challenge", "for", "deploying", "FL", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "federated learning"}, {"tokens": ["This", "correlation", "between", "more", "awareness", "/", "training", "and", "less", "use", "of", "ADAS", "is", "similar", "to", "previous", "work", "which", "found", "the", "more", "learner", "drivers", "felt", "confident", "using", "ADAS", "such", "as", "ACC", ",", "the", "less", "they", "say", "they", "need", "the", "ACC", "system", ",", "and", "the", "more", "they", "argue", "against", "its", "introduction", "into", "drivers", "\u2019", "education", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adaptive cruise control"}, {"tokens": ["Performance", "of", "MobileNetV2", "classifiers", ",", "free", "trained", "and", "Fast", "-", "ARD", ",", "on", "CIFAR-10", ",", "where", "robust", "accuracy", "is", "with", "respect", "to", "a", "-step", "PGD", "attack", "as", "in", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "adversarially robust distillation"}, {"tokens": ["However", ",", "class", "imbalances", "(", "i.e.", ",", "differences", "in", "prior", "class", "probabilities", ")", "can", "cause", "ROC", "curves", "to", "poorly", "represent", "the", "classifier", "performance", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "receiver operating characteristic"}, {"tokens": ["The", "detailed", "discussion", "about", "BQ", "concatenation", "algorithm", "is", "described", "in", "the", "Section", "6.4", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "basic question"}, {"tokens": ["In", "the", "considered", "approach", ",", "the", "AP", "first", "sends", "a", "grant", "packet", "to", "all", "STAs", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "access part"}, {"tokens": ["This", "gave", "a", "distinct", "advantage", "to", "the", "SDD", "for", "the", "early", "targets", ",", "and", "therefore", "considerably", "more", "time", "was", "available", "for", "finding", "smaller", "targets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["SystemTwo", "-", "pass", "IB", "(", "TPIB", ")"], "acronym_pos": [0, 0, 0, 1, 0, 0, 0], "long_form": "information bottleneck"}, {"tokens": ["Five", "important", "areas", "of", "ELD", "problems", "have", "been", "identified", ",", "and", "the", "papers", "published", "in", "the", "general", "area", "of", "ELD", "using", "PSO", "have", "been", "classified", "into", "these", "five", "sections", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["PSC", "Bridges", "is", "a", "1.35"], "acronym_pos": [1, 0, 0, 0, 0], "long_form": "pittsburgh supercomputing center"}, {"tokens": ["Qualitative", "results", "for", "the", "instance", "segmentation", "from", "UAV123", "and", "SDD", "datasets", "are", "shown", "in", "Figure", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "long_form": "stanford drone dataset"}, {"tokens": ["Continual", "GP", "priorInspired", "on", "online", "Bayesian", "inference", "methods", ",", "where", "past", "posterior", "distributions", "are", "usually", "taken", "as", "future", "priors", ",", "our", "main", "goal", "is", "to", "reconstruct", "the", "GP", "prior", "conditioned", "on", "the", "given", "parameters", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "gaussian process"}, {"tokens": ["The", "AR", "for", "small", ",", "medium", "and", "large", "objects", "are", "computed", "for", "100", "proposals", "."], "acronym_pos": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "average recall"}, {"tokens": ["The", "best", "known", "semi", "-", "honest", "OT", "extension", "protocol", "before", "KK13", "is", "IKNP", "protocol", "which", "has", "a", "communication", "complexity", "of", "bits", "for", "producing", "from", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "oblivious transfer"}, {"tokens": ["Zhisheng", ",", "developed", "a", "quantum", "-", "behaved", "PSO", ",", "namely", "QPSO", "algorithm", "for", "solving", "ELD", "problems", "of", "power", "systems", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "power system operations"}, {"tokens": ["MSCPThis", "section", "integrates", "all", "generalisations", "that", "have", "been", "proposed", "in", "previous", "section", "to", "the", "GCP", "in", "order", "to", "properly", "formalise", "the", "Lossy", "Multistream", "Compression", "Problem", "(", "MSCP", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "graph compression problem"}, {"tokens": ["weighted", "images", "were", "acquired", "using", "a", "T", "MR", "imagingunit", "(", "Avanto", ";", "Siemens", ",", "Erlangen", ")", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "magnetic resonance"}, {"tokens": ["Bystanders", "can", "then", "use", "their", "choice", "of", "MR", "display", "technology", "to", "display", "the", "robots", "-", "and", "their", "actions", "-", "in", "a", "way", "that", "is", "easier", "to", "perceive", ",", "thus", "enhancing", "their", "comfort", "in", "the", "vincinity", "of", "robots", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "mixed reality"}, {"tokens": ["We", "believe", "such", "a", "framework", "is", "needed", "to", "have", "fair", "comparisons", ",", "focused", "on", "robotics", "control", ",", "among", "SRL", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "state representation learning"}, {"tokens": ["The", "experiment", "results", "show", "that", "ECS", "-", "DBN", "outperforms", "WELM", "and", "ECO", "-", "ensemble", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], "long_form": "deep belief network"}, {"tokens": ["In", "addition", ",", "we", "carry", "out", "simulations", "to", "show", "the", "results", "from", "MP", "and", "LASSO", "based", "hypothesis", "testing", "methods", "and", "compare", "them", "against", "the", "results", "from", "LT", "methods", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "message passing"}, {"tokens": ["In", "the", "UI", "context", ",", "ML", "is", "classically", "used", "to", "improve", "the", "accuracy", "of", "an", "existing", "interaction", "protocol", ":", "in", ",", "a", "gaussian", "process", "regression", "is", "used", "to", "improve", "touch", "accuracy", "."], "acronym_pos": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "user interface"}, {"tokens": ["A", "small", "network", "is", "appropriate", "to", "train", "with", "limited", "labeled", "SAR", "targets", "but", "when", "transferring", "to", "other", "SAR", "target", "recognition", "tasks", "the", "feature", "generality", "is", "not", "enough", "to", "extract", "a", "good", "representation", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["Figure", "show", "the", "survey", "results", "for", "the", "Ease", "of", "Use", "of", "the", "SDD", "and", "the", "TDW", "respectively", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "standard desktop display"}, {"tokens": ["Age", "differences", "are", "not", "present", "within", "the", "sample", "of", "students", "participating", "in", "the", "CNS", "study", ",", "and", "they", "are", "not", "estimated", "to", "be", "relevant", "with", "respect", "to", "spatial", "behaviour", "in", "the", "MDC", "study", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], "long_form": "mobile data challenge"}, {"tokens": ["Due", "to", "different", "imaging", "mechanisms", ",", "approaches", "for", "the", "interpretation", "of", "optical", "remote", "sensing", "images", "can", "not", "be", "directly", "used", "for", "interpreting", "SAR", "images", "in", "general", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], "long_form": "synthetic aperture radar"}, {"tokens": ["More", "than", "just", "to", "avoid", "revisiting", ",", "the", "BSP", "tree", "archive", "naturally", "offers", "parameter", "-", "less", "adaptive", "mutation", "operations", "for", "local", "search", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "binary space partitioning"}, {"tokens": ["Both", "MSE", "and", "CCC", "are", "calculated", "based", "on", "the", "model", "'s", "response", "and", "the", "gold", "standard", "."], "acronym_pos": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "concordance correlation coefficient"}, {"tokens": ["After", "tags", "projection", ",", "a", "target", "language", "POS", "tagger", "based", "on", "TNT", "approach", "is", "trained", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["The", "vector", "is", "then", "composed", "of", "the", "numbers", "of", "occurrences", "of", "different", "POS", "tags", "in", "the", "tweet", ",", "parsed", "using", "Twitie", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "part of speech"}, {"tokens": ["In", "our", "perspective", ",", "uplink", "MU", "-", "MIMO", "would", "follow", "a", "coordinated", "and", "scheduled", "approach", "controlled", "by", "the", "AP", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], "long_form": "access part"}, {"tokens": ["The", "lengths", "of", "the", "CC", "phase", "are", "derived", "from", "the", "voltage", "curve", "of", "the", "battery", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "charging current"}, {"tokens": ["The", "idea", "of", "the", "MAD", "is", "that", "an", "increase", "or", "decrease", "of", "percentage", "points", "would", "likely", "be", "of", "similar", "interest", "to", "institutions", "with", "different", "PP", "(", ")", "scores", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "median absolute difference"}, {"tokens": ["Finally", ",", "we", "demonstrate", "that", "our", "MDC", "framework", "performs", "better", "than", "several", "state", "-", "of", "-", "the", "-", "art", "MDC", "approaches", "regarding", "image", "coding", "efficiency", "when", "tested", "on", "several", "commonly", "available", "datasets", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "multiple description coding"}, {"tokens": ["As", "identified", "in", "the", "OLS", "regression", "analysis", ",", "the", "number", "of", "likes", "is", "a", "suitable", "predictor", "of", "the", "number", "of", "interactions", "on", "a", "post", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "ordinary least square"}, {"tokens": ["A", "sample", "estimate", "of", "CC", "can", "be", "obtained", "by", ":", "where", "number", "of", "authored", "papers", "published", "in", "a", "discipline", "in", "the", "period", "of", "study", ",", "is", "the", "total", "papers", "published", "in", "that", "time", "period", ",", "and", "represent", "the", "maximum", "no", "of", "authors", "in", "a", "paper", "in", "the", "discipline", "."], "acronym_pos": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "long_form": "collaboration coefficient"}, {"tokens": ["This", "section", "presents", "three", "categories", "of", "FEC", "codes", "as", "shown", "below", "."], "acronym_pos": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], "long_form": "forward error correction"}]